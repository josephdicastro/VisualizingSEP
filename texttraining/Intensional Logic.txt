There is an obvious difference between what a term designates and what
it means. At least it is obvious that there is a difference. In some
way, meaning determines designation, but is not synonymous with it.
After all, “the morning star” and “the evening
star” both designate the planet Venus, but don’t have the same
meaning. Intensional logic attempts to study both designation and
meaning and investigate the relationships between them. 
 
1. What is this about?


If you are not skilled in colloquial astronomy, and I tell you that
the morning star is the evening star, I have given you
information—your knowledge has changed. If I tell you the
morning star is the morning star, you might feel I was wasting your
time. Yet in both cases I have told you the planet Venus was
self-identical. There must be more to it than this. Naively, we might
say the morning star and the evening star are the same in one way, and
not the same in another. The two phrases, “morning star”
and “evening star” may designate the same object, but they
do not have the same meaning. Meanings, in this sense, are often
called intensions, and things designated,
extensions. Contexts in which extension is all that matters
are, naturally, called extensional, while contexts in which
extension is not enough are intensional. Mathematics is
typically extensional throughout—we happily write
“1+4=2+31+4=2+31+4=2+3” even though the two terms involved may
differ in meaning (more about this later). “It is known
that…” is a typical intensional context—“it
is known that 1+4=2+31+4=2+31+4 = 2 + 3” may not be correct when the
knowledge of small children is involved. Thus mathematical pedagogy
differs from mathematics proper. Other examples of intensional
contexts are “it is believed that…”, “it is
necessary that…”, “it is informative
that…”, “it is said that…”, “it
is astonishing that…”, and so on. Typically a context
that is intensional can be recognized by a failure of the
substitutivity of equality when naively applied. Thus, the morning
star equals the evening star; you know the morning star equals the
morning star; then on substituting equals for equals, you know the
morning star equals the evening star. Note that this knowledge arises
from purely logical reasoning, and does not involve any investigation
of the sky, which should arouse some suspicion. Substitution of
co-referring terms in a knowledge context is the problematic
move—such a context is intensional, after all. Admittedly this
is somewhat circular. We should not make use of equality of extensions
in an intensional context, and an intensional context is one in which
such substitutivity does not work.


The examples used above involve complex terms, disguised definite
descriptions. But the same issues come up elsewhere as well, often in
ways that are harder to deal with formally. Proper names constitute
one well-known area of difficulties. The name “Cicero”
and the name “Tully” denote the same person, so
“Cicero is Tully” is true. Proper names are generally
considered to be rigid, once a designation has been specified it does
not change. This, in effect, makes “Cicero is Tully” into
a necessary truth. How, then, could someone not know it?
“Superman is Clark Kent” is even more difficult to deal
with, since there is no actual person the names refer to. Thus while
the sentence is true, not only might one not know it, but one might
perfectly well believe Clark Kent exists, that is “Clark
Kent” designates something, while not believing Superman exists.
Existence issues are intertwined, in complex ways, with intensional
matters. Further, the problems just sketched at the ground level
continue up the type hierarchy. The property of being an equilateral
triangle is coextensive with the property of being an equiangular
triangle, though clearly meanings differ. Then one might say,
“it is trivial that an equilateral triangle is an equilateral
triangle,” yet one might deny that “it is trivial that an
equilateral triangle is an equiangular triangle”.


In classical first-order logic intension plays no role. It is
extensional by design since primarily it evolved to model the
reasoning needed in mathematics. Formalizing aspects of natural
language or everyday reasoning needs something richer. Formal systems
in which intensional features can be represented are generally
referred to as intensional logics. This article discusses
something of the history and evolution of intensional logics. The aim
is to find logics that can formally represent the issues sketched
above. This is not simple and probably no proposed logic has been
entirely successful. A relatively simple intensional logic that can
be used to illustrate several major points will be discussed in some
detail, difficulties will be pointed out, and pointers to other, more
complex, approaches will be given.
2. A Brief History


Recognition that designating terms have a dual nature is far from
recent. The Port-Royal Logic used terminology that translates as
“comprehension” and “denotation” for
this. John Stuart Mill used “connotation” and
“denotation.” Frege famously used “Sinn” and
“Bedeutung,” often left untranslated, but when translated,
these usually become “sense” and “reference.”
Carnap settled on “intension” and “extension.”
However expressed, and with variation from author to author, the
essential dichotomy is that between what a term means, and
what it denotes. “The number of the planets”
denotes the number 9 (ignoring recent disputes about the status of
bodies at the outer edges of the solar system), but it does not have
the number 9 as its meaning, or else in earlier times scientists might
have determined that the number of planets was 9 through a process of
linguistic analysis, and not through astronomical observation. Of the
many people who have contributed to the analysis of intensional
problems several stand out. At the head of the list is Gottlob Frege.
2.1 Frege


The modern understanding of intensional issues and problems begins
with a fundamental paper of Gottlob Frege, (Frege 1892). This paper
opens with a recital of the difficulties posed by the notion of
equality. In his earlier work, Frege notes, he had taken equality to
relate names, or signs, of objects, and not objects themselves. For
otherwise, if aaa and bbb designate the same object,
there would be no cognitive difference between a=aa=aa = a
and a=ba=ba = b, yet the first is analytic while the
second generally is not. Thus, he once supposed, equality relates
signs that designate the same thing. But, he now realizes, this cannot
be quite correct either. The use of signs is entirely arbitrary,
anything can be a sign for anything, so in considering a=ba=ba =
b we would also need to take into account the mode of
presentation of the two signs—what it is that associates
them with the things they designate. Following this line of thought,
equality becomes a relation between signs, relative to their modes of
presentation. Of course the notion of a mode of presentation is
somewhat obscure, and Frege quickly shifts attention elsewhere.


A sign has both a reference, and what Frege calls a sense
—we can think of the sense as being some kind of embodiment of
the mode of presentation. From here on in his paper, sense is under
discussion, and modes of presentation fade into the background. A name
expresses its sense, and designates its
reference. Thus, “morning star” and “evening
star” have the same designation, but express different senses,
representing different modes of presentation—one is a celestial
body last seen in the morning before the sun obscures it, the other is
a celestial body first seen in the evening after the sun no longer
obscures it. Frege goes on to complicate matters by introducing the
idea associated with a sign, which is distinct from its sense
and its reference. But the idea is subjective, varying from person to
person, while both sense and denotation are said by Frege to be not
dependent in this way. Consequently the idea also fades into the
background, while sense and reference remain central.


Generally when a sign appears as part of a declarative sentence, it is
the reference of the sign that is important. Both “Venus”
and “the morning star” designate the same object. The
sentence “The morning star is seen in the sky near
sunrise” is true, and remains true when “the morning
star” is replaced with “Venus”. Substitution of
equi-designating signs preserves truth. But not always; there are
contexts in which this does not happen, indirect reference
contexts. As a typical example, “George knows that the morning
star is seen in the sky near sunrise” may be true while
“George knows that Venus is seen in the sky near sunrise”
may be false. Besides knowledge contexts, indirect reference arises
when a sentence involves “I believe that…”,
“I think that…”, “It seems to me
that…”, “It is surprising that…”,
“It is trivial that…”, and so on. In such contexts,
Frege concludes, not designation but sense is central. Then, since
“George knows that…” is an indirect reference
context, senses are significant. The signs “the morning
star” and “Venus” have different senses, we are not
replacing a sense by a sense equal to it, and so should not expect
truth to be preserved.


Frege notes that an expression might have a sense, but not a
reference. An example he gives is, “the least rapidly convergent
series.” Of course an object might have several signs that
designate it, but with different senses. Frege extends the
sense/reference dichotomy rather far. In particular, declarative
sentences are said to have both a sense and a reference. The sense is
the proposition it expresses, while the reference is its truth value.
Then logically equivalent sentences have the same designation, but may
have different senses. In indirect contexts sense, and not
designation, matters and so we may know the well-ordering principle
for natural numbers, but not know the principle of mathematical
induction because, while they are equivalent in truth value, they have
different senses.


No formal machinery for dealing with sense, as opposed to reference,
is proposed in Frege 1892. But Frege defined the terms under which
further discussion took place. There are two distinct but related
notions, sense and reference. Equality plays a fundamental role, and a
central issue is the substitutivity of equals for equals. Names,
signs, expressions, can be equal in designation, but not equal in
sense. There are both direct or extensional, and indirect or
intensional contexts, and reference matters for the first while sense
is fundamental for the second.
2.2 Church


Frege gave the outline of a theory of intensionality, but no
intensional logic in any formal sense. There have been attempts to
fill in his outline. Alonzo Church (1951) went at it quite directly.
In this paper there is a formal logic in which terms have both senses
and denotations. These are simply taken to be different sorts, and
minimal requirements are placed on them. Nonetheless the logic is
quite complex. The formal logic that Frege had created for his work on
the foundations of mathematics was type free. Russell showed his
famous paradox applied to Frege’s system, so it was inconsistent. As a
way out of this problem, Russell developed the type theory that was
embodied in Principia Mathematica. Church had given an
elegant and precise formulation of the simple theory of types (Church
1940), and that was incorporated into his work on intensionality,
which is one of the reasons for its formal complexity.


Church uses a notion he calls a concept, where anything that
is the sense of a name for something can serve as a concept of that
something. There is no attempt to make this more precise—indeed
it is not really clear how that might be done. It is explicit that concepts
are language independent, and might even be uncountable. There is a
type ο0ο0\omicron_{0} of the two truth values. Then, there is a
type ο1ο1\omicron_{1} of concepts of members of
ο0ο0\omicron_{0}, which are called propositional
concepts. There is a type ο2ο2\omicron_{2} of concepts of
members of ο1ο1\omicron_{1}, and so on. There a type
ι0ι0\iota_{0} of individuals, a type ι1ι1\iota_{1} of
concepts of members of ι0ι0\iota_{0}, a type ι2ι2\iota_{2}
of concepts of members of ι1ι1\iota_{1}, and so on. And finally,
for any two types αα\alpha and ββ\beta there is a type
(αβ)(αβ)(\alpha\,\beta ) of functions from items of type ββ\beta to
items of type αα\alpha. Church makes a simplifying assumption
concerning functional types. In order to state it easily he introduces
some special notation: if αα\alpha is a type symbol, for example
((ι3ο2)(ο5ι4))((ι3ο2)(ο5ι4))((\iota_{3}\,\omicron_{2})(\omicron_{5}\,\iota_{4})),
then α1α1\alpha_{1} is the result of increasing each subscript by
1, in our example we get
((ι4ο3)(ο6ι5))((ι4ο3)(ο6ι5))((\iota_{4}\,\omicron_{3})(\omicron_{6}\,\iota_{5})). (There
is a similar definition for αnαn\alpha_{n} for each
positive integer nnn, but we will not need it here.) Church’s
assumption is that the concepts of members of the functional type
(αβ)(αβ)(\alpha\,\beta ) are the members of the type
(α1β1)(α1β1)(\alpha_{1}\,\beta_{1}). With this assumption,
uniformly the concepts of members of any type αα\alpha are the members
of type α1α1\alpha_{1}.


Quantification and implication are introduced, or rather versions
appropriate for the various types are introduced.
λλ\lambda abstraction notation is present. And finally, for each
type αα\alpha it is assumed there is a relation that holds
between a concept of something of type αα\alpha and the thing
itself; this is a relation between members of type
α1α1\alpha_{1} and members of type αα\alpha. This
is denoted ΔΔ\Delta, with appropriate type-identifying subscripts.


A fundamental issue for Church is when two names, lambda terms, have
the same sense. Three alternatives are considered. Common to all three
alternatives are the assumptions that sense is unchanged under the
renaming of bound variables (with the usual conditions of freeness),
and under ββ\beta reduction. Beyond these, Alternative 0 is
somewhat technical and is only briefly mentioned, Alternative 1 is fine
grained, making senses distinct as far as possible, while Alternative 2
makes two terms have the same sense whenever equality between them is a
logical validity. The proper definition of the alternatives is
axiomatic, and altogether various combinations of some 53 axiom schemes
are introduced, with none examined in detail. Clearly Church was
proposing an investigation, rather than presenting full results.


As noted, the primary reference for this work is Church 1951, but
there are several other significant papers including Church 1973,
Church 1974, and the Introduction to Church 1944, which contains an
informal discussion of some of the ideas. In addition, the expository
papers of Anderson are enlightening (Anderson 1984, 1998). It should
be noted that there are relationships between Church’s work and that
of Carnap, discussed below. Church’s ideas first appeared in an
abstract (Church 1946), then Carnap’s book appeared (Carnap 1947). A
few years later Church’s paper expanded his abstract in Church 1951.
The second edition of Carnap’s book appeared in 1956. Each man had an
influence on the other, and the references between the two authors are
thoroughly intertwined.
2.3 Carnap


Church simply(!) formalized something of how intensions behaved,
without saying what they were. Rudolf Carnap took things further with
his method of intension and extension, and provided a semantics in
which quite specific model-theoretic entities are identified with
intensions (Carnap 1947). Indeed, the goal was to supply intensions
and extensions for every meaningful expression, and this was done in a
way that has heavily influenced much subsequent work.


Although Carnap attended courses of Frege, his main ideas are based on
Wittgenstein 1921. In the Tractatus, Wittgenstein
introduced a precursor of possible world semantics. There are
states of affairs, which can be identified with the set of
all their truths, “(1.13) The facts in logical space are the
world.” Presumably these facts are atomic, and can be varied
independently, “(1.21) Each item can be the case or not the case
while everything else remains the same.” Thus there are many
possible states of affairs, among them the actual one, the real
world. Objects, in some way, involve not only the actual state of
affairs, but all possible ones, “(2.0123) If I know an object I
also know all its possible occurrences in states of affairs. (Every
one of these possibilities must be part of the nature of the object.)
A new possibility cannot be discovered later.” It is from these
ideas that Carnap developed his treatment.


Carnap begins with a fixed formal language whose details need not
concern us now. A class of atomic sentences in this language,
containing exactly one of AAA or ¬A¬A\neg A for each
atomic sentence, is a state-description. In each
state-description the truth or falsity of every sentence of the
language is determined following the usual truth-functional
rules—quantifiers are treated substitutionally, and the language
is assumed to have ‘enough’ constants. Thus truth is
relative to a state-description. Now Carnap introduces a stronger
notion than truth, L-truth, intended to be “an
explicatum for what philosophers call logical or necessary or analytic
truth.” Initially he presents this somewhat informally, “a
sentence is LLL-true in a state description SSS if it is
true in SSS in such a way that its truth can be established on
the basis of the semantical rules of the system SSS alone,
without any reference to (extra-linguistic) facts.” But this is
quickly replaced by a more precise semantic version, “A sentence is
LLL-true if it holds in every state-description.”


One can recognize in LLL-truth a version of necessary truth
using possible world semantics. There is no accessibility relation, so
what is being captured is more like S5 than like other modal
logics. But it is not S5 semantics either, since there is a fixed set
of state-descriptions determined by the language itself. (If
PPP is any propositional atom, some state-description
will contain PPP, and so ◊P◊P\Diamond P will
be validated.) Nonetheless, it is a clear anticipation of possible
world semantics. But what concerns us here is how Carnap treats
designating terms in such a setting. Consider predicates
PP and QQ. For Carnap these are intensionally
equivalent if ∀x(Px≡Qx)\forall x(Px \equiv Qx) is an LL-truth, that is, in each
state-description PP and QQ have the same
extension. Without being quite explicit about it, Carnap is proposing
that the intension of a predicate is an assignment of an extension for
it to each state-description—intensional identity means identity
of extension across all state-descriptions and not just at the actual
one. Thus the predicate ‘HH’, human, and the
predicate ‘FBFB’, featherless biped, have the same
extension—in the actual state-description they apply to the same
beings—but they do not have the same intension since there are
other state-descriptions in which their extensions can differ. In a
similar way one can model individual expressions, “The extension
of an individual expression is the individual to which it
refers.” Thus, ‘Scott’ and ‘the author of
Waverly’ have the same extension (in the actual
state-description). Carnap proposes calling the intension of an
individual expression an individual concept, and
such a thing picks out, in each state-description, the individual to
which it refers in that state description. Then ‘Scott’
and ‘the author of Waverly’ have different intensions
because, as most of us would happily say, they could have been
different, that is, there are state-descriptions in which they are
different. (I am ignoring the problems of non-designation in this
example.)


Carnap’s fundamental idea is that intensions, for whatever entities
are being considered, can be given a precise mathematical embodiment
as functions on states, while extensions are relative to a single
state. This has been further developed by subsequent researchers, of
course with modern possible world semantics added to the mix. The
Carnap approach is not the only one around, but it does take us quite
a bit of the way into the intensional thicket. Even though it does
not get us all the way through, it will be the primary version
considered here, since it is concrete, intuitive, and natural when it
works.
2.4 Marcus

 Carnap’s work was primarily semantic, and resulted in a logic that did not
correspond to any of the formal systems that had been studied up to
this point. Axiomatically presented propositional modal logics were
well-established, so it was important to see how (or if) they could be
extended to include quantifiers and equality. At issue were decisions
about what sorts of things quantifiers range over, and substitutivity
of equals for equals. Quine’s modal objections needed to be
addressed. Ruth Barcan Marcus began a line of development in (Marcus
1946) by formally extending the propositional system S2 of C. I. Lewis
to include quantification, and developing it axiomatically in the
style of Principia Mathematica. It was clear that other
standard modal logics besides S2 could have been used, and S4 was
explicitly discussed. The Barcan formula, in the form
 ◊(∃α)\Diamond (\exists \alpha )A ⊃(∃α)◊\supset (\exists \alpha )\DiamondA, made its first
appearance in (Marcus
 1946),[1]
 though a full understanding of its significance would have to wait
for the development of a possible-world semantics. Especially
significant for the present article, her system was further extended
in (Marcus 1947) to allow for abstraction and identity. Two versions
of identity were considered, depending on whether things had the same
properties (abstracts) or necessarily had them. In the S2 system the
two versions were shown to be equivalent, and in the S4 system,
necessarily equivalent. In a later paper (Marcus 1953) the
fundamental role of the deduction theorem was fully explored as
well. 

 Marcus proved that in her system identity was necessary if true, and
the same for distinctness. She argued forcefully in subsequent works,
primarily (Marcus 1961), that morning star/evening star problems were
nonetheless avoided. Names were understood as tags. They
might have their designation specified through an initial use of a
definite description, or by some other means, but otherwise names had
no meaning, only a designation. Thus they did not behave like
definite descriptions, which were more than mere tags. Well, the
object tagged by “morning star ” and that tagged by
“evening star ” are the same, and identity between objects
is never contingent.

 The essential point had been made. One could develop formal modal
systems with quantifiers and equality. The ideas had coherence.
Still missing was a semantics which would help with the understanding
of the formalism, but this was around the corner.
2.5 Montague, Tichý, Bressan, and Gallin


Carnap’s ideas were extended and formalized by Richard Montague, Pavel
Tichý, and Aldo Bressan, independently. All made use of some version
of Kripke/Hintikka possible world semantics, instead of the more specialized
structure of Carnap. All treated intensions functionally.


In part, Bressan wanted to provide a logical foundation for physics. The connection
with physics is this. When we say something has such-and-such a mass,
for instance, we mean that if we had conducted certain experiments, we
would have gotten certain results. This does not assume we did conduct
those experiments, and thus alternate states (or cases, as Bressan
calls them) arise. Hence there is a need for a rich modal language,
with an ontology that includes numbers as well as physical objects. In
Bressan 1972, an elaborate modal system was developed, with a full
type hierarchy including numbers as in Principia Mathematica.


Montague’s work is primarily in Montague 1960 and 1970, and has natural
language as its primary motivation. The treatment is
semantic, but in Gallin 1975 an axiom system is presented. The
logic Gallin axiomatized is a full type-theoretic system,
with intensional objects of each type. Completeness is proved relative
to an analog of Henkin models, familiar for higher type classical
logics.


Tichý created a system of intensional logic very similar to
that of Montague, beginning, in English, in Tichý 1971, with a
detailed presentation in Tichý 1988. Unfortunately his work did
not become widely known. Like Montague’s semantics,
Tichý’s formal work is based on a type hierarchy with
intensions mapping worlds to extensions at each type level, but it
goes beyond Montague in certain respects. For one thing, intensions
depend not only on worlds, but also on times. For another, in addition
to intensions and extensions Tichý also
considers constructions. The idea is that expressions
determine intensions and extensions, and this itself is a formal
process in which compound expressions act using the simpler
expressions that go into their making; compositionality at the level
of constructions, in other words. Using this formal machinery,
“1+41+4” and “2+32+3” prescribe different
constructions; their meaning is not simply captured by their
intensional representation as discussed here.
3. A Particular Intensional Logic


As has been noted several times earlier, formal intensional logics
have been developed with a full hierarchy of higher types, Church, 
Montague, Bressan, Tichý for instance. Such logics can be rather
formidable, but Carnap’s ideas are often (certainly not always) at the
heart of such logics, these ideas are simple, and are sufficient to
allow discussion of several common intensional problems. Somehow,
based on its sense (intension, meaning) a designating phrase may
designate different things under different conditions—in
different states. For instance, “the number of the
planets” was believed to designate 6 in ancient times (counting
Earth). Immediately after the discovery of Uranus in 1781 “the
number of the planets” was believed to designate 7. If we take
as epistemic states of affairs the universe as conceived by the
ancients, and the universe as conceived just after 1781, in one state
“the number of the planets” designates 6 and in the other
it designates 7. In neither state were people wrong about the concept
of planet, but about the state of affairs constituting the
universe. If we suppress all issues of how meanings are determined,
how meanings in turn pick out references, and all issues of what
counts as a possible state of affairs, that is, if we abstract all
this away, the common feature of every designating term is that
designation may change from state to state—thus it can be
formalized by a function from states to objects. This bare-bones
approach is quite enough to deal with many otherwise intractable
problems.


In order to keep things simple, we do not consider a full type
hierarchy—first-order is enough to get the basics across. The
first-order fragment of the logic of Gallin 1975 would be sufficient,
for instance. The particular formulation presented here comes from
Fitting 2004, extending Fitting and Mendelsohn 1998. Predicate
letters are intensional, as they are in every version of Kripke-style
semantics, with interpretations that depend on possible worlds. The
only other intensional item considered here is that of individual
concept—formally represented by constants and variables that can
designate different objects in different possible worlds. The same
ideas can be extended to higher types, but what the ideas contribute
can already be seen at this relatively simple level. Intensional
logics often have nothing but intensions—extensions are inferred
but are not explicit. However, an approach that is too minimal can
make life hard, so consequently here we explicitly allow both objects
and individual concepts which range over objects. There are two kinds
of quantification, over each of these sorts. Both extensional and
intensional objects are first-class citizens.


Basic ideas are presented semantically rather than
proof-theoretically, though both axiom systems
and tableau systems exist. Even so, technical details can become baroque,
so as far as possible, we will separate informal presentation, which
is enough to get the general idea, from its formal counterpart, which
is of more specialized interest. A general acquaintance with modal
logic is assumed (though there is a very brief discussion to establish
notation, which varies some from author to author). It should be noted
that modal semantics is used here, and generally, in two different
ways. Often one has a particular Kripke model in mind, though it may
be specified informally. For instance, we might consider a Kripke
model in which the states are the present instant and all past ones,
with later states accessible from earlier ones. Such a model is
enlightening when discussing “the King of France” for
instance, even though the notion of instant is somewhat vaguely
determined. But besides this use of informally specified concrete
models, there is formal Kripke semantics which is a mathematically
precise thing. If it is established that something, say
◻(X⊃Y)⊃(◻X⊃◻Y)\Box (X \supset Y) \supset (\Box X \supset \Box Y), is valid in all formal Kripke models, we can
assume it will be so in our vaguely specified, intuitive models, no
matter how we attempt to make them more precise. Informal models
pervade our discussions—their fundamental properties come from
the formal semantics.
3.1 Propositional Modal Logic


A propositional language is built up from
propositional letters, P,Q,…P, Q,\ldots, using
 ∧,∨,⊃,¬\wedge , 
 \vee , \supset , \neg and other
propositional connectives, and ◻\Box (necessary) and ◊\Diamond
(possible) as modal operators. These operators can be thought of as
alethic, deontic, temporal, epistemic—it will matter which
eventually, but it does not at the moment. Likewise there could be
more than one version of ◻\Box, as in a logic of knowledge with
multiple knowers—this too doesn’t make for any essential
differences.


Kripke semantics for propositional modal logic is, by now, a very
familiar thing. Here is a quick presentation to establish notation,
and to point out how one of Frege’s proposals fits in. A more
detailed presentation can be found in the article on modal logic in
this encyclopedia.
3.1.1 The Informal Version


A model consists of a collection of states, some determination of
which states are relevant to which, and also some specification of
which propositional letters hold at which of these states. States could
be states of the real world at different times, or states of knowledge,
or of belief, or of the real world as it might have been had
circumstances been different. We have a mathematical abstraction here.
We are not trying to define what all these states might
‘mean,’ we simply assume we have them. Then more complex
formulas are evaluated as true or false, relative to a state. At each
state the propositional connectives have their customary classical
behavior. For the modal operators. ◻X\Box X, that is,
necessarily XX, is true at a state if XX itself
is true at every state that is relevant to that state (at all
accessible states). Likewise ◊X\Diamond X,
possibly XX, is true at a state if XX is true at
some accessible state. If we think of things epistemically,
accessibility represents compatibility, and so XX is known in a
state if XX is the case in all states that are compatible with
that state. If we think of things alethically, an accessible state can
be considered an alternate reality, and so XX is necessary in a
state if XX is the case in all possible alternative states.
These are, by now, very familiar ideas.
3.1.2 The Formal Version


A frame is a structure ⟨G,R⟩\langle \bG,
\bR\rangle, where G\bG is a non-empty set
and R\bR is a binary relation on
G\bG. Members of G\bG are states
(or possible worlds). R\bR is an
accessibility relation. For Γ,Δ∈G,ΓRΔ\Gamma , \Delta \in \bG, \Gamma \bR \Delta is read
“Δ\Delta is accessible from Γ\Gamma.” A (propositional)
valuation on a frame is a mapping, V\bV, that
assigns to each propositional letter a mapping from states of the
frame to truth values, true or false. For
simplicity, we will abbreviate V(P)(Γ)\bV(P)(\Gamma )
by V(P,Γ)\bV(P, \Gamma ). A propositional
model is a structure
 M=⟨G,R,V⟩\cM = \langle \bG,
\bR, \bV\rangle, where
⟨G,R⟩\langle \bG, \bR\rangle is a frame and
V\bV is a propositional valuation on that frame.


Given a propositional model 
 M=⟨G,R,V⟩\cM = \langle \bG,
\bR, \bV\rangle, the notion of
formula XX being true at state Γ\Gamma will be denoted
 M,Γ⊨X\cM, 
 \Gamma \vDash X, and is characterized by the following standard rules,
where PP is atomic.
M,Γ⊨P⇔V(P,Γ)=trueM,Γ⊨X∧Y⇔M,Γ⊨X and M,Γ⊨Y…⇔…M,Γ⊨◻X⇔M,Δ⊨X for every Δ∈G with ΓRΔM,Γ⊨◊X⇔M,Δ⊨X for some Δ∈G with ΓRΔ\begin{align}
\cM, \Gamma \vDash P &amp;\Leftrightarrow \bV(P, \Gamma ) = \textit{true} \\

\cM, \Gamma \vDash X \wedge Y &amp;\Leftrightarrow \cM, \Gamma \vDash X
  \text{ and } \cM, \Gamma \vDash Y \\

\ldots &amp;\Leftrightarrow \ldots \\

\cM, \Gamma \vDash \Box X &amp;\Leftrightarrow \cM, \Delta \vDash X
 \text{ for every }\Delta \in \bG \text{ with } \Gamma \bR \Delta \\

\cM, \Gamma \vDash \Diamond X &amp;\Leftrightarrow \cM, \Delta \vDash X
 \text{ for some } \Delta \in \bG \text{ with } \Gamma \bR \Delta
\end{align}


Suppose we think about formulas using an intensional/extensional
distinction. Given a model M\cM, to each
formula XX we can associate a function, call it
fXf_{X}, mapping states to truth values, where
we set fX(Γ)f_{X}(\Gamma ) = true just
in case
M,Γ⊨X\cM, \Gamma \vDash X.



Think of the function fXf_{X} as the intensional meaning of
the formula XX—indeed, think of it as the
proposition expressed by the formula (relative to a
particular model, of course). At a state Γ\Gamma, 
fX(Γ)f_{X}(\Gamma ) is a truth value—think
of this as the extensional meaning of XX at that
state. This is a way of thinking that goes back to Frege, who
concluded that the denotation of a sentence should be a truth value,
but the sense should be a proposition. He was a little vague about
what constituted a proposition—the formalization just presented
provides a natural mathematical entity to serve the purpose, and was
explicitly proposed for this purpose by Carnap. It should be clear
that the mathematical structure does, in a general way, capture some
part of Frege’s idea. Incidentally we could, with no loss,
replace the function fXf_{X} on states with
the set {Γ∈G∣fX(Γ)=true}\{ \Gamma \in \bG \mid f_{X}(\Gamma) = \textit{true}\}.
The function fXf_{X} is simply the
characteristic function of this set. Sets like these are commonly
referred to as propositions in the modal logic community. In a
technical sense, then, Frege’s ideas on this particular topic
have become common currency.
3.2 The Move To First Order


First we discuss some background intuitions, then introduce a
formal semantics. Intensions will be introduced formally in Section
3.3. The material discussed here can be found more fully developed in
(Fitting and Mendelsohn 1998, Hughes and Cresswell 1996), among other
places.
3.2.1 Actualist and Possibilist


If we are to think of an intension as designating different things
under different circumstances, we need things. At the propositional
level truth values play the role of things, but at the first order
level something more is needed. In classical logic each model has a
domain, the things of that model, and quantifiers are understood as
ranging over the members of that domain. It is, of course, left open
what constitutes a thing—any collection of any sort can serve as
a domain. That way, if someone has special restrictions in mind because
of philosophical or mathematical considerations, they can be
accommodated. It follows that the validities of classical logic are, by
design, as general as possible—they are true no matter what we
might choose as our domain, no matter what our things are.


A similar approach was introduced for modal logics in Kripke 1963.
Domains are present, but it is left open what they might consist
of. But there is a complication that has no classical counterpart: in
a Kripke model there are multiple states. Should there be a single
domain for the entire model, or separate domains for each state? Both
have natural intuitions.


Consider a version of Kripke models in which a separate domain is
associated with each state of the model. At each state, quantifiers are
thought of as ranging over the domain associated with that state. This
has come to be known as an actualist semantics. Think of the
domain associated with a state as the things that actually exist at
that state. Thus, for example, in the so-called real world the Great
Pyramid of Khufu is in the domain, but the Lighthouse of Alexandria is
not. If we were considering the world of, say, 1300, both would be in
the domain. In an actualist approach, we need to come to some decision
on what to do with formulas containing references to things that exist
in other states but not in the state we are considering. Several
approaches are plausible; we could take such formulas to be false, or
we could take them to be meaningless, for instance, but this seems to
be unnecessarily restrictive. After all, we do say things like
“the Lighthouse of Alexandria no longer exists,” and we
think of it as true. So, the formal version that seems most useful
takes quantifiers as ranging over domains state by state, but otherwise
allows terms to reference members of any domain. The resulting
semantics is often called varying domain as well as
actualist.


Suppose we use the actualist semantics, so each state has an
associated domain of actually existing things, but suppose we allow
quantifiers to range over the members of any domain, without
distinction, which means quantifiers are ranging over the same set, at
every state. What are the members of that set? They are the things
that exist at some state, and so at every state they are the possible
existents—things that might exist. Lumping these separate
domains into a single domain of quantification, in effect, means we
are quantifying over possibilia. Thus, a semantics in which there is a
single domain over which quantifiers range, the same for every state,
is often called possibilist semantics or, of course,
constant domain semantics.


Possibilist semantics is simpler to deal with than the actualist
version—we have one domain instead of many for quantifiers to
range over. And it turns out that if we adopt a possibilist approach,
the actualist semantics can be simulated. Suppose we have a single
domain of quantification, possibilia, and a special predicate,
EE, which we think of as true, at each state, of the things
that actually exist at that state. If ∀\forall is a quantifier
over the domain of possibilia, we can think of the relativized
quantifier, ∀\forallx(E(x)⊃…)(E(x)
\supset \ldots ) as corresponding to actualist
quantification. (We need to assume that, at each state, EE is
true of something—this corresponds to assuming domains are
non-empty.) This gives an embedding of the actualist semantics into the
possibilist one, a result that can be formally stated and proved.
Here possibilist semantics will be used, and we assume we have an
existence predicate EE available.
3.2.2 Possibilist Semantics, Formally


The language to be used is a straightforward first order extension of
the propositional modal language. There is an infinite list of
object variables, x,y,x1,x2,…x, y,
x_{1}, x_{2},\ldots, and a list
of relation symbols, R,P,P1,P2,…R, P,
P_{1}, P_{2},\ldots, of all
arities. Among these is the one-place symbol EE and the
two-place symbol =. Constant and function symbols could be added, but
let’s keep things relatively simple, along with simply relative. If
x1,…,xnx_{1}, \ldots ,x_{n} are
object variables and PP is an nn-place relation
symbol, P(x1,…,xn)P(x_{1}, \ldots ,x_{n}) is an atomic formula. We’ll write
x=yx = y in place of = (x,y). More complex
formulas are built up using propositional connectives, modal
operators, and quantifiers, ∀\forall and ∃\exists, in the usual
way. Free and bound occurrences of variables have the standard
characterization.


A first order model is a structure ⟨G,R,DO,I⟩\langle \bG, \bR,
\bD_{O}, \bI\rangle where ⟨G,R⟩\langle \bG, \bR\rangle is a frame, as
in Section 3.1, DO\bD_{O} is a non-empty object domain, and
I\bI is an interpretation that assigns to each nn-place
relation symbol PP a mapping, I(P)\bI(P) from G\bG to subsets of
DnO\bD_{O}^{n}. We’ll write I(P,Γ)\bI(P, \Gamma ) as an
easier-to-read version of I(P)(Γ)\bI(P)(\Gamma ). It is required that
I(=,Γ)\bI(=, \Gamma ) is the equality relation on DO\bD_{O}, for every
state Γ\Gamma, and I(E,Γ)\bI(E, \Gamma ) is non-empty, for every
Γ\Gamma. A first-order valuation in a model is a mapping
vv that assigns a member of DO\bD_{O} to each variable. Note that
first order valuations are not state-dependent in the way that
interpretations are. A first order valuation ww is an
xx-variant of valuation vv if vv and ww agree on
all variables except possibly for xx. Truth, at a state Γ\Gamma
of a model M=⟨G,R,DO,I⟩\cM = \langle \bG, \bR, \bD_{O}, \bI\rangle, with
respect to a first order valuation vv, is characterized as follows,
where P(x1,…,xn)P(x_{1}, \ldots ,x_{n}) is an atomic formula:
M,Γ⊨vP(x1,…,xn)⇔⟨v(x1),…,v(xn)⟩∈I(P,Γ)M,Γ⊨vX∧Y⇔M,Γ⊨vX and M,Γ⊨vY…⇔…M,Γ⊨v◻X⇔M,Δ⊨vX for every Δ∈G with ΓRΔM,Γ⊨v◊X⇔M,Δ⊨vX for some Δ∈G with ΓRΔM,Γ⊨v∀xX⇔M,Γ⊨wX for every x-variant w of vM,Γ⊨v∃xX⇔M,Γ⊨wX for some x-variant w of v\begin{align}
\cM, \Gamma \vDash_{v} P(x_{1}, \ldots ,x_{n})
  &amp;\Leftrightarrow \langle v(x_{1}), \ldots ,v(x_{n})\rangle \in \bI(P, \Gamma ) \\

\cM, \Gamma \vDash_{v} X \wedge Y
  &amp;\Leftrightarrow \cM, \Gamma \vDash_{v} X \text{ and } \cM, \Gamma \vDash_{v} Y \\

\ldots &amp;\Leftrightarrow \ldots \\

\cM, \Gamma \vDash_{v} \Box X
  &amp;\Leftrightarrow \cM, \Delta \vDash_{v} X
  \text{ for every } \Delta \in \bG \text{ with } \Gamma \bR \Delta \\

\cM, \Gamma \vDash_{v} \Diamond X
  &amp;\Leftrightarrow \cM, \Delta \vDash_{v} X 
  \text{ for some } \Delta \in \bG \text{ with } \Gamma \bR \Delta \\

\cM, \Gamma \vDash_{v} \forall xX
  &amp;\Leftrightarrow \cM, \Gamma \vDash_{w} X 
  \text{ for every } x\text{-variant } w \text{ of } v \\

\cM, \Gamma \vDash_{v} \exists xX
  &amp;\Leftrightarrow \cM, \Gamma \vDash_{w} X
  \text{ for some } x\text{-variant } w \text{ of } v
\end{align}


Call a formula valid if it is true at every state of every
first order model with respect to every first-order valuation, as
defined above. Among the validities are the usual modal candidates,
such as ◻(X⊃Y)⊃(◻X⊃◻Y)\Box (X \supset Y) \supset (\Box X \supset \Box Y), and the usual quantificational candidates,
such as ∀xX⊃∃xX\forall xX \supset \exists xX. We also have mixed cases such as the
Barcan and converse Barcan formulas:
∀x◻X≡◻∀xX\forall x\Box X \equiv \Box \forall xX, which are characteristic of
constant domain models, as was shown in Kripke 1963. Because of the
way equality is treated, we have the validity of both
∀x∀y(x=y⊃◻x=y)\forall x\forall y(x = y \supset \Box x = y) and
∀x∀y(x≠y⊃◻x≠y)\forall x\forall y(x \ne y \supset \Box x \ne y). Much has been made about the
identity of the number of the planets and 9 (Quine 1963), or the
identity of the morning star and the evening star (Frege 1892), and
how these identities might behave in modal contexts. But that is not
really a relevant issue here. Phrases like “the morning
star” have an intensional aspect, and the semantics outlined so
far does not take intensional issues into account. As a matter of
fact, the morning star and the evening star are the same object and,
as Gertrude Stein might have said, “an object is an object is an
object.” The necessary identity of a thing and itself should not
come as a surprise. Intensional issues will be dealt with shortly.


Quantification is possibilist—domains are constant. But, as was
discussed in Section 3.2.1, varying domains can be brought in
indirectly by using the existence predicate, EE, and this
allows us to introduce actualist quantification definitionally. Let
∀ExX\forall^{E}xX abbreviate
∀x(E(x)⊃X)\forall x(E(x) \supset X), and let
∃ExX\exists^{E}xX abbreviate
∃x(E(x)∧X)\exists x(E(x)
 \wedge X). Then, while
 ∀xϕ(x)⊃ϕ(y)\forall x\phi (x) \supset \phi (y) is valid, assuming yy is free for
xx in ϕ(x)\phi (x), we do not have the validity
of ∀Exϕ(x)⊃ϕ(y)\forall^{E}x\phi (x)
\supset \phi (y). What we have instead is the validity
of
[∀Exϕ(x)∧E(y)]⊃ϕ(y)[\forall^{E}x\phi (x)
 \wedge E(y)] \supset \phi (y).


As another example of possibilist/actualist difference, consider
∃x◻P(x)⊃◻∃xP(x)\exists x\Box P(x) \supset \Box \exists xP(x). With possibilist
quantifiers, this is valid and reasonable. It asserts that if some
possibilia has the PP property in all alternative states, then
in every alternative state some possibilia has the PP
property. But when possibilist quantification is replaced with
actualist,
∃Ex◻P(x)⊃◻∃ExP(x)\exists^{E}x\Box P(x)
\supset \Box \exists^{E}xP(x),
the result is no longer valid. As a blatant (but somewhat informal)
example, say the actual state is Γ\Gamma and PP is the
property of existing in state Γ\Gamma. Then, at Γ,∃Ex◻P(x)\Gamma ,
\exists^{E}x\Box P(x)
says something that actually exists has, in all alternative states,
the property of existing in the state Γ\Gamma. This is true; in fact
it is true of everything that exists in the state
Γ\Gamma. But
◻∃ExP(x)\Box \exists^{E}xP(x)
says that in every alternative state there will be an actually
existent object that also exists in the state Γ\Gamma, which need not
be the case.
3.3 Adding Intensions


In Section 3.2 a first order modal logic was sketched, in which
quantification was over objects. Now a second kind of quantification
is added, over intensions. As has been noted several times, an
intensional object, or individual concept, will be modeled by a
function from states to objects, but now we get into the question of
what functions should be allowed. Intensions are supposed to be
related to meanings. If we consider meaning to be a human construct,
what constitutes an intension should probably be restricted. There
should not, for instance, be more intensional objects than there are
sentences that can specify meanings, and this limits intensions to a
countable set. Or we might consider intensions as ‘being
there,’ and we pick out the ones that we want to think about, in
which case cardinality considerations don’t apply. This is an issue
that probably cannot be settled once and for all. Instead, the
semantics about to be presented allows for different choices in
different models—it is not required that all functions from
states to objects be present. It should be noted that, while this
semantical gambit does have philosophical justification, it also makes
an axiomatization possible. The fundamental point is the same as in
the move from first to second order logic. If we insist that second
order quantifiers range over all sets and relations, an axiomatization
is not possible. If we use Henkin models, in which the range of second
order quantifiers has more freedom, an axiomatization becomes
available.


Formulas are constructed more-or-less in the obvious way, with two
kinds of quantified variables instead of one: extensional and
intensional. But there is one really important addition to the
syntactic machinery, and it requires some discussion. Suppose we have
an intension, ff, that picks out an object in each state. For
example, the states might be various ways the universe could have been
constituted, and at each state ff picks out the number of the
planets which could, of course, be 0. Suppose PP is a one-place
relation symbol—what should be meant by P(f)P(f)?
On the one hand, it could mean that the intension ff has the
property PP, on the other hand it could mean that the object
designated by ff has the property PP. Both versions are
useful and correspond to things we say every day. We will allow for
both, but the second version requires some cleaning up. Suppose
P(f)P(f) is intended to mean that the object designated
by ff (at a state) has property PP. Then how do we read
◊P(f)\Diamond P(f)? Under what circumstances should
we take it to be true at state Γ\Gamma? It could be understood as
asserting the thing designated by ff at Γ\Gamma (call it
fΓ)f_{\Gamma }) has the ‘possible-PP’
property, and so at some alternative state Δ\Delta we have that
fΓf_{\Gamma } has property PP. This is the
de re reading, in which a possible property is ascribed to a
thing. Another way of understanding
◊P(f)\Diamond P(f) takes the possibility operator
as primary: to say the formula is true at Γ\Gamma means that at some
alternative state, Δ\Delta, we have P(f)P(f), and so at
Δ\Delta the object designated by ff (call it
fΔ)f_{\Delta }) has property PP. This is the
de dicto reading, possibility applies to a sentence. Of course
there is no particular reason why fΓf_{\Gamma } and
fΔf_{\Delta } should be identical. The de re and
de dicto readings are different, both need representation, and
we cannot manage this with the customary syntax.


An abstraction mechanism will be used to disambiguate our syntax. The
de re reading will be symbolized
[λx◊P(x)](f)[\lambda x\,\Diamond P(x)](f)
and the de dicto will be symbolized
◊[λxP(x)](f)\Diamond [\lambda x\,P(x)](f). The
(incomplete) expression [λxX][\lambda x\,X] is
often called a predicate abstraction; one can think of it as
the predicate abstracted from the formula XX. In
[λx◊P(x)](f)[\lambda x\,\Diamond P(x)](f) we
are asserting that ff has the possible-PP property,
while in
◊[λxP(x)](f)\Diamond [\lambda x\,P(x)](f) we
are asserting the possibility that ff has the PP
property. Abstraction disambiguates. What we have said about ◊\Diamond
applies equally well to ◻\Box of course. It should be noted that one
could simply think of abstraction as a scope-specifying device, in a
tradition that goes back to Russell, who made use of such a mechanism
in his treatment of definite descriptions. Abstraction in modal logic
goes back to Carnap 1947, but in a way that ignores the issues
discussed above. The present usage comes from Stalnaker & Thomason
1968 and Thomason & Stalnaker 1968.
3.4 The Semantics Formally


Now the more technical part begins. There are two kinds of variables,
object variables as before, and intension variables,
or individual concept variables, f,g,g1,g2,…f, g,
g_{1}, g_{2},\ldots. With two
kinds of variables present, the formation of atomic formulas becomes a
little more complex. From now on, instead of just being
nn-place for some nn, a relation symbol will have a
type associated with it, where a type is an nn-tuple
whose entries are members of {O,I}\{O, I\}. An atomic
formula is an expression of the form P(α1,…,αn)P(\alpha_{1},
\ldots ,\alpha_{n}) where PP is a
relation symbol whose type is ⟨t1,…,tn⟩\langle t_{1}, \ldots ,t_{n}\rangle and, for each ii, if
ti=Ot_{i} = O then
αi\alpha_{i} is an object variable, and if
ti=It_{i} = I then
αi\alpha_{i} is an intension variable. Among the
relation symbols we still have EE, which now is of type
⟨O⟩\langle O\rangle, and we have ==, of type ⟨O,O⟩\langle O,O \rangle.


Formulas are built up from atomic formulas in the usual way, using
propositional connectives, modal operators, and two kinds of
quantifiers: over object variables and over intension variables. In
addition to the usual formula-creating machinery, we have the
following. If XX is a formula, xx is an object variable,
and ff is an intension variable, then
[λxX](f)[\lambda x\,X](f) is a
formula, in which the free variable occurrences are those of
XX except for xx, together with the displayed occurrence
of ff.


To distinguish the models described here from those in Section 3.2.2,
these will be referred to as FOIL models, standing for
first order intensional logic. They are discussed more fully
in (Fitting 2004). A FOIL
model is a structure
 M=⟨G,R,DO,Di,I⟩\cM =
 \langle \bG, \bR,
\bD_{O},
\bD_{i}, \bI\rangle where
⟨G,R,DO,I⟩\langle \bG, \bR,
\bD_{O}, \bI\rangle meets
the conditions of Section 3.2.2, and in addition,
Di\bD_{i} is a non-empty set of
functions from G\bG to
DO\bD_{O}; it is the intension
domain.


A first-order valuation in FOIL model 
 M\cM is a mapping that assigns to each
 object variable a member of DO\bD_{O},
as before, and to each intension variable a member of
Di\bD_{i}. If ff is an
intension variable, we’ll write v(f,Γ)v(f, \Gamma ) for
v(f)(Γ)v(f)(\Gamma ). Now, the definition of truth, at a
state Γ\Gamma of a model
 M\cM, with respect to a valuation
 vv, meets the conditions set forth in
Section 3.2.2 and, in addition, the following:
M,Γ⊨v∀fX⇔M,Γ⊨wX,for every f-variant w of vM,Γ⊨v∃fX⇔M,Γ⊨wX,for some f-variant w of vM,Γ⊨v[λxX](f)⇔M,Γ⊨wX,where w is like v except that w(x)=v(f,Γ).\begin{align}
\cM, \Gamma \vDash_{v} \forall fX \Leftrightarrow &amp;\cM, \Gamma \vDash_{w} X,
 \mbox{for every \(f\)-variant \(w\) of \(v\)} \\

\cM, \Gamma \vDash_{v} \exists fX \Leftrightarrow &amp;\cM, \Gamma \vDash_{w} X,
 \mbox{for some \(f\)-variant \(w\) of \(v\)} \\

\tag{1}\label{cond1}
\cM, \Gamma \vDash_{v} [\lambda x\,X](f) \Leftrightarrow &amp;\cM, \Gamma \vDash_{w} X, \\
 &amp;\text{where } w \text{ is like } v \text{ except that } w(x) = v(f, \Gamma).
\end{align}


Let us agree to abbreviate
[λx[λyX](g)](f)[\lambda x\,[\lambda y\,X](g)](f)
by [λxyX](f,g)[\lambda xy\,X](f, g), when
convenient. Suppose ff is intended to be the intension of
“the morning star,” and gg is intended to be the
intension of “the evening star.” Presumably ff and
gg are distinct intensions. Even so,
[λxyx=y][\lambda xy\,x = y](f, g) is
correct in the real world—both ff and gg do
designate the same object.


Here is another example that might help make the de re /
de dicto distinction clearer. Suppose ff is the
intension of “the tallest person,” and gg is the
intension of “the oldest person,” and suppose it happens
that, at the moment, these are the same people. Also, let us read
◻\Box epistemically. It is unlikely we would say that
◻[λxyx=y]\Box [\lambda xy\,x = y](f, g) is
the case. We can read ◻[λxyx=y]\Box [\lambda xy\,x =
y](f, g) as saying we know that
ff and gg are the same. It asserts that under all
epistemic alternatives—all the various ways the world could be that
are compatible with what we know—ff and gg designate
the same object, and this most decidedly does not seem to be the
case. However, we do have [λxy◻(x=y)][\lambda xy\,\Box (x
= y)](f, g), which we can read as saying we know
of ff and gg, that is, of their denotations,
that they are the same, and this could be the case. It asserts that in
all epistemic alternative states, what ff and gg
designate in this one will be the same. In the setup
described, ff and gg do designate the same object, and
identity of objects carries over across states.


It should be noted that the examples of designating terms just given
are all definite descriptions. These pick out different objects in
different possible worlds quite naturally. The situation with proper
names and with mathematics is different, and will be discussed later
in section 3.6.
3.4.1 A Formal Example


Here’s an example to show how the semantics works in a technical
way. An intension is rigid if it is constant, the same in
every state. We might think of a rigid intension as a disguised
object, identifying it with its constant value. It should not be a
surprise, then, that for rigid intensions, the distinction between
de re and de dicto disappears. Indeed, something a
bit stronger can be shown. Instead of rigidity, consider the weaker
notion called local rigidity in Fitting and Mendelsohn 1998:
an intension is locally rigid at a state if it has the same
designation at that state that it has at all accessible ones. To say
ff is locally rigid at a state, then, amounts to asserting the
truth of
[λx◻[λyx=y](f)](f)[\lambda x\,\Box [\lambda y\,x
= y](f)](f) at that state. Local rigidity
at a state implies the de re /de dicto distinction
vanishes at that state. To show how the formal semantics works, here
is a verification of the validity of
[λx◻[λyx=y](f)](f)⊃([λx◊X](f)⊃◊[λxX](f))\tag{2}\label{eq2}
[\lambda x\,\Box [\lambda y\,x = y](f)](f) \supset 
([\lambda x\,\Diamond X](f) \supset \Diamond [\lambda x\,X](f))



In a similar way one can establish the validity of
[λx◻[λyx=y](f)](f)⊃[◊[λxX](f)⊃[λx◊X](f)]\tag{3}\label{eq3}
[\lambda x\,\Box [\lambda y\,x = y](f)](f) \supset 
[\Diamond [\lambda x\,X](f) \supset [\lambda x\,\Diamond X](f)]



and from these two follows the validity of
[λx◻[λyx=y](f)](f)⊃([λx◊X](f)≡◊[λxX](f))\tag{4}\label{eq4}
[\lambda x\,\Box [\lambda y\,x = y](f)](f) \supset 
([\lambda x\,\Diamond X](f) \equiv \Diamond [\lambda x\,X](f))



which directly says local rigidity implies the de re /de
dicto distinction vanishes.


Suppose (2)\eqref{eq2} were not valid. Then there would be a model
 M=⟨G,R,DO,Di,I⟩\cM = \langle \bG, \bR, \bD_{O}, \bD_{i}, \bI\rangle, a
state Γ\Gamma of it, and a valuation vv in it, such that
M,Γ⊨v[λx◻[λyx=y](f)](f)\tag{5}\label{eq5}
\cM, \Gamma \vDash_{v} [\lambda x\,\Box [\lambda y\,x = y](f)](f)

M,Γ⊨v[λx◊X](f)\tag{6}\label{eq6}
\cM, \Gamma \vDash_{v} [\lambda x\,\Diamond X](f) 

not M,Γ⊨v◊[λxX](f)\tag{7}\label{eq7}
\text{not } \cM, \Gamma \vDash_{v} \Diamond [\lambda x\,X](f)

 

From (6)\eqref{eq6} we have the following, where ww is the
xx-variant of vv such that w(x)=v(f,Γ)w(x) = v (f, \Gamma ).
M,Γ⊨w◊X\tag{8}\label{eq8}
\cM, \Gamma \vDash_{w} \Diamond X



By (8)\eqref{eq8} there is some Δ∈G\Delta \in \bG with ΓRΔ\Gamma
\bR \Delta such that we have the following.
M,Δ⊨wX\tag{9}\label{eq9}
\cM, \Delta \vDash_{w} X



Then, as a consequence of (7)\eqref{eq7}
not M,Δ⊨v[λxX](f)\tag{10}\label{eq10}
\text{not } \cM, \Delta \vDash_{v} [\lambda x\,X](f)



and hence we have the following, where w′w' is the xx-variant of
vv such that w′(x)=v(f,Δ)w'(x) = v(f, \Delta ).
not M,Δ⊨w′X\tag{11}\label{eq11}
\text{not } \cM, \Delta \vDash_{w'} X



Now from (5)\eqref{eq5}, since w(x)=v(f,Γ)w(x) = v(f, \Gamma), we have
M,Γ⊨w◻[λyx=y](f)\tag{12}\label{12}
\cM, \Gamma \vDash_{w} \Box [\lambda y\,x=y](f)

and so
M,Δ⊨w[λyx=y](f)\tag{13}\label{eq13}
\cM, \Delta \vDash_{w} [\lambda y\,x=y](f)

and hence
M,Δ⊨w″x=y\tag{14}\label{eq14}
\cM, \Delta \vDash_{w''} x=y



where w″w'' is the yy-variant of ww such that w″(y)=w(f,Δ)w''(y) = w(f,
\Delta ).


We claim that valuations ww and w′w' are the same, which means
that (9)\eqref{eq9} and (11)\eqref{eq11} are contradictory. Since both are xx-variants of
vv, it is enough to show that w(x)=w′(x)w(x) = w'(x), that is, v(f,Γ)=v(f,Δ)v(f,
\Gamma ) = v(f, \Delta ), which is intuitively what local rigidity
says. Proceeding formally, v(f,Γ)=w(x)=w″(x)v(f, \Gamma ) = w(x) = w''(x) since
w″w'' is a yy-variant of ww and so they agree on xx. We
also have v(f,Δ)=w″(y)v(f, \Delta ) = w''(y). And finally, w″(x)=w″(y)w''(x) = w''(y)
by (14)\eqref{eq14}.


Having reached a contradiction, we conclude that (2)\eqref{eq2} must be
valid.
3.4.2 Possible Extra Requirements


In models the domain of intensions is to be some non-empty set of
functions from states to objects. We have deliberately left vague the
question of which ones we must have. There are some conditions we
might want to require. Here are some considerations along these lines,
beginning with a handy abbreviation.
D(f,x) abbreviates [λyy=x](f)\tag{15}\label{eq15}
D(f, x) \text{ abbreviates } [\lambda y\,y=x](f) 


(where xx and yy are distinct object variables).


Working through the FOIL semantics, 
 M,Γ⊨vD(f,x)\cM, \Gamma \vDash_{v} D(f,x) is true just in case
v(f,Γ)=v(x)v(f, \Gamma ) = v(x). Thus
D(f,x)D(f, x) says the intension ff
designates the object xx.


The formula ∀f∃xD(f,x)\forall f\exists xD(f, x) is valid in FOIL
models as described so far. It simply says intensions always
designate. On the other hand, there is no a priori reason to
believe that every object is designated by some intension, but under
special circumstances we might want to require this. We can do it by
restricting ourselves to models in which we have the validity of
∀x∃fD(f,x)\tag{16}\label{eq16}
\forall x\exists fD(f, x)



If we require (16)\eqref{eq16}, quantification over objects is reducible to
intensional quantification:
∀xΦ≡∀f[λxΦ](f).
\tag{17}\label{eq17}
\forall x\Phi \equiv \forall f[\lambda x\,\Phi ](f).



More precisely, the implication (16)⊃(17)\eqref{eq16} \supset \eqref{eq17} is valid in
FOIL semantics.


We also might want to require the existence of choice
functions. Suppose that we have somehow associated an object
dΓd_{\Gamma } with each state Γ\Gamma of a model. If
our way of choosing dΓd_{\Gamma } can be specified by a
formula of the language, we might want to say we have specified an
intension. Requiring the validity of the following formula seems as
close as we can come to imposing such an existence condition on
FOIL models. For each formula Φ\Phi:
◻∃xΦ⊃∃f◻[λxΦ](f).
\Box \exists x\Phi \supset \exists f\Box [\lambda x\,\Phi ](f).

3.5 Partial Intensional Objects


“The King of France in 1700” denotes an object, Louis
XIV, who does not exist, but did. “The present King of
France” does not denote at all. To handle such things, the
representation of an intension can be generalized from being a total
function from states to objects, to being a partial function.
We routinely talk about non-existent objects—we have no problem
talking about the King of France in 1700. But there is nothing to be
said about the present King of France—there is no such thing.
This will be our guide for truth conditions in our semantics.
3.5.1 Modifying the Semantics


The language stays the same, but intension variables are now
interpreted by partial functions on the set of
states—functions whose domains may be proper subsets of the set
of states. Thus 
 M=⟨G,R,DO,Di,I⟩\cM = \langle \bG,
\bR, \bD_{O},
\bD_{i}, \bI\rangle is a
partial FOIL model if it is as in Section 3.4 except
that members of Di\bD_{i} are partial
functions from G\bG to
DO\bD_{O}. Given a partial FOIL
model
 M\cM
 and a valuation vv in it, an intension variable ff
designates at state Γ\Gamma of this model with respect to
vv if Γ\Gamma is in the domain of v(f)v(f).


Following the idea that nothing can be said about the present King of
France, we break condition (1)\eqref{cond1} from Section 3.4 into two parts. Given
a partial FOIL model
 M\cM
 and a valuation vv in it:

If ff does not designate at Γ\Gamma with respect to vv,
 
 it is not the case that
 M,Γ⊨v[λxX](f)\cM, \Gamma \vDash_{v}
[\lambda x\,X](f)
If ff designates at Γ\Gamma with respect to vv,

M,Γ⊨v[λxX](f)⇔M,Γ⊨wX\cM, \Gamma \vDash_{v}
[\lambda x\,X](f)
\Leftrightarrow \cM, \Gamma \vDash_{w} X

where ww is like vv except that
w(x)=v(f,Γ)w(x) = v(f, \Gamma )



Thus designating terms behave as they did before, but nothing can be
truly asserted about non-designating terms.


Recall, we introduced a formula (15)\eqref{eq15} abbreviated by
D(f,x)D(f,x) to say ff designates xx.
Using that, we introduce a further abbreviation.
D(f) abbreviates ∃xD(f,x)\tag{18}\label{eq18}
D(f) \text{ abbreviates } \exists xD(f, x)



This says ff designates. Incidentally, we could have used
[λxx=x](f)[\lambda x\,x = x](f) just
as well, thus avoiding quantification.


It is important to differentiate between existence and designation.
As things have been set up here, existence is a property of objects,
but designation really applies to terms of the formal language, in a
context. To use a temporal example from Fitting and Mendelsohn 1998,
in the usual sense “George Washington” designates a person
who does not exist, though he once did, while “George
Washington’s eldest son,” does not designate at all. That an
intensional variable ff designates an existent object is
expressed by an abstract,
[λxE(x)](f)[\lambda x\,E(x)](f). We have to be
a bit careful about non-existence though. That ff designates a
non-existent is not simply the denial of the previous expression,
¬[λxE(x)](f)\neg [\lambda x\,E(x)](f). After
all, [λxE(x)](f)[\lambda x\,E(x)](f)
expresses that ff designates an existent, so its denial says
either ff does not designate, or it does, but designates a
non-existent. To express that ff designates, but designates a
non-existent, we need
[λx¬E(x)](f)[\lambda x\,\neg E(x)](f). The
formula
∀f([λxE(x)](f)∨¬[λ\forall f([\lambda x\,E(x)](f)
 \vee \neg [\lambdax E(x)](f))(x)](f)) is valid,
but
 ∀f([λxE(x)](f)∨[λx¬E(x)](f))\forall f([\lambda x\,E(x)](f)
 \vee 
 [\lambda x\,\neg E(x)](f)) is
not—one can easily construct partial FOIL models that
invalidate it. What we do have is the following important item.
∀f[D(f)≡([λxE](f)∨[λx¬E(x)](f))]\tag{19}\label{eq19}
\forall f[D(f) \equiv ([\lambda x\,E](f) \vee [\lambda x\,\neg E(x)](f))]



In words, intensional terms that designate must designate existents or
non-existents.
3.5.2 Definite Descriptions


In earlier parts of this article, among the examples of intensions and
partial intensions have been “the present King of France,”
“the tallest person,” and “the oldest person.”
One could add to these “the number of people,” and
“the positive solution of x2−9=0x^{2} - 9 = 0.” All have been specified using definite
descriptions. In a temporal model, the first three determine
partial intensions (there have been instants of time with no people);
the fourth determines an intension that is not partial; the fifth
determines an intension that is rigid.


So far we have been speaking informally, but there are two equivalent
ways of developing definite descriptions ideas formally. The approach
introduced by Bertrand Russell (Russell 1905, Whitehead and Russell
1925) is widely familiar and probably needs little explication
here. Suffice it to say, it extends to the intensional setting without
difficulty. In this approach, a term-like expression,
ιyϕ(y)\atoi y\phi (y),
 is introduced, where ϕ(y)\phi (y) is a formula and yy is an
object variable. It is read, “the yy such that
ϕ(y)\phi (y).” This expression is given no
independent meaning, but there is a device to translate it away in an
appropriate context. Thus,
 [λxψ(x)]ιyϕ(y))[\lambda x\,\psi (x)] \atoi y\phi (y))
 is taken to abbreviate the formula
∃y[∀z(ϕ(z)≡z=y)∧ψ(y)]\exists y[\forall z(\phi (z)
\equiv z = y)
 \wedge \psi (y)]. 
 (The standard device has been used of writing ϕ(z)\phi (z) to
represent the substitution instance of ϕ(y)\phi (y) resulting
from replacing free occurrences of yy with occurrences of
zz, and modifying bound variables if necessary to avoid
incidental capture of zz.) The present abstraction notation,
using λ\lambda, is not that of Russell, but he used an equivalent
scoping device. As he famously pointed out, Russell’s method allows us
to distinguish between “The present King of France is not
bald,” which is false because there is no present King of
France, and “It is not the case that the present King of France
is bald,” which is true because “The present King of
France is bald” is false. It becomes the distinction between
 [λx¬Bald(x)](ιyKing(y))[\lambda x\,\neg\textit{Bald}(x)](\atoi y\textit{King}(y))
 and
 ¬[λxBald(x)](ιyKing(y))\neg [\lambda x\textit{Bald}(x)](\atoi y\textit{King}(y)).


As an attractive alternative, one could make definite descriptions
into first-class things. Enlarge the language so that if
ϕ(y)\phi (y) is a formula where yy is an object
variable, then
 ιyϕ(y)\atoi y\phi (y)
 is an intension term whose free variables are those of
ϕ(y)\phi (y) except for yy. Then modify the
definition of formula, to allow these new intension terms to appear in
places we previously allowed intension variables to appear. That leads
to a complication, since intension terms involve formulas, and formulas
can contain intension terms. In fact, formula and term must be defined
simultaneously, but this is no real problem.


Semantically we can model definite descriptions by partial
intensions. We say the term
 ιyϕ(y)\atoi y\phi (y)
 designates at state Γ\Gamma of a partial FOIL model
 M\cM with respect to valuation
 vv if 
 M,Γ⊨wϕ(y)\cM, \Gamma \vDash_{w} \phi (y) for exactly one yy-variant
ww of vv. Then the conditions from section 3.5.1 are
extended as follows.

If
 ιyϕ(y)\atoi y\phi (y)
 does not designate at Γ\Gamma with respect to vv,

 it is not the case that
 M,Γ⊨v[λxX](ιyϕ(y))\cM, \Gamma \vDash_{v}
 [\lambda x\,X](\atoi y\phi (y))

If
 ιyϕ(y)\atoi y\phi (y)
 designates at Γ\Gamma with respect to vv,
 
M,Γ⊨v[λxX](ιyϕ(y))⇔M,Γ⊨wX\cM, \Gamma \vDash_{v}
 [\lambda x\,X](\atoi y\phi (y))
 \Leftrightarrow \cM, \Gamma \vDash_{w} X

where ww is the yy-variant of vv such that
 M,Γ⊨wϕ(y)\cM, \Gamma \vDash_{w} \phi (y)



One can show that the Russell approach and the approach just sketched
amount to more-or-less the same thing. But with definite descriptions
available as formal parts of the language, instead of just as
removable abbreviations in context, one can see they determine
intensions (possibly partial) that are specified by formulas.


A property need not hold of the corresponding definite description,
that is,
 [λxϕ(x)](ιxϕ(x))[\lambda x\,\phi (x)](\atoi x\phi (x))
 need not be valid. This is simply because the definite description
might not designate. However, if it does designate, it must have its
defining property. Indeed, we have the validity of the following:
D(ιxϕ(x))≡[λxϕ(x)](ιxϕ(x))
D(\atoi x\phi (x)) \equiv [\lambda x\,\phi (x)](\atoi x\phi (x))



One must be careful about the interaction between definite
descriptions and modal operators, just as between them and negation.
For instance,
 D(ιx◊ϕ(x))⊃◊D(ιxϕ(x))D(\atoi x\Diamond \phi (x)) \supset \Diamond D(\atoi x\phi (x))
 is valid, but its converse is not. For a more concrete example of
modal/description interaction, suppose K(x)K(x) is a
formula expressing that xx is King of France. In the present
state,
 [λx◊E(x)](ιxK(x))[\lambda x\,\Diamond E(x)](\atoi xK(x))
 is false, because the definite description has no designation, but
 ◊[λxE(x)](ιxK(x))\Diamond [\lambda x\,E(x)](\atoi xK(x))
is true, because there is an alternative (earlier) state in which the
definite description designates an existent object.
3.6 Problems With Rigidity
It was noted that for rigid terms the de re/de dicto distinction
collapses. Indeed, if ff and gg are rigid, [λxy x=y](f,g)[\lambda xy\
x=y](f, g), ◻[λxy x=y](f,g){\square}[\lambda xy\ x=y](f, g) and [λxy ◻x=y](f,g)[\lambda xy\
{\square}x=y](f, g) are all equivalent. This is a problem that sets
a limit on what can be handled by the Carnap-style logic as presented
so far. Two well-known areas of difficulty are mathematics and proper
names, especially in an epistemic setting.
3.6.1 Mathematical Problems
How could someone not know that 1+4=2+31 + 4 = 2 + 3? Yet it happens
for small children, and for us bigger children similar, but more
complex, examples of mathematical truths we don’t know can be
found. Obviously the designations of “1+41 + 4” and
“2+32 + 3” are the same, so their senses must be
different. But if we model sense by a function from states to
designations, the functions would be the same, mapping each state to
5. If it is necessary truth that is at issue, there is no problem; we
certainly want that 1+4=2+31 + 4 = 2 + 3 is a necessary truth. But if
epistemic issues are under consideration, since we cannot have a
possible world in which “1+41 + 4” and “2+32 +
3” designate different things, “1+4=2+31 + 4 = 2 + 3”
must be a known truth. So again, how could one not know this, or any
other mathematical truth?
One possible solution is to say that for mathematical terms,
intension is a different thing than it is for definite descriptions
like “the King of France.” The expression “1+41 +
4” is a kind of miniature computing program. Exactly what
program depends on how we were taught to add, but let us standardize
on: x+yx + y instructs us to start at the number xx and count off
the next yy numbers. Then obviously, “1+41 + 4” and
“2+32 + 3” correspond to different programs with the same
output. We might identify the program with the sense, and the output
with the denotation. Then we might account for not knowing that 1+4=2+31 +
4 = 2 + 3 by saying we have not executed the two programs, and so
can’t conclude anything about the output.
Identifying the intension of a mathematical term with its
computational content is a plausible thing to do. It does, however,
clash with what came earlier in this article. Expressions like
“the King of France” get treated one way, expressions like
“1+41 + 4” another. For any given expression, how do we
decide which way to treat it? It is possible to unify all this. Here
is one somewhat simple-minded way. If we think of the sense of
“1+41 + 4” as a small program, there are certainly
states, possible worlds, in which we have not executed the program,
and others in which we have. We might, then, think of the intension of
“1+41 + 4” as a partial function on states, whose domain
is the set of states in which the instructions inherent in “1+41
+ 4” have been executed, and mapping those states to 5. Then,
clearly, we can have states of an epistemic possible world model in
which we do not know that “1+41 + 4” and “2+32 +
3” have the same outputs.
This can be pushed only so far. We might be convinced by some
general argument that addition is a total function always
defined. Then it is conceivable that we might know “1+41 +
4” designates some number, but not know what it is. But this
cannot be captured using the semantics outlined thus far, assuming
arithmetic terms behave correctly. If at some state we know ∃x([λy x=y](1+4))\exists
x([\lambda y\ x = y](1 + 4)), that is, we know “1+41 +
4” designates, then at all compatible states, “1+41 +
4” designates, and since arithmetic terms behave correctly, at
all compatible states “1+41 + 4” must designate 5, and
hence we must know [λy 5=y](1+4)[\lambda y\ 5 = y](1 + 4) at the original
state. We cannot know “1+41 + 4” designates without
knowing what.
It is also possible to address the problem from quite a different
direction. One does not question the necessity of mathematical
truths—the issue is an epistemic one. And for this, it has long
been noted that a Hintikka-style treatment of knowledge does not deal
with actual knowledge, but with potential knowledge—not what we
know, but what we are entitled to know. Then familiar logical
omniscience problems arise, and we have just seen yet another
instance of them. A way out of this was introduced in Fagin and
Halpern 1988, called awareness logic. The idea was to enrich
Hintikka’s epistemic models with an awareness function, mapping
each state to the set of formulas we are aware of at that state. The
idea was that an awareness function reflects some bound on the
resources we can bring to bear. With such semantical machinery, we
might know simple mathematical truths but not more complex ones,
simply because they are too complex for us.
Awareness, in this technical sense, is a blunt instrument. A
refinement was suggested in van Benthem 1991: use explicit
knowledge terms. As part of a project to provide a constructive
semantics for intuitionistic logic, a formal logic of explicit proof
terms was presented in Artemov 2001. Later a possible world semantics
for it was created in Fitting 2005. In this logic truths are known for
explicit reasons, and these explicit reasons provide a measure of
complexity. The work was subsequently extended to a more general family
of justification logics, which are logics of knowledge in
which reasons are made explicit.
In justification logics, instead of the familiar KXKX of
epistemic logic we have t:Xt{:}X, where tt is an explicit
justification term. The formula t:Xt{:}X is read,
“XX is known for reason tt.” Justification terms
have structure which varies depending on the particular justification
logic being investigated. Common to all justification logics is the
following minimal machinery. First there are justification constants,
intended to be unanalyzed justifications of accepted logical
truths. Second, there are justification variables, standing for
arbitrary justifications. And finally there are binary operations,
minimally ⋅\cdot and ++. The intention is that if ss
justifies X⊃YX \supset Y and tt justifies XX, then s⋅ts\cdot
t justifies YY, and also s+ts+t justifies anything that ss
justifies and also anything that tt justifies. There are very close
connections between justification logics and epistemic logics,
embodied in Realization Theorems. This is not the appropriate
place to go into details; a thorough discussion of justification
logics can be found in this encyclopedia's entry on justification logic.
If one follows the justification logic approach one might say, of
1+4=2+31 + 4 = 2 + 3 or some more complicated mathematical truth, that it
is knowable but too hard for us to actually know. That is, the
justification terms embodying our reasons for this knowledge are too
complex for us. This follows the general idea of awareness logic, but
with a specific and mathematically useful measure of the complexity of
our awareness.
3.6.2 Proper Names
Proper names are even more of a problem than mathematical
expressions. These days proper names are generally understood to be
rigid designators but, unlike mathematical terms, they have no
structure that we can make use of. Here is a very standard
example. Suppose “Hesperus” is used as a name for the
evening star, and “Phosphorus” for the morning star. It
should be understood that “the evening star” is
conventional shorthand for a definite description, “the first
heavenly body seen after sunset” and similarly for “the
morning star”. Definite descriptions have structure, they pick
out objects and in different possible worlds they may pick out
different objects. But proper names are not like that. Once the
designations of “Hesperus” and “Phosphorus” are
fixed—as it happens they both name the planet Venus—that
designation is fixed across possible worlds and so they are rigid
designators. It follows that while the morning star is the evening
star, that identity is not necessary because definite descriptions are
not rigid, but Hesperus is Phosphorus and that identity is a necessary
one. How, then, could the identity of Hesperus and Phosphorus not be a
known truth, known without doing any astronomical research?
There is more than one solution of the dilemma just mentioned. One
way is very simple indeed. Possible world models can be used to
represent various kinds of modalities. They provide mathematical
machinery, but they do not say what the machinery is for. That is up
to the user. So, we might want to have such a model to represent
necessary truth, or we might want to have such a model to represent
epistemic issues. The argument that proper names are rigid designators
applies to models representing necessary truth. It does not follow
that this is the case for epistemic models too. Here is a quote from
(Kripke 1980) that sheds some light on the issue.

But being put in a situation where we have exactly the same
evidence, qualitatively speaking, it could have turned out that
Hesperus was not Phosphorus; that is, in a counterfactual world in
which ‘Hesperus’ and ‘Phosphorus’ were not
used in the way that we use them, as names of this planet, but as
names of some other objects, one could have had qualitatively
identical evidence and concluded that ‘Hesperus’ and
‘Phosphorus’ named two different objects. But we, using
the names as we do right now, can say in advance, that if Hesperus and
Phosphorus are one and the same, then in no other possible world can
they be different. We use ‘Hesperus’ as the name of a
certain body and ‘Phosphorus’ as the name of a certain
body. We use them as names of these bodies in all possible worlds. If,
in fact, they are the same body, then in any other possible
world we have to use them as a name of that object. And so in any
other possible world it will be true that Hesperus is Phosphorus. So
two things are true: first, that we do not know a priori that
Hesperus is Phosphorus, and are in no position to find out the answer
except empirically. Second, this is so because we could have evidence
qualitatively indistinguishable from the evidence we have and
determine the reference of the two names by the positions of two
planets in the sky, without the planets being the same.

In short, proper names are rigid designators in models where the
possible worlds represent logically alternative states. They need not
be rigid designators in models where the possible worlds represent
epistemically alternative states. Hesperus and Phosphorus are the
same, necessarily so, but we could have used the names
“Hesperus” and “Phosphorus” differently
without being able to tell we were doing so—a state in which we
did this might be epistemically indistinguishable from the actual
one. There can be necessary identities that we do not know because
necessary truth and known truth do not follow the same rules.
3.6.3 Non-Carnapian Approaches
The formal machinery behind the discussion above traces back to
ideas of Carnap. In this tradition possible worlds are central, and
sense or intension is a function from possible worlds to
denotations. Senses determine denotations, but detailed machinery
accounting for how this happens is not made concrete (except for
definite descriptions). One need not do things this way. If the Church
approach is followed, one can simply say that “Hesperus”
and “Phosphorus” have the same designation rigidly, hence
necessarily, but even so they do not have the same sense. This is
possible because senses are, in effect, independent and not derived
things. Senses can determine the same extension across possible worlds
without being identical.
A logic breaking the Carnapian mold, that is thorough and fully
developed, can be found in Zalta 1988. In this a class of abstract
objects is postulated, some among them being ordinary. A distinction
is made between an object exemplifying a property
and encoding it. For instance, an abstract object might
perfectly well encode the property of being a round square, but could
not exemplify it. A general comprehension principle is assumed, in the
form that conditions determine abstract individuals that encode (not
exemplify) the condition. Identity is taken to hold between objects if
they are both abstract and encode the same properties, or they are
both ordinary and exemplify the same properties. In effect, this deals
with problems of substitutivity. The formal theory (more properly,
theories) is quite general and includes both logical necessity and
temporal operators. It is assumed that encoding is not contingent,
though exemplifying may be, and thus properties have both an
exemplification extension that can vary across worlds, and an encoding
extension that is rigid. With all this machinery available, a detailed
treatment of proper names can be developed, along with much else.
4. Sense as Algorithm
Following Frege, the mathematical expressions “1+41+4”
and “2+32+3” have the same denotation but different
senses. Frege did not actually say what a sense was, though it was
clear that, somehow, sense determined denotation. Earlier we talked of
computations associated with “1+41+4” and
“2+32+3”, but what we presented was quite
simple-minded. Tichý introduced the idea of
a construction with these two expressions prescribing
different constructions. A much more formal version of this appears in
a series of papers, (Moschovakis 1994; Moschovakis 2006; Kalyvianaki
and Moschovakis 2008), all of which trace back to (Moschovakis
1989). In these is a very sophisticated formalism in which the sense
or intension of an expression is an algorithm, and algorithm execution
determines denotation. In what follows we sketch the ideas, skimping
on most technical details.
To keep things relatively simple we confine our discussion to
sentences of a formal language for which, again following Frege,
denotation is simply a truth value. Both “there are infinitely
many primes” and “there are infinitely many even
numbers” agree on denotation—both are true—but
clearly have different senses. All the basic ideas of Moschovakis are
already present at the sentence level, though the ideas extend
broadly. We quote from (Moschovakis 1994), on which our presentation
is based.

The mathematical results of the paper are about formal languages,
but they are meant to apply also to those fragments of natural
language which can be formalized, much as the results of denotational
semantics for formal languages are often applied to fragments of
natural language. In addition to the language of predicate logic whose
sense semantics are fairly simple, the theory also covers languages
with description operators, arbitrary connectives and modal operators,
generalized quantifiers, indirect reference and the ability to define
their own truth predicate.

If sense is to be identified with algorithm, perhaps the most basic
question is: what is an algorithm. For Moschovakis, as for many
working mathematicians, an algorithm is an abstract mathematical
object, in the same way that a number is. Of course one uses special
notation to work with a number or an algorithm, but notation is
syntactic while mathematical objects are semantic (even
ideal). Algorithmic subject matter may vary: an algorithm for baking a
cake does not operate in the same space as an algorithm for solving
quadratic equations. Some formalism is needed so that algorithms can
be specified, and this machinery should be suitable for all subjects,
yet as simple as possible. There are several general, but equivalent,
approaches to algorithmic specification across a range of subject
matters. Moschovakis (1994) introduces a very simple, direct mechanism
which he calls the Lower Predicate Calculus with Reflection,
where reflection essentially
means self-reference. Of course not all algorithms terminate,
and consequently the underlying truth value space needs some
consideration, but a solution along Kripke’s lines in his Theory
of Truth works well. We lead up to a general definition via some (for
the time being) informal examples.
4.1 Motivating Examples
Suppose we have a structure with a given domain and some given
relations of various arities, say ⟨D,R1,…,Rn⟩\langle \bD, \bR_1,
\ldots, \bR_n\rangle. And suppose we have a first-order
language formed in the usual way, with relation symbols, R1R_1,
…, RnR_n whose arities match those of the given relations. We
will generally use the typographical convention that R\bR is
a relation and RR is the associated formal symbol interpreted by
that relation. In the usual way we can build up a first-order language
that talks about the structure, where atomic formulas involve R1R_1,
…, RnR_n and ==. Constants can be simulated by the use of
unary relations that are true of single things. For example, in
arithmetic we can have a relation Z\bZ such that
Z(x)\bZ(x) holds only when x=0x=0. In the interests of
readability, in such a case we would act as if we had a constant
symbol in our language that was interpreted by 0. Such informal
simplifications make formula reading a bit easier, while nothing
significant is lost.
What is added to the usual first-order machinery is a
where\textsf{where} construction. We will give a proper definition
shortly but first, here is a concrete example. Let us assume we have a
structure for arithmetic, ⟨{0,1,2,…},S,Z⟩\langle \{0,1,2,\ldots\}, \bS,
\bZ\rangle. Here S\bS is the two-place successor
relation on the domain, that is, we have S(0,1)\bS(0,1),
S(1,2)\bS(1,2), …. We also assume Z\bZ is true
uniquely of 0 and, in accord with what we said above about relations
and individual constants, we act as if we had a constant symbol 0 in
the formal language. Consider the following formula, where SS is a
two-place relation symbol interpreted by S\bS, and EE and
OO are auxiliary one-place relation symbols.
even(x)≡E(x) where {E(x)≃x=0∨(∃y)(S(y,x)∧O(y)),O(x)≃(∃y)(S(y,x)∧E(y))}\tag{20}\label{evenone}
\begin{array}{rl}
\even(x) \equiv E(x) \textsf{ where } \{&amp; E(x) \simeq x=0 \lor (\exists y)(S(y,x)\land O(y)),\\
     &amp;O(x) \simeq (\exists y)(S(y,x) \land E(y))\}
\end{array}
For the time being think of ≃\simeq as something like “is
defined to be”. This will be discussed further later. Think of
E(x)E(x) as representing the ‘output’ relation. It is
defined in terms OO, where OO is defined in terms of
EE. Mutual recursion is involved. Even at this informal stage it is
not hard to see that even\even defines the set of even
numbers, in the sense that even(x)\even(x) evaluates to true for
even xx and to false for odd xx. Here is an informal calculation
showing that even(2)\even(2) evaluates to true. In it we use
⇐\Leftarrow for reverse implication. Also we write members of the
domain (numbers) directly into formulas, rather than using the
machinery of valuations assigning numbers to free variables.
even(2)≡E(2)≃2=0∨(∃y)(S(y,2)∧O(y))⇐2=0∨(S(1,2)∧O(1))≃2=0∨(S(1,2)∧(∃y)(S(y,1)∧E(y)))⇐2=0∨(S(1,2)∧(S(0,1)∧E(0)))≃2=0∨(S(1,2)∧(S(0,1)∧(0=0∨(∃y)(S(y,0)∧E(y)))))\begin{aligned}
\even(2) &amp;\equiv E(2)\\
&amp; \simeq 2=0 \lor (\exists y)(S(y,2) \land O(y))\\
&amp; \Leftarrow 2=0 \lor (S(1,2) \land O(1))\\
&amp; \simeq 2=0 \lor (S(1,2) \land (\exists y)(S(y,1) \land E(y)))\\
&amp; \Leftarrow 2=0 \lor (S(1,2) \land (S(0,1) \land E(0)))\\
&amp; \simeq 2=0 \lor (S(1,2) \land (S(0,1) \land (0=0\lor (\exists y)(S(y,0)\land E(y)))))\end{aligned}


We used the clause three times, replacing E(2)E(2), O(1)O(1), and
E(0)E(0). The final line is true because S(1,2)S(1,2), S(0,1)S(0,1), and
0=00=0 are true.
This example is a start, but it is misleadingly simple. The
machinery is rich enough to allow formulation of the liar sentence. In
the following, PP is an auxiliary relation symbol of arity 0, that
is, a propositional letter. We have written just PP instead of
P()P(). 
liar≡P where {P≃¬P}\tag{21}\label{liar}
\textit{liar} \equiv P \textsf{ where } \{ P \simeq \lnot P\}

Clearly an evaluation attempt of the sort shown above will not
terminate. A solution to non-termination is familiar from classical
recursion theory, and also from work on the theory of truth: allow the
relations defined by our formal machinery to be partial. Not
all instances of a relation have to receive a truth value. But these
are semantic issues and before getting to them we need to give a
proper syntactic definition of the language within which our formulas
will be written.
4.2 Syntax
Above we spoke of a first-order language appropriate for a
structure ⟨D,R1,…,Rn⟩\langle\bD, \bR_1, \ldots,
\bR_n\rangle, enhanced with clauses, but these clauses were
only shown via examples. Here is a proper definition. The Lower
Predicate Calculus with Reflection (LPCR) for ⟨D,R1,…,Rn⟩\langle\bD,
\bR_1, \ldots, \bR_n\rangle is the language built up
using the machinery of ordinary first-order logic with equality,
together with the following formation clause. If ϕ0\phi_0,
ϕ1\phi_1, …, ϕk\phi_k are formulas and P1P_1, …,
PkP_k are (new) auxiliary relation variables, the following is a
formula.
ϕ0 where {P1(x1)≃ϕ1,…,Pk(xk)≃ϕk}\tag{22}\label{whereformula}
\phi_0 \textsf{ where } \{ P_1(\bx_1) \simeq \phi_1,
\ldots,
P_k(\bx_k) \simeq \phi_k\}

In this each xi\bx_i is a sequence of variables whose length
is the arity of PiP_i. The PiP_i may appear in the formulas
ϕ0\phi_0, …, ϕk\phi_k themselves, and so we have a
self-referential set of defining equations, with ϕ0\phi_0 as
‘output’. Note that with (22)\eqref{whereformula} added to the
definition of formula,  where \textsf{ where } conditions can appear in some of the
ϕi\phi_i, and so means of preventing inappropriate interaction
between nested conditions is needed. This is done through the familiar
machinery of free and bound variables. The symbols P1P_1, …,
PkP_k are taken to be relation variables, and are
considered to be bound in (22)\eqref{whereformula}. Likewise the occurrences
of individual variables in xi\bx_i are understood to be bound
in Pi(xi)≃ϕiP_i(\bx_i) \simeq \phi_i. In effect, these are local
variables.
Now the language LPCR has been defined, and we turn to notions of sense and reference.
4.3 Denotation
We have been discussing sentences and more generally formulas with
free variables. The familiar Tarskian semantics provides a basis for
understanding here, but we need modifications and extensions to deal
with the construct.
A partial function on a space SS is a function that
assigns values to some, but not necessarily to all, members of
SS. Said otherwise, it is a function whose domain is a subset of
SS. For a partial function ff, f(x)≃yf(x)\simeq y means xx is
in the domain of ff and f(x)=yf(x) = y. (Finally we have a proper
accounting of our use of ≃\simeq in the examples
earlier.) Partial relations are partial functions from
kk-tuples to {t,f}\{{\textsf{t}}, {\textsf{f}}\}. The given
relations of our structures are relations in the usual sense, but it
is partial relations that we may find ourselves defining.
Assume we have a structure ⟨D,R1,…,Rn⟩\langle\bD, \bR_1,
\ldots, \bR_n\rangle, and suppose we have an LPCR language
associated with it. A valuation vv in this structure is a
mapping from individual variables to members of D\bD and
from auxiliary relation symbols to partial relations on
D\bD. We would like to associate with each valuation vv a
mapping TvT_v from formulas of LPCR to truth values but since things
like the liar sentence are formulable, TvT_v must be a partial
function, and so we must be careful even about familiar things like
propositional connectives. Various three valued logics have been
developed; perhaps the most common is Kleene’s strong
three-valued logic, motivated by recursion theory and familiar from
much work on the Theory of Truth. The following table says how
connectives and quantifiers behave. Cases that are not explicitly
covered are understood to be those for which a truth valuation is left
undefined. (For instance, if the truth value of XX is undefined,
the same is the case for ¬X\lnot X.)
Tv(¬X)≃tTv(X)≃fTv(¬X)≃fTv(X)≃tTv(X∧Y)≃tTv(X)≃t and Tv(Y)≃tTv(X∧Y)≃fTv(X)≃f or Tv(Y)≃fTv(X∨Y)≃tTv(X)≃t or Tv(Y)≃tTv(X∨Y)≃fTv(X)≃f and Tv(Y)≃fTv((∀x)X)≃tTv′(X)≃t for all x-variants v′ of vTv((∀x)X)≃fTv′(X)≃f for some x-variant v′ of vTv((∃x)X)≃tTv′(X)≃t for some x-variant v′ of vTv((∃x)X)≃fTv′(X)≃f for all x-variants v′ of v\begin{array}{rc@{\mbox{if\ \ }}l}
T_v(\lnot X) \simeq {\textsf{t}}&amp;&amp; T_v(X) \simeq {\textsf{f}}\\
T_v(\lnot X) \simeq {\textsf{f}}&amp;&amp; T_v(X) \simeq {\textsf{t}}\\
T_v(X \land Y) \simeq {\textsf{t}}&amp;&amp; T_v(X) \simeq {\textsf{t}}\mbox{ and } T_v(Y) \simeq {\textsf{t}}\\
T_v(X \land Y) \simeq {\textsf{f}}&amp;&amp; T_v(X) \simeq {\textsf{f}}\mbox{ or } T_v(Y) \simeq {\textsf{f}}\\
T_v(X \lor Y) \simeq {\textsf{t}}&amp;&amp; T_v(X) \simeq {\textsf{t}}\mbox{ or } T_v(Y) \simeq {\textsf{t}}\\
T_v(X \lor Y) \simeq {\textsf{f}}&amp;&amp; T_v(X) \simeq {\textsf{f}}\mbox{ and } T_v(Y) \simeq {\textsf{f}}\\
T_v((\forall x)X) \simeq {\textsf{t}}&amp;&amp; T_{v'}(X) \simeq {\textsf{t}}\mbox{ for all \(x\)-variants \(v'\) of \(v\)}\\
T_v((\forall x)X) \simeq {\textsf{f}}&amp;&amp; T_{v'}(X) \simeq {\textsf{f}}\mbox{ for some \(x\)-variant \(v'\) of \(v\)}\\
T_v((\exists x)X) \simeq {\textsf{t}}&amp;&amp; T_{v'}(X) \simeq {\textsf{t}}\mbox{ for some \(x\)-variant \(v'\) of \(v\)}\\
T_v((\exists x)X) \simeq {\textsf{f}}&amp;&amp; T_{v'}(X) \simeq {\textsf{f}}\mbox{ for all \(x\)-variants \(v'\) of \(v\)}
\end{array}
This still leaves formulas to deal with. Suppose we have the following.
ϕ0 where {P1(x1)≃ϕ1,…,Pk(xk)≃ϕk}\tag{23}\label{Eexample}
\phi_0 \textsf{ where } \{ P_1(\bx_1) \simeq \phi_1, \ldots, P_k(\bx_k) \simeq \phi_k\}
We make two simplifying assumptions to keep our discussion from
being too intricate. We assume no ϕi\phi_i contains a nested
 where \textsf{ where } clause. The basic ideas are amply illustrated with this condition
imposed, but everything extends to the general case without too much
difficulty. It is a general requirement that the variables in
xi\bx_i are ‘local’ to Pi(xi)≃ϕiP_i(\bx_i) \simeq
\phi_i, that is, they are considered to be bound in this formula. To
this we add another simplifying assumption: the variables in
xi\bx_i are the only variables that may occur free
in ϕi\phi_i. Roughly this means that we have no parameters, only
local variables. This serves to allow us to discuss things with less
clutter. Again, everything extends to the more general case with no
fundamental changes.
Continuing with (23)\eqref{Eexample}, consider the following associated set
EE of equations.
P1(x1)≃ϕ1P2(x2)≃ϕ2⋮Pk(xk)≃ϕk\tag{24}\label{equationsE}
\begin{align}
P_1(\bx_1) &amp;\simeq \phi_1\\
P_2(\bx_2) &amp;\simeq \phi_2\\
&amp;\vdots\\
P_k(\bx_k) &amp;\simeq \phi_k
\end{align}
The difficulty, of course, is that each PiP_i is allowed to occur
in one or more ϕj\phi_j, possibly even in ϕi\phi_i, and so EE
is self-referential. In many computer programming languages one sees
things like x=x+1x = x+1. It is explained to beginning programmers that
this takes the current value of xx, adds 1, and calls the result
xx again. Occurrences of xx on the right have
‘before’ values, occurrences on the left have
‘after’ values. Analogously, let us think of the members
of EE as (simultaneous) assignment statements. Occurrences of
PiP_i on the right of ≃\simeq are current values, occurrences on
the left are next values. Taking all of P1P_1, …, PkP_k
into account, we can think of EE as defining a functional that maps
kk-tuples of partial relations (‘before’ values of
these relation symbols) to kk-tuples of partial relations
(‘after’ values of these relation symbols). Now here are
the details a bit more formally.
Suppose we have a kk-tuple ⟨P1,…,Pk⟩\langle\bP_1, \ldots,
\bP_k\rangle of partial relations, where for each ii the
arity of Pi\bP_i matches that of the partial relation
variable PiP_i. This is our input (‘before’ values). For
each ii we want to define an output partial relation which we call
P′i\bP'_i, of the same arity as Pi\bP_i, so that
⟨P′1,…,P′k⟩\langle\bP'_1, \ldots, \bP'_k\rangle serves as our
overall output (‘after’ values). To do this we must say
when P′i(d)\bP'_i(\bd) maps to t{\textsf{t}}, when it
maps to f{\textsf{f}}, and when it is undefined, for each
d\bd with components from D\bD. Well, take vv
to be a valuation assigning to each auxiliary relation symbol PiP_i
the corresponding partial relation Pi\bP_i (this is how
‘before’ values for our partial relation symbols come in),
and assigning to the variables in xi\bx_i the corresponding
members of d\bd. Now, simply let
P′i(d)≃Tv(ϕi)\bP'_i(\bd)\simeq T_v(\phi_i). In this way a new
partial relation P′i\bP'_i is specified, and more generally a
vector of them, ⟨P′1,…,P′k⟩\langle\bP'_1, \ldots,
\bP'_k\rangle. The set of equations EE can be thought of
as specifying a functional transforming kk-tuple
⟨P1,…,Pk⟩\langle\bP_1, \ldots, \bP_k\rangle into
⟨P′1,…,P′k⟩\langle\bP'_1, \ldots, \bP'_k\rangle. Let us call
this functional [E][E], and write [E](⟨P1,…,Pk⟩)=⟨P′1,…,P′k⟩[E](\langle\bP_1, \ldots,
\bP_k\rangle) = \langle\bP'_1, \ldots,
\bP'_k\rangle.
If we are to have equations EE behave well in a logic setting,
each PiP_i should have the same valuation no matter where we see
it—there should be no distinction between what we have been
calling left and right sides; Pi\bP_i and P′i\bP'_i
should be the same. In other words, we would like to have partial
relations P1\bP_1, …, Pk\bP_k to interpret
P1P_1, …, PkP_k so that [E](⟨P1,…,Pk⟩)=⟨P1,…,Pk⟩[E](\langle\bP_1, \ldots,
\bP_k\rangle) = \langle\bP_1, \ldots,
\bP_k\rangle—‘before’ and
‘after’ values agree. This is called a fixed
point of [E][E]. So, we need to know that [E][E] has a fixed
point, and if it has more than one then there is a plausible candidate
we can choose as the best one.
If ff and gg are two partial functions from a space SS to
RR, one writes f⊆gf\subseteq g to mean that whenever f(x)≃wf(x)\simeq
w then also g(x)≃wg(x)\simeq w. Then for two partial relations
P\bP and Q\bQ of the same arity,
P⊆Q\bP\subseteq\bQ means that whenever
P(d)\bP(\bd) is defined, so is
Q(d)\bQ(\bd), and both have the same truth value. We can
extend this to kk-tuples by setting ⟨P1,…,Pk⟩⊆⟨Q1,…,Qk⟩\langle\bP_1, \ldots,
\bP_k\rangle\subseteq\langle\bQ_1, \ldots,
\bQ_k\rangle if Pi⊆Qi\bP_i\subseteq\bQ_i for
each ii. It is not terribly difficult to show that the functional
[E][E] defined above, and based on (23)\eqref{Eexample}, has
the monotonicity property: if ⟨P1,…,Pk⟩⊆⟨Q1,…,Qk⟩\langle\bP_1, \ldots,
\bP_k\rangle\subseteq\langle\bQ_1, \ldots,
\bQ_k\rangle then [E](⟨P1,…,Pk⟩)⊆[E](⟨Q1,…,Qk⟩)[E](\langle\bP_1, \ldots,
\bP_k\rangle)\subseteq[E](\langle\bQ_1, \ldots,
\bQ_k\rangle). There is a very general theory of monotone
mappings like this, from which it follows that [E][E] does have a
fixed point. Moreover, if there are more than one then there is a
unique one that is least, in the sense that it is in the ⊆\subseteq
relation to any other. This least fixed point is precisely the best
candidate we mentioned above. It contains the information that any
fixed point must have.
Now we finish saying how to evaluate the formula
(23)\eqref{Eexample}. First, construct the associated set of equations,
EE. Next, construct the functional [E][E]. There is a least fixed
point for [E][E], let us say it is ⟨F1,…,Fk⟩\langle\bF_1, \ldots,
\bF_k\rangle. Finally, evaluate ϕ0\phi_0 using
Fi\bF_i to interpret PiP_i for each ii. The resulting
truth value, or undefined, is the value (denotation) associated with
(23)\eqref{Eexample}.
We have now said how to associate a truth value, or undefined, with
every formula of LPCR (under our simplifying assumptions). We have
(partial) denotations.
4.4 Sense
Each formula of LPCR specifies an algorithm for its evaluation,
that is, for the determination of its truth value (if
possible). Moschovakis identifies the sense of a formula with
that algorithm. Two formulas that evaluate to the same result, thus
having the same denotation, may have different senses because the
associated algorithms are different. For example, in (20)\eqref{evenone} we
gave a formula that defines the even numbers. Here is another such
formula. 
even(x)≡E(x) where {E(x)≃x=0∨(∃y)(S(y,x)∧¬E(y))}\tag{25}\label{eventwo}
\even(x) \equiv E(x) \textsf{ where } \{ E(x) \simeq x=0 \lor (\exists y)(S(y,x)\land \lnot E(y))\}
We leave it to you to verify that (25)\eqref{eventwo} also defines the even
numbers. It is intuitively plausible that (20)\eqref{evenone} and (25)\eqref{eventwo}
evaluate using algorithms that differ, and so have different
senses. But of course this must be made precise. What is needed is a
uniform method of comparison between algorithms. Here we just briefly
sketch the ideas.
There is very general machinery, from Moschovakis 1989, called the
Formal Language of Recursion, FLR. Using it a thorough exploration of
recursive definitions and fixpoints is possible. The language that
concerns us here, LPCR, embeds into FLR, even allowing nested clauses
and parameters, something we ignored in our discussion of
denotation. In FLR there is a method for converting recursive
definitions into a normal form, which cannot be further reduced. That
normal form has a very simple structure, consisting of a set of
self-referential equations with no nesting present at all. Normal
forms reveal essential evaluation structure most clearly. When working
with a single structure, ⟨D,R1,…,Rn⟩\langle\bD, \bR_1, \ldots,
\bR_n\rangle, all normal forms will be built from a common
set of functionals. This makes it easy to compare normal forms. The
idea is that if two formulas of LPCR, when embedded into FLR, have
differing normal forms, the two formulas have different senses. Of
course this must be taken with some reasonable flexibility. For
instance, two sets of equations that differ only by renaming variables
or switching order of equations do not differ in any fundamental
way. With this understood, if two LPCR formulas, when embedded into
FLR, have truly distinct normal forms, the two LPCR formulas are
defined to have different senses. This meets all the informal
conditions one wants a notion of sense to have. Moschovakis even
proves the important theorem that equality of sense, as just defined,
is decidable under natural conditions.
4.5 Algorithms Need Not Be Effective
The word “algorithm” suggests something effective, but
here it is being used in a more general sense, as a set of
instructions that, for reasons of our finitistic limitations, we may
not be able to actually carry out. Consider again the paradigm
formula, (22)\eqref{whereformula}. If one of the ϕi\phi_i contains an
existential quantifier in a positive position (or a universal
quantifier in a negative position) it can be thought of as invoking a
systematic search through the domain D\bD for a verifying
witness. This is plausible for reasonable domains. But if ϕi\phi_i
should contain a universal quantifier in a positive position or an
existential quantifier in a negative position, something must be
verified for every member of the domain and unless the domain is
finite, this is not a human task. Nonetheless, we generally believe we
understand quantification. What we are dealing with is algorithms
relative to that understanding.
The problem with quantifiers is inescapable for much that we
routinely discuss using sense and reference. Consider Russell’s
treatment of definite descriptions. In this “the AA has
property BB” is replaced by “exactly one thing has
property AA and it has property BB”. To say that only one
thing has property AA one says that something has property AA
and everything else does not. The first part of this involves an
existential quantifier and the second part a universal one. Then if
the definite description occurs in a positive location we have a
positive occurrence of a universal quantifier, and if it occurs in a
negative location we have a negative occurrence of an existential
quantifier. Essential problems arise either way. Moschovakis is not
claiming to turn sense and reference into something computable, but
simply to provide mathematical machinery that can plausibly formalize
the ideas involved using a generalized notion of algorithm.
There is a second, related problem where lack of effectiveness
comes in. In our discussion of denotation we considered a set EE of
equations (24)\eqref{equationsE} and a functional [E][E] associated with
them. Recall that [E][E] mapped kk-tuples of partial relations to
kk-tuples of partial relations. We noted that [E][E] would
be monotone, and by very general results such functionals
always have least fixed points. There is more than one way of showing
this. One well-known argument has a decidedly algorithmic flavor to
it. It goes as follows. Start with the smallest kk-tuple of partial
relations—this is the one where every partial relation is always
undefined. Call this T0T_0. Apply the functional [E][E] to T0T_0,
getting T1T_1. Apply the functional [E][E] to T1T_1 getting
T2T_2, and so on. It is easy to show that T0⊆T1⊆T2⊆…T_0\subseteq
T_1\subseteq T_2\subseteq\ldots. We have that T0⊆T1T_0\subseteq T_1
because T0T_0 is in the ⊆\subseteq relation to every
kk-tuple. By monotonicity we then have [E](T0)⊆[E](T1)[E](T_0)\subseteq
[E](T_1), but this says T1⊆T2T_1 \subseteq T_2. And so on. Continue
with this increasing sequence and eventually the least fixed point of
[E][E] will be reached.
But this is very misleading. What does “continue” mean?
We have T0T_0, T1T_1, T2T_2, …. None of these may be a
fixed point. For instance, suppose we carry out this construction with
the functional arising from (20)\eqref{evenone} for even(x)\even(x). Then
T0T_0 will be ⟨E0,O0⟩\langle E_0, O_0\rangle, where both E0E_0 and
O0O_0 are the everywhere undefined 1-place relation. We leave it to
you to check that we get successive Ti=⟨Ei,Oi⟩T_i=\langle E_i, O_i\rangle
where we have the following, with cases not displayed being
undefined. 
iEiOi1E1(0)=tO1(0)=f2E2(0)=tO2(0)=fE2(1)=fO2(1)=t3E3(0)=tO3(0)=fE3(1)=fO3(1)=tE3(2)=tO3(2)=f⋮⋮⋮\begin{array}{c|c|c}
i &amp; E_i &amp; O_i\\
\hline
1 &amp; E_1(0) = {\textsf{t}}&amp; O_1(0) = {\textsf{f}}\\
2 &amp; E_2(0) = {\textsf{t}}&amp; O_2(0) = {\textsf{f}}\\
   &amp; E_2(1) = {\textsf{f}}&amp; O_2(1) = {\textsf{t}}\\
3 &amp; E_3(0) = {\textsf{t}}&amp; O_3(0) = {\textsf{f}}\\
   &amp; E_3(1) = {\textsf{f}}&amp; O_3(1) = {\textsf{t}}\\
   &amp; E_3(2) = {\textsf{t}}&amp; O_3(2) = {\textsf{f}}\\
\vdots &amp; \vdots &amp; \vdots  
\end{array}
None of T0T_0, T1T_1, T2T_2, …is a fixed point, but
there is a clear notion of a limit, called TωT_\omega, that
accumulates the results produced along the way. It is the least fixed
point in this example.
But iterating and taking a limit may not be sufficient. Consider
the following elaboration of (20)\eqref{evenone}.
ϕ(x)≡A(x) where {E(x)≃x=0∨(∃y)(S(y,x)∧O(y)),O(x)≃(∃y)(S(y,x)∧E(x)),A(x)≃x=1∧((∀y)(E(y)∨O(y))}\tag{26}\label{evenmore}
\begin{array}{rl}
\phi(x) \equiv A(x) \textsf{ where } \{&amp; E(x) \simeq x=0 \lor (\exists y)(S(y,x)\land O(y)),\\
     &amp;O(x) \simeq (\exists y)(S(y,x) \land E(x)),\\
     &amp;A(x) \simeq x=1 \land ((\forall y)(E(y)\lor O(y))\}
 \end{array}
The set of equations arising from (26)\eqref{evenmore} has the two members
of (20)\eqref{evenone}, and one more for AA. Using these equations, in
order to conclude A(1)A(1) we must already have one of E(y)E(y) or
O(y)O(y) evaluating to t{\textsf{t}} for every number yy. If we
carry out the construction outlined above, we won’t have this
for EE and OO until stage ω\omega, and so we must go one more
step, to what is called Tω+1T_{\omega+1}, before we reach a fixed
point.
More and more extreme examples can be given. The fixed point
construction may have to be continued to larger and larger transfinite
ordinals. This is a well-known phenomenon, especially in areas like
the Theory of Truth. It cannot be avoided. Incidentally, it should be
noted that the machinery introduced by Kripke in his treatment of
truth has a natural embedding into LPCR, but we do not discuss this
here.