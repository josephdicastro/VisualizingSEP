Decision theory is concerned with the reasoning underlying an
agent’s choices, whether this is a mundane choice between taking
the bus or getting a taxi, or a more far-reaching choice about whether
to pursue a demanding political career. (Note that “agent”
here stands for an entity, usually an individual person, that is
capable of deliberation and action.) Standard thinking is that what an
agent does on any given occasion is completely determined by her
beliefs and desires/values, but this is not uncontroversial, as will
be noted below. In any case, decision theory is as much a theory of
beliefs, desires and other relevant attitudes as it is a theory of
choice; what matters is how these various attitudes (call them
“preference attitudes”) cohere together.
The focus of this entry is normative decision theory. That is, the
main question of interest is what criteria an agent’s preference
attitudes should satisfy in any generic
circumstances. This amounts to a minimal account
of rationality, one that sets aside more substantial
questions about appropriate values and preferences, and reasonable
beliefs, given the situation at hand. The key issue in this regard is
the treatment of uncertainty. The orthodox normative decision
theory, expected utility (EU) theory, essentially says that,
in situations of uncertainty, one should prefer the option with
greatest expected desirability or value. This simple maxim
will be the focus of much of our discussion.
The structure of this entry is as follows: Section 1 discusses the
basic notion of “preferences over prospects”, which lies
at the heart of decision theory. Section 2 describes the development
of normative decision theory in terms of ever more powerful and
flexible measures of preferences. Section 3 discusses the two
best-known versions of EU theory. Section 4 considers the broader
significance of EU theory for practical action, inference, and
valuing. Section 5 turns to prominent challenges to EU theory, while
Section 6 addresses sequential decisions, and how this richer setting
bears on debates about rational preferences.
 
1. What are preferences over prospects?
The two central concepts in decision theory
are preferences and prospects (or
equivalently, options). Roughly speaking, we say that an
agent “prefers” the “option” AA over BB just
in case, for the agent in question, the former is more desirable or
choice-worthy than the latter. This rough definition makes clear that
preference is a comparative attitude; it is one of comparing options
in terms of how desirable/choice-worthy they are. Beyond this, there
is room for argument about what preferences over options actually
amount to, or in other words, what it is about an agent (perhaps
oneself) that concerns us when we talk about his/her preferences over
options. This section considers some elementary issues of
interpretation that set the stage for introducing (in the next
section) the decision tables and expected utility rule that for many
is the familiar subject matter of decision theory. Further
interpretive questions regarding preferences and prospects will be
addressed later, as they arise.
Let us nonetheless proceed by first introducing basic candidate
properties of (rational) preference over options and only afterwards
turning to questions of interpretation. As noted above, preference
concerns the comparison of options; it is a relation between
options. For a domain of options we speak of an
agent’s preference ordering, this being the ordering of
options that is generated by the agent’s preference between any
two options in that domain.
In what follows, ⪯\preceq
represents a weak preference relation, i.e., the relation
“… is not preferred to
…”. So A⪯BA\preceq B
represents that the agent we are interested in considers
option BB to be at least as
preferable as option AA. From the
weak preference relation we can define the strict preference
relation, ≺\prec, as
follows: A≺B⇔A⪯B & ¬(B⪯A)A\prec B\Leftrightarrow A\preceq
B \ \&amp; \ \neg (B\preceq A), where ¬X\neg X means “it is not the case
that XX”. The indifference
relation, ∼\sim, is defined
as: A∼B⇔A⪯B & B⪯AA\sim B \Leftrightarrow A\preceq B \
\&amp; \ B\preceq A. This represents that the agent we are
interested in considers AA
and BB to be equally
preferable.
We say that ⪯\preceq weakly
orders a set SS of options
whenever it satisfies the following two conditions:
Axiom 1 (Completeness)
For any A,B∈SA, B\in S: either A⪯BA\preceq B or B⪯AB\preceq A.
Axiom 2 (Transitivity)
For any A,B,C∈SA, B, C\in S: if A⪯BA\preceq B and B⪯CB\preceq C
then A⪯CA\preceq C.
The above can be taken as a preliminary characterisation of
rational preference over options. Even this limited characterisation
is contentious, however, and points to divergent interpretations of
“preferences over prospects/options”.
Start with the Completeness axiom, which says that an agent can
compare, in terms of the weak preference relation, all pairs of
options in SS. Whether or not
Completeness is a plausible rationality constraint depends both on
what sort of options are under consideration, and how we interpret
preferences over these options. If the option set includes all kinds
of states of affairs, then Completeness is not immediately
compelling. For instance, it is questionable whether an agent should
be able to compare the option whereby two additional people in the
world are made literate with the option whereby two additional people
reach the age of sixty. If, on the other hand, all options in the set
are quite similar to each other, say, all options are investment
portfolios, then Completeness is more compelling. But even if we do
not restrict the kinds of options under consideration, the question of
whether or not Completeness should be satisfied turns on the meaning
of preference. For instance, if preferences merely represent choice
behaviour or choice dispositions, as they do according to the
“revealed preference theory” popular amongst economists
(see Sen 1973), then Completeness is automatically satisfied, on the
assumption that a choice must inevitably be made. By contrast, if
preferences are understood rather as mental attitudes, i.e.,
considered judgments about whether an option is better or more
desirable than another, then the doubts about Completeness alluded to
above are pertinent (for further discussion, see Mandler 2001).
Most philosophers and decision theorists subscribe to the latter
interpretation of preference as a kind of judgment that explains, as
opposed to being identical with, choice dispositions and resultant
choice behaviour (see, e.g., Dietrich and List, 2015). Moreover,
many hold that Completeness is not rationally required; that
rationality makes demands only on the judgments an agent actually
holds, but says nothing of whether a judgement must be held in the
first place. Nevertheless, following Richard Jeffrey (1983), most
decision theorists suggest that rationality requires that preferences
be coherently extendible. This means that even if your
preferences are not complete, it should be possible to complete them
without violating any of the conditions that are rationally required,
in particular Transitivity.
This brings us to the Transitivity axiom,
which says that if an option BB is
at least as preferable as AA,
and CC is at least as preferable
as BB, then AA cannot be strictly preferred to CC. A recent 
challenge to Transitivity turns on
heterogeneous sets of options, as per the discussion of Completeness
above. But here a different interpretation of preference is brought to
bear on the comparison of options. The idea is that preferences, or
judgments of desirability, may be responsive to a salience
condition. For example, suppose that the most salient feature when
comparing cars AA
and BB is how fast they can be
driven, and BB is no worse
than AA in this regard, yet the
most salient feature when comparing cars BB and CC is how
safe they are, and that CC is no
worse than BB in this
regard. Furthermore, when comparing AA and CC, the
most salient feature is their beauty. In such a case, some argue
(e.g., Temkin 2012) that there is no reason why Transitivity should be
satisfied with respect to the preferences concerning AA, BB
and CC. Others (e.g., Broome
1991a) argue that
Transitivity is part of the very meaning of the betterness relation
(or objective comparative desirability); if rational preference is a
judgment of betterness or desirability, then Transitivity is
non-negotiable. With respect to the car example, Broome would argue
that the desirability of a fully specified option should not vary,
simply in virtue of what other options it is compared with. Either the
choice context affects how the agent perceives the option at hand, in
which case the description of the option should reflect this, or else
the choice context does not affect the option. Either way,
Transitivity should be satisfied.
There is a more straightforward defence of Transitivity in
preference; a defence that hinges on the sure losses that may befall
anyone who violates the axiom. This is the so-called money
pump argument (for recent discussion and revision of this
argument, see Gustafsson 2010 & 2013). It is based on the
assumption that if you find XX at
least as desirable as YY, then you
should be happy to trade the latter for the former. Suppose you
violate Transitivity, i.e., for you: A⪯BA\preceq B, B⪯CB\preceq
C but C≺AC\prec
A. Moreover, suppose you presently have AA. Then you should be willing to
trade AA for BB. The same goes for BB and CC: you
should be willing to trade BB
for CC. You strictly
prefer AA to CC, so you should be willing to trade
in CC plus some
sum $x\$x for AA. But now you are in the same situation as you
started, having AA but
neither BB nor CC, except that you have lost $x\$x! So in a few steps, each of which was
consistent with your preferences, you find yourself in a situation
that is clearly worse, by your own lights, than your original
situation. The picture is made more dramatic if we imagine that the
process could be repeated, turning you into a “money
pump”. Hence, the argument goes, there is something
(instrumentally) irrational about your intransitive preferences. If
your preferences were transitive, then you would not be vulnerable to
choosing a dominated option and serving as a money pump. Therefore,
your preferences should be transitive.
While the aforementioned controversies have not been settled, the
following assumptions will be made in the remainder of this entry: i)
the objects of preference may be heterogeneous prospects, incorporating a
rich and varied domain of properties, ii) preference between options
is a judgment of comparative desirability or choice-worthiness, and
iii) preferences satisfy both Transitivity and Completeness (although
the the latter condition will be revisited in Section 5). The question that now arises is
whether there are further general constraints on rational preference
over options.
2. Utility measures of preference
In our continuing investigation of rational preferences over
prospects, the numerical representation
(or measurement) of preference orderings will become
important. The numerical measures in question are known as utility
functions. The two main types of utility function that will play
a role are the ordinal utility function and the more
information-rich interval-valued (or cardinal)
utility function.
2.1 Ordinal utilities
It turns out that as long as the set of
prospects/options, SS, is finite,
any weak order of the options in SS can be represented by an ordinal utility
function. To be precise, let us say that uu is a utility function with
domain SS. We say that the
function uu represents
the preference ⪯\preceq between
the options in SS just in
case:
For any A,B∈S:u(A)≤u(B)⇔A⪯B(1)\tag{1}\text{For any}\ A, B \in S: u(A)\leq u(B) \Leftrightarrow A\preceq B
Another way to put this is that, when the above holds, the
preference relation can be represented as maximising utility,
since it always favours the option with highest utility.
The only information contained in an ordinal utility representation
is how the agent whose preferences are being represented orders
options, from least to most preferable. This means that
if uu is an ordinal utility
function that represents the ordering ⪯\preceq, then any utility
function u′u' that is an ordinal
transformation of uu—that
is, any transformation of uu that
also satisfies the biconditional in
(1)—represents ⪯\preceq just
as well as uu does. Hence, we say
that an ordinal utility function is unique only up to ordinal
transformations.
The result referred to above can be summarised as follows:
Theorem 1 (Ordinal
representation). Let SS be a finite set, and ⪯\preceq a weak
preference relation on SS. Then there is an ordinal utility
function that represents ⪯\preceq just in case ⪯\preceq is
complete and transitive.
This theorem should not be too surprising. If ⪯\preceq is complete and transitive
over SS, then the options
in SS can be put in an order, from
the most to the least preferred, where some options may fall in the
same position (if they are deemed equally desirable) but where there
are no cycles or loops. Theorem 1 just says
that we can assign numbers to the options in SS in a way that represents this order. (For a
simple proof of Theorem 1, except for a strict rather than a weak
preference relation, consult Peterson 2009: 95.)
Note that ordinal utilities are not very mathematically
“powerful”, so to speak. It does not make sense, for
instance, to compare the probabilistic expectations of different sets
of ordinal utilities. For example, consider the following two pairs of
prospects: the elements of the first pair are assigned ordinal
utilities of 2 and 4, while those in the second pair are assigned ordinal
utilities of 0 and 5. Let us specify a “flat” probability
distribution in each case, such that each element in the two pairs
corresponds to a probability of 0.5. Relative to this probability assignment, the
expectation of the first pair of ordinal utilities
is 3, which is larger
than 2.5, the expectation of the
second pair. Yet when we transform the ordinal utilities in a
permissible way—for instance by increasing the highest utility
in the second pair from 5
to 10—the ordering of
expectations reverses; now the comparison is between 3 and 5. The
significance of this point will become clearer in what follows, when
we turn to the comparative evaluation of lotteries and risky
choices. An interval-valued or cardinal utility function is necessary
for evaluating lotteries/risky prospects in a consistent way. By the
same token, in order to construct or conceptualise a cardinal utility
function, one typically appeals to preferences over lotteries.
2.2 Cardinalizing utility
In order to get a cardinal (interval-valued) utility representation
of a preference ordering—i.e., a measure that represents not
only how an agent orders the options but also says something about the
desirabilistic “distance” between options—we need a
richer setting; the option set and the corresponding preference
ordering will need to have more structure than for an ordinal utility
measure. One such account, owing to John von Neumann and Oskar
Morgenstern (1944), will be cashed out in detail below. For now, it is
useful to focus on the kind of option that is key to understanding and
constructing a cardinal utility function:
lotteries.[1]
Consider first an ordering over three regular options, e.g., the
three holiday destinations Amsterdam, Bangkok and Cardiff, denoted
AA, BB and CC respectively. Suppose your preference ordering
is A≺B≺CA\prec B \prec C. This information suffices to ordinally
represent your judgement; recall that any assignment of utilities is
then acceptable as long as CC gets a higher value than BB which
gets a higher value than AA. But perhaps we want to know more than
can be inferred from such a utility function—we want to know how
much CC is preferred over BB, compared to how much BB is
preferred over AA. For instance, it may be that Bangkok is
considered almost as desirable as Cardiff, but Amsterdam is a long way
behind Bangkok, relatively speaking. Or else perhaps Bangkok is only
marginally better than Amsterdam, compared to the extent to which
Cardiff is better than Bangkok. This kind of information about the
relative distance between options, in terms of strength of preference
or desirability, is precisely what is given by an interval-valued
utility function. The problem is how to ascertain this
information.
To solve this problem, Ramsey (1926) and later von Neumann and
Morgenstern (hereafter vNM) made the following suggestion: we
construct a new option, a lottery, LL, that has AA
and CC as its possible
“prizes”, and we figure out what chance the lottery must
confer on CC for you to be
indifferent between this lottery and a holiday in Bangkok. The basic
idea is that your judgment about Bangkok, relative to Cardiff on the
one hand and Amsterdam on the other, can be measured by the riskiness
of the lottery LL involving
Cardiff and Amsterdam that you deem equally desirable as Bangkok. For
instance, if you are indifferent between Bangkok and a lottery that
provides a very low chance of winning a trip to Cardiff, then you
evidently do not regard Bangkok to be much better than Amsterdam,
vis-à-vis Cardiff; for you, even a small improvement on Amsterdam,
i.e., a lottery with a small chance of Cardiff rather than Amsterdam,
is enough to match Bangkok.
The above analysis presumes that lotteries are evaluated in
terms of their expected choice-worthiness or
desirability. That is, the desirability of a lottery is effectively
the sum of the chances of each prize multiplied by the desirability of
that prize. Consider the following example: Suppose you are
indifferent between the lottery, LL, and the holiday in Bangkok,
BB, when the chance of the lottery resulting in a holiday in
Cardiff is 3/43/4. Call this particular lottery L′L'. The idea is
that Bangkok is therefore three quarters of the way up the
desirability scale that has Amsterdam at the bottom and Cardiff at the
top. If we stipulate that u(A)=0u(A)=0 and u(C)=1u(C)=1, then
u(B)=u(L′)=3/4u(B)=u(L')=3/4. This corresponds to the expected
desirability—or, as it is usually called, the expected
utility—of the lottery, since u(L′)=1/4⋅0+3/4⋅1=3/4u(L') = 1/4\cdot 0 + 3/4\cdot 1 =
3/4. That is, the value of the lottery is a probability weighted sum
of the utilities of its prizes, where the weight on each prize is
determined by the probability that the lottery results in that
prize.
We thus see that an interval-valued utility measure over options
can be constructed by introducing lottery options. As the name
suggests, the interval-valued utility measure conveys information
about the relative sizes of the intervals between the options
according to some desirability scale. That is, the utilities are
unique after we have fixed the starting point of our measurement and
the unit scale of desirability. In the above example, we could have,
for instance, assigned a utility value of 1 to AA and 5 to CC,
in which case we would have had to assign a utility value of 4
to BB, since 4 is 3/4 of the way
between 1 and 5. In other words, once we have assigned utility values
to AA and CC, the utility of L′L' and thus BB
has been determined. Let us call this second utility
function u′u'. It is related to our
original function as follows: u′=4⋅u+1u'=4\cdot u
+1. This relationship always holds between two such
functions: If uu is an
interval-valued utility function that represents the preference
ordering, ⪯\preceq,
and u′u' is a another utility
function that also represents this ordering, then there are
constants aa and bb, where aa
must be positive, such that u′=a⋅u+bu'=a\cdot u +
b. This is to say that interval-valued utility functions are
unique only up to positive linear transformation.
Before concluding this discussion of measuring utility, two related
limitations regarding the information such measures convey should be
mentioned. First, since the utilities of options, whether ordinal or
interval-valued, can only be determined relative to the
utilities of other options, there is no such thing as
the absolute utility of an option, at least not without
further assumptions.[2] Second, by the same reasoning, neither
interval-valued nor ordinal utility measures, as discussed here,
are interpersonally commensurable with respect to levels and
units of utility. By way of a quick illustration, suppose that both
you and I have the preference ordering described above over the
holiday options: A≺B≺CA\prec B \prec
C. Suppose too that, as per the above, we are both
indifferent between BB and the
lottery L′L' that has
a 3/43/4 chance of
yielding CC and
a 1/41/4 chance of
yielding AA. Can we then say that
granting me Cardiff and you Bangkok would amount to the same amount of
“total desirability” as granting you Cardiff and me
Bangkok? We are not entitled to say this. Our shared preference
ordering is, for instance, consistent with me finding a vacation in
Cardiff a dream come true while you just find it the best of a bad
lot. Moreover, we are not even entitled to say that the difference in
desirability between Bangkok and Amsterdam is the same for you as it
is for me. According to me, the desirability of the three options
might range from living hell to a dream come true, while according to
you, from bad to quite bad; both evaluations are consistent with the
above preference ordering. In fact, the same might hold for our
preferences over all possible options, including lotteries:
even if we shared the same total preference ordering, it might be the
case that you are just of a negative disposition—finding no
option that great—while I am very extreme—finding some
options excellent but others a sheer torture. Hence, utility
functions, whether interval-valued or ordinal, do not allow for
meaningful interpersonal comparisons. (Elster and Roemer 1993 contains
a number of papers discussing these issues; see also the SEP entry
on Social Choice Theory.)
2.3 The von Neumann and Morgenstern (vNM) representation theorem
The last section provided an interval-valued utility
representation of a person’s preferences over lotteries, on the
assumption that lotteries are evaluated in terms of expected
utility. Some might find this a bit quick. Why should we assume that people evaluate lotteries in terms of their expected utilities? The vNM theorem effectively
shores up the gaps in reasoning by shifting attention back to the
preference relation. In addition to Transitivity and Completeness, vNM
introduce further principles governing rational preferences over
lotteries, and show that an agent’s preferences can be
represented as maximising expected utility whenever her preferences
satisfy these principles.
Let us first define, in formal terms, the expected utility of a
lottery: Let LiL_i be a lottery
from the set L\bL of lotteries, and OikO_{ik} the outcome, or prize, of
lottery LiL_i that arises with
probability pikp_{ik}. The expected
utility of LiL_i is then defined
as:

The vNM equation.
EU(Li)=˙∑ku(Oik)⋅pikEU(L_i)\dot=\sum_k u(O_{ik}) \cdot p_{ik}

The assumption made earlier can now be formally stated:
For any Li,Lj∈L:Li⪯Lj⇔EU(Li)≤EU(Lj)(2)\begin{equation}\tag{2}
\text{For any}\ L_i, L_j\in \bL: L_i\preceq L_j\Leftrightarrow EU(L_i)\leq EU(L_j)
\end{equation}
When the above holds, we say that there is an expected utility
function that represents the agent’s preferences; in other
words, the agent can be represented as maximising expected
utility.
The question that vNM address is: What sort of preferences can be
thus represented? To answer this question, we must return to the
underlying preference relation ⪯\preceq over the set of options, in this case
involving lotteries. The vNM theorem requires the
set L\bL of lotteries be rather extensive: it is closed
under “probability mixture”, that is, if Li,Lj∈LL_i, L_j\in \bL, then compound lotteries
that have LiL_i
and LjL_j as possible prizes are
also in L\bL. (Another technical assumption, that will
not be discussed in detail, is that compound lotteries can always be
reduced, in accordance with the laws of probability, to simple
lotteries that only involve basic prizes.)
A basic rationality constraint on the preference relation has
already been discussed—that it weakly orders the options (i.e.,
satisfies Transitivity and Completeness). The following notation will
be used to introduce the two additional vNM axioms of
preference: {pA,(1−p)B}\{pA, (1-p)B\}
denotes a lottery that results either in AA, with probability pp, or BB, with
probability 1−p1-p.

Axiom 3 (Continuity)

Suppose A⪯B⪯CA\preceq B\preceq C. Then there is a p∈[0,1]p\in
[0,1] such that:
{pA,(1−p)C}∼B\{pA, (1-p)C\}\sim B
Axiom 4 (Independence)
Suppose A⪯BA\preceq B. Then for any CC, and any p∈[0,1]p\in
[0,1]:
{pA,(1−p)C}⪯{pB,(1−p)C}\{pA, (1-p)C\}\preceq \{pB, (1-p)C\}

Continuity implies that no outcome is so bad that you would not be
willing to take some gamble that might result in you ending up with
that outcome, but might otherwise result in you ending up with a more
favourable outcome, by your current lights, provided the chances of
the better outcome are good enough. Intuitively, Continuity guarantees
that an agent’s evaluations of lotteries are appropriately
sensitive to the probabilities of the lotteries’ prizes. It also
ensures, as the name suggests, that a sufficiently rich preference
ordering over lotteries can be represented by a continuous cardinal
function.
Independence implies that when two alternatives have the same
probability for some particular outcome, our evaluation of the two
alternatives should be independent of our opinion of that particular
outcome. Intuitively, this means that preferences between lotteries
should be governed only by the features of the lotteries that differ;
the commonalities between the lotteries should be effectively
ignored. A preference ordering must satisfy some version of
the Independence axiom for it to be possible to
represent it as maximising what is called an additively
separable function; in particular, a function according to which
the value (i.e., expected utility) of an option is a (probability
weighted) sum of the values of its possible outcomes.
Some people find the Continuity axiom an
unreasonable constraint on rational preference. Is there any
probability pp such that you would
be willing to accept a gamble that has that probability of you losing
your life and probability (1−p)(1-p)
of you winning $10? Many people think there is not. However, the very
same people would presumably cross the street to pick up a $10 bill
they had dropped. But that is just taking a gamble that has a very
small probability of being killed by a car but a much higher
probability of gaining $10! More generally, although people rarely
think of it this way, they constantly take gambles that have minuscule
chances of leading to immanent death, and correspondingly very high
chances of some modest reward. Every time we go for a walk,
drive our car, fly somewhere, and so on, there is some chance of us
having a fatal accident. But since the probabilities of these
accidents are sufficiently small, we decide to take our chances.
Independence seems a compelling requirement of rationality, when
considered in the abstract. Nevertheless, there are famous examples
where people often violate Independence without seeming
irrational. These examples involve complementarities between
the possible lottery outcomes. A particularly well-known such example
is the so-called Allais Paradox, which the French economist
Maurice Allais (1953) first introduced in the early 1950s. The paradox turns
on comparing people’s preferences over two pairs of lotteries
similar to those given in Table 1. The lotteries are described in
terms of the prizes that are associated with particular numbered
tickets, where one ticket will be drawn randomly (for
instance, L1L_1 results in a prize
of $2500 if one of the tickets numbered 2–34 is drawn).



 
1
2–34
35–100


L1L_1
$0
$2500
$2400


L2L_2
$2400
$2400
$2400




 
1
2–34
35–100


L3L_3
$0
$2500
$0


L4L_4
$2400
$2400
$0


Table 1. Allais’ paradox

In this situation, many people strictly prefer L2L_2 over L1L_1
but also L3L_3
over L4L_4 (as evidenced by their
choice behaviour, as well as their testimony), a pair of preferences
which will be referred to as Allais’
preferences.[3] A common way to rationalise Allais’
preferences, is that in the first choice situation, the risk of ending
up with nothing when one could have had $2400 for sure does not
justify the increased chance of a higher prize. In the second choice
situation, however, the minimum one stands to gain is $0 no matter
which choice one makes. Therefore, in that case many people do think
that the slight extra risk of $0 is worth the chance of a better
prize.
While the above reasoning may seem compelling, Allais’
preferences conflict with the Independence
axiom. The following is true of both choice situations: whatever
choice you make, you will get the same prize if one of the tickets in
the last column is drawn. Therefore, Independence implies that both
your preference between L1L_1
and L2L_2 and your preference
between L3L_3 and L4L_4 should be independent of the prizes in that
column. But when you ignore the last column, L1L_1 becomes identical to L3L_3 and L2L_2
to L4L_4. Hence, if you
prefer L2L_2 over L1L_1 but L3L_3
over L4L_4, there seems to be an
inconsistency in your preference ordering. And there is definitely a
violation of Independence. As a result, the pair of preferences under
discussion cannot be represented as maximising expected utility. (Thus
the “paradox”: many people think that Independence is a
requirement of rationality, but nevertheless also want to claim that
there is nothing irrational about Allais’ preferences.)
Decision theorists have reacted in different ways to Allais’
Paradox. This issue will be revisited
in Section 5.2, when challenges to EU
theory will be discussed. The present goal is simply to show that
Continuity and Independence are compelling constraints on rational
preference, although not without their detractors. The result vNM
proved can be summarised thus:
Theorem 2 (von Neumann-Morgenstern)
Let O\bO be a finite set of outcomes, L\bL
a set of corresponding lotteries that is closed under probability
mixture and ⪯\preceq a weak preference relation
on L\bL. Then ⪯\preceq satisfies axioms 1–4 if
and only if there exists a function uu, from
O\bO into the set of real numbers, that is unique up to
positive linear transformation, and relative to which ⪯\preceq can
be represented as maximising expected utility.
David Kreps (1988) gives an accessible illustration of the proof of
this theorem. The proof proceeds in two steps: first the existence of
an interval-valued utility function satisfying the preference axioms
is proved (this being a utility function that evaluates lotteries in
terms of their expected utility, as described previously). Then the
uniqueness of this utility measure (up to positive linear
transformation) is proved.
3. Making real decisions
The vNM theorem is a very important result for measuring the
strength of a rational agent’s preferences over sure options
(the lotteries effectively facilitate a cardinal measure over sure
options). But this does not get us all the way to making rational
decisions in the real world; we do not yet really have a decision
theory. The theorem is limited to evaluating options that come with an
objective probability distribution over outcomes—a situation
decision theorists and economists often describe as “choice
under risk” (Knight 1921).
In most ordinary choice situations, the objects of choice, over
which we must have or form preferences, are not like this. Rather,
decision-makers must consult their own beliefs about the
probability that one outcome or another will result from a specified
option. Decisions in such circumstances are often described as
“choices under uncertainty” (Knight 1921). For example,
consider the predicament of a mountaineer deciding whether or not to
attempt a dangerous summit ascent, where the key factor for her is the
weather. If she is lucky, she may have access to comprehensive weather
statistics for the region. Nevertheless, the weather statistics differ
from the lottery set-up in that they do not determine the
probabilities of the possible outcomes of attempting versus not
attempting the summit on a particular day. Not least, the mountaineer
must consider how confident she is in the data-collection procedure,
whether the statistics are applicable to the day in question, and so
on, when assessing her options in light of the weather.
Some of the most celebrated results in decision theory address, to
some extent, these challenges. They consist in showing what conditions
on preferences over “real world options” suffice for the
existence of a pair of utility and probability functions
relative to which the agent can be represented as maximising expected
utility. The standard interpretation is that, just as the utility
function represents the agent’s desires, so the probability
function represents her beliefs. The theories are referred to
collectively as subjective expected utility (SEU) theory as
they concern an agent’s preferences over prospects that are
characterised entirely in terms of her own beliefs and desires (but we
will continue to use the simpler label EU theory). In this
section, two of these results will be briefly discussed: that of
Leonard Savage (1954) and Richard Jeffrey (1965). A notable omission
due to space limitations is Anscombe and Aumann’s (1963)
result.
Note that these EU decision theories apparently prescribe two
things: (a) you should have consistent preference attitudes, and (b)
you should prefer the means to your ends, or at least you should
prefer the means that you assess will on average lead to your
ends (cf. Buchak forthcoming). The question arises: What is the
relationship between these prescriptions? The EU representation
theorems that will be outlined shortly seem to show that, despite
appearances, the two prescriptions are actually just one: anyone who
has consistent attitudes prefers the means to her ends, and vice
versa. But the puzzle remains that there are many ways to have
consistent preference attitudes, and surely not all of these amount to
preferring the means to one’s own true ends. This
puzzle is worth bearing in mind when appraising EU theory in its
various guises; it will come up again later.
3.1 Savage’s theory
Leonard Savage’s decision theory, as presented in his
(1954) The Foundations of Statistics, is without a doubt the
best-known normative theory of choice under uncertainty, in particular
within economics and the decision sciences. In the book Savage
presents a set of axioms constraining preferences over a set of
options that guarantee the existence of a pair of probability and
utility functions relative to which the preferences can be represented
as maximising expected utility. Nearly three decades prior to the
publication of the book, Frank P. Ramsey (1926) had actually proposed that a
different set of axioms can generate more or less the same
result. Nevertheless, Savage’s theory has been much more
influential than Ramsey’s, perhaps because Ramsey neither gave a
full proof of his result nor provided much detail of how it would go
(Bradley 2004). Savage’s result will not be described here in
full detail. However, the ingredients and structure of his theorem
will be laid out, highlighting its strengths and weaknesses.
The options or prospects in Savage’s theory are similar to
lotteries, except that the possible outcomes do not come with
objective chances but rather depend on whether a particular state of
the world is actual. Indeed, the primitives in Savage’s theory
are outcomes[4] and states (of the world). The former
are the good or bad states of affairs that ultimately affect and
matter to an agent, while the latter are the features of the world
that the agent has no control over and which are the locus of her
uncertainty about the world. Sets of states are
called events. This distinction between outcomes and states
serves to neatly separate desire and belief: the former are, according
to Savage’s theory, the target of desire, while the latter are
the target of belief.
The lottery-like options over which the agent has preferences are a
rich set of acts that effectively amount to all the possible
assignments of outcomes to states of the world. That is, acts are
functions from the state space to the outcome space, and the
agent’s preference ordering is taken to be defined over all such
possible functions. Some of these acts will look quite sensible:
consider the act that assigns to the event “it rains” the
outcome “miserable wet stroll” and assigns to the event
“it does not rain” the outcome “very comfortable
stroll”. This is apparently the act of going for a stroll
without one’s umbrella. Other Savage acts will not look quite so
sensible, such as the constant act that assigns to both
“it rains” and “it does not rain” the same
outcome “miserable wet stroll”. (Note that the constant
acts provide a way of including sure outcomes within the preference
ordering.) The problem with this act (and many others) is that it does
not correspond to anything that an agent could even in principle
choose to do or perform.[5]
Savage’s act/state(event)/outcome distinction can be
naturally represented in tabular form, with rows serving as acts that
yield a given outcome for each state/event column. Table 2 depicts the
two acts mentioned above plus a third one that the decision maker
might care about: the acts i) “go for stroll without
umbrella”, ii) “go for stroll with umbrella”, and
iii) the bizarre constant act. Of course, the set of acts required for
Savage’s theorem involve even more acts that account for all the
possible combinations of states and outcomes.



 
no rain
rain


stroll without umbrella
very comfortable stroll
miserable wet stroll


stroll with umbrella
comfortable stroll
comfortable stroll


constant act
miserable wet stroll
miserable wet stroll


Table 2. Savage-style decision
table

Before discussing Savage’s axioms, let us state the result
that they give rise to. The following notation will be
used: ff, gg, etc, are various acts, i.e., functions from the
set S\bS of states of the world to the
set O\bO of outcomes, with F\bF the set of these
functions. f(si)f(s_i) denotes the
outcome of ff when
state si∈Ss_i\in\bS
is actual. The expected utility of ff, according to Savage’s theory,
denoted U(f)U(f), is given by:

Savage’s equation
U(f)=∑iu(f(si)).P(si)U(f)=\sum_i u(f(s_i)).P(s_i)

The result Savage proved can be stated as
follows:[6]

Theorem 3 (Savage).
Let ⪯\preceq be a weak preference relation on F\bF. If
⪯\preceq satisfies Savage’s axioms, then the following holds:


The agent’s confidence in the actuality of the states
in S\bS can be represented by a unique (and
finitely additive) probability function, PP;

the strength of her desires for the ultimate outcomes
in O\bO can be represented by a utility
function, uu, that is unique up to
positive linear transformation;

and the pair (P,u)(P, u) gives rise
to an expected utility function, UU, that represents her preferences for the
alternatives in F\bF; i.e.,
for any f,g∈Ff, g\in\bF:
f⪯g⇔U(f)≤U(g)f\preceq g\Leftrightarrow U(f)\leq U(g)


The above result may seem remarkable; in particular, the fact that
a person’s preferences can determine a unique probability
function that represents her beliefs. On a closer look, however, it is
evident that some of our beliefs can be determined by examining our
preferences. Suppose you are offered a choice between two lotteries,
one that results in you winning a nice prize if a coin comes up heads
but getting nothing if the coin comes up tails, another that results
in you winning the same prize if the coin comes up tails but getting
nothing if the coin comes up heads. Then assuming that the
desirability of the prize (and similarly the desirability of no prize)
is independent of how the coin lands, your preference between the two
lotteries should be entirely determined by your comparative beliefs
for the two ways in which the coin can land. For instance, if you
strictly prefer the first lottery to the second, then that suggests
you consider heads more likely than tails.
The above observation suggests that one can gauge an agent’s
comparative beliefs, and perhaps more, from her preferences. Savage
went one step further than this, and defined comparative
beliefs in terms of preferences. To state Savage’s definition,
let .≾.\wcbrel be a weak comparative
belief relation, defined on the set S\bS of states of the
world. (.≺.\cbrel
and .∼.\wcbsim are defined in terms
of .≾.\wcbrel  in the usual
way.)

Definition 1 (Comparative Belief).
Suppose EE and FF are two events (i.e., subsets
of S\bS). Suppose XX and YY are two outcomes and
ff and gg two acts, with the following properties:

f(si)=Xf(s_i)=X for 
all si∈Es_i\in E, f(sj)=Yf(s_j)=Y for all sj∉Es_j\not\in E,
g(si)=Xg(s_i)=X for
all si∈Fs_i\in F, g(sj)=Yg(s_j)=Y for all sj∉Fs_j\not\in F,
Y⪯XY\preceq X.

Then E.≾.F⇔f⪯gE \wcbrel F\Leftrightarrow
f\preceq g.

Definition 1 is based on the simple observation that one would
generally prefer to stake a good outcome on a more rather than less
probable event. But the idea that this defines comparative
beliefs might seem questionable. We could, for instance, imagine
people who are instrumentally irrational, and as a result fail to
prefer gg to ff, even when the above conditions all hold and they
find FF more likely
than EE. Moreover, this definition
raises the question of how to define the comparative beliefs of those
who are indifferent between all outcomes. Perhaps no such
people exist (and Savage’s axiom P5
indeed makes clear that his result does not pertain to such
people). Nevertheless, it seems a definition of comparative beliefs
should not preclude that such people, if existent, have comparative
beliefs. Savage suggests that this definition of comparative beliefs
is plausible in light of his axiom P4, which will be stated below. In
any case, it turns out that when a person’s preferences satisfy
Savage’s axioms, we can read off her preferences a comparative
belief relation that can be represented by a (unique) probability
function.
Without further ado, let us state Savage’s axioms in
turn. These are intended as constraints on an agent’s preference
relation, ⪯\preceq, over a set of
acts, F\bF, as described above.  The first of
Savage’s axioms is the basic ordering axiom.
P1. (Ordering)
The relation ⪯\preceq is complete and transitive.
The next axiom is reminiscent of vNM’s Independence axiom. We
say that alternative ff
“agrees with” gg in
event EE if, for any state in
event EE, ff and gg yield
the same outcome.

P2. (Sure Thing Principle)
If ff, gg, and f′f', g′g' are such that:

ff agrees with gg and f′f' agrees with g′g' in event ¬E\neg
E,
ff agrees
with f′f' and gg agrees with g′g' in event EE,
and f⪯gf\preceq g,

then f′⪯g′f'\preceq g'.

The idea behind the Sure Thing Principle (STP) is essentially the
same as that behind Independence: since we should be able to evaluate
each outcome independently of other possible outcomes, we can safely
ignore states of the world where two acts that we are comparing result
in the same outcome. Putting the principle in tabular form may make
this more apparent. The setup involves four acts with the following
form:



 
EE
¬E\neg E


ff
X
Z


gg
Y
Z


f′f'
X
W


g′g'
Y
W


The intuition behind the STP is that if gg is weakly preferred
to ff, then that must be because the consequence YY is
considered at least as desirable as XX, which by the same reasoning
implies that g′g' is weakly preferred to f′f'.
Savage also requires that the desirability of an outcome be
independent of the state in which it occurs. To formalise this
requirement, Savage introduces the notion of a null event,
defined as follows:

Definition 2 (Null)
Event E is null just in case for any alternatives
f,g∈Ff,g\in\bF, f∼gf\sim g given E.
The intuition is that null events are those events an agent is
certain will not occur. If and only if an agent is certain
that EE will not occur, then it is
of indifference to her what the acts before her yield
under EE. The following axiom then
stipulates that knowing what state is actual does not affect the
preference ordering over outcomes:

P3. (State Neutrality)
If f(si)=Xf(s_i)=X and g(si)=Yg(s_i)=Y whenever si∈Es_i\in E and EE is
not null, then f⪯gf\preceq g given EE just in case X⪯YX\preceq
Y.
The next axiom is really what makes it possible to determine a
comparative belief relation from an agent’s preferences. Above
it was suggested that by asking you to stake a prize on whether a coin
comes up heads or tails, it can be determined which of these events,
heads or tails, you find more likely. But that suggestion is only
plausible if the size of the prize does not affect your
judgement of the relative likelihood of these two events. That
assumption is captured by the next axioms. Since the axiom is rather
complicated it will be stated in tabular form:

P4. Consider the
following acts:


 
EE
¬E\neg E


ff  
XX
X′X'


gg  
YY
Y′Y'




 
FF
¬F\neg F


f′f'
XX
X′X'


g′g'
YY
Y′Y'



Now suppose:
X′Y′f′⪯X,⪯Y,⪯f\begin{align}
X' &amp;\preceq X, \\
Y' &amp;\preceq Y,  \\
f' &amp;\preceq f
\end{align}
Then
g′⪯g.g'\preceq g.

Less formally (and stated in terms of strict preference): if you
prefer to stake the prize XX on ff rather than f′f', you must
consider EE more probable than FF. Therefore, you should prefer
to stake the prize YY on gg rather than g′g' since the prize
itself does not affect the probability of the events.
The next axiom is arguably not a rationality requirement, but one
of Savage’s “structural axioms” (see e.g., Suppes
2002). An agent needs to have some variation in preference for it to
be possible to read off her comparative beliefs from her preferences;
and, more generally, for it to be possible to represent her as
maximising expected utility. To this end, the next axiom simply
requires that there be some alternatives between which the agent is
not indifferent:

P5.
There are some f,g∈Ff,g\in\bF such that f≺gf\prec g.
When these five axioms are satisfied, the agent’s preferences
give rise to a comparative belief relation, .≾.\wcbrel , which has
the property of being a qualitative probability relation,
which is necessary for it to be possible to represent .≾.\wcbrel  by
a probability function. In other words, .≾.\wcbrel  satisfies the
following three conditions, for any events EE, FF and GG:


.≾.\wcbrel  is transitive and
complete,

if E∩G=∅=F∩GE\cap G=\emptyset=F\cap G,
then E.≾.F⇔E∪G.≾.F∪GE \wcbrel F\Leftrightarrow E\cup G
\wcbrel F\cup G,

∅.≾.E,\emptyset \wcbrel E,
  ∅.≺.S\emptyset
\cbrel \bS

Being a qualitative probability relation is, however, not
sufficient to ensure the possibility of probabilistic representation
(given Savage’s other axioms). To ensure this possibility,
Savage added the following structural axiom:

P6. (Non-atomicity)
Suppose f≺gf\prec g. Then for any X∈OX\in\bO, there
is a finite partition, {E1,E2,…Em}\{E_1, E_2, … E_m\},
of S\bS such that:


f′(si)=Xf'(s_i)=X for any si∈Eis_i\in E_i, but f′(si)=f(si)f'(s_i)=f(s_i) for any
sj∉Eis_j\not\in E_i,

g′(si)=Xg'(s_i)=X for any si∈Eis_i\in E_i, but g′(si)=g(si)g'(s_i)=g(s_i) for any
sj∉Eis_j\not\in E_i,

and f′≺gf'\prec g and f≺g′f\prec g'.


Like the Continuity axiom of vNM, Non-Atomicity implies that no
matter how bad an outcome XX is,
if gg is already preferred
to ff, then if we
add XX as one of the possible
outcomes of ff—thereby
constructing a new alternative f′f'—gg
will still be preferred to the modified alternative as long as the
probability of XX is sufficiently
small. In effect, Non-Atomicity implies that S\bS
contains events of arbitrarily small probability. It is not too
difficult to imagine how that could be satisfied. For instance, any
event FF can be partitioned into
two equiprobable sub-events according to whether some coin would come
up heads or tails if it were tossed. Each sub-event could be similarly
partitioned according to the outcome of the second toss of the same
coin, and so on, ad infinitum.
Savage showed that whenever these six axioms are satisfied, the
comparative belief relation can be represented by a unique
probability function. Having done so, he could rely on the vNM
representation theorem to show that an agent who satisfies all six
axioms[7] can be
represented as maximising expected utility, relative to a unique
probability function that plausibly represents the agents’
beliefs over the states and a cardinal utility function that plausibly
represents the agent’s desires for ultimate outcomes (recall the
statement of Savage’s theorem
above).[8]
Savage’s own proof is rather complicated, but Kreps (1988)
provides a useful illustration of it.
There is no doubt that Savage’s expected utility
representation theorem is very powerful. There are, however, two
important questions to ask about whether Savage achieves his aims: 1)
Does Savage characterise rational preferences, at least in
the generic sense? And 2) Does Savage’s theorem tell us how to
make rational decisions in the real world? Savage’s theory has
problems meeting these two demands, taken together. Arguably the core
weakness of the theory is that its various constraints and assumptions
pull in different directions when it comes to constructing realistic
decision models, and furthermore, at least one constraint (notably,
the Sure Thing Principle) is only plausible under decision modelling
assumptions that are supposed to be the output, not the input, of the
theory.
One well recognised decision-modelling requirement for
Savage’s theory is that outcomes be maximally specific in every
way that matters for their evaluation. If this were not the case, the
axiom of State Neutrality, for instance, would be a very implausible
rationality constraint. Suppose we are, for example, wondering whether
to buy cocoa or lemonade for the weekend, and assume that how good we
find each option depends on what the weather will be like. Then we
need to describe the outcomes such that they include the state of the
weather. For if we do not, the desirability of the outcomes will
depend on what state is actual. Since lemonade is, let us suppose,
better on hot days than cold, an outcome like “I drink lemonade
this weekend” would be more or less desirable depending on
whether it occurs in a state where it is hot or cold. This would be
contrary to the axiom of State Neutrality. Therefore, the appropriate
outcomes in this case are those of the form “I drink lemonade
this weekend in hot weather”. (Of course, this outcome must be
split into even more fine-grained outcomes if there are yet further
features that would affect the choice at hand, such as sharing the
drink with a friend who loves lemonade versus sharing the drink with a
friend who loves hot cocoa, and so on.)
The fact that the outcomes in the above case must be specific
enough to contain the state of the weather may seem rather
innocuous. However, this requirement exacerbates the above-mentioned
problem that many of the options/acts that Savage requires for his
representation theorem are nonsensical, in that the semantic content
of state/outcome pairs is contradictory. Recall that the domain of the
preference ordering in Savage’s theory amounts to every
function from the set of states to the set of outcomes (what Broome
1991a refers to as
the Rectangular Field Assumption). So if “I drink
lemonade this weekend in hot weather” is one of the outcomes we
are working with, and we have partitioned the set of states according
to the weather, then there must, for instance, be an act that has this
outcome in the state where it is cold! The more detailed the outcomes
(as required for the plausibility of State Neutrality), the less
plausible the Rectangular Field Assumption. This is an internal
tension in Savage’s framework. Indeed, it is difficult to see
how/why a rational agent can/should form preferences over nonsensical
acts (although see Dreier 1996 for an argument that this is not such an important
issue). If not, however, the agent’s preference ordering will
not be adequately rich for Savage’s rationality constraints to
yield the EU representation result.[9]
The axiom in Savage’s theory that has received most attention
is the Sure Thing Principle. It is not hard to see that this principle
conflicts with Allais’ preferences for the same reason these
preferences conflict with Independence
(recall Section 2.3). Allais’ challenge
will be discussed again later. For now, our concern is rather the Sure
Thing Principle vis-à-vis the internal logic of Savage’s
theory. To begin with, the Sure Thing Principle, like State
Neutrality, exacerbates concerns about the Rectangular Field
Assumption. This is because the Sure Thing Principle is only plausible
if outcomes are specific enough to account for any sort of
dependencies between outcomes in different states of the world. For
instance, if the fact that one could have chosen a risk-free
alternative—and thereby guaranteed an acceptable
outcome—makes a difference to the desirability of receiving
nothing after having taken a risk (as in Allais’ problem), then
that has to be accounted for in the description of the outcomes. But
again, if we account for such dependencies in the description of the
outcomes, we run into the problem that there will be acts in the
preference ordering that are nonsensical (see e.g., Broome 1991a:
ch. 5).
There is a further internal problem with Savage’s theory
associated with the Sure Thing Principle: the principle is only
reasonable when the decision model is constructed such that there is
probabilistic independence between the acts an agent is considering
and the states of the world that determine the outcomes of these
acts. Recall that the principle states that if we have four options
with the following form:



 
EE
¬E\neg E


ff
X
Z


gg
Y
Z


f′f'
X
W


g′g'
Y
W


then if gg is weakly preferred to ff, g′g' must be weakly
preferred to f′f'. Suppose, however, that there is probabilistic
dependency between the states of the world and the alternatives we are
considering, and that we find ZZ to be better than both XX and
YY, and we also find WW to be better than both XX and
YY. Moreover, suppose that gg makes ¬E\neg E more likely than
ff does, and f′f' makes ¬E\neg E more likely than g′g'
does. Then it seems perfectly reasonable to prefer gg over ff
but f′f' over g′g'.
Why is the requirement of probabilistic independence problematic?
For one thing, in many real-world decision circumstances, it is hard
to frame the decision model in such a way that states are intuitively
probabilistically independent of acts. For instance, suppose an agent
enjoys smoking, and is trying to decide whether to quit or not. How
long she lives is amongst the contingencies that affect the
desirability of smoking. It would be natural to partition the set of
states according to how long the agent lives. But then it is obvious
that the options she is considering could, and arguably should, affect
how likely she finds each state of the world, since it is well
recognised that life expectancy is reduced by smoking. Savage would
thus require an alternative representation of the decision
problem—the states do not reference life span directly, but
rather the agent’s physiological propensity to react in a
certain way to smoking.
Perhaps there is always a way to contrive decision models such that
acts are intuitively probabilistically independent of states. But
therein lies the more serious problem. Recall that Savage was trying
to formulate a way of determining a rational agent’s beliefs
from her preferences over acts, such that the beliefs can ultimately
be represented by a probability function. If we are interested in
real-world decisions, then the acts in question ought to be recognisable
options for the agent (which we have seen is questionable). Moreover, now we see that one of Savage’s
rationality constraints on preference—the Sure Thing
Principle—is plausible only if the modelled acts are
probabilistically independent of the states. In other words, this
independence must be built into the decision model if it is to
facilitate appropriate measures of belief and desire. But this is to
assume that we already have important information about the beliefs of
the agent whose attitudes we are trying to represent; namely what
state-partitions she considers probabilistically independent of her
acts.
The above problems suggest there is a need for an alternative
theory of choice under uncertainty. Richard Jeffrey’s theory,
which will be discuss next, avoids all of the problems that have been
discussed so far. But as we will see, Jeffrey’s theory has
well-known problems of its own, albeit problems that are not
insurmountable.
3.2 Jeffrey’s theory
Richard Jeffrey’s expected utility theory differs from
Savage’s in terms of both the prospects under
consideration and the rationality constraints on preferences
over these prospects. The distinct advantage of Jeffrey’s theory
is that real-world decision problems can be modelled just as the agent
perceives them; the plausibility of the rationality constraints on
preference do not depend on decision problems being modelled in a
particular (and one might add question-begging) way. We first describe
the prospects or decision set-up and the resultant expected utility
rule, before turning to the pertinent rationality constraints on
preferences and the corresponding theorem.
Unlike Savage, Jeffrey does not make a distinction between the
objects of instrumental and non-instrumental desire (acts and outcomes
respectively) and the objects of belief (states of the world). Rather,
Jeffrey assumes that propositions describing states of
affairs are the objects of both desire and belief. On first sight,
this seems unobjectionable: just as we can have views about whether it
will in fact rain, we can also have views about how desirable that
would be. The uncomfortable part of this setup is that acts, too, are
just propositions—they are ordinary states of affairs about
which an agent has both beliefs and desires. Just as the agent has a
preference ordering over, say, possible weather scenarios for the
weekend, she has a preference ordering over the possible acts that she
may perform, and in neither case is the most preferred state of
affairs necessarily the most likely to be true. In other words, the
only thing that picks out acts as special is their substantive
content—these are the propositions that the agent has the power
to choose/make true in the given situation. It is as if the agent
assesses her own options for acting from, rather, a third-person
perspective. If one holds that a decision model should convincingly
represent the subjective perspective of the agent in question, this is
arguably a weakness of Jeffrey’s theory, although it may be one
without consequence.[10]
Before proceeding, a word about propositions may be helpful: they
are abstract objects that can be either true or false, and are
commonly identified with sets of possible worlds. A possible world can
be thought of as an abstract representation of how things are or could
be (Stalnaker 1987; see also SEP entry
on Possible Worlds). The proposition
that it rains at time tt, for
example, is just the set of all worlds where it rains at
time tt. And this particular
proposition is true just in case the actual world happens to be a
member of the set of all worlds where it rains at
time tt. In the context of
decision theory, the pertinent worlds are the epistemically
possible ones, given the agent’s vantage point.
The basic upshot of Jeffrey’s theory is that the desirability
of a proposition, including one representing acts, depends both on the
desirabilities of the different ways in which the proposition can be
true, and the relative probability that it is true in these respective
ways. To state this more precisely, pp, qq, etc., will denote
propositional variables. Let {p1,p2,…,pn}\{p_1, p_2, …, p_n\} be one
amongst many finite partitions of the proposition pp; that is, sets
of mutually incompatible but jointly exhaustive ways in which the
proposition pp can be realised. For instance, if pp is the
proposition that it is raining, then we could partition this
proposition very coarsely according to whether we go
to the beach or not, but we could also partition pp much more
finely, for instance according to the precise millimetres-per-hour amount of rain. The desirability of
pp according to Jeffrey, denoted Des(p)Des(p), is given by:

Jeffrey’s equation.
Des(p)=∑iDes(pi).P(pi∣p)Des(p)=\sum_i Des(p_i).P(p_i\mid p)

This is effectively a conditional expected utility formula
for evaluating pp. As noted, a special case is when the content of
pp is such that it is recognisably something the agent can choose
to make true, i.e., an act.
One important difference between Jeffrey’s desirability
formula and Savage’s expected utility formula, is that there is
no distinction made between desirability and “expected”
desirability, unlike what has to be done in Savage’s theory,
where there is a clear distinction between utility, measuring an
agent’s fundamental desires for ultimate outcomes, and expected
utility, measuring an agent’s preferences over uncertain
prospects or acts. This disanalogy is due to the fact that there is no
sense in which the pip_is
that pp is evaluated in terms of
need to be ultimate outcomes; they can themselves be thought of as
uncertain prospects that are evaluated in terms of their different
possible realisations.
Another important thing to notice about Jeffrey’s way of
calculating desirability, is that it does not assume probabilistic
independence between the alternative that is being
evaluated, pp, and the possible
ways, the pip_i, that the
alternative may be realised. Indeed, the probabilities of
each pip_i are explicitly
conditional on the pp in
question. When it comes to evaluating acts, this is to say (in
Savage’s terminology) that the probabilities for the possible
state-outcome pairs for the act are conditional on the act in
question. Thus we see why the agent can describe her decision problem
just as she sees it; there is no requirement that she identify a set
of states (in Jeffrey’s case, this would be a partition of the
proposition space that is orthogonal to the act partition) such that
the states are appropriately fine-grained and probabilistically
independent of the acts.
It should moreover be evident, given the discussion of the Sure
Thing Principle (STP) in Section 3.1, that
Jeffrey’s theory does not have this axiom. Since states may be
probabilistically dependent on acts, an agent can be represented as
maximising the value of Jeffrey’s desirability function while
violating the STP. Moreover, unlike Savage’s, Jeffrey’s
representation theorem does not depend on anything like the
Rectangular Field Assumption. The agent is not required to have
preferences over artificially constructed acts or propositions that
turn out to be nonsensical, given the interpretation of particular
states and outcomes. In fact, only those propositions the agent
considers to be possible (in the sense that she assigns them a
probability greater than zero) are, according to Jeffrey’s
theory, included in her preference ordering.
Of course, we still need certain structural assumptions in order to
prove a representation theorem for Jeffrey’s theory. In
particular, the set Ω\Omega, on
which the preference ordering ⪯\preceq is defined, has to be an atomless
Boolean algebra of propositions, from which the impossible
propositions, denoted ⊥\bot, have
been removed. A Boolean algebra is just a set of e.g., propositions or
sentences that is closed under the classical logical operators and
negation. An algebra is atomless just in case all of its elements can
be partitioned into finer elements. The assumption
that Ω\Omega is atomless is thus
similar to Savage’s P6, and can be given
a similar justification: any way pip_i in which pp
can be true can be partitioned into two further propositions according
to how some coin would land if tossed.
So under what conditions can a preference
relation ⪯\preceq on the
set Ω\Omega be represented as
maximising desirability? Some of the required conditions on preference
should be familiar by now and will not be discussed further. In
particular, ⪯\preceq has to be
transitive, complete and continuous (recall our discussion
in Section 2.3 of vNM’s Continuity
preference axiom).
The next two conditions are, however, not explicitly part of the
two representation theorems that have been considered so far:

Averaging
If p, q∈Ωp,\ q\in \Omega are mutually incompatible, then
p⪯q⇔p⪯p∪q⪯qp\preceq q\Leftrightarrow p\preceq p\cup q\preceq q
Impartiality
Suppose p, q∈Ωp,\ q\in \Omega are mutually incompatible and p∼qp\sim
q. Then if p∪r∼q∪rp\cup r\sim q\cup r for some rr that is
mutually incompatible with both pp and qq and is such that
¬(r∼p)\neg(r\sim p), then p∪r∼q∪rp\cup r\sim q\cup r for every
such rr.

Averaging is the distinguishing rationality condition in
Jeffrey’s theory. It can actually be seen as a weak version of
Independence and the Sure Thing Principle, and it plays a similar role
in Jeffrey’s theory. But it is not directly inconsistent with
Allais’ preferences, and its plausibility does not depend on the
type of probabilistic independence that the STP implies. The postulate
requires that no proposition be strictly better or worse than all of
its possible realisations, which seems to be a reasonable
requirement. When pp and qq are mutually incompatible, p∪qp\cup
q implies that either pp or qq is true, but not both. Hence,
it seems reasonable that p∪qp\cup q should be neither strictly more
nor less desirable than both pp and qq. Suppose one of pp
or qq is more desirable than the other. Then since p∪qp\cup q is
compatible with the truth of either the more or the less desirable of
the two, p∪qp\cup q’s desirability should fall strictly between
that of pp and that of qq. However, if pp and qq are
equally desirable, then p∪qp\cup q should be as desirable as each of
the two.
The intuitive appeal of Impartiality, which plays a similar role in
Jeffrey’s theory as P4 does in Savage’s, is not as great
as that of Averaging. Jeffrey himself admitted as much in his comment:

 The axiom is there because we need it, and it is
justified by our antecedent belief in the plausibility of the result
we mean to deduce from it.  (1965: 147)

Nevertheless, it does seem that an argument can
be made that any reasonable person will satisfy this axiom. Suppose
you are indifferent between two propositions, pp and qq, that
cannot be simultaneously true. And suppose now we find a
proposition rr, that is pairwise
incompatible with both pp
and qq, and which you find more
desirable than both pp
and qq. Then if it turns out that
you are indifferent between pp
joined with rr
and qq joined
with rr, that must be because you
find pp and qq equally probable. Otherwise, you would prefer
the union that contains the one of pp and qq that
you find less probable, since that gives you a higher chance of the
more desirable proposition rr. It
then follows that for any other proposition ss that satisfies the aforementioned
conditions rr satisfies, you
should also be indifferent between p∪sp\cup
s and q∪sq\cup s, since,
again, the two unions are equally likely to result
in ss.
The first person to prove a theorem stating sufficient conditions
for a preference relation to be representable as maximising the value
of a Jeffrey-desirability function was actually not Jeffrey himself,
but the mathematician Ethan Bolker (1966,
1967). He proved
the following result (recall the definition of a “desirability
measure” given above):[11]
Theorem 4 (Bolker)
Let Ω\Omega be a complete and atomless Boolean algebra of
propositions, and ⪯\preceq a continuous, transitive and complete
relation on Ω∖⊥\Omega \setminus \bot , that satisfies Averaging and
Impartiality. Then there is a desirability measure on Ω∖⊥\Omega
\setminus \bot  and a probability measure on Ω\Omega relative to
which ⪯\preceq can be represented as maximising
desirability.
Unfortunately, Bolker’s representation theorem does not yield
a result anywhere near as unique as Savage’s. That is, even if a
person’s preferences satisfy all the conditions in
Bolker’s theorem, then it is neither guaranteed that there will
be just one probability function that represents her beliefs nor that
the desirability function that represents her desires will be unique
up to a positive linear transformation. Even worse, the same
preference ordering satisfying all these axioms could be represented
as maximising desirability relative to two probability functions that
do not even agree on how to order propositions according to their
probability.[12]
For those who think that the only way to determine a person’s
comparative beliefs is to look at her preferences, the lack of
uniqueness in Jeffrey’s theory is a big problem. Indeed, this
may be one of the main reasons why economists have largely ignored
Jeffrey’s theory. Economists have traditionally been skeptical
of any talk of a person’s desires and beliefs that goes beyond
what can be established by examining the person’s preferences,
which they take to be the only attitude that is directly revealed by a
person’s behaviour. For these economists, it is therefore
unwelcome news if we cannot even in principle determine the
comparative beliefs of a rational person by looking at her
preferences.
Those who are less inclined towards behaviourism might, however,
not find this lack of uniqueness in Bolker’s theorem to be a
problem. James Joyce (1999), for instance, thinks that Jeffrey’s
theory gets things exactly right in this regard, since one should not
expect that reasonable conditions imposed on a person’s
preferences would suffice to determine a unique probability function
representing the person’s beliefs. It is only by imposing overly
strong conditions, as Savage does, that we can achieve this. However,
if uniqueness is what we are after, then we can, as Joyce points out,
supplement the Bolker-Jeffrey axioms with certain conditions on the
agent’s comparative belief relation that guarantee that it gives
rise to one and only one probability function (for instance, the
comparative belief conditions proposed in Villegas 1964). Having done
so, we can show that any function representing the agent’s
desires will be unique up to a positive linear transformation.
Instead of adding specific belief-postulates to Jeffrey’s theory,
as Joyce suggests, one can get the same uniqueness result by enriching
the set of prospects. Richard Bradley (1998) has, for instance, shown
that if one extends the Boolean algebra in Jeffrey’s theory to
indicative conditionals, then a preference relation on the extended
domain that satisfies the Bolker-Jeffrey axioms (and some related
axioms that specifically apply to conditionals) will be representable
as maximising desirability, where the probability function is unique
and the desirability function unique up to a positive linear
transformation.
4. Broader significance of  Expected Utility (EU) theory
Even if we suspend doubts about the basic commitments of prominent
versions of EU theory (which will be taken up
in Section 5), there is a large question as to
what the theory really establishes about how agents should reason in
the real world. This section begins with the negative perspective, by
considering the gaps left open by EU theory regarding rational
preference attitudes. The positive perspective will then be discussed, in
particular the substantial contribution that EU theory makes, not just
to questions of choice or practical rationality, but also to
epistemology and value theory.
4.1 Limits of EU theory
When it comes to making real decisions, one might wonder how much
EU theory helps. Sure, the theory has much to say about assessing the
rationality of an agent’s preference attitudes once these
attitudes are suitably expressed relative to a particular
representation of the agent’s decision situation. The concern,
however, is that EU theory does not itself address important prior
questions of representation/decision modelling. As such, one might
doubt whether the theory is adequate for assessing the rationality of
real-world choices, or whether it has any substantial content at
all.
One way to put the worry is in terms of an infinite regress of
decisions. Consider for instance, a decision about how to spend a
holiday period: What is the full range of available options and how
should one conceive the possible outcomes of these options? It seems
the agent faces an initial choice about representation. But such a
choice, if it is to be justified, must surely be governed by a theory
of rational decision. As pointed out by Resnik (1987: 11), this seems
to lead to an infinite regress: before using decision theory
to make a particular choice, an agent apparently needs to employ the
theory to decide how to frame the decision problem. That is, she needs
to initially solve a second-order decision problem; in
formulating that problem, however, presumably she needs to solve
a third-order decision problem; and so on, ad
infinitum. Such a regress would surely make EU theory unusable
because the agent can never actually begin to solve her initial
decision problem.
There are at least two flaws, however, in the above
argument. First, it is not clear that expected utility theory can be
applied to a choice between two decision representations. How would
the two representations be compared? What would be the relevant
utility function to be maximised? So the infinite regress looks to be
ill-conceived. Second, defenders of EU theory can simply argue that,
as per all normative models, the initial representation of the world
is beyond the scope of the theory. Indeed, whatever the modelling
perspective, whether that of the deciding agent herself or rather an
external observer (i.e., the first-person or the third-person
normative perspective, to use the terminology of Bermúdez 2009), the
decision problem must simply be described in as much detail as
necessary, given what the agent cares
about.[13]
Furthermore, even if a choice is ultimately judged in relation to an
arational framing of the decision problem, that does not mean that the
choice itself cannot be deemed rational. Consider the first-person
perspective: Suppose that a decision-maker has arationally settled on
a frame for a decision she is faced with, and the decision she makes
based on this frame accords with the principles of rationality, i.e.,
EU theory. Moreover, suppose the decision-maker has good reasons for
believing that another way of framing the decision problem would not
lead her to make a better choice, as judged by her own lights. When
these two conditions are satisfied, it seems we should accept the
choice as rational, even though it is ultimately based on a choice of
frame that was not fully rational. (See Joyce 1999: 74–77, for
an excellent discussion of this issue.)
There remains a deeper worry about the lack of a rational basis for
decision framing—that it makes EU theory too permissive in that
any choice dispositions can be represented as reflecting rational
preferences, via astute selection of decision frame. Even worse, it
seems that if an agent’s preferences were modelled as
irrational, this would suggest a defect in the decision framing rather
than a defect in the agent’s reasoning, since, after all, the decision
model is supposed to capture everything that bears on an agent’s
preferences. This issue is far-reaching. It arises even in cases like
Allais’ decision problem that is specifically designed to
identify preferences that are at odds with EU theory: some argue that
apparently irrational preferences by the lights of EU theory can be
shown to be rational under an appropriate model of the problem. This
position, alongside other positions on Allais’ problem, will be
discussed in Section 5.2 below. For the
moment, let us simply note two responses to the general charge that EU
theory is vacuous as a standard of rationality:


One can resist the charge by asserting that some decision framings
are more adequate than others and the better framings need not yield
consistency with EU theory. Adequacy here may hinge on empirical
tradeoffs between fit and simplicity in representing the agent’s
“web” of preference attitudes, or it may hinge on further
normative principles regarding what sorts of outcomes an agent may
reasonably discriminate (for discussion, see Tversky 1975; Broome
1991a & 1993; Pettit
1993; Guala 2006).

One can alternatively embrace the charge that EU theory is
maximally permissive and interpret the theory not as a standard
against which an agent may pass or fail, but rather as an organising
principle that enables the identification and measurement of an
agent’s fundamental preference attitudes, namely her beliefs and
desires (see esp. Guala 2008).

Whether or not it is true by definition, i.e., whether real agents
can fail to satisfy its demands, the EU characterisation of
rationality serves to structure and thus identify an agent’s
preference attitudes. The substantial nature of these preference
attitudes—the agent’s beliefs and desires—can then
be examined, perhaps with an eye to transformation or reform.
It may yet be argued that EU theory does not go far enough in
structuring an agent’s preference attitudes so that we may
understand and assess these attitudes. Various generalisations of the
theory have been suggested that offer more detailed analyses of
preferences. For instance, the multiple criteria decision
framework (see, for instance, Keeney and Raiffa 1993) takes an
agent’s overall preference ordering over options to be an
aggregate of the set of preference orderings corresponding to all the
pertinent dimensions of value. Under certain assumptions, the overall
or aggregate preference ordering is compatible with EU
theory. Dietrich and List (2013 & 2015) have proposed an
even more general framework for representing the reasons underlying
preferences. In their framework, preferences satisfying some minimal
constraints are representable as dependent on the bundle of properties
in terms of which each option is perceived by the agent in a given
context. Properties can, in turn, be categorised as either option
properties (which are intrinsic to the outcome), relational
properties (which concern the outcome in a particular context),
or context properties (which concern the context of choice
itself). Such a representation permits more detailed analysis of the
reasons for an agent’s preferences and captures different kinds
of context-dependence in an agent’s choices. Furthermore, it
permits explicit restrictions on what counts as a legitimate reason
for preference, or in other words, what properties legitimately
feature in an outcome description; such restrictions may help to
clarify the normative commitments of EU theory.
4.2 On rational belief
It was noted from the outset that EU theory is as much a theory of
rational choice, or overall preferences amongst acts, as it is a
theory of rational belief and desire. Indeed, the label Bayesian
decision theory (used in epistemology circles) brings to the
forefront the commitment to probabilism, i.e., that beliefs
may come in degrees which, on pain of irrationality, can be
represented numerically in accordance with the probability
calculus. This is a substantial position in epistemology/ philosophy
of science. It makes explicable the notion of partial belief,
or varying strength of belief. Moreover, it allows for a particular
approach to scientific inference, including key concepts like
“evidence”, “evidential support”,
“induction” versus “abduction”, and the
bearing of “coherence” and “explanatory power”
on truth (see the relevant SEP entries). The major
competitor to probabilism, as regards scientific inference, is
arguably the collection of approaches known as Classical or error
statistics, which deny the sense of “degrees of support”
(probabilistic or otherwise) conferred on a hypothesis by
evidence. These approaches focus instead on whether a hypothesis has
survived various “severe tests”, and inferences are made
with an eye to long-run error as opposed to single-case error, which
would require decision-theoretic reasoning (see the SEP entry
on Philosophy of Statistics). There are
also more limited criticisms of Bayesian decision theory, notably,
those motivating imprecise probabilism, which bear on rational belief and will be
discussed in Section 5.3 below.
With respect to the Bayesian position itself, the question arises:
How deep is the connection between rational preference and rational
belief? At the far pragmatic end of the spectrum is the position that
the very meaning of belief involves preference. Indeed, recall this
manoeuvre in Savage’s theory, discussed earlier
in Section 3.1. Many question the plausibility,
however, of equating comparative belief with preferences over
specially contrived prospects. A more moderate position is to regard
these preferences as entailed by, but not identical with, the relevant
comparative beliefs. Whether or not beliefs merely ground or are
defined in terms of preference, there is a further question as to
whether the only justification for the claim that rational belief satisfies the
probability calculus is a pragmatic one, i.e., an argument resting on
there being otherwise bad consequences in terms of preferences and
implied choice behaviour. Some contend that accounts of rational
belief can and should be ultimately justified on epistemic grounds;
Joyce (1998), for instance, offers a non-pragmatic justification of
probabilism that rests on the notion of overall “expected
distance from the truth” of one’s beliefs. (For further
developments of this position, see the SEP entry
on Epistemic Utility Arguments for
Probabilism.) The advantage of the latter position is that
probabilism, as an account of rational belief, does not stand or fall
with any particular theory of practical rationality.
There are differences in the Bayesian camp regarding the tightness
of the connection between rational belief and rational choice. What is
undeniable, however, is the significant role that pragmatic
rationality plays in the Bayesian approach to managing one’s
beliefs. To begin with, the clear connection between belief and
decision allows one to reflect on one’s beliefs in light of
their pragmatic consequences. Moreover, whether or not one should seek
further evidence to inform one’s beliefs is treated as a
pragmatic issue, referred to as the “value of information”
problem. The idea is that we can reason about whether and how to go
about seeking further evidence only in relation to a decision problem;
the subjective expected utility of making the decision on the basis of
existing evidence is compared with the expected utility of seeking
further evidence before making the decision. This reasoning was made
prominent in a paper by Good (1967), where he proves that one should
always seek “free evidence” that may have a bearing on the
decision at hand. (Precursors of this theorem can be found in Ramsey
(1990, published posthumously) and Savage (1954).) Strictly speaking,
value-of-information reasoning should underpin all Bayesian
experimental design. It is certainly employed explicitly by Bayesian
statisticians in cases where delicate tradeoffs must be made between
the desiderata of well-informed inference and low-cost evidence (for
one example, see Anscombe 1963).
4.3 On rational desire
The EU characterisation of rational desire is in many ways highly
permissive, but it may be more controversial than first meets the
eye. Here the focus will be on the compatibility of EU theory with
prominent ethical positions regarding the choice-worthiness of acts,
as well as meta-ethical positions regarding the nature of value and
its relationship to belief.
The initial question is whether EU theory is neutral with respect
to normative ethics, or whether it is compatible only with ethical
consequentialism, given that the ranking of an act is fully determined
by the expectation of the utility of its possible outcomes. Such a
model does not seem able to capture or even accommodate basic
deontological notions like strict cutoffs between prohibited and
permissible acts, the permissibility of an act depending on more than
its expected consequences, or the significance of intended versus
non-intended harms and benefits. An initial response, however, is that
we should not read too much into the formal concepts of EU theory. The
utility measure over acts and outcomes is simply a convenient way to
represent a preference ordering, and leaves much scope for different
ways of identifying and evaluating outcomes. Just as the theory is not
restricted to the selfish evaluation of outcomes (a common
misconception due to the prominence of this type of EU model in
orthodox economics; see, for instance, Sen 1977), it is also not
restricted to evaluations in line with orthodox
consequentialism. To begin with, properties that are typically
associated with acts themselves may nonetheless be included in the
description of the outcomes. For instance, the decision-maker’s
own act of lying can be referenced in all possible outcomes, and
treated differently from others’ acts of lying. If an act is
prohibited, then this may be referenced in all the possible outcomes
of the act. Indeed, any tensions between EU theory and deontological
ethical accounts (perhaps to do with the interplay of absolute prohibitions
and risk) may simply reveal gaps or perhaps even inconsistencies in
those deontological accounts (see, for instance, Broome
1991b; Jackson and Smith
2006; Colyvan et al. 2010).
There are subtler features of the EU account of rational desire
that warrant investigation; a number of these issues concerning
particular EU axioms have been discussed in earlier sections, or will
be taken up in more detail in later sections. One issue worth singling
out here, given its relevance to the compatibility of EU theory with
prominent positions in ethics, is the assumption of a single complete
preference ordering. Indeed, the dispensability of completeness is
typically motivated by appeal to cases involving competing sources of
value that are difficult to tradeoff against each other (see Levi 1986
and Chang 2002; cf. the brief comments on the Completeness axiom
in Section 1). Must a rational agent have
a defined preference between, say, two career options that pull in
different directions as regards opportunities for creative
self-expression versus community service (perhaps a career as a dancer
versus a career as a doctor in remote regions)? The incommensurability
of certain dimensions of value, say, freedom versus welfare, or
average versus total welfare, may even be a feature of some
ethical theories; this puts a lot of pressure on completeness being a
reasonable idealisation, let alone a requirement, for rational
preference.
Let us turn now to potential meta-ethical commitments of EU
theory. David Lewis (1988, 1996) famously employed EU theory to argue
against anti-Humeanism, the position that we are sometimes
moved entirely by our beliefs about what would be good, rather than by
our desires as the Humean claims. He formulated the anti-Humean theory as postulating a necessary connection between, on the one hand,
an agent’s desire for any proposition AA, and, on the other hand, her belief in a
proposition about AA’s
goodness; and claimed to prove that when such a connection is formulated in
terms of EU theory, the agent in question will be dynamically
incoherent. Several people have criticised Lewis’s argument. For
instance, Broome (1991c), Byrne and Hájek (1997) and Hájek and Pettit
(2004) suggest
formulations of anti-Humeanism that are immune to Lewis’
criticism, while Stefánsson (2014) and Bradley and Stefánsson (2016) argue that Lewis’ proof
relies on a false assumption. Nevertheless, Lewis’ argument no
doubt provoked an interesting debate about the sorts of connections
between belief and desire that EU theory permits. There are, moreover,
further questions of meta-ethical relevance that one might investigate
regarding the role and structure of desire in EU theory. For instance,
Jeffrey (1974) and Sen (1977) offer some preliminary investigations as
to whether the theory can accommodate higher-order
desires/preferences, and if so, how these relate to first-order
desires.
5. Challenges to EU theory
Thus far the focus has been on prominent versions of the
standard theory of rational choice: EU theory. This section picks up
on the key criticisms of EU theory that have been developed into
alternative accounts of rational choice. The proposed innovations to
the standard theory are distinct and so are discussed separately, but
they are not necessarily mutually exclusive.
5.1 Causal anomalies
Only a few remarks will be made about the “causal
challenge” to EU theory, as the interested reader can consult
the SEP entry on Causal Decision
Theory and the references therein. The supposed problem for EU
theory (or at least Jeffrey’s version of it) is its commitment
to the desirability or choice-worthiness of acts being dependent on
the states of affairs that are probabilistically correlated with the
acts. Jeffrey’s theory has accordingly been
dubbed evidential decision theory. Dissenters point out that
correlation is not necessarily causation; in particular there may be a
common cause underlying the correlation between a particular act being
chosen and a good state of affairs or outcome. The position
of causal decision theorists is that we should choose acts
because they actually bring about good outcomes, not because they
happen to harbour news of good outcomes. Savage’s theory leaves
open this possibility, but offers no resources for determining whether
acts, states and outcomes are defined in a way that reflects causal
relationships rather than mere probabilistic relationships. The
various causal decision theories make causal hypotheses explicit, and
rank acts according to their expected success in bringing about good
outcomes. The theories differ in terms of the underlying EU theory,
and the model of causal dependency that is employed.
5.2 On separability: Risk and regret attitudes
Expected utility theory has been criticised for not allowing for
value interactions between outcomes in different, mutually
incompatible states of the world. For instance, recall that when
deciding between two risky options you should, according to
Savage’s version of the theory, ignore the states of the world
where the two options result in the same outcome. That seems very
reasonable if we can assume separability between outcomes in
different states of the world; i.e., if the contribution that an
outcome in one state of the world makes towards the overall value of
an option is independent of what other outcomes the option might
result in. For then identical outcomes (with equal probabilities)
should cancel each other out in a comparison of two options, which
would entail that if two options share an outcome in some state of the
world, then when comparing the options, it does not matter what that
shared outcome is.
The Allais paradox, discussed in Section
2.3 above, is a classic example where the aforementioned
separability fails. For ease of reference, the options that generate
the paradox are reproduced as Table 3. Recall
from Section 2.3 that people tend to
prefer L2L_2 over L1L_1 and L3L_3
over L4L_4—an attitude that
has been called Allais’ preferences—in violation
of expected utility theory. The violation occurs precisely because the
contributions that some of these outcomes make towards the overall
value of an option is not independent of the other outcomes that the
option can have. Compare the extra chance of outcome $0
that L1L_1 has
over L2L_2 with the same extra
chance of $0 that L3L_3 has
over L4L_4. Many people think that
this extra risk counts more heavily in the first comparison than the
latter; i.e., that an extra 0.01 chance of $0 contributes a greater
negative value to L1L_1 than
to L3L_3. Some explain this by
pointing out that the regret one would experience by winning
nothing when one could have had $2400 for sure—i.e., when
choosing L1L_1
over L2L_2 and the first ticket is
drawn—is much greater than the regret one would experience by
winning nothing when the option one turned down also had a high chance
of resulting in $0—such as when choosing L3L_3 over L4L_4
(see e.g., Loomes and Sugden 1982). Others think the difference that
$0 contributes towards the value of the options has nothing to do with
what one experiences when winning nothing, but is explained by the
fact that the increased chance of winning nothing counts as a greater
risk when the minimum one stands to gain without the increased chance
is $2400, than when the minimum one stands to gain without the
increased chance is only $0 anyway (see, e.g., Buchak 2013). In either
case, the value that $0 contributes towards the overall value of an
option clearly depends on what other outcomes the option might result
in.



 
1
2–34
35–100


L1L_1
$0
$2500
$2400


L2L_2
$2400
$2400
$2400




 
1
2–34
35–100


L3L_3
$0
$2500
$0


L4L_4
$2400
$2400
$0


Table 3. Allais’ paradox

Various attempts have been made to make Allais’ preferences
compatible with some version of expected utility theory. A common
response is to suggest that the choice problem has been incorrectly
described. If it really is rational to evaluate $0 differently
depending on which lottery it is part of, then perhaps this should be
accounted for in the description of the outcomes (Broome 1991a). For
instance, we could add a variable to the $0 outcome that L1L_1 might
result in to represent the extra regret or risk associate with that
outcome compared to the $0 outcomes from the other lotteries (as done
in Table 4). If we do that, Allais’
preferences are no longer inconsistent with EU theory. The simplest
way to see this, is to note that when we ignore the state of the world
where the options that are being compared have the same outcome (i.e.,
when we ignore the last column in Table 4), L1L_1 is no longer
identical to L3L_3, which means that the Independence axiom of von
Neumann and Morgenstern (and Savage’s Sure Thing Principle) no
longer requires that one prefer L2L_2 over L1L_1 just in case one
prefers L4L_4 over L3L_3.



 
1
2–34
35–100


L1L_1
$0 + δ\delta
$2500
$2400


L2L_2
$2400
$2400
$2400




 
1
2–34
35–100


L3L_3
$0
$2500
$0


L4L_4
$2400
$2400
$0


Table 4. Allais’ paradox re-described

The above “re-description strategy” could be employed
whenever the value and/or contribution of an outcome depends on other
possible outcomes: just describe the outcomes in a way that accounts
for this dependency. But more worryingly, the strategy could be
employed whenever one comes across any violation of expected
utility theory or other theories of rationality (as discussed
in Section 4.1). For instance, if a person
prefers AA over BB, BB
over CC and CC over AA, in
violation of the Transitivity axiom, then we can simply re-describe
the options such that AA
when BB is on offer differs
from AA when CC is on offer, thereby making the person satisfy
the axiom. Therefore, unless we have a principled way of determining
when we should re-describe outcomes or options to make a preference
consistent with expected utility theory, the theory becomes
normatively vacuous.
Lara Buchak (2013) has recently developed a decision
theory that can explicitly accommodate Allais’ preferences. On
Buchak’s interpretation, the explanation for Allais’
preferences is not the different value that the outcome $0
has depending on what lottery it is part of. The outcome itself has
the same value. However, the contribution that $0 makes
towards the overall value of an option partly depends on what other
outcomes are possible, she suggests, which reflects the fact that the
option-risk that the possibility of $0 generates depends on what other
outcomes the option might result in. To accommodate Allais’
preferences (and other intuitively rational attitudes to risk that
violate EU theory), Buchak introduces a risk function that
represents people’s willingness to trade chances of something
good for risks of something bad. And she shows that if an agent
satisfies a particular set of axioms, which is essentially
Savage’s except that the Sure Thing Principle is replaced with a
strictly weaker one, then the agent’s preferences can be
represented as maximising risk weighted expected utility;
which is essentially Savage-style expected utility weighted by a risk
function.
Bradley and Stefánsson (2016) also develop a new decision theory
partly in response to the Allais paradox. But unlike Buchak, they
suggest that what explains Allais’ preferences is that the value
of wining nothing from a chosen lottery partly depends on what would
have happened had one chosen differently. To accommodate this, they
extend the Boolean algebra in Jeffrey’s decision theory
to counterfactual propositions, and show that Jeffrey’s
extended theory can represent the value-dependencies one often finds
between counterfactual and actual outcomes. In particular, their
theory can capture the intuition that the (un)desirability of winning
nothing partly depends on whether or not one was guaranteed to win
something had one chosen differently. Therefore, their theory can
represent Allais’ preferences as maximising the value of an
extended Jeffrey-desirability function.
5.3 On completeness: Vague beliefs and desires
As noted in Section 4, criticisms of the
EU requirement of a complete preference ordering are motivated by both
epistemic and desire/value considerations. On the values side, many
contend that a rational agent may simply find two
options incomparable due to their incommensurable
qualities. (Here a prominent usage of these terms will be followed,
whereby particular options may be described as incomparable in value,
while general properties or dimensions of value may be described as
incommensurable.) As in, the agent’s evaluations of the
desirability of sure options may not be representable by any precise
utility function. Likewise, on the belief side, some contend (notably,
Joyce 2010) that the evidence may be such that it does not commit a
rational agent to precise beliefs measurable by a unique probability
function.
There are various alternative, “fuzzier”
representations of desire and belief that might be deemed more
suitable. Halpern (2003), for instance, investigates different ways of
conceptualising and representing epistemic uncertainty, once we depart
from probabilities. Presumably there are also various ways to
represent uncertain desire. Here the focus will be on just one
proposal that is popular amongst philosophers: the use of sets of
probability and utility functions to represent uncertainty in belief
and desire respectively. This is a minimal generalisation of the
standard EU model, in the sense that probability and utility measures
still feature. Roughly, the more severe the epistemic uncertainty, the
more probability measures over the space of possibilities needed to
conjointly represent the agent’s beliefs. This notion of
rational belief is referred to as imprecise probabilism
(refer to the SEP entry
on Imprecise
Probabilities). Likewise, the more severe the evaluative
uncertainty, the more utility measures over the space of sure options
needed to conjointly represent the agent’s desires. Strictly
speaking, we should not treat belief and desire separately, but rather
talk of the agent’s incomplete preferences being represented by
a set of probability and utility pairs. Recall the requirement that
incomplete preferences be coherently extendible (refer back
to Section 1); on this representation, all
the probability-utility pairs amount to candidate extensions of the
incomplete preferences.
The question then arises: Is there a conservative generalisation of
the EU decision rule that can handle sets of probability and utility
pairs? Contender decision rules are standardly framed in terms of
choice functions that take as input some set of feasible options and
return as output a non-empty set of admissible choices that is a
subset of the feasible options. A basic constraint on these choice
functions is that they respect the agent’s preferences in cases
where options are in fact comparable. That is, if all pairs of
probability and utility functions characterising the agent’s
attitudes agree on the ranking of two options, then these particular
options should be ranked accordingly. The relevant constraint on
choice functions is that “EU-dominated options” are not
admissible choices, i.e., if an option has lower expected utility than
another option according to all pairs of probability and utility
functions, then the former dominated option is not an admissible
choice. Note that Levi (1986) has a slightly more restrictive
condition on admissibility: if an option does not have maximum EU for
at least one pair of probability and utility functions, then it is not
admissible. In ordinary cases where sets of probability and utility
functions are closed convex sets, however, Levi’s condition is
equivalent to the aforementioned one that rules out EU-dominated
options (Schervish et al.  2003).
The treatment of genuinely incomparable options (those surviving
the above admissibility test) is where the real controversies begin. A
consideration that is often appealed to in order to discriminate
between such options is caution. The Maxmin-EU rule, for instance,
recommends picking the action with greatest minimum expected utility
(see Gilboa and Schmeidler 1989; Walley 1991). The rule is simple to
use, but arguably much too cautious, paying no attention at all to the
full spread of expected utilities. The α\alpha-Maxmin rule, by contrast, recommends taking
the action with the greatest α\alpha-weighted sum of the minimum and maximum
expected utilities associated with it. The relative weights for the
minimum and maximum expected utilities can be thought of as reflecting
either the decision maker’s pessimism in the face of uncertainty
or else her degree of caution (see Binmore 2009).
There are more complicated choice rules that depend on a richer
representation of uncertainty involving a notion
of confidence. For instance, Klibanoff et al. (2005) propose
a rule whereby choices are made between otherwise incomparable options
on the basis of confidence-weighted expected utility. It presupposes
that weights can be assigned to the various expected utilities
associated with an act, reflecting the agent’s confidence in the
corresponding probability and utility pairs. There are alternative rules that appeal
to confidence even in the absence of precise cardinal
weights. Gärdenfors and Sahlin (1982), for instance, suggest simply
excluding from consideration any probability (and utility) functions
that fall below a confidence threshold, and then applying the
Maxmin-EU rule based on the remainder. Hill’s (2013) choice
theory is somewhat similar, although confidence thresholds for
probability and utility pairs are allowed to vary depending on the
choice problem (and the term “confidence” is itself used
differently). There are further proposals whereby acts are compared in
terms of how much uncertainty they can tolerate (which again depends
on levels of confidence) and yet still be a satisfactory option (see,
e.g., Ben-Haim 2001). These rules are compelling, but they do raise a
host of difficult questions regarding how to interpret and measure the
extra subjective attitudes that play a role, like “amount of
confidence in a belief/desire” and “satisfactory level of
desirability”.
6. Sequential decisions
The decision theories of Savage and Jeffrey, as well as those of
their critics, apparently concern a single “one shot only”
decision; at issue is an agent’s preference ordering, and
ultimately her choice of act, at a particular point in time. One may
refer to this as a static decision problem. The question
arises as to whether this framework is adequate for handling more
complex scenarios, in particular those involving a series or sequence
of decisions; these are referred to as sequential decision
problems.
On paper, at least, static and sequential decision models look very
different. The static model has familiar tabular or normal
form, with each row representing an available act/option, and columns
representing the different possible states of the world that yield a
given outcome for each act. The sequential decision model, on the
other hand, has tree or extensive form (such as
in Figure 1). It depicts a series of anticipated
choice points, where the branches extending from a choice point
represent the options at that choice point. Some of these branches
lead to further choice points, often after the resolution of some
uncertainty due to new evidence.
These basic differences between static and sequential decision
models raise a couple of key questions about how, in fact, they relate
to each other:


Do static and sequential decision models depict the same kind of
decision problem? If so, what is the static counterpart of a
sequential decision model?

Is EU theory vindicated in the sequential decision setting?

These issues turn out to be rather controversial, raising a host of
interpretive questions regarding sequential decision models and rational choice in this setting. These
questions will be addressed in turn, after the scene has been set with
an old story of Ulysses.
6.1 Was Ulysses rational? 
A well-known sequential decision problem is the one facing Ulysses
on his journey home to Ithaca in Homer’s great tale from
antiquity. Ulysses must make a choice about the manner in which he
will sail past an island inhabited by sweet-singing sirens. He can
choose to sail unrestrained or else tied to the mast. In the former
case, Ulysses will later have the choice, upon hearing the sirens, to
either continue sailing home to Ithaca or to stay on the island
indefinitely. In the latter case, he will not be free to make further
choices and the ship will sail onwards to Ithaca past the
sweet-singing sirens. The final outcome depends on what sequence of
choices Ulysses makes. Ulysses’ decision problem is represented
in tree (or extensive) form in Figure 1 (where the
two boxes represent choice points for Ulysses).


Figure 1. Ulysses’ decision
problem

We are told that, before embarking, Ulysses would most prefer to freely
hear the sirens and return home to Ithaca. The problem is that Ulysses
predicts his future self will not comply: if he sails unrestrained, he
will later be seduced by the sirens and will not in fact continue home
to Ithaca but will rather remain on the island indefinitely. Ulysses
therefore reasons that it would be better to be tied to the mast,
because he would prefer the shame and discomfort of being tied to the
mast and making it home to remaining on the sirens’ island
forever.
One cannot deny that Ulysses makes a wise choice in being tied to
the mast. Some hold, however, that Ulysses is hardly an exemplary
agent—after all, he has to play against his future self who will
be unwittingly seduced by the sirens. While Ulysses is rational by
static decision standards, we might regard him irrational by
sequential decision standards. In order to be rational in the
sequential or dynamic sense, Ulysses would need to demonstrate
continuous rationality over the extended time period: he
would need to, say, act as an EU maximiser at all choice points, and
furthermore not undergo any erratic changes of belief or desire, i.e.,
changes that do not accord with the standard learning rule
of Bayesian conditionalisation (which states that, upon
learning some proposition, beliefs are updated to the relevant
conditional probabilities). In other words, one might hold that the
sequential decision model addresses issues of
rationality-over-time.
While rationality-over-time may have some import (say, in allowing
us to identify serial behaviour), what really matters is is how an
agent should act at any given point in time. To this end, the
sequential decision model is more fruitfully viewed as a tool for
helping determine rational choice at a particular time, just like the
static decision model. The sequential decision tree is effectively a
way of visualising the temporal series of choices and learning events
that an agent believes he/she will confront in the future,
depending on what part of the decision tree he/she will find himself/herself. The
key question, then, is: How should an agent choose amongst his/her
initial options in light of his/her projected decision tree? This
question has generated a surprising amount of controversy. Three major
approaches to negotiating sequential decision trees have appeared in
the literature. These are the naïve or myopic
approach, the sophisticated approach and
the resolute approach. These will be discuss in turn, and it
will be suggested that the disputes may not be substantial but rather
indicate subtle differences in the interpretation of sequential
decision models.
The so-called naïve approach to negotiating sequential decisions
serves as a useful contrast to the other two approaches. The naïve
agent assumes that any path through the decision tree is possible, and
so sets off on whichever path is optimal, given his/her present
attitudes. For instance, a naïve Ulysses would simply presume that he
has three overall strategies to choose from: either ordering the crew
to tie him to the mast, or issuing no such order and later stopping at
the sirens’ island, or issuing no such order and later sticking
to his course. Ulysses prefers the outcome associated with the latter
combination, and so he initiates this strategy by not ordering the
crew to restrain him. Table 5 presents the static counterpart of naïve
Ulysses’ decision problem. In effect, this decision model does
not take into account Ulysses’ present knowledge of his future
preferences, and hence advises that he pursue an option that is
predicted to be impossible.


ActOutcome
order tying to mast reach home, some humiliation
sail unconstrained then stay with sirens  life with sirens
sail unconstrained then home to Ithaca  reach home, no humiliation

Table 5. Naïve Ulysses’
decision problem

There is no need to labour the point that the naïve approach to
sequential choice is aptly named. The hallmark of the sophisticated
approach, by contrast, is its emphasis on backwards planning: the
sophisticated chooser does not assume that all paths through the
decision tree, or in other words, all possible combinations of choices
at the various choice nodes, will be possible. The agent considers,
rather, what he/she will be inclined to choose at later choice nodes
when he/she gets to the temporal position in question. Sophisticated
Ulysses would take note of the fact that, if he reaches the island of
the sirens unrestrained, he will want to stop there indefinitely, due
to the transformative effect of the sirens’ song on his
preferences. This is then reflected in the static representation of
the decision problem, as per Table 6. The states here concern
Ulysses’ future preferences, once he reaches the island. Since
the second state has probability zero, the acts are decided on the
basis of the first state, so Ulysses wisely chooses to be tied to the
mast.


Act later choose sirens (p=1) (p = 1) later choose
   Ithaca (p=0) (p = 0)
order tying to mast  home, some
humiliation  home, some humiliation
sail unconstrained  life with sirens  home,
no humiliation

Table 6. Sophisticated Ulysses’
decision problem

Resolute choice deviates from sophisticated choice only under
certain conditions that are not fulfilled by Ulysses, given his
inexplicable change in attitudes. Defenders of resolute choice
typically defend decision theories that violate the Independence
axiom/Sure-thing principle (notably McClennen 1990 and Machina 1989;
see also Rabinowicz 1995 for discussion), and appeal to resolute
choice to make their decision theory more palatable in the sequential
context. According to resolute choice, in appropriate contexts
(involving preferences that are stable but which violate
Independence), the agent should count on simply sticking to the
strategy that was initially deemed best at all future choice
nodes. The question is whether the resolute approach makes sense,
given the standard interpretation of a sequential-decision model. Can
an agent really count on choosing against her preferences at some
given time in order to fulfill an old plan? This would seem a case of
falling for the sunk-cost fallacy. Of course, an agent may place considerable
importance on honouring previous commitments. Any such integrity
concerns, however, should arguably be reflected in the agent’s
actual preferences, at the time in question. This is quite different
from choosing out of step with one’s all-things-considered
preferences at a time.
Arguably, defenders of resolute choice actually have in mind a
different interpretation of sequential decision models, whereby future
“choice points” are not really points at which an agent is
free to choose according to her preferences at the time. If this is
right, it amounts to changing the question or the problem of
interest. In what follows, thes standard interpretation of sequential decision models will be assumed, and moreover, it will be assumed that rational agents reason about
such decisions in a sophisticated manner (as per Levi 1991, Maher
1992, Seidenfeld 1994, amongst others).
6.2 The EU axioms revisited
We have seen that sequential decision trees can help an agent like
Ulysses take stock of the consequences of his current choice, so that
he can better reflect on what to do now. The literature on
sequential choice is primarily concerned, however, with more ambitious
questions. Indeed, the sequential setting effectively offers new ways
to “test” theories of rational preference, as well as
rational belief/desire change. These are controlled tests in that the
agent is assumed to predict stable preferences over time, i.e., she
does not expect her preference ordering over final outcomes to change,
except in ways that accord with her rule for belief/desire
change. Strictly speaking, what is put to the test is the whole
package of decision rule plus learning rule. In practice, the two are
treated separately: different decision rules are compared under the
assumption that learning is by Bayesian conditionalisation, or else
different learning rules are compared under the assumption that the
agent maximises expected utility. The question is whether the
agent’s decision or learning rule is shown to be self-defeating
(or in other words, dynamically inconsistent), in some sense,
in the sequential setting.
Let us first consider the sequential-decision argument for learning
in response to new evidence by Bayesian conditionalisation, as it
serves as a useful comparison for other sequential arguments. Skyrms
(1993) presents such an argument; it is arguably the most
sophisticated version of the so-called “diachronic Dutch
book” argument for conditionalisation being the only rational
learning rule. The agent is assumed to be an expected utility
maximiser who takes a sophisticated (backwards reasoning) approach to
sequential decision problems. Skyrms shows that any such agent who
plans to learn in a manner at odds with conditionalisation will make
self-defeating choices in some specially contrived sequential decision
situations. A good conditionalising agent, by contrast, will never
make choices that are self-defeating in this way. The kind of
“self-defeating choices” at issue here are ones that
amount to a sure loss. That is, the agent chooses a strategy that is
surely worse, by her own lights, than another strategy that she might
otherwise have chosen, if only her learning rule was such that she
would choose differently at one or more future choice nodes.
A similar argument can be used to defend EU preferences. In this
case, we assume that the agent’s learning rule is
conditionalisation; moreover, we assume, as before, that the agent has
stable preferences and takes a sophisticated approach to sequential
decision problems. Hammond (1976, 1977, 1988b,c) gives a
“dynamic consistency” argument for EU theory that is
similar to the one above for conditionalisation; he shows that only
preferences with an EU structure are such that the agent can plan to
pursue any path in a sequential decision tree that is deemed optimal
by the agent from the initial choice node. Unlike other preference
structures (decision rules), EU preferences never lead to
“self-defeating choices”, in the sense that the agent is
forced to choose a strategy that is worse by her own lights than
another strategy that she might otherwise have chosen, if only her
preferences were such that she would choose differently at future
choice nodes.
Hammond’s argument for EU theory, and the notion of dynamic
consistency that it invokes, has been criticised from different
quarters, both by those who defend theories that violate the
Independence axiom but retain the Completeness and Transitivity (i.e.,
Ordering) axioms of EU theory, and those who defend theories that
violate the latter (for discussion, see Steele 2010). The approach taken by some defenders of
Independence-violating theories (notably, Machina 1989 and McClennen
1990) has already been alluded to: They reject the assumption of
sophisticated choice that drives the dynamic consistency
arguments. Seidenfeld (1988a,b, 1994, 2000a,b) rather rejects
Hammond’s notion of dynamic consistency in favour of a more
subtle notion that discriminates between theories that violate
Ordering and those that violate Independence alone; the former, unlike
the latter, pass Seidenfeld’s test. This argument too is not
without its critics (see McClennen 1988, Hammond 1988a, Rabinowicz 2000). Note that the costs of
any departure from EU theory are well highlighted by Al-Najjar and
Weinstein (2009) and Kadane et al. (2008), in particular the
possibility of aversion to free information and aversion to
opportunities for greater choice in the future.
7. Concluding remarks
Let us conclude by summarising the main reasons why decision
theory, as described above, is of philosophical interest. First,
normative decision theory is clearly a (minimal) theory
of practical rationality. The aim is to characterise the
attitudes of agents who are practically rational, and various (static
and sequential) arguments are typically made to show that certain
practical catastrophes befall agents who do not satisfy standard
decision-theoretic constraints. Second, many of these constraints
concern the agents’ beliefs. In particular, normative
decision theory requires that agents’ degrees of beliefs satisfy
the probability axioms and that they respond to new information by
conditionalisation. Therefore, decision theory has great implications
for debates in epistemology and philosophy of science; that is, for
theories of epistemic rationality.
Finally, decision theory should be of great interest to
philosophers of mind and psychology, and others who are interested in
how people can understand the behaviour and intentions of others; and,
more generally, how we can interpret what goes on in other
people’s minds. Decision theorists typically assume that a
person’s behaviour can be fully explained in terms of her
beliefs and desires. But perhaps more interestingly, some of the most
important results of decision theory—the various representation
theorems, some of which have discussed here—suggest that if a
person satisfies certain rationality requirements, then we can read
her beliefs and desires, and how strong these beliefs and desires are,
from her choice dispositions (or preferences). How much these theorems
really tell us is a matter of debate, as discussed above. But on an
optimistic reading of these results, they assure us that we can
meaningfully talk about what goes on in other people’s minds
without much evidence beyond information about their dispositions to
choose.