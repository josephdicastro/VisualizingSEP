Montague semantics is a theory of natural language semantics and of
its relation with syntax. It was originally developed by the logician
Richard Montague (1930–1971) and subsequently modified and
extended by linguists, philosophers, and logicians. The most important
features of the theory are its use of model theoretic semantics which
is nowadays commonly used for the semantics of logical languages and
its adherence to the principle of compositionality—that is, the
meaning of the whole is a function of the meanings of its parts and
their mode of syntactic combination. This entry presents the origins
of Montague Semantics, summarizes important aspects of the classical
theory, and sketches more recent developments. We conclude with a
small example, which illustrates some modern features.
 
1. Introduction
1.1 Background

Montague semantics is the approach to the semantics of natural
language introduced by Richard Montague in the 1970s. He described the
aim of his enterprise as follows:

The basic aim of semantics is to characterize the notion of a true
sentence (under a given interpretation) and of entailment (Montague
1970c, 223 fn).


The salient points of Montague's approach are a model theoretic
semantics, a systematic relation between syntax and semantics, and a
fully explicit description of a fragment of natural language. His
approach constituted a revolution: after the Chomskyan revolution that
brought mathematical methods into syntax, now such methods were
introduced in semantics.

Montague's approach became influential, as many authors began to work
in his framework and conferences were devoted to ‘Montague
grammar’. Later on, certain aspects of his approach were adapted
or changed, became generally accepted or were entirely abandoned.
Nowadays not many authors would describe their own work as
‘Montague semantics’ given the many differences that have
taken shape in semantics since Montague's own work, but his ideas have
left important traces, and changed the semantic landscape forever. In
our presentation of Montague semantics the focus will be on these
developments.

Richard Montague was a mathematical logician who had specialized in
set theory and modal logic. His views on natural language must be
understood with his mathematical background in mind. Montague held the
view that natural language was a formal language very much in the same
sense as predicate logic was a formal language. As such, in Montague's
view, the study of natural language belonged to mathematics, and not
to psychology (Thomason 1974, 2). Montague formulated his views:

There is in my opinion no important theoretical difference between
natural languages and the artificial languages of logicians; indeed I
consider it possible to comprehend the syntax and semantics of both
kinds of languages with a single natural and mathematically precise
theory. (Montague 1970c, 222)


Sometimes only the first part of the quote is recalled, and that might
raise the question whether he did not notice the great differences:
for instance that natural languages develop without an a priori set of
rules whereas artificial languages have an explicit syntax and are
designed for a special purpose. But the quote as a whole expresses
clearly what Montague meant by ‘no important theoretical
difference’; the ‘single natural and mathematically
precise theory’ which he aimed at, is presented in his paper
‘Universal Grammar’ (Montague 1970c). He became most
well-known after the appearance of Montague 1973, in which the theory
is applied to some phenomena which were discussed intensively in the
philosophical literature of those days.

Montague's interest in the field arose while teaching introductory
logic courses. Standard in such courses are exercises in which one is
asked to translate natural language sentences into logic. To answer
such exercises required a bilingual individual, understanding both the
natural language and the logic. Montague provided, for the first time
in history, a mechanical method to obtain these logical translations.
About this, Montague said:

It should be emphasized that this is not a matter of vague intuition,
as in elementary logic courses, but an assertion to which we have
assigned exact significance. (Montague 1973, 266)


We next describe the basic ideas of Montague semantics. Section 2
presents several components of Montague semantics in more detail.
Section 3 includes a discussion of philosophically interesting
aspects, and Section 4 provides a detailed example and further
reading.
1.2 Basic Aspects

To implement his objective, Montague applied the method which is
standard for logical languages: model theoretic semantics. This means
that, using constructions from set theory, a model is defined, and
that natural language expressions are interpreted as elements (or
sets, or functions) in this universe. Such a model should not be
conceived of as a model of reality. On the one hand the model gives
more than reality: natural language does not only speak about past,
present and future of the real world, but also about situations that
might be the case, or are imaginary, or cannot be the case at all. On
the other hand, however, the model offers less: it merely specifies
reality as conceived by language. An example: we speak about mass
nouns such as water as if every part of water is water again,
so as if it has no minimal parts, which physically is not correct. For
more information on natural language metaphysics, see Bach 1986b.

Montague semantics is not interested in a particular situation (e.g.
the real world) but in semantical properties of language. When
formalizing such properties, reference to a class of models has to be
made, and therefore the interpretation of a language will be defined
with respect to a set of (suitable) models. For example, in the
introduction we mentioned that the characterization of entailment was
a basic goal of semantics. That notion is defined as follows. Sentence
A entails sentence B if in all models in which the
interpretation of A is true, also the interpretation of
B is true. Likewise a tautology is true in all models, and a
contradiction is true in no model.

An essential feature of Montague semantics is the systematic relation
between syntax and semantics. This relation is described by the
Principle of Compositionality which reads, in a formulation that is
standard nowadays:

The meaning of a compound expression is a function of the meanings of
its parts and of the way they are syntactically combined. (Partee
1984, 281)


An example. Suppose that the meaning of walk, or
sing is (for each model in the class) defined as the set of
individuals who share respectively the property of walking or the
property of singing. By appealing to the principle of
compositionality, if there is a rule that combines these two
expressions to the verb phrase walk and sing, there must be a
corresponding rule that determines the meaning of that verb phrase. In
this case, the resulting meaning will be the intersection of the two
sets. Consequently, in all models the meaning of walk and
sing is a subset of the meaning of walk. Furthermore we
have a rule that combines the noun phrase John with a verb
phrase. The resulting sentence John walks and sings means
that John is an element of the set denoted by the verb phrase. Note
that in any model in which John is element of the intersection of
walkers and singers, he is an element of the set of walkers. So
John walks and sings entails John walks.

An important consequence of the principle of compositionality is that
all the parts which play a role in the syntactic composition of a
sentence, must also have a meaning. And furthermore, each syntactic
rule must be accompanied by a semantic rule which says how the meaning
of the compound is obtained. Thus the meaning of an expression is
determined by the way in which the expression is formed, and as such
the derivational history plays a role in determining the meaning. For
further discussion, see Section 2.5.

The formulation of the aim of Montague semantics mentioned in the
introduction (‘to characterize truth and entailment of
sentences’) suggests that the method is restricted to
declarative sentences. But this is need not be the case. In Montague
1973 (248 fn) we already find suggestions for how to deal with
imperatives and questions. Hamblin (1973) and Karttunen (1977) have
given a semantics for questions by considering them with a meaning
that is based upon sentences (viz. sets of propositions). Groenendijk
and Stokhof (1989) consider questions as expressions with meanings of
their own nature (namely partitions).

Since Montague only considered sentences in isolation, certain
commentators pointed out that the sentence boundary was a serious
limitation for the approach. But what about discourse? An obvious
requirement is that the sentences from a discourse are interpreted one
by one. How then to treat co-referentiality of anaphora over sentence
boundaries? The solution which was proposed first, was Discourse
Representation Theory (Kamp 1981). On the one hand that was an
offspring of Montague's approach because it used model theoretic
semantics, on the other hand it was a deviation because (discourse)
representations were an essential ingredient. Nowadays there are
several reformulations of DRT that fit into Montague's framework (see
van Eijck and Kamp 1997). A later solution was based upon a change of
the logic; dynamic Montague semantics was developed and that gave a
procedure for binding free variables in logic which has an effect on
subsequent formulas (Groenendijk and Stokhof 1991). Hence the sentence
boundary is not a fundamental obstacle for Montague semantics.
2. Components of Montague Semantics
2.1 Unicorns and Meaning Postulates

Montague's most influential article was ‘The Proper Treatment of
Quantification in Ordinary English’ (Montague 1973). It
presented a fragment of English that covered several phenomena which
were in those days discussed extensively. One of the examples gave
rise to the trademark of Montague grammar: the unicorn (several
publications on Montague grammar are illustrated with unicorns).

Consider the two sentences John finds a unicorn and John
seeks a unicorn. These are syntactically alike
(subject-verb-object), but are semantically very different. From the
first sentence follows that there exists at least one unicorn, whereas
the second sentence is ambiguous between the so called de
dicto reading which does not imply the existence of unicorns, and
the de re reading from which existence of unicorns
follows.

The two sentences are examples of a traditional problem called
‘quantification into intensional contexts’. Traditionally
the second sentence as a whole was seen as an intensional context, and
the novelty of Montague's solution was that he considered the object
position of seek as the source of the phenomenon. He
formalized seek not as a relation between two individuals,
but as a relation between an individual and a more abstract entity,
see Section 2.2. Under this analysis the existence of a unicorn does
not follow. The de re reading is obtained in a different way,
see Section 2.5.

It was Montague's strategy to apply to all expressions of a category
the most general approach, and narrow this down, when required, by
meaning postulates. So initially, find is also considered to
be a relation between an individual and such an abstract entity, but
some meaning postulate restricts the class of models in which we
interpret the fragment to only those models in which the relation for
find is the (classical) relation between individuals.

As a consequence of this strategy, Montague's paper has many meaning
postulates. Nowadays semanticists often prefer to express the semantic
properties of individual lexical items directly in their lexical
meaning, and then find is directly interpreted as a relation
between individuals. Nowadays meaning postulates are mainly used to
express structural properties of the models (for instance the
structure of time axis), and to express relations between the meanings
of words. For a discussion of the role of meaning postulates, see
Zimmermann 1999.
2.2 Noun Phrases and Generalized Quantifiers

Noun phrases like a pig, every pig, and
Babe, behave in many respects syntactically alike: they can
occur in the same positions, can be conjoined, etc. But a uniform
semantics seems problematic. There were proposals which said that
every pig denotes the universally generic pig, and a
pig an arbitrary pig. Such proposals were rejected by Lewis
(1970), who raised, for instance, the question which would be the
color of the universal pig, all colors, or would it be colorless?

Montague proposed the denotation of a descriptive phrase to be a set
of properties. For instance, the denotation of John is the
set consisting of properties which hold for him, and of every
man the set of properties which hold for every man. Thus they are
semantically uniform, and then conjunction and/or disjunction of
arbitrary quantifier phrases (including e.g. most but not
all) can be dealt with in a uniform way.

This abstract approach has led to generalized quantifier theory, see
Barwise & Cooper 1981 and Peters & Westerståhl 2006. By
using generalized quantifier theory a remarkable result has been
achieved. It concerns ‘negative polarity items’: words
like yet and ever. Their occurrence can be licensed
by negation: The 6:05 has arrived yet is out, whereas The
6:05 hasn't arrived yet is OK. But there are more contexts in
which negative polarity items may occur, and syntacticians did not
succeed in characterizing them. Ladusaw (1980) did so by using a
characterization from generalized quantifier theory. This was a great
success for formal semantics! His proposal roughly was as follows.
Downward entailing expressions are expressions that license inferences
from supersets to subsets. No is downward entailing because
from No man walks it follows that No father walks. A
negative polarity item is acceptable only if it is interpreted in the
scope of a downward entailing expression, e.g. No man ever
walks. Further research showed that the analysis needed refining,
and that a hierarchy of negative polarity items should be used
(Ladusaw 1996).
2.3 Logic and Translating

An expression may directly be associated with some element from the
model. For instance, walk with some set of individuals. Then
also the operations on meanings have to be specified directly, and
that leads to formulations such as:

G3 is that function f ∈
((2I)A×A)Aω
such that, for all x ∈ Aω, all
u,t ∈ A and all i ∈ I :
f(x)(t,u)(i) = 1 if and only if
t = u. (Montague 1970a, 194)


Such descriptions are not easy to understand, nor convenient to work
with. Montague (1973, 256) said, ‘it is probably more
perspicuous to proceed indirectly.’ For this purpose he
introduced a language, called ‘intensional logic’. The
operation described above is then represented by
∧λtλu[t = u].
The λt says that it is a function that takes t as
argument, likewise for λu. So
λtλu[t = u] is a function
which takes two arguments, and yields true if the arguments are equal,
and otherwise false. The preceding ∧ says that we
consider a function from possible worlds and moments of time to the
thus defined function.

Two features of the Montague's ‘intensional logic’
attracted attention.

It is a higher order logic. In those days, linguists, philosophers
and mathematicians were only familiar with first order logic (the
logic in which there are only variables for basic entities). Since in
Montague semantics the parts of expressions must have meaning too, a
higher order logic was needed (we have already seen that every
man denotes a set of properties).
The logic has lambda abstraction, which in Montague's days was not
a standard ingredient of logic. The lambda operator makes it possible
to express with higher order functions, and the operator made it
possible to cope differences between syntax and semantics. For
instance, in John walks and he talks there is only one
occurrence of John, whereas in the logic John should occur
with the predicate walk and with the predicate
talk. The use of lambda-operators enables us to plug
in the meaning of John at several positions. The importance
of lambdas is expressed by Partee at a talk on ‘The first decade
of Montague Grammar’: ‘Lambdas changed my life’
(Partee 1996, 24). Nowadays lambdas are a standard tool in all papers
in semantics. In section 4.1 an example will be given that illustrates
the power of lambdas.


This motivation for using translations (a tool for obtaining
perspicuous representations of meanings) has certain consequences.

 Translation is a tool to obtain formulas which represent
meanings. Different, but equivalent formulas are equally acceptable.
In the introduction of this article it was said that Montague grammar
provided a mechanical procedure for obtaining the logical translation.
As a matter of fact, the result of Montague's translation of Every
man runs is not identical with the traditional translation,
although equivalent with it, see the example in Section 4.1.
The translation into logic should be dispensable. So in Montague
semantics there is nothing like ‘logical form’(which plays
such an important role in the tradition of Chomsky).
For each syntactic rule which combines one or more expressions
there is a corresponding semantic rule that combines the corresponding
representations of the meanings. This connection is baptized the
rule-to-rule hypothesis (Bach 1976). Maybe it is useful to emphasize
that (in case the syntactic operation is meaning preserving) the
corresponding semantic rule can be the identity mapping .
Operations depending on specific features of formulas are not
allowed. Janssen (1997) criticized several proposals on this aspect.
He showed that proposals that are deficient in this respect are either
incorrect (make wrong predictions for closely related sentences), or
can be corrected and generalized, and thus improved.


The method of using a logic for representing meanings has a long
history. One might point to philosophers such as Dalgarno and Leibniz
who developed formal languages in order to express philosophy clearly.
In the 19th century there were several proposals for artificial
languages in order to make mathematical argumentation more
transparent, for instance by Frege and by Peano. Frege's
‘Begriffsschrift’ (Frege 1879) can be seen as the birth of
predicate logic: he introduced quantifiers. His motivation came from
mathematical needs; he did not use his Begriffsschrift in his papers
on natural language. Russell (1905) used logic to represent the
meanings of natural language. A classical example in his paper is the
analysis of The king of France is bald. Syntactically it has
the form subject-predicate, but if it would be constructed logically
as a subject-predicate, then the king of France, which
denotes nothing, cannot be the subject. So there is a difference
between the syntactic form, and the logical form: natural language
obscures the view of the real meaning. This became known as the
‘misleading form thesis’. Therefore philosophers of
language saw, in those days, the role of logic as a tool to improve
natural language. An interesting overview of the history of
translating is given in Stokhof 2007.

Note, however, that Montague semantics has nothing to do with the aim
of improving natural language or providing its logical form.
2.4 Intensionality and Tautologies

Montague defined the denotation of a sentence as a function from
possible worlds and moments of time to truth values. Such a function
is called an ‘intension’. As he said (Montague 1970a,
218), this made it possible to deal with the semantics of common
phenomena such as modifiers, e.g. in Necessarily the father of
Cain is Adam. Its denotation cannot be obtained from the truth
value of The father of Cain is Adam : one has to know the
truth value for other possible worlds and moments of time. The
intensional approach also made it possible to deal with several
classical puzzles. Two examples from Montague 1973 are: The
temperature is rising, which should not be analyzed as stating
that some number is rising. And John wishes to catch a fish and
eat it should not be analyzed as stating that John has a
particular fish in mind, but that he wants to eat the fish he will
catch.

Intensional semantics has been criticized for the fact that all
tautologies get the same meaning (are synonymous). Indeed, a tautology
as John is ill or he is not ill gets as intension the
function that constantly yields true, and the same
holds for other tautologies. If one is interested in discriminating
semantically between tautologies, then a refinement of the notions
‘meaning’ and ‘equivalence’ is needed:
‘meaning’ should see distinctions between tautologies, and
‘equivalence’ should be sensitive for the thus refined
notion of meaning. The oldest proposals to account for this problem is
by Lewis (1970): propositions are structured by including in their
meanings also the meanings of their parts. Then indeed Green grass
is green and White snow is white have different
meanings. However, lexical synonyms still pose a problem. Since
woodchuck and groundhog are names for the same
species, John believes that Phil is a groundhog is, under
this view, equivalent with John believes that Phil is a
woodchuck. One could consider belief contexts a separate problem,
but most authors see it as part of the problem of equivalence of all
tautologies. 

Later several proposals for dealing with this are given. Bäuerle
and Cresswell (2003) give an overview of the older proposals, and Fox
and Lappin (2005) review more recent ones. The latter authors explain
that there are two strategies: the first is to introduce impossible
worlds in which woodchuck and groundhog are not
equivalent, and the second is to introduce an entailment relation with
the property that identity does not follow from reciprocal entailment.
Fox and Lappin follow the second strategy.
2.5 Scope and Derivational History

A well known example of scope ambiguity is Every man loves a
woman. Is there only one woman involved (e.g. mother Mary), or
does every man love a different woman? The sentence has no lexically
ambiguous words, and there are no syntactic arguments to assign them
more than one constituent structure. How to account for the
ambiguity?

In Montague 1973, the scope ambiguity is dealt with by providing for
the sentence two different derivations. On the reading that
every has wide scope, the sentence is produced from every
man and loves a woman. On the reading that only one
woman is involved, the sentence is obtained from Every man loves
him1. The him1 is an artifact, a
placeholder, or, one might say, a syntactic variable. A special kind
of rule, called a ‘quantifying-in rule’, will replace this
him1 by a noun phrase or a pronoun (in case there
are more occurrences of this placeholder). The placeholder corresponds
with a logical variable that becomes bound by the semantic counterpart
of the quantifying-in rule. For the sentence under discussion, the
effect of the application of the quantifying-in rule to a
woman and Every man loves him1 is that the
desired sentence is produced and that the quantifier corresponding
with a woman gets wide scope. When we would depict its
derivation as a tree, this tree would be larger than the constituent
structure of the sentence due to the introduction and later removal of
him1.

This quantifying-in rule is used by Montague for other phenomena as
well. An example is co-referentiality: Mary loves the man whom she
kissed is obtained from He1 loves the man
whom he1 kissed. And the de re
reading of John seeks a unicorn is obtained from a
unicorn and John seeks him1.

Many researchers did not like this analysis in which powerful
syntactic rules and artificial symbols (him1) are
used. Below we consider two strategies to remedy.

The first strategy was to deny the ambiguity. Some linguists have
argued that the scope order is the same as the surface order; this is
known as ‘Jackendoff's principle’ (Jackendoff 1972). But
there are sentences where this does not work. Others said that it is
sufficient only to obtain the weakest reading (every wide
scope), and that the stronger reading is inferred when additional
information is available. But there are sentences for which the
different scope readings are logically independent, as in Every
woman loves one man.

The second strategy was to capture the ambiguity in another way than
by the quantifying-in rules. Historically the first method was to put
the interpretations of the noun phrases in a store from which these
interpretations could be retrieved when needed: different stages of
retrieving correspond with differences in scope. One might see this as
a grammar in which the direct correspondence between syntax and
semantics has been relaxed. The method is called ‘Cooper
Store’, after the author who proposed this (Cooper 1983). A
later proposal is DRT (= discourse representation theory), where
representations are used to account for such ambiguities (van Eijck
& Kamp 1997).

A recent method is by means of ‘lifting rules’ (see Sect.
3.3): the meaning of a noun-phrase is ‘lifted’ to a more
abstract level, and different levels yield different scope readings
(see Hendriks 2001 and Jacobson 2014).

Even if the role of derivational history can be avoided for scope and
co-referentiality, other phenomena remain for which derivational
histories have a role. An example is John wondered when Alice said
she would leave. This is ambiguous between John asking for the
time of leaving, or for the time of saying. So the sentence is
ambiguous, even though there are no arguments for assigning to it more
than one constituent structure. Pelletier (1993) presents this
sentence and others, and says: ‘In order to maintain the
Compositionality Principle, theorists have resorted to a number of
devices which are all more or less unmotivated (except to maintain the
Principle): Montagovian “quantifying-in” rules, traces,
gaps, […].’ Pelletier's objection can be appreciated if
one assumes that meaning assignment is directly linked with
constituent structure. But, as explained in Section 1.2, this is not
the case. The derivation specifies which rules are combined in which
order, and this derivation constitutes the input to the meaning
assignment function. The constituent structure is determined by the
output of the syntactic rules, and different derivation processes may
generate one and the same constituent structure. In this way, semantic
ambiguities are accounted for. One should not call something
‘constituent structure’ if it is not intended as such, and
next refute it because it does not have the desired properties.

The distinction between a derivation tree and a constituent tree is
made in several theories of grammar. In Tree Adjoining Grammars
(TAG's) the different scope readings of the sentence about loving a
woman differ in the order in which the noun-phrases are substituted in
the basic tree. A classical example in Chomskyan grammar is The
shooting of the hunters was bloody, which is ambiguous between
the hunters shooting, or the hunters being shot at. The two readings
come from two different sources: one in which the hunters is
the subject of the sentence, and one in which it is the object.
3. Philosophical Aspects
3.1 From Frege to Intensions

Frege (1892) introduced the distinction between ‘sense’
and ‘reference’. It has been said that Montague followed
this distinction, and that ‘intension’ coincides with
‘sense’. But that is not correct. Let us first consider
Frege's argumentation. It concerns The Greeks did not know that
the morning star is the evening star. During classical antiquity,
it had not yet been discovered that both the morning star and the
evening star are the planet Venus. We would, however, not like to
analyze the sentence as stating that the Greeks did not know that
Venus is the same as Venus, i.e. that they did not recognize an
obvious truth. Frege's theory is that in ordinary contexts the
expression the morning star denotes its referent (a celestial
object), but in indirect contexts it denotes something different that
is called ‘its sense’. This notion includes not only the
referent, but also the way in which one refers to an object. Since
referring to a celestial object by the morning star differs
from referring to it by the evening star, the sentence
The morning star is the evening star does not express an
analytic truth.

Frege's approach was abandoned because it was not really satisfactory.
It introduced an ambiguity of the of the phrase the morning
star, whereas it is not a lexical ambiguity: there is no sentence
that has different readings due to that phrase. Nevertheless, Frege
associated with that expression two denotations. The situation gets
even worse: Carnap (1947) noted that under Frege's approach we would
also need the ‘sense of a sense’ etc. Consequently,
Frege's approach requires an infinite hierarchy of semantic
denotations (and that for an expression which never gives rise to the
ambiguity of a sentence). Carnap proposed another formalization of the
same idea, but in which with one expression only one denotation is
associated. Montague (1970c, 233) introduced with his
‘intensional logic’ a variant of this idea. The difference
with Frege (one denotation for an expression, instead of infinitely
many) was possible due to two novelties (see Montague 1970a,
217–218): ‘descriptive phrases do not denote
individuals’, and ‘the denotation of a sentence is not a
truth-value’.

For an more elaborated discussion, see Janssen 2011; for information
on the history of intensional logic, see Montague 1970b (145).
3.2 Compositionality

For Montague the principle of compositionality was not a subject of
deliberation or discussion, because for him, as a mathematical
logician, it was the only way to proceed. He describes his method in
side remarks with phrases like ‘following Tarski’, or
‘following Frege’, without ever calling it a principle.
Later authors identified the Principle of Compositionality as the
cornerstone of Montague's work. The reason was that discussions arose,
and an investigation of the foundations of Montague grammar was asked
for.

It has been claimed that Montague himself did not work compositionally
in the case of pronouns. This is, however, not the case. In order to
explain the compositional nature of his treatment of pronouns, both
Janssen (1997) and Dowty (2007) explain how variables are interpreted
in logic; we follow their explanations. Consider the following clauses
from the traditional Tarskian interpretation of predicate logic.

⟦ϕ ∧ ψ⟧g = 1
if and only if ⟦ϕ⟧g = 1
and ⟦ψ⟧g = 1
⟦∀xϕ⟧g =
1 if and only if for all h
∼xg holds
⟦ϕ⟧h = 1


The first clause says: ϕ ∧ ψ is true when using
assignment g if and only if ϕ and ψ are true when the
assignment g is used. In the second clause assignments h
are introduced (by ∼x g) which are equal
to g except maybe for the value they assign to variable
x. Montague uses the same format, with the difference that
besides g he also has i, the time of reference and
j, the possible world, as superscripts.

In the formulation of the clauses there is nothing which can be
pointed at as ‘the meaning’, in fact it is a definition of
truth with g and h as parameters. So how is it possible
that this (and Montague's work) are compositional?

The answer requires a shift in perspective. The meaning of a formula
ϕ, shortly M(ϕ), is the set of assignments for which
the formula is true. Then the first clause says that M(ϕ
∧ ψ) = M(ϕ) ∩ M(ψ), so a simple
set-theoretic combination on the two meanings is performed. And
M(∀xϕ) = {h
∼xg∣g ∈
M(ϕ)}, which can be described as: extend the set
M(ϕ) with all x-variants. Likewise, in Montague
semantics the meaning of an expression is a function which has as
domain the triples <moment of time, possible world, assignment to
variables>.

Is it possible to achieve compositionality for natural language?
Obvious candidates for counterexamples are idioms, because their
meanings seem not to be built from their constituting words. However,
Westerståhl (2002) presents a collection of methods, varying
from compound basic expressions, to deviant meanings for constituting
parts. Janssen (1997) refutes several other counterexamples that are
put forward in the literature.

How strong is compositionality? Mathematical results show that any
language can be given a compositional semantics, either by using an
unorthodox syntax (Janssen 1997) or by using an unorthodox semantics
(Zadrozny 1994). However their proofs are not helpful in practice.
Hodges (2001) showed how a given compositional semantics for a
fragment can be extended to a larger language.

Among formal semanticists one can find the following attitudes towards
compositionality (nearly the same list is given in Partee 1996):

Compositionality is a basic methodological principle; any proposal
should obey it. Janssen(1997) and Jacobson(2014) are adherents of this
position.
Compositionality is a good method, but other methods can be used
as well. For instance formal meaning representation can be used in an
essential way. An example is DRT (discourse representation theory,
Kamp 1981).
Compositionality is an ideal, but a proposal need not to satisfy
it.
It is an empirical issue whether compositionality can be achieved.
See Dowty 2007 for a discussion.


An extensive discussion of compositionality is given in Janssen 1997,
and in the entry on
 compositionality
 (Szabó 2007).
3.3 Syntactic Categories and Semantic Types

According to Montague the purpose of syntax is to produce the input
for the semantics:

I fail to see any interest in syntax except as a preliminary to
semantics. (Montague 1970c, 223)


Although the syntax was in his eyes subordinate, he was fully explicit
in his rules in which he used some ad hoc syntactic tools. 

In Montague 1970a, the relation between syntactic categories and
semantic types is given only by a list. Montague (1973) defines a
systematic relation which amounts to the same relation as one would
have in categorial grammar. However, Montague's syntax is not a
categorial syntax because the rules are not always category driven and
because some of the rules are not concatenation rules.

For each of these two aspects, proposals have been put forward to
change the situation. One direction was to stay closer to the ideals
of categorial grammar, with only type driven rules, sometimes allowing
for a restricted extension of the power of concatenation rules. See,
for example, Morrill 1994 and Carpenter 1998. The other approach was
to incorporate in Montague grammar as much as possible the insights
from syntactic theories, especially originating from the tradition of
Chomsky. A first step was made by Partee (1973), who let the grammar
produce structures (labelled bracketings). A syntactically
sophisticated grammar (with Chomskyan movement rules) was used in the
Rosetta translation project (Rosetta 1994).

Montague introduced the and in John walks and Mary
sings not from a given lexical entry, but as effect of a rule.
This is known as treating and syncategorematically. He did
this for all determiners, and also for negation. For John walks
and sings a different rule is needed than for John walks and
Mary sings because syntactically the first one is a conjunction
of verb phrases and the second one of sentences. However, the two
meanings of and are closely related and a generalisation is
missed. As general solution it was proposed to use rules (or
alternatively general principles) that change the category of an
expression to another category; a change that corresponds with a
semantic rule that ‘lifts’ the meaning. For instance, the
meaning of and as a connective between verb phrases is
obtained by lifting the meaning of sentence connective ∧ to
λPλQλx[P(x)
∧ Q(x)]. Classical papers about the approach with
lifting rules are Partee and Rooth 1983, Partee 1987 and Hendriks
2001. In a monograph (Winter 2001) the whole complex of conjoined
phrases is considered.

Nowadays the syntactic side usually plays no important role in
publications on Montague semantics. Montague's method to present
fragments with a fully explicit syntax is largely abandoned. One
rather focuses on a semantically interesting phenomenon, suggesting
rules which are only explicit concerning the semantic side. Whether
and how the phenomenon fits together with the treatment of other
phenomena is not considered. But Partee in Janssen 1997 and Jacobson
2014 give arguments against this tendency. Jacobson 2014 indeed
provides a fragment. 
3.4 Pragmatics

The meaning of sentences is sometimes determined by factors from the
context of use; e.g. whether I am happy is true, depends on
who the speaker is. Other examples are here and
this. Montague writes about these factors in his paper
‘Pragmatics’ (Montague 1968) and in Montague 1970b. He
indicates how this could be done by introducing additional parameters
(besides the time and the possible world). His papers focus on the
formal apparatus, and he works it out only for the pronoun
I.

Several authors followed Montague's approach, and extended, when
needed, the list of parameters. A classical example is Kaplan 1989,
which deals with demonstratives and indexicals. He uses
‘context’ as a parameter, which consists at least in
agent, moment of time, location, and possible world. The content of a
sentence, with respect to a context, is a proposition, and the
linguistic meaning, or character, of an expression is a function from
contexts to contents. This difference between content and meaning is
exploited to develop his (influential) theory of demonstratives
(she, her, that) and indexicals (I, today).

Cresswell (1973, 111) has another opinion. He argues that the approach
with parameters requires that a finite list of contextual features is
given in an advance. He considers that to be impossible and provides
an alternative. His proposal is not followed by other authors.

Presuppositions and implicatures are often considered as belonging to
pragmatics. The aim of a recursive approach to presupposition was
always in the air, for the practical reason that it seems the only way
to deal with presuppositions for infinitely many sentences. An example
of a compositional treatment is Peters 1979. But the phenomena are
complex, and later treatments are not always completely compositional;
several correcting factors have to be taken into consideration (Beaver
1997).

Finally, there is pragmatics in the sense of using a language in
practical situations. Declarative sentences can be used to ask
questions, and to give orders, and sometimes sentences are not used
literally, but metaphorically. On this aspect of pragmatics not much
has been written, but Cresswell (1973) explains that formal semantics
has all the ingredients to cope with it.
3.5 Ontology

Montague's ‘intensional logic’ is a higher order logic.
This aspect provoked a very critical attack by Hintikka:

It seems to me that this is the strategy employed by Montague
Grammarians, who are in fact strongly committed to compositionality.
[…]. There is a price to be paid however. The higher order
entities evoked in this “type theoretical ascent” are much
less realistic philosophically and psycholinguistically than our
original individuals. Hence the ascent is bound to detract from the
psycholinguistic and methodological realism of one's theory. (Hintikka
1983, 20)


Hintikka's criticism has not found many supporters. Ironically,
Hintikka's alternative (game theoretical semantics), is encapsulated
in the traditional Tarskian approach (see Hodges 1997 or Caicedo et
al. 2009); they define the meaning of a formula as a collection of
sets of assignments.

In Montague's approach possible worlds are basic objects without
internal or external structure. Phenomena having to do with belief,
require external structure, such as an accessibility relation for
belief-alternatives. Counterfactuals require a distance notion to
characterize worlds which differ minimally from each other. Structures
on possible worlds are used frequently.

Sometimes an internal structure for possible worlds is proposed. A
possible world determines a set of propositions (those propositions
which are true with respect to that world), and in Fox and Lappin
2005, the reverse order is followed. They have propositions as
primitive notions, and define possible worlds on the basis of them.
Also Cresswell (1973) provides a method for obtaining possible worlds
with internal structure: he describes how to build possible worlds
from basic facts. None of these proposals for internal structure have
been applied by other authors than the proposers.

The philosophical status of certain entities is not so clear, such as
pains, tasks, obligations and events. These are needed when evaluating
sentences like e.g. Jones had a pain similar to the one he had
yesterday. In ‘On the nature of certain philosophical
entities’ (Montague 1969), Montague describes how these notions
can be described using his intentional logic; they are properties of
moments of time in a possible world. Of these notions, only events
occur in papers by other authors, albeit not in the way Montague
suggested. They are seen as basic, but provided with an algebraic
structure allowing, e.g., subevents (Link 1998, ch. 10–12; Bach
1986a).

The set E may include whatever one would like to consider as
basic entities: numbers, possible objects, and possible individuals.
Whether an individual is considered to be really living or existing at
a certain moment of time or in a certain possible world is not given
directly by the model; one has to introduce a predicate expressing
this. Normally the set E has no internal structure, but for
mass nouns (which have the characteristic property that any part of
water is water), a structure is needed, see Pelletier & Schubert
2003. Also plurals might evoke a structure on the set E, e.g.
when sum-individuals are used (see Link 1983, 1998 (ch. 1–4),
and Bach 1986a). Also when properties (loving John) are
considered as entities for which predicates may hold (Mary likes
loving John) structure is needed: property theory gives the tools
to incorporate them (see Turner 1983).
3.6 Psychology

When Montague grammar emerged, the leading theory about syntax was
Chomskyan grammar. That approach claimed that it revealed processes
that went on in the brain, and that linguistics was a branch of
biology. In those days it was experimentally shown that the passive
transformation was a real process in the brain. Chomskyan grammar
still is a leading theory, and although most of the theory has changed
considerably (there is no passive transformation anymore), it still
considers itself to be revealing psychologically real processes.
Montague had no psychological claim for his theory; on the contrary,
he considered linguistics as a branch of mathematics and not of
psychology (Thomason (ed.) 1974, 2). 

However, the field remained interested in psychological aspects.
Partee (1977) explained to a meeting of psychologists that the theory
cannot be applied directly to psychology because of the huge numbers
of entities in the models (infinite numbers of functions from
functions to functions). Partee (1979) argues that there is a deep gap
between the mathematical view and the psychological view, especially
concerning propositional attitude verbs and the behavior of proper
names in such contexts, and she says that this gap has, somehow, to be
bridged.

An argument often put forward in defense of compositionality concerns
its psychological motivation. The principle explains how a person can
understand sentences he has never heard before; Frege (1923, 55)
already mentioned this argument This motivation for compositionality
is attacked by Schiffer (1987). On the one hand he argues that
compositionality is not needed in an explanation of that power, and on
the other hand that a compositional approach does not work. His
argumentation is illustrated by Tanya believes that Gustav is a
dog. Schiffer considers several compositional theories and argues
that none of these theories offers a plausible account for the
proposition that is supposed to be the content of Tanya's belief. So
there is nothing from which the meaning of the sentence can be formed
compositionally. Hence compositionality cannot hold. Partee (1988)
discusses Schiffer's arguments against compositionality, and explains
that Schiffer does not make a sufficient distinction between semantic
facts and psychological facts. Partee points out the analogy between
these problems with belief and those with the semantics of proper
names (how can one correctly use proper names without being acquainted
with the referent). The latter is discussed and explained by Kripke
(1972). Partee proposes to solve the problems of belief along the same
lines. Schiffer (1988) replies to this paper, but he does not react to
her analogy, nor to the main point: that a semantic theory is to be
distinguished from a psychological theory.

An extensive discussion of the relation between Montague semantics and
psychology is given in the last chapter in Dowty 1979. He starts his
chapter with a description of the situation. ‘Contemporary
linguists, unlike many philosophers of language, almost invariably
profess to be concerned with the “psychological reality”
of the theoretical concepts they postulate in semantics
analysis’ (Dowty 1979). He works out this point and then
describes his own position. ‘To get the point right away, let me
confess that I believe that the model theoretic intension of a word
has in principle nothing whatsoever to do with what goes on
in a person's head when he uses a word.’ Nevertheless, he tries
to show that the notion of intension is a fundamental and
indispensable concept from the point of view of ‘psychological
semantics’. He gives three reasons. The first is that semantics
provides a theory that explains entailment (and synonymity, validity
contradiction etc.]), all notions that must somehow be part of a
theory of language understanding. Secondly, the theory of truth and
reference must be a bottom line in any general account of
‘meaning’ in natural language. And thirdly, when certain
ways of compositionally deriving the meanings from their parts can be
shown to be necessary in a theory of truth and reference, then it may
be concluded that the same compositional analysis is necessary in a
theory of language understanding.

These examples illustrate the general opinion that psychological
reality can only very indirectly be associated with what is going on
in Montague semantics; only a few articles discuss the connection.
4. Concluding Remarks
4.1 Legacy

Montague revolutionized the field of semantic theory. He introduced
methods and tools from mathematical logic, and set standards for
explicitness in semantics. Now all semanticists know that logic has
more to offer than first order logic only. Finally, recall that
Barbara Partee said: ‘lambdas really changed my life’; in
fact lambdas changed the lives of all semanticists.
4.2 Further Reading

A recent introduction is Jacobson 2014. It is a gentle introduction to
the field, especially for linguists and philosophers. It presents
several successes obtained by the approach. Older introductions are
Dowty et al 1981 and Gamut 1991, which are more technical and prepare
for Montague's original paper. An overview of the history of the field
is given by Partee and Hendriks (1997). Collections of important
papers are Portner and Partee (eds.) 2002 and Partee 2004. The
‘Handbook of compositionality’(Werning et al 2011)
discusses many aspects of the approach. The most important journal in
the field are Linguistics and Philosophy, Natural Language Semantics,
and Semantics and Pragmatics. 
4.3 Example

A small example is presented below, it consists of the two sentences
John is singing, and Every man is singing. The
example is not presented in Montague's original way, but modernized:
there is a lifting rule, the determiner is a basic expression, and
intensional aspects are not considered.

The grammar has four basic expressions:

1. John is an expression of the category Proper Name. Its
denotation is an individual represented in logic by John.

2. The Intransitive Verb sing denotes a set (the set of
singers), and is represented by the predicate symbol sing.

3. The Common Noun man, which denotes a set, represented by
man.

4. The Determiner every. Its denotation is
λPλQ∀x[P(x)
→ Q(x)]; an explanation of this formula will be
given below.

The grammar has three rules.

1. A rule which takes as input a Proper Name, and produces a Noun
Phrase. The input word is not changed: it is lifted to a
‘higher’ grammatical category. Semantically its meaning is
lifted to a more abstract, a ‘higher’ meaning: the
representation of the denotation of John as Noun Phrase is
λP[P(John)]. An explanation of the formula
is as follows. P is a variable over properties: if we have
chosen an interpretation for P, we may say whether P
holds for John or not, i.e. whether P(John) is true. The
λP abstracts from the possible interpretations of
P: the expression λP[P(John)]
denotes a function that takes as input properties and yields
true if the property holds for John, and
false otherwise. So the denotation of John
is the characteristic function of the set of properties he has.

2. A rule that takes as input a Noun Phrase and an Intransitive Verb,
and yields as output a Sentence: from John and sing
it produces John is singing. The corresponding semantic rule
requires the denotation of the Noun Phrase to be applied to the
denotation of the Intransitive Verb. This is represented as
λP[P(John)](sing). When applied to
the argument sing, the function represented by
λP[P(John)] yields true
if the predicate sing holds for John, so precisely in
case sing(John) is true. So
λP[P(John)](sing) and
sing(John) are equivalent. The latter formula can be
obtained by removing the λP and substituting
sing for P. This is called
‘lambda-conversion’.

3. A rule that takes as inputs a Determiner and a Common Noun, and
yields a Noun Phrase: from every and man it produces
every man. Semantically the denotation of the Determiner has
to be applied to the denotation of the Common Noun, hence
λPλQ∀x[P(x)
→ Q(x)](man). By lambda conversion (just
explained) this is simplified to
λQ∀x[man(x) →
Q(x)]. This result denotes a function that, when applied
to property A, yields true just in case all
man have property A.

The example given with the last rule helps us to understand the
formula for every : that denotes a relation between
properties A and B which holds in case every A
has property B.

The next step is now easy. Apply the rule for combining a Noun Phrase
and an Intransitive Verb to the last result, producing Every man
is singing. The output of the semantic rule is
λQ∀x[man(x) →
Q(x)](sing). By lambda conversion we obtain
∀x[man(x) →sing(x)],
which is the traditional logical representation of Every man is
singing.

Note the role of lambda-operators:

1. John and every man are interpreted in a similar
way: sets of properties. These sets can be represented due to
lambda-operators.

2. Every man and sing are syntactically on the same
level, but semantically sing has a subordinated role: it occurs
embedded in the formula. This switch of level is possible due to
lambda-operators.