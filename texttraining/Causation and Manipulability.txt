Manipulability theories of causation, according to which causes are to
be regarded as handles or devices for manipulating effects, have
considerable intuitive appeal and are popular among social scientists
and statisticians. This article surveys several prominent versions of
such theories advocated by philosophers, and the many difficulties
they face. Philosophical statements of the manipulationist approach
are generally reductionist in aspiration and assign a central role to
human action. These contrast with recent discussions employing a
broadly manipulationist framework for understanding causation, such as
those due to the computer scientist Judea Pearl and others, which are
non-reductionist and rely instead on the notion of an intervention.
This is simply an appropriately exogenous causal process; it has no
essential connection with human action. This interventionist framework
manages to avoid at least some of these difficulties faced by
traditional philosophical versions of the manipulability theory and
helps to clarify the content of causal claims.
 
1. Introduction

A commonsensical idea about causation is that causal relationships are
relationships that are potentially exploitable for purposes of
manipulation and control: very roughly, if CCC is genuinely a cause
of EEE, then if I can manipulate CCC in the right way, this should
be a way of manipulating or changing EEE. This idea is the
cornerstone of manipulability theories of causation developed by
philosophers such as Gasking (1955), Collingwood (1940), von Wright
(1971), Menzies and Price (1993), and Woodward (2003). It is also an
idea that is advocated by many non-philosophers. For example, in their
extremely influential text on experimental design (1979) Cook and
Campbell write:


The paradigmatic assertion in causal relationships is that
manipulation of a cause will result in the manipulation of an
effect. … Causation implies that by varying one factor I
can make another vary. (Cook & Campbell 1979: 36, emphasis in
original)


Similar ideas are commonplace in econometrics and in the so-called
structural equations or causal modeling literature, and very recently
have been forcefully reiterated by the computer scientist Judea Pearl
in very influential book length treatment of causality (Pearl
2009).

At least until recently philosophical discussion has been
unsympathetic to manipulability theories: two standard complaints have
been that manipulability theories are unilluminatingly circular and
that they lead to a conception of causation that is unacceptably
anthropocentric or at least insufficiently general in the sense that
it is linked much too closely to the practical possibility of human
manipulation (see, e.g., Hausman 1986, 1998). Both objections seem
prima facie plausible. Suppose that XXX is a variable that
takes one of two different values, 0 and 1, depending on whether some
event of interest occurs. Then for an event or process MMM to
qualify as a manipulation of XXX, it would appear that there must be
a causal connection between MMM and XXX: to manipulate XXX, one
must cause it to change in value. How then can we use the
notion of manipulation to provide an account of causation? Moreover,
it is uncontroversial that causal relationships can obtain in
circumstances in which manipulation of the cause by human beings is
not practically possible—think of the causal relationship
between the gravitational attraction of the moon and the motion of the
tides or causal relationships in the very early universe. How can a
manipulability theory avoid generating a notion of causation that is
so closely tied to what humans can do that it is inapplicable to such
cases?

These philosophical criticisms of manipulability theories contrasts
with the widespread view among statisticians, theorists of
experimental design, and many social and natural scientists that an
appreciation of the connection between causation and manipulation can
play an important role in clarifying the meaning of causal claims and
understanding their distinctive features. This in turn generates a
puzzle. Are non-philosophers simply mistaken in thinking that focusing
on the connection between causation and manipulation can tell us
something valuable about causation? Does the widespread invocation of
something like a manipulability conception among practicing scientists
show that the usual philosophical criticisms of manipulability
theories of causation are misguided?

The ensuing discussion is organized as follows.
 Section 2
 describes a well-known version of an manipulability theory due to
Menzies and Price (1993) which assigns a central role to the notion of
agency or free action.
 Section 3
 describes reasons why the notion of a free action seems an inadequate
basis for the formulation of a manipulability theory.
 Section 4
 introduces the notion of an intervention which allows for a more
adequate statement of the manipulability approach to causation and
which has figured prominently in recent discussion.
 Section 5
 considers Pearl’s “interventionist” formulation of
a manipulability theory and an alternative to it, due to Woodward
(2003).
 Section 6
 takes up the charge that manipulability theories are circular.
 Section 7
 explores how interventionist ideas can be used to explicate a variety
of different causal concepts.
 Section 8
 returns to the relationship between interventions and human actions,
while
 §9
 discusses the role of counterfactuals in interventionist theories.
Sections
 10,
 11 and
 12
 consider the scope of manipulability accounts, while
 §13
 considers some objections to such accounts and
 §14
 some recent positive developments.

As we shall see, the somewhat different assessments of manipulability
accounts of causation within and outside of philosophy derive in part
from the different goals or aspirations that underlie the versions of
the theory developed by these two groups. Early philosophical
defenders of the manipulability conception such as von Wright and
Menzies and Price attempted to turn the connection between causation
and manipulability into a reductive analysis: their strategy was to
take as primitive the notion of manipulation (or some related notion
like agency or bringing about an outcome as a result of a free
action), to argue that this notion is not itself causal (or at least
does not presuppose all of the features of causality the investigator
is trying to analyze), and to then attempt to use this notion to
construct a non-circular reductive definition of what it is for a
relationship to be causal. Philosophical critics have (quite
reasonably) assessed such approaches in terms of this aspiration
(i.e., they have tended to think that manipulability accounts are of
interest only insofar as they lead to a non-circular analysis of
causal claims) and have found the claim of a successful reduction
unconvincing. By contrast, statisticians and other non-philosophers
who have explored the link between causation and manipulation
generally have not had reductionist aspirations—instead their
interest has been in unpacking what causal claims mean and in showing
how they figure in inference by tracing their interconnections with
other related concepts (such as manipulation) but without suggesting
that the notion of manipulation is itself a causally innocent
notion.

The impulse toward reduction contributes to the other features that
critics have found objectionable in standard formulations of the
manipulability theory. To carry through the reduction, one needs to
show that the notion of agency is independent of or prior to the
notion of causality and this in turn requires that human actions or
manipulations be given a special status—they can’t be
ordinary causal transactions, but must instead be an independent
fundamental feature of the world in their own right. This both seems
problematic on its own terms (it is prima facie inconsistent
with various naturalizing programs) and leads directly to the problem
of anthropocentricity: if the only way in which we understand
causation is by means of our prior grasp of an independent notion of
agency, then it is hard to see what could justify us in extending the
notion of causation to circumstances in which manipulation by human
beings is not possible and the relevant experience of agency
unavailable. Both von Wright and Menzies and Price struggle, not
entirely successfully, with this difficulty.

The way out of these problems is to follow Pearl and others in
reformulating the manipulability approach in terms of the notion of an
intervention, where this is characterized in purely causal terms that
make no essential reference to human action. Some human actions will
qualify as interventions but they will do so in virtue of their causal
characteristics, not because they are free or carried out by humans.
This “interventionist” reformulation allows the
manipulability theory to avoid a number of counterexamples to more
traditional versions of the theory. Moreover, when so reformulated, it
is arguable that the theory may be extended readily to capture causal
claims in contexts in which human manipulation is impossible. However,
the price of such a reformulation is that we lose the possibility of a
reduction of causal claims to claims that are non-causal. Fortunately
(or so
 §§7 and
 8 argue) an interventionist formulation of a manipulability
theory may be non-trivial and illuminating even if it fails to be
reductive.
2. Agency Theories. 

A comparatively early and influential statement of a manipulability
theory which assigns a central role to human agency is due to von
Wright (1971; see
 An Early Version of an Agency Theory
 for further discussion). However, this entry will focus on the more
recent version of an agency theory developed by Peter Menzies and Huw
Price (1993) (also discussed in a series of papers written by Price
alone [1991, 1992).
Menzies’ and Price’s basic thesis is that:


… an event AAA is a cause of a distinct event BBB just in
case bringing about the occurrence of AAA would be an effective
means by which a free agent could bring about the occurrence of BBB.
(1993: 187)


They take this connection between free agency and causation to support
a probabilistic analysis of causation (according to which “AAA
causes BBB” can be plausibly identified with “AAA
raises the probability of BBB”) provided that the
probabilities appealed to are what they call “agent
probabilities,” where


[a]gent probabilities are to be thought of as conditional
probabilities, assessed from the agent’s perspective under the
supposition that antecedent condition is realized ab initio,
as a free act of the agent concerned. Thus the agent probability that
one should ascribe to BBB conditional on AAA is the probability
that BBB would hold were one to choose to realize AAA. (1993:
190)


The idea is thus that the agent probability of BBB conditional on
AAA is the probability that BBB would have conditional on the
assumption that AAA has a special sort of status or history—in
particular, on the assumption that A is realized by a free act. AAA
will be a cause of BBB just in case the probability of BBB
conditional on the assumption that AAA is realized by a free act is
greater than the unconditional probability of BBB; AAA will be a
spurious cause of BBB just in case these two probabilities are
equal. As an illustration, consider a stock example of
philosophers—a structure in which atmospheric pressure,
represented by a variable ZZZ, is a common cause of the reading
XXX of a barometer and the occurrence of a storm YYY, with no
causal relationship between XXX and Y.XY.XY. X and YYY will be
correlated, but Price’s and Menzies’ intuitive idea is
that conditional on the realization of XXX by a free act, this
correlation will disappear, indicating that the correlation between
XXX and YYY is spurious and does not reflect a causal connection
from XXX to YYY. If, by contrast, this correlation were to
persist, this would be an indication that XXX was after all a cause
of YYY. (What “free act” might mean in this context will
be explored below, but I take it that what is
intended—as opposed to what Price and Menzies actually
say—is that the manipulation of XXX should satisfy the
conditions we would associate with an ideal experiment designed to
determine whether XXX causes YYY—thus, for example, the
experimenter should manipulate the position of the barometer dial in a
way that is independent of the atmospheric pressure ZZZ, perhaps by
setting its value after consulting the output of some randomizing
device.)

Menzies and Price claim that they can appeal to this notion of agency
to provide a non-circular, reductive analysis of causation. They claim
that circularity is avoided because we have a grasp of the
experience of agency that is independent of our grasp of the
general notion of causation.


The basic premise is that from an early age, we all have direct
experience of acting as agents. That is, we have direct experience not
merely of the Humean succession of events in the external world, but
of a very special class of such successions: those in which the
earlier event is an action of our own, performed in circumstances in
which we both desire the later event, and believe that it is more
probable given the act in question than it would be otherwise. To put
it more simply, we all have direct personal experience of doing one
thing and thence achieving another. … It is this common and
commonplace experience that licenses what amounts to an ostensive
definition of the notion of ‘bringing about’. In other
words, these cases provide direct non-linguistic acquaintance with the
concept of bringing about an event; acquaintance which does not depend
on prior acquisition of any causal notion. An agency theory thus
escapes the threat of circularity. (1993: 194–5)


Menzies and Price recognize that, once the notion of causation has
been tied in this way to our “personal experience of doing one
thing and hence achieving another” (1993: 194), a problem arises
concerning unmanipulable causes. To use their own example, what can it
mean to say that “the 1989 San Francisco earthquake was caused
by friction between continental plates” (1993: 195) if no one
has (or given the present state of human capabilities could have) the
direct personal experience of bringing about an earthquake by
manipulating these plates? Their response to this difficulty is
complex, but the central idea is captured in the following
passages


… we would argue that when an agent can bring about one event
as a means to bringing about another, this is true in virtue of
certain basic intrinsic features of the situation involved, these
features being essentially non-causal though not necessarily physical
in character. Accordingly, when we are presented with another
situation involving a pair of events which resembles the given
situation with respect to its intrinsic features, we infer that the
pair of events are causally related even though they may not be
manipulable. (1993: 197)

Clearly, the agency account, so weakened, allows us to make causal
claims about unmanipulable events such as the claim that the 1989 San
Francisco earthquake was caused by friction between continental
plates. We can make such causal claims because we believe that there
is another situation that models the circumstances surrounding the
earthquake in the essential respects and does support a means-end
relation between an appropriate pair of events. The paradigm example
of such a situation would be that created by seismologists in their
artificial simulations of the movement of continental plates. (1993:
197)


One problem with this suggestion has to do with how we are to
understand the “intrinsic” but (allegedly)
“non-causal” features in virtue of which the movements of
the continental plates “resemble” the artificial models
which the seismologists are able to manipulate. It is well-known that
small scale models and simulations of naturally occurring phenomena
that superficially resemble or mimic those phenomena may nonetheless
fail to capture their causally relevant features because, for example,
the models fail to “scale up”—because causal
processes that are not represented in the model become quite important
at the length scales that characterize the naturally occurring
phenomena. Thus, when we ask what it is for a model or simulation
which contains manipulable causes to “resemble” phenomena
involving unmanipulable causes, the relevant notion of resemblance
seems to require that the same causal processes are operative
in both. Menzies and Price do not provide any reason to think that
this notion of resemblance can be characterized in non-causal terms.
But if the extension of their account to unmanipulable causes requires
a notion of resemblance that is already causal in character and which,
ex hypothesi cannot be explained in terms of our experience
of agency, then their reduction fails.

It might be thought the difficulty under discussion can be avoided by
the simple expedient of adhering to a counterfactual formulation of
the manipulability theory. Indeed, it is clear that some
counterfactual formulation is required if the theory is to be even
remotely plausible: after all, no one supposes that AAA can only be
a cause of BBB if AAA is in fact manipulated. One thus might
consider a formulation along the lines of:

(CF) AAA
causes BBB if and only if BBB would change if an appropriate
manipulation [by humans] on AAA were to be carried
out.


The suggestion under consideration attempts to avoid the difficulties
posed by causes that are not manipulable by human beings by contending
that for
 (CF)
 to be true, it is not required that the manipulation in question be
practically possible for human beings to carry out or even that human
beings exist. Instead all that is required is that ififif human beings
were to carry out the requisite manipulation of AAA (e.g., the
continental plates), BBB (whether or not an earthquake occurs) would
change. (The possibility of adopting such a counterfactual formulation
is sympathetically explored, but not fully endorsed by Ernest Sosa and
Michael Tooley in the introduction to their 1993.)

One fundamental problem with this suggestion is that, independently of
whether a counterfactual formulation is adopted, the notion of a free
action or human manipulation cannot by itself, for reasons to be
described in
 §3,
 do the work (that of distinguishing between genuine and spurious
causal relationships) that Menzies and Price wish it to do. But in
addition to this, a counterfactual formulation along the lines of
 (CF)
 seems completely unilluminating unless accompanied by some sort of
account of how we are to understand and assess such counterfactuals
and, more specifically, what sort of situation or possibility we are
supposed to envision when we imagine that the antecedent of
 (CF)
 is true. Consider, for example, a causal claim about the very early
universe during which temperatures are so high that atoms and
molecules and presumably anything we can recognize as an agent cannot
exist. What counterfactual scenario or possible world are we supposed
to envision when we ask, along the lines of
 (CF),
 what would happen if human beings were to exist and were able to
carry out certain manipulations in this situation? A satisfying
version of an agency theory should give us an account of how our
experience of agency in ordinary contexts gives us a purchase on how
to understand and evaluate such counterfactuals. To their credit,
Menzies and Price attempt to do this, but in my view they are
unsuccessful.
3. Causation and Free Action

As we have seen, Menzies and Price assign a central role to
“free action” in the elucidation of causation. They do not
further explain what they mean by this phrase, preferring instead, as
the passage quoted above indicates, to point to a characteristic
experience we have as agents. It seems clear, however, that whether
(as soft determinists would have it) a free action is understood as an
action that is uncoerced or unconstrained or due to voluntary choices
of the agent, or whether, as libertarians would have it, a free action
is an action that is uncaused or not deterministically caused, the
persistence of a correlation between AAA and BBB when AAA is
realized as a “free act” is not sufficient for
AAA to cause BBB. Suppose that, in the example described above,
the position of the barometer dial XXX is set by a free act (in
either of the above senses) of the experimenter but that this free act
(and hence X)X)X) is correlated with ZZZ, the variable measuring
atmospheric pressure, perhaps because the experimenter observes the
atmospheric pressure and freely chooses to set XXX in a way that is
correlated with ZZZ. (This possibility is compatible with the
experimenter’s act of setting XXX being free in either of the
above two senses.) In this case, XXX will remain correlated with
YYY when produced by a free act, even though XXX does not cause
YYY. Suppose, then, that we respond to this difficulty by adding to
our characterization of AAA’s being realized by a free act the
idea that this act must not itself be correlated with any other cause
of AAA. (Passages in Price 1991 suggest such an additional proviso,
although the condition in question seems to have nothing to do with
the usual understanding of free action.) Even with this proviso, it
need not be the case that AAA causes BBB if AAA remains
correlated with BBB when AAA is produced by an act that is free in
this sense, since it still remains possible that the free act that
produces AAA also causes BBB via a route that does not go through
AAA. As an illustration, consider a case in which an
experimenter’s administration of a drug to a treatment group (by
inducing patients to ingest it) has a placebo effect that enhances
recovery, even though the drug itself has no effect on recovery. There
is a correlation between ingestion of the drug and recovery that
persists under the experimenter’s free act of administering the
drug even though ingestion of the drug does not cause recovery.
4. Interventions

Examples like those just described show that if we wish to follow
Menzies and Price in defending the claim that if an association
between AAA and BBB persists when AAA is given the right sort of
“independent causal history” or is
“manipulated” in the right way, then AAA causes BBB,
we need to be much more precise by what we mean by the quoted phases.
There have been a number of attempts to do this in the recent
literature on causation. The basic idea that all of these discussions
attempt to capture is that of a “surgical” change in AAA
which is of such a character that if any change occurs in BBB, it
occurs only as a result of its causal connection, if any, to AAA and
not in any other way. In other words, the change in BBB, if any,
that is produced by the manipulation of AAA should be produced only
via a causal route that goes through AAA. Manipulations or changes
in the value of a variable that have the right sort of surgical
features have come to be called interventions in the recent
literature (e.g., Spirtes, Glymour, and Scheines 2000; Meek and
Glymour 1994; Hausman 1998; Pearl 2009; Woodward 1997, 2000, 2003;
Woodward and Hitchcock 2003; Cartwright 2003) and I will follow this
practice. The characterization of the notion of an intervention is
rightly seen by many writers as central to the development of a
plausible version of a manipulability theory. One of the most detailed
attempts to think systematically about interventions and their
significance for understanding causation is due to Pearl 2009 and I
turn now to a discussion of his views.
5. Structural Equations, Directed Graphs, and Manipulationist Theories of Causation

A great deal of recent work on causation has used systems of equations
and directed graphs to represent causal relationships. Judea Pearl
(e.g., Pearl 2009) is an influential example of this approach. His
work provides a striking illustration of the heuristic usefulness of a
manipulationist framework in specifying what it is to give such
systems a causal
 interpretation.[1]
 Pearl characterizes the notion of an intervention by reference to a
primitive notion of a causal mechanism. A functional causal model is a
system of equations Xi=F(Pai,Ui)Xi=F(Pai,Ui)X_i = F(Pa_i, U_i) where PaiPaiPa_i represents
the parents or direct causes of XiXiX_i that are explicitly included
in the model and UiUiU_i represents an error variable that summarizes
the impact of all excluded variables. Each equation represents a
distinct causal mechanism which is understood to be
“autonomous” in the sense in which that notion is used in
econometrics; this means roughly that it is possible to interfere with
or disrupt each mechanism (and the corresponding equation) without
disrupting any of the others. The simplest sort of intervention in
which some variable XiXiX_i is set to some particular value xixix_i
amounts, in Pearl’s words, to 


lifting XiXiX_i from the influence of the old functional mechanism
Xi=Fi(Pai,Ui)Xi=Fi(Pai,Ui)X_i = F_i(Pa_i, U_i) and placing it under the influence of a new
mechanism that sets the value xixix_i while keeping all other
mechanisms undisturbed. (Pearl 2009: 70; I have altered the notation
slightly) 


In other words, the intervention disrupts completely the relationship
between XiXiX_i and its parents so that the value of XiXiX_i is
determined entirely by the intervention. Furthermore, the intervention
is surgical in the sense that no other causal relationships in the
system are changed. Formally, this amounts to replacing the equation
governing XiXiX_i with a new equation Xi=xiXi=xiX_i = x_i, substituting for
this new value of XiXiX_i in all the equations in which XiXiX_i occurs
but leaving the other equations themselves unaltered. In a graphical
representation of causal relationships (see below), an intervention of
this sort on a variable XiXiX_i breaks or removes all other arrows
directed into XiXiX_i, so that the value of XiXiX_i is now completely
fixed by the intervention. Pearl’s assumption is that the other
variables that change in value under this intervention will do so only
if they are effects of XiXiX_i.

Again, if we want to use this notion of an intervention to elucidate
what it is for XXX to cause YYY it is natural to move to a
counterfactual formulation in the sense that what matters for whether
XXX causes YYY is what would happen to YYY if an intervention on
XXX of the sort described above were to occur. Following what has
become an established usage I will call such counterfactuals, the
antecedents of which correspond to claims about interventions (If
XXX were set to value xxx under an intervention, then…)
interventionist counterfactuals. These are the
counterfactuals that (under some interpretation, perhaps not
necessarily involving Pearl’s particular notion of an
intervention) seem most suitable for formulating a manipulability
theory of causation.

The need for such a counterfactual formulation raises several
questions that will be explored in more detail below. First, how
should one understand (what is the appropriate interpretation of or
semantics for) the counterfactuals in question? Without attempting to
answer this question in detail, it seems plausible that if
interventionist counterfactuals are to be useful in elucidating causal
claims, their semantics must be different from the familiar
Lewis/Stalnaker possible world semantics in some respects, as is
argued by Woodward (2003), Briggs (2012), Fine (2012). For example, on
the Lewis/Stalnaker semantics, counterfactuals with logically or
metaphysically impossible antecedents are always vacuously true, but
presumably we don’t want the causal claims that might be
associated with such counterfactuals to be automatically true (cf.
 §12).
 

A second difference is that an interventionist counterfactual of form
“If an intervention were to set X=xX=xX=x, then Y=yY=yY= y”
requires for its truth that all such interventions (or at
least all such interventions within the background circumstances in
which the causal model of interest is taken to hold) would be followed
by Y=yY=yY= y. This has the consequence that, for example, “strong
centering” which holds for the Lewis/Stalnaker semantics, does
not hold for interventionist counterfactuals. According to
strong centering the actual world is more similar to itself than any
other possible world. Thus if both ppp and qqq hold in the actual
world, then the “counterfactual” (that is, subjunctive
conditional) “if ppp were the case, qqq would be the
case”, is automatically true, As an illustration of the
difference this makes, suppose that XXX and YYY obey the following
intervention–supporting functional relation: If and only if X=1X=1X=
1.5, then Y=3Y=3Y= 3. Suppose that in the actual world, X=1.5X=1.5X= 1.5,
Y=3Y=3Y= 3. Now consider the counterfactual CCC : If 1<X<31<X<31\lt X \lt 3,
then Y=3Y=3Y=3. Assuming strong centering, the closest world to the
actual world in which the antecedent of CCC is true is the actual
world in which X=1.5X=1.5X=1.5. In this world, Y=3Y=3Y=3, so CCC is true. By
contrast, CCC is false under an interventionist interpretation,
since values of XXX between 1 and 3 other than 1.5 are not followed
by 3. Arguably the interventionist verdict that CCC (and the
associated causal claim that “XXX being between 1 and 3 causes
Y=3)Y=3)Y=3)” are false is the correct view. Several other
differences between interventionist counterfactuals and the
Lewis/Stalnaker semantics will be noted below.

A second general issue, related to the one just described, concerns
the sense, if any, in which interventions must be
“possible” and the bearing of this on the truth of the
associated causal claims. Returning to the notion of intervention
associated with Pearl above, note that this notion says nothing about
whether there is an actual or even possible causal factor that might
accomplish the kind of surgical modification Pearl describes. We may
if we wish represent such an intervention III by means of arrow
directed into the variable XiXiX_i that is intervened on which breaks
all other arrows directed into XiXiX_i (and Pearl sometimes uses this
representation) but both the III variable and this arrow seem
dispensable. We could instead just think of XiXiX_i as set to some new
value in the arrow-breaking or equation replacement manner described
above, with no further restrictions on when such a setting operation
is possible (or when it is permissible or legitimate to invoke it). I
will call this a setting intervention. This contrasts with an
alternative conception of interventions and their connection to causal
claims according to which the truth of a claim like “XXX
causes YYY” requires that interventions on XXX must be
“possible” in some non-trivial sense of this notion, which
then must be specified. (In other words, the truth of “XXX
causes YYY” requires both that YYY changes under an
intervention on XXX and that this intervention be
possible.) When a possibility condition of this sort is imposed, I
will say we are making use of a possibility constrained
notion of intervention. Use of this notion raises the difficult
question of how the relevant notion of possibility should be
understood. I will suggest below that the best way of making sense of
this notion is in terms of some notion of conceptual or mathematical
(or if you like, “metaphysical”) coherence—roughly
speaking, the issue is whether there is an appropriately empirically
grounded theoretical/mathematical apparatus that allows for a coherent
description of the possible intervention in question and allows us to
determine what would happen if the intervention were realized. In some
cases (see below) such a description may be available even though the
intervention in question may not be physically
 possible.[2]
 Recognizing obvious worries about the clarity of this notion of
possibility (which in my view should be acknowledged by defenders of
this notion), one might think that it is preferable to always employ
the setting notion in formulating an interventionist account. However,
as we shall see, formulations in terms of the “possibility
constrained” notion have appealing features (they seem to do a
better job of capturing the truth conditions for some causal claims)
and a number of writers seem to rely on such a conception. 

Returning to Pearl, and following his framework, let us represent the
proposition that the value of XXX has been set by an intervention to
some particular value, x0x0x_0, by means of a “dodo\do”
operator (do(X=x0)(do⁡(X=x0)(\do(X=x_0), or more simply, dox0)do⁡x0)\do x_0). It is
important to understand that conditioning on the information that the
value of XXX has been set to x0x0x_0 will in general be
quite different from conditioning on the information that the value of
XXX has been observed to be x0x0x_0 (see Meek and Glymour
1994; Pearl 2009). For example, in the case in which XXX and YYY
are joint effects of the common cause ZZZ, and XXX does not cause
YYY, P(Y/X=x0)≠P(Y)P(Y/X=x0)≠P(Y)P(Y/X=x_0) \ne P(Y); that is, YYY and XXX are not
independent. However, P(Y/do(X=x0)=P(Y)P(Y/do⁡(X=x0)=P(Y)P(Y/\do(X=x_0) = P(Y); that is, YYY will
be independent of XXX, if the value of XXX is set by an
intervention. This is because the intervention on XXX will break the
causal connection from ZZZ to XXX, so that the probabilistic
dependence between YYY and XXX that is produced by ZZZ in the
undisturbed system will no longer hold once the intervention occurs.
In this way, we may capture Menzies’ and Price’s idea that
XXX causes YYY if and only if the correlation between XXX and
YYY would persist under the right sort of manipulation of XXX.

This framework allows for a simple definitions of various causal
notions. For example, Pearl defines the “causal effect” of
XXX on YYY associated with the “realization” of a
particular value xxx of XXX as:

(C)P(Y/dox)P(Y/do⁡x)P(Y /{\do
x})


that is, as the distribution that YYY would assume under an
intervention that sets the value of XXX to the value xxx. Again,
it is obvious that this is a version of a counterfactual account of
causation. 

One of the many attractions of this approach is that it yields a very
natural account of what it is to give a causal interpretation to a
system of equations of the sort employed in the so-called causal
modeling literature. For example, if a linear regression equation Y=aX+UY=aX+UY
= aX + U makes a causal claim, it is to be understood as claiming
that if an intervention were to occur that sets the value of X=x0X=x0X=x_0
in circumstances U=u0U=u0U=u_0, the value of YYY would be y=ax0+u0y=ax0+u0y = ax_0 +
u_0, or alternatively that an intervention that changes XXX by
amount dxdxdx will change YYY by amount adxadxa\; dx. As another
illustration consider the system of equations

(1)Y=aX+UY=aX+UY = aX +
U
(2) Z=bX+cY+VZ=bX+cY+VZ = bX +
cY + V


We may rewrite these as follows:

(1)Y=aX+UY=aX+UY = aX +
U
(3) Z=dX+WZ=dX+WZ = dX +
W


where d=b+acd=b+acd = b + ac and W=cU+VW=cU+VW = cU + V. Since (3) has been obtained
by substituting (1) into (2), the system (1)–(2) has exactly the
same solutions in X,YX,YX, Y, and ZZZ as the system (1)–(3).
Since X,YX,YX, Y and ZZZ are the only measured variables,
(1)–(2) and (1)–(3) are “observationally
equivalent” in the sense that they imply or represent exactly
the same facts about the patterns of correlations that obtain among
the measured variables. Nonetheless, the two systems correspond to
different causal structures. (1)–(2) says that XXX is a direct
cause of YYY and that XXX and YYY are direct causes of ZZZ. By
contrast, (1)–(3) says that XXX is a direct cause of YYY and
that XXX is a direct cause of ZZZ but says nothing about a causal
relation between YYY and ZZZ. We can cash this difference out
within the interventionist/manipulationist framework described
above—(2) claims that an intervention on YYY will change ZZZ
while (1)–(3) denies this. (Recall that an intervention on YYY
with respect to ZZZ must not be correlated with any other cause of
ZZZ such as XXX, and will break any causal connection between
XXX and YYY.) Thus while the two systems of equations agree about
the correlations so far observed, they disagree about what would
happen under an intervention on YYY. According to an
interventionist/manipulationist account of causation, it is the system
that gets such counterfactuals right that correctly represents the
causal facts.

One possible limitation of the notion of a setting intervention (or at
least Pearl’s characterization of it) concerns the scope of the
requirement that an intervention on XiXiX_i leave intact all
other mechanisms besides the mechanism that previously determined the
value of X.iXi.X_i^. If, as Pearl apparently intends, we understand this
to include the requirement that an intervention on XiXiX_i must leave
intact the causal mechanism if any, that connects XXXi to its
possible effects YYY, then an obvious worry about circularity
arises, at least if we want to use the notion of an intervention to
characterize what it is for XiXiX_i to cause YYY. A closely related
problem is that given the way Pearl characterizes the notion of an
intervention, his definition
 (C)
of the causal effect of XXX on YYY, seems to give us not the
causal contribution made by X=xX=xX = x alone to YYY but rather the
combined impact on YYY of this contribution and whatever
contribution is made to the value of YYY by other causes of YYY
besides XXX. For example, in the case of the regression equation Y=aX+UY=aX+UY
= aX+U, the causal effect in Pearl’s sense of X=xonYX=xonYX=x
\textrm{on} Y is apparently P(Y)=ax+UP(Y)=ax+UP(Y) = ax + U, rather than, as one
might expect, just axaxax. In part for these reasons (and for other
reasons, described below), Woodward (2003) and Woodward and Hitchcock
(2003) explore a different way of characterizing the notion of an
intervention which does not make reference to the relationship between
the variable intervened on and its effects. For Woodward and
Hitchcock, in contrast to Pearl, an intervention III on a variable
XXX is always defined with respect to a second variable YYY (the
intent being to use the notion of an intervention on XXX with
respect to YYY to characterize what it is for XXX to cause Y)Y)Y).
Such an intervention III must meet the following requirements
(M1–M4):

(M1)III
must be the only cause of XXX; i.e., as with Pearl, the intervention
must completely disrupt the causal relationship between XXX and its
previous causes so that the value of XXX is set entirely by
III,
(M2)III
must not directly cause YYY via a route that does not go through
XXX as in the placebo example,
(M3)III
should not itself be caused by any cause that affects YYY via a
route that does not go through XXX, and
(M4)III
leaves the values taken by any causes of YYY except those that are
on the directed path from III to XXX to YYY (should this exist)
unchanged.


This characterization makes explicit reference to conditions that must
be satisfied by the intervention variable I.I.I. Although perhaps not
mandatory, questions about what it means for such an III to be
possible and how we are to understand the antecedents of the
associated interventionist counterfactuals (“If an intervention
satisfying
 (M1)–(M4)
 on XXX were to occur,…”) thus arise in a natural way
on this characterization—or at so I will assume in what follows.


Putting aside these issues about possibility for the present, the most
natural way of defining the notion of causal effect in the framework
associated with
 (M1)–(M4)
 is in terms of the difference made to the value of YYY by
a change or difference in the value of XXX. (This is also
effectively the definition of causal effect adopted in Rubin 1974. Focusing on differences in
this way allows us to isolate the contribution made to YYY by XXX
alone from the contribution made to YYY by its other causes.
Moreover, since in the non-linear case, the change in the value of
YYY caused by a given change in the value of XXX will depend on
the values of the other causes of YYY, it seems to follow that the
notion of causal effect must be relativized to a background context
BiBiB_i which incorporates information about these other values. In
deterministic contexts, we might thus define the causal effect on
YYY of a change in the value of XXX from X=xX=xX=x to X=x′X=x′X=x' in
circumstances BiBiB_i as:

(CD) Ydox,Bi−Ydox′,BiYdo⁡x,Bi−Ydo⁡x′,BiY_{\do
x, B_i} - Y_{\do x', B_i}


that is, as the difference between the value that YYY would take
under an intervention that sets X=xX=xX=x in circumstances BiBiB_i and
the value that YYY would take under an intervention that sets
X=x′X=x′X=x' in BiBiB_i, where the notion of an intervention is now
understood in terms of
 (M1)–(M4) rather than in the way
 recommended by Pearl. In non-deterministic contexts, the
 characterization of causal effect is less straightforward, but one
 natural proposal is to define this notion in terms of expectations:
 If we let  EPdox,Bi(Y)EPdo⁡x,Bi(Y)E P_{\do x, B_{i}}(Y) be the expectation of YYY with
 respect to the probability distribution PPP if XXX is set to
 X=xX=xX=x by means of an intervention, then the causal effect on YYY
 of a change in XXX from X=x′′X=x″X=x'' to X=xX=xX=x might be defined as:
 EPdox,Bi(Y)−EPdox′,Bi(Y)EPdo⁡x,Bi(Y)−EPdo⁡x′,Bi(Y)E P_{\do x, B_{i}}(Y) - E P_{\do x', B_{i}}
 (Y). 

I will not attempt to adjudicate here among these and various other
proposals concerning the best way to characterize the notions of
intervention and causal effect. Instead, I want to comment on the
general strategy they embody and to compare it with the approach to
causation associated with theorists like Menzies and Price. Note first
that the notion of an intervention, when understood along either of
the lines described above, is an unambiguously causal notion in the
sense that causal notions are required for its
characterization—thus the proposals variously speak of an
intervention on XXX as breaking the causal connection between XXX
and its causes while leaving other causal mechanisms intact or as not
affecting YYY via a causal route that does not go through XXX.
This has the immediate consequence that one cannot use the notion of
an intervention to provide a reduction of causal claims to non-causal
claims. Moreover, to the extent that reliance on some notion like that
of an intervention is unavoidable in any satisfactory version of a
manipulability theory (as I believe that it is), any such theory must
be non-reductionist. Indeed, we can now see that critics who have
charged manipulability theories with circularity have in one important
sense understated their case: manipulability theories turn out to be
“circular” not just in the obvious sense that for an
action or event III to constitute an intervention on a variable
XXX, there must be a causal relationship between III and XXX,
but in the sense that III must meet a number of other causal
conditions as well.
6. Is Circularity a Problem?

Suppose that we agree that any plausible version of a manipulability
theory must make use of the notion of an intervention and that this
must be characterized in causal terms. Does this sort of
“circularity” make any such theory trivial and
unilluminating? It is arguable that it does not, for at least two
reasons. First, it may be, as writers like Woodward (2003) contend,
that in characterizing what it is for a process III to qualify as an
intervention on XXX for the purposes of characterizing what it is
for XXX to cause YYY, we need not make use of information about
the causal relationship, if any, between XXX and YYY. Instead, it
may be that we need only to make use of other sorts of causal
information, e.g., about the causal relationship between III and
YYY or about whether III is caused by causes that cause YYY
without causing XXX, as in
 (M1)–(M4)
 above. To the extent that this is so, we may use one set of claims
about causal relationships (e.g., that XXX has been changed in a way
that meets the conditions for an intervention) together with
correlational information (that XXX and YYY remain correlated
under this change) to characterize what it is for a different
relationship (the relationship between XXX and Y)Y)Y) to be causal.
This does not yield a reduction of causal talk to non-causal talk, but
it is also not viciously circular in the sense that it presupposes
that we already have causal information about the very relationship
that we are trying to characterize. One reason for thinking that there
must be some way of characterizing the notion of an
intervention along the lines just described is that we do sometimes
learn about causal relationships by performing experiments—and
it is not easy to see how this is possible if to characterize the
notion of an intervention on XXX we had to make reference to the
causal relationship between XXX and its effects.

A related point is that even if manipulability accounts of causation
are non-reductive, they can conflict with other accounts of
causation, leading to different causal judgments in particular cases.
As an illustration consider a simple version of manipulability account
along the lines of
 (CD),
 according to which a sufficient condition for XXX to cause (have a
causal effect on Y)Y)Y) is that some change in the value of XXX
produced by an intervention is associated with a change in the value
of YYY (in the background circumstances of interest). Such an
account implies that omissions (e.g., the failure of a gardener to
water a plant) can be causes (e.g., of the plant’s death) since
a change under an intervention in whether the gardener waters is
associated with a change in the value of the variable measuring
whether the plant dies. For a similar reason relationships involving
“double prevention” (Hall 2000) or “causation by
disconnection” (Schaffer 2000) count as genuine causal
relationships on interventionist accounts. Consider, by contrast, the
verdicts about these cases reached by a simple version of a causal
process theory (in the sense of Salmon 1984, Dowe 2000) according
to which a necessary condition for a particular instantiation xxx of
a value XXX to cause a particular instantiation yyy of a value
YYY is that there be a spatio-temporally continuous process
connecting xxx to yyy involving the transfer of energy, momentum
or perhaps some other conserved quantity. According to such a theory,
“causation” by omission or by double prevention does not
qualify as genuine causation. Similarly, if an “action at a
distance” version of Newtonian gravitational theory had turned
out to be correct, this would be a theory that described genuine
causal relationships according to interventionist accounts of
causation, but not according to causal process accounts. Whether one
regards the verdicts about these cases reached by causal process
accounts or by interventionist accounts as more defensible, the very
fact that the accounts lead to inconsistent judgments shows that
interventionist approaches are not trivial or vacuous, despite their
“circular”, non-reductive character.
7. The Plurality of Causal Concepts

A second respect in which reliance on the notion of an intervention
need not be thought of as introducing a vicious circularity is this:
So far, I have been following Menzies and Price in assuming that there
is just one causal notion or locution (A(A(A causes BBB, where AAA
and BBB are types of events) that we are trying to analyze. But in
fact there are many such notions. For example, among causal notions
belonging to the family of so-called type causal notions (i.e., causal
claims that relate types of events or variables) there is a
distinction to be drawn between what we might call claims about total
or net causes and claims about direct causes. Even if the notion of an
intervention presupposes some causal notion such as some notion of
type causation, it may be that we can use it to characterize other
causal notions.

As an illustration consider the causal structure represented by the
following equations and associated directed graph


YZ=aX+cZ=bXY=aX+cZZ=bX
\begin{align*}
Y &amp; = aX + cZ\\
Z &amp; = bX\\
\end{align*}







In this structure, there are two different causal routes from XXX to
YYY—a direct causal relationship and an indirect relationship
with ZZZ as an intermediate variable. If a=−bca=−bca = {-bc}, there is
cancellation along these two routes. This means that no intervention
on XXX will change the value of YYY. In one natural sense, this
seems to mean that XXX does not cause YYY, assuming that (C*) a
necessary condition for XXX to cause YYY is that some
interventions on XXX are associated with changes in the value of
Y,Y,Y, as an obvious extension of CD seems to suggest. In another
natural sense, however, XXX does seem to be a cause—indeed a
direct cause—of YYY. We can resolve this apparent
inconsistency by distinguishing between two kinds of causal claims
(for a related distinction, see Hitchcock 2001b )—the claim XXX is a total
or net cause of YYY, where this is captured by (C*) and the claim
that XXX is a direct cause of YYY, where this is understood along
the following lines: XXX is a direct cause of YYY if and only if
under some intervention that changes the value of XXX, the value of
YYY changes when all other variables in the system of interest
distinct from XXX and YYY including those that are on some causal
route from XXX to YYY, are held fixed at some value, also by
interventions. (For related, but different, characterizations of
direct causation along these lines, see Pearl 2009 and Woodward 2003.)
Fixing the other values of other variables means that each of these
values is determined by separate processes, each meeting the
conditions for an intervention, that are appropriately independent of
each other and of the intervention that changes the value of XXX.
The effect of intervening to fix the values of these variables is thus
that each variable intervened on is disconnected from its causes,
including XXX. In the example under discussion, XXX qualifies as a
direct cause of YYY because if we were to fix the value of ZZZ in
a way that disconnects it from the value of XXX, and then intervene
to change the value of XXX, the value of YYY would change. This
idea can then be generalized to provide a characterization of
“contributing” causation along a causal route, i.e., to
capture the sense in which XXX is an indirect cause of YYY along
the route that goes through ZZZ (Woodward 2003).

So far our focus has been on type causal claims of various kinds.
There are also a number of proposals in the literature that provide
interventionist treatments of token or actual cause claims (these have
to do with the event of XXX’s taking on a particular value
being an actual cause of YYY’s taking on a particular value,
as when it is claimed that Jones’ smoking caused his lung
cancer), including those that involve various forms of pre-emption and
over-determination (e.g., Halpern and Pearl 2005 a, b; ; Hitchcock
2001a; Woodward 2003; Hitchcock 2007a; Hall 2007; Glymour and Wimberly
2007; Halpern and Hitchcock 2015; Halpern 2016; Weslake
forthcoming). Considerations of space preclude detailed description,
but one strategy that has been explored is to appeal to what will
happen to the effect under combinations of interventions that
both affect the cause and that fix certain other variables to specific
values. As an illustration, consider a standard case of causal
pre-emption: Gunman one shoots (s1)(s1)(s_1) victim, causing his death
ddd, while gunman two does not shoot but would have shot (s2)(s2)(s_2)
also causing ddd, if s1s1s_1 had not occurred.  If we fix (via an
intervention) the behavior of the gunman two at its actual value (he
does not shoot), then an independent intervention that alters whether
gunman one shoots will alter whether victim dies, thus identifying
s1s1s_1 as the actual cause of ddd, despite the absence of
counterfactual dependence (of the usual sort) between ddd and
s1s1s_1. Accounts along these lines are able to deal with a number
(although admittedly not all; see Hitchcock 2007a for details) of the
standard counterexamples to other counterfactual treatments of token
causation.

It is worth adding that although this appeal to combinations of
interventions may seem artificial, it maps on to standard experimental
procedures in an intuitive way. Consider a case of genetic
redundancy—gene complex G1G1G_1 is involved in causing
phenotypic trait PPP but if G1G1G_1 is inactivated another gene
complex G2G2G_2 (which is inactive when G1G1G_1 is active) will become
active and will cause PPP. The geneticist may test for this
possibility by, first, intervening on G2G2G_2 so that it is fixed at
the value = inactive, then intervening to vary G1G1G_1 and observing
whether there is a corresponding change in PPP. Second, the
investigator may intervene to render G1G1G_1 inactive and then,
independently of this intervening to change G2G2G_2 and observing
whether there is a change in PPP. As this example illustrates, we
may think of different complex causal structures in which there are
multiple pathways, redundancy, cancellation and so on, as encoding
different sets of claims about what will happen under various possible
combinations of interventions.

Thus even if a “manipulationist” or
“interventionist” framework does not yield a reduction of
causal talk to non-causal talk, it provides a natural way of marking
the distinctions among a number of different causal notions and
exhibiting their interrelations. More generally, even if a
manipulationist account of causation does not yield a reduction but
instead simply connects “causation” (or better, various
more specific causal concepts) with other concepts within the same
circle, we still face many non-trivial choices about how the concepts
on this circle are to be elucidated and connected up with one another.
For example, it is far from obvious how to characterize the notion of
an intervention so as to avoid the various counterexamples to standard
statements of the manipulability theory such as the theory of Menzies
and Price. It is in part because the notion of
manipulation/intervention has an interesting and complex fine
structure—a structure that is left largely unexplored in
traditional manipulability theories-- that working out the connection
between causation and manipulation turns out to be interesting and
non-trivial rather than banal and obvious.
8. Interventions That Do Not Involve Human Action

We noted above that a free action need not meet the conditions for an
intervention, on any of the conceptions of intervention described in
 §5.
 It is also true that a process or event can qualify as an
intervention even if it does not involve human action or intention at
any point. This should be apparent from the way in which the notion of
an intervention has been characterized, for this is entirely in terms
of causal and correlational concepts and makes no reference to human
beings or their activities. In other words, a purely
“natural” process involving no animate beings at all can
qualify as an intervention as long as it has the right sort of causal
history—indeed, this sort of possibility is often described by
scientists as a “natural experiment”. Moreover, even when
manipulations are carried out by human beings, it is the causal
features of those manipulations and not the fact that they are carried
out by human beings or are free or are attended by a special
experience of agency that matters for recognizing and characterizing
causal relationships. Thus, by giving up any attempt at reduction and
characterizing the notion of an intervention in causal terms, an
“interventionist” approach of the sort described under
 §§4–5
 and
 7
 avoids the second classical problem besetting manipulability
theories—that of anthropocentrism and commitment to a privileged
status for human action. For example, under this approach XXX will
qualify as a (total) cause of YYY as long as it is true that for
some value of XXX that if XXX were to be changed to that value by
a process having the right sort of causal characteristics, the value
of YYY would change. Obviously, this claim can be true even if human
beings lack the power to manipulate XXX or even in a world in which
human beings do not or could not exist. There is nothing in the
interventionist version of a manipulability theory that commits us to
the view that all causal claims are in some way dependent for their
truth on the existence of human beings or involve a
“projection” on to the world of our experience of
agency.
9. Interventions and Counterfactuals

We noted above that interventionist versions of manipulability
theories are counterfactual theories. What is the relationship between
such theories and more familiar versions of counterfactual theories
such as the theory of David Lewis? Lewis’ theory is an account
of what it is for one individual token event to cause another while,
as explained above, versions of interventionist treatments are
available for different sorts of type causal claims as well as token
causal claims. But if we abstract away from this, there are both
important similarities and important differences between the two
approaches. As readers of Lewis will be aware, any counterfactual
theory must explain what we should envision as changed and what should
be held fixed when we evaluate a counterfactual the antecedent of
which is not true of the actual world—within Lewis’
framework, this is the issue of which worlds in which the antecedent
of the counterfactual holds are “closest” or “most
similar” to the actual world. Lewis’ answer to this
question invokes a “similarity” ordering that ranks the
importance of various respects of resemblance between worlds in
assessing overall similarity. (Lewis 1979). For example, avoiding
diverse, widespread violations of law is said to be the most important
consideration, preserving perfect match of particular fact over the
largest possible spatio-temporal region is next in importance and more
important than avoiding small localized violations of law, and so on.
As is well-known the effect of this similarity ordering is, at least
in most situations, to rule out so-called “back-tracking”
counterfactuals (e.g., the sort of counterfactual that is involved in
reasoning that if the effect of some cause had not occurred, then the
cause would not have occurred). When the antecedent of a
counterfactual is not true of the actual world, Lewis’
similarity metric commonly leads us (at least in deterministic
contexts) to think of that antecedent as made true by a
“small” miracle.

The notion of an intervention plays a somewhat (but only somewhat)
similar role within manipulability theories of causation to
Lewis’ similarity ordering. Like Lewis’ ordering, the
characterization of an intervention tells us what should be envisioned
as changed and what should be held fixed when we evaluate the sorts of
counterfactuals that are relevant to elucidating causal claims. For
example, on Pearl’s understanding of an intervention, in
evaluating an interventionist counterfactual like “If XXX were
to be changed by an intervention to such and such a value, the value
of YYY would change”, we are to consider a situation in which
the previously existing causal relationship between XXX and its
causes is disrupted, but all other causal relationships in the system
of interest are left unchanged. A moment’s thought will also
show that, as in Lewis’ account, both Pearl’s (in its
setting version) and the characterization of interventions in terms of
 M1–M4
 rule out backtracking counterfactuals—for example, in
evaluating a counterfactual of the form “if an intervention were
to occur that changes EEE, (where EEE is an effect of C)C)C), then
CCC would change”, Pearl holds that we should consider a
situation in which the relationship between EEE and its causes (in
this case, C)C)C) is disrupted, but all other causal relationships are
left unchanged, so that CCC still occurs, and the above
counterfactual is false, as it should be. Moreover, there is a clear
similarity between Lewis’ idea that the appropriate
counterfactuals for analyzing causation are often counterfactuals the
antecedents of which are made true by “miracles”, and the
idea of an intervention as an exogenous change that disrupts the
mechanism that was previously responsible for the cause event
C—both of these notions function so as to provide CCC
with the kind of “independent causal history” that allows
us to distinguish the effects (if any) of CCC on EEE from the
effects of other “confounding” variables on EEE. From
this perspective, one might think of an interventionist treatment of
causation as explaining why Lewis’ account, with its somewhat
ad hoc looking similarity ordering, works as well as it
does—Lewis’ account works because his similarity ordering
picks out roughly those relationships that are stable under
interventions and hence exploitable for purposes of manipulation and
control and, as a manipulability theory claims, it is just these
relationships that are causal.

As noted above, however, this is not to say that the two
approaches are identical or always yield identical assessments of
particular causal and counterfactual claims. One central difference is
that Lewis’ account is reductionist in aspiration—the
elements that go into his similarity metric (avoidance of big
miracles, perfect match of particular facts etc.) are (at least
officially) characterized in non-causal, non-modal terms. By contrast,
as explained above, the notion of an intervention and the standards
for evaluating counterfactuals to which it gives rise are
characterized in causal terms, so that the resulting account is
non-reductionist.

There are other differences as well, a number of which are explored in
an important paper by Briggs (2012). We have already noted that strong
centering holds in Lewis’ semantics but not for counterfactuals
with an interventionist interpretation. In addition, the inference
from (i) “if ppp or qqq were the case, rrr would be the
case” to (ii) “if ppp were the case, rrr would be the
case” is invalid within Lewis’ semantics but valid if
these counterfactuals are given an interventionist interpretation
(Briggs 2012; Fine 2012). It is arguable that in each of these cases,
the assessments provided by the interventionist interpretation are
correct, assuming that what we want to capture are those
counterfactuals that behave in a way that is appropriate for causal
interpretation. In addition, Woodward 2003 describes several specific
examples in which the two approaches diverge in their judgments about
which causal relations are present and in which the interventionist
approach seems more
 satisfactory.[3]
10. Possible and Impossible Interventions 

In the versions of a manipulability theory considered under
 §5ff
 above, causal claims are elucidated in terms of counterfactuals about
what would happen under interventions. As we have seen, the notion of
an intervention should be understood without reference to human
action, and this permits formulation of a manipulability theory that
applies to causal claims in situations in which manipulation by human
beings is not a practical possibility. 

However, as already intimated, interesting questions arise about how
far this framework may be extended to other sorts of cases in which
interventions are not “possible”. These also illustrate
some additional differences between thinking of interventions as
setting or, alternatively, in terms of
 M1–M4
 and as possibility constrained. Consider the (presumably true) causal
claim
 (G):

(G) The
gravitational attraction of the moon causes the motion of the
tides.


Within Pearl’s framework and using the notion of a setting
intervention, it might be argued that there is no problem with
capturing claims like (G), at least if we assume (as we did above)
that the relevant setting operation is always “possible”
or legitimate: we just imagine the gravitational attraction of the
moon set to some different value via a setting intervention (we
don’t need to specify how this comes about—whether the
mass of the moon or its distance from the earth etc. is different) and
then note (by applying Newtonian gravitational theory) that the motion
of the tides would be
 different.[4]

Suppose, by contrast, we require that interventions be
“possible” in some more demanding sense (that is, we adopt
a notion of possibility constrained intervention) and we consider
counterfactuals of the form: “if an intervention meeting
 M1–M4
 were to occur that sets the gravitational attraction of the moon to a
different value, then…”. It may well be that there is no
physically possible process that will meet the conditions
 M1–M4
 for intervention on the moon’s position with respect to the
tides—all possible processes that would alter the gravitational
force exerted by the moon may be insufficiently
“surgical”. For example, it may very well be that any
possible process that alters the position of the moon by altering the
position of some other massive object will have an independent impact
on the tides in violation of condition
 (M2)
 for an intervention. Woodward (2003) argues that nonetheless we have
a principled basis in Newtonian mechanics and gravitational theory
themselves for answering questions about what would happen if such a
surgical intervention were to occur and that this is enough to
vindicate the causal claim
 (G).
 On this view of the matter, what is crucial is not whether the
antecedent of the relevant counterfactual is nomologically or
physically possible but rather whether we are in possession of
well-grounded scientific theories and accompanying mathematics that
allow us to reliably answer questions about what would happen under
the supposition of such antecedents. We count interventions as
“possible” as long as this is the case. Such interventions
should be distinguished from interventions that are logically,
conceptually or mathematically inconsistent or incoherent (see below
for additional illustrations). 

11. The Scope of Interventionist Accounts

One context in which issues about the range of cases in which
interventionist account may be legitimately or fruitfully applied
concerns “cosmological” claims in which fundamental
physical theories are understood as applying to the whole universe.
Consider the following claim

(4) The
state StStS_t of the entire universe at time ttt causes the state
St+dSt+dS_{t +d} of the entire universe at time t+dt+dt+d, where StStS_t and
St+dSt+dS_{t+d} are specifications in terms of some fundamental physical
theory.


On an interventionist construal,
 (4)
 is unpacked as a claim to the effect that under some possible
intervention that changes StStS_t, there would be an associated change
in St+dSt+dS_{t+d}. This raises the worry that it is unclear what would be
involved in such an intervention (given that there is nothing in
addition to StStS_t that might realize the intervention) and unclear
how to assess what would happen if it were to occur, given the
stipulation that StStS_t is a specification of the entire state of the
universe. 

Commenting on an example like this, Pearl writes:


If you wish to include the whole universe in the model, causality
disappears because interventions disappear—the manipulator and
the manipulated lose their distinction. (2009: 419-20)  


Note that here Pearl seems to invoke a notion of intervention that is
different from (and stronger than) a pure setting conception. After
all, as Reutlinger (2012) notes, it is arguable that there is no
problem about imagining the state of the universe at StStS_t set to
some different value and then determining by reference to the laws
governing its evolution what its state will be at St+1St+1S_{t
 +1}.[5]
 Pearl’s remark seems to assume that the imagined intervention
has to meet some additional constraint beyond this (having to do in
some way with the possibility of realizing the intervention).
Pearl’s claim is controversial—it is discussed
sympathetically by Hitchcock 2007b and Woodward 2007 and criticized by
other writers such as Reutlinger 2012.

We will not try to resolve the issues surrounding this particular
claim of Pearl’s here, but there is a related and more general
issue concerning the implications of interventionism for the status of
causal claims in physics, even outside of cosmological contexts, that
deserves discussion. Return to the contrast between explicating causal
claims by appealing to a pure setting notion of intervention and,
alternatively, explicating them by reference to interventions that
meet some further non-trivial constraints regarding possibility, as
discussed above. Consider cases in which there is a physical law
according to which there is counterfactual dependence between YYY
and XXX but interventions on XXX are in some appropriately
relevant sense impossible. A pure setting treatment may conclude that
such relationships are causal while an account relying on a
possibility constrained notion of intervention will not.

Two possible illustrations are discussed in Woodward (2016). The field
equations of General Relativity describe a lawful or nomological
relationship between the stress energy tensor and the spacetime
metric. “Setting” the former to different values (by
specifying initial and boundary conditions) one may calculate the
associated different values of the latter. One may doubt, however,
that it is appropriate to think of the field equations as describing a
causal relationship between the stress-energy tensor and the
metric. It is arguable that a possibility constrained interventionist
account supports this judgment: specification of the stress energy

tensor requires reference to the metric in such a way that
interventions on the former with respect to the latter will violate
the conditions
 M1–M4
 for an intervention. One might conclude on these grounds that
although there is a relation of nomic dependence between the state of
the stress energy tensor and the metric, this relation is not causal.
Employment of a setting conception of intervention seems to realize
the opposite conclusion.

As a second example, the spins of the entangled particles in an
EPR–type experiment are lawfully related by a conservation law.
It is arguable (cf. Skyrms 1984; Butterfield 1992) that many standard
philosophical theories, including regularity and Lewis-style
counterfactual theories treat this relationship as causal, and a
setting version of an interventionist theory seems to suggest a
similar conclusion. By contrast, various no signaling theorems are
commonly interpreted as implying that it is impossible both to
intervene on one of the separated spin settings and to use the
relationship between the two settings to manipulate the other setting.
In this case a possibility constrained version of interventionism can
judge that no causal relationship is present. Although the matter is
controversial among philosophers, most physicists agree with this
judgment of non-causality.

Both of these examples illustrate different implications of setting
and possibility constrained versions of interventionism in physics
contexts and how the latter framework requires more than just the
presence of a nomically sufficient condition or law-based
counterfactual dependence for causation. More generally, if one
thinks, as many philosophers of physics and some physicists do, that
causal concepts do not apply, at least in any straightforward way, to
some or many fundamental physics contexts, then it is arguably a
consideration in favor of a version of interventionism that imposes a
non-trivial possibility constraint that it might be used to support
this judgment. By contrast, a setting version of interventionism will
tend to find causation in physics whenever there is nomic
dependence.

There has been considerable discussion recently both about the extent
to which fundamental physics is causal and about what interventionist
frameworks imply about the status of causal claims in physics. A
number of the essays in Price and Corry 2007 (Price 2007; Hitchcock
2007b; Woodward 2007) express varying degrees of skepticism about the
applicability of causal notions in portions of physics, in part on the
basis of interventionist considerations. By contrast, Frisch (2014)
argues vigorously that many physical theories, at least in classical
physics, such as classical electromagnetism, make extensive use of
causal concepts and that the relevant notion of cause is captured by
the interventionist framework and associated technical ideas (such as
structural equations and directed graphs). He suggests that writers
like Price, Hitchcock, and Woodward underestimate the degree to which
interventionist ideas of causation are applicable to such contexts. Of
course it is also possible, consistently, with the views of both
Frisch and these other writers, that causal notions, understood along
possibility constrained interventionist lines, are important in many
areas of physics but that there are other physical theories that are
not fruitfully interpreted as making causal claims, whether understood
along interventionist or other lines. In any case, the question of the
scope of interventionist theories and their implications for causal
claims in fundamental physics is an important and at present
unresolved
 issue.[6]
12. (Alleged) Causes That Are Unmanipulable for Logical, Conceptual, or Metaphysical Reasons

Several statisticians (e.g., Holland 1986; Rubin 1986), as well as
similarly minded epidemiologists (e.g., Hernan and Taubman 2008) who advocate treatments of
causation in terms of manipulation-based ideas (in this case in terms
of “potential outcome” theory) have held that causal
claims involving causes that are unmanipulable in principle are
defective or lack a clear meaning—they think of this conclusion
as following directly from a manipulationist approach to causation.
What is meant by an unmanipulable cause is not made very clear, but
what these authors have in mind are not candidate causes that cannot
be manipulated as a practical matter, but rather candidates that are
such that we lack any clear conception of what would be involved in
manipulating them or any basis for assessing what would happen under
such manipulations—cases in which manipulation seems
“impossible” for conceptual or (if you like)
“metaphysical” reasons. Proposed examples include such
candidate causes as race, membership in a particular species, and
gender. Other examples discussed in this connection involve cases in
which there are many different things one might have in mind by
“manipulation” of the candidate causes with different
results flowing from such manipulations so that the claims in question
are taken, from a manipulationist or interventionist standpoint, to be
unclear or ambiguous. All such cases contrast with the case involving
 (G)
 above, where the notion of manipulating the moon’s orbit seems
perfectly clear and well-defined, and the problem is simply that the
world happens to be arranged in such a way that an intervention that
produces such a change is not physically possible.

A sympathetic reconstruction of the position under discussion might go
as follows. On an interventionist account of causation, causes
(whether we think of them as events, types of events, properties,
facts, or what have you) must be representable by means of
variables—where this means, at a minimum, that it must
be possible for the cause to change or to assume different values, for
whatever object, unit or system those values are assigned to, as when
it is possible for the same particle to be either at position p1p1p_1
specified by a position variable PPP or at some alternative position
p2p2p_2. This is required if we are to have a well-defined notion of
manipulating a candidate cause and well-defined answers to
counterfactual queries about what would happen if the cause were to be
manipulated in some way—matters which are central to what causal
claims mean on any version of a manipulability theory worthy of the
name. However, for some putative causes, there may be no well-defined
notion of change or variation in value and if so, a manipulability
theory will not count these as genuine causes. Suppose, for example,
we lack any coherent conception of what it is for something to exist
but to be non-physical. Then there will be no well-defined notion of
intervening to change whether something is or is not a physical object
and being a physical object will not be a factor or property that can
serve as a cause. (Of course it is consistent with this that there are
true and perhaps even lawful generalizations about all physical
objects.). For example, although to the best of our knowledge, it is a
law of nature that 

(L) no physical object
can be accelerated from a velocity less than that of light to a
velocity greater than light,


(L) is not, according to this version of a manipulability theory, a
causal generalization: being a physical object is not a cause
of the incapacity in question.

Moreover, even with respect to variables that can take more than one
value, the notion of an intervention or manipulation will not be
well-defined if there is no well-defined notion of changing
the values of that variable. Suppose that we introduce a variable
“animal” which takes the values {{\{lizard, kitten,
raven}}\}. By construction, this variable has more than one value,
but if, as seems plausible, we have no coherent idea of what it is to
change a raven into lizard or kitten, there will be no well-defined
notion of an intervention for this variable and being an animal (or
being a raven) will not be the sort of thing that can count as a
bona fide cause on a manipulability theory. The notion of
changing the value of a variable seems to involve the idea of an
alteration from one value of the variable to another in circumstances
in which the very same system or entity can possess both values and
this notion seems inapplicable to the case under discussion.

Note that, just as with some of the examples considered in
 §12,
 this conclusion does not seem to follow on the pure setting
interpretation of the interventionist account. One can, after all, set
up an equation Y=XY=XY = X with a candidate variable XXX, taking the
values 0 and 1, according to whether some object is a kitten or lizard
and a candidate effect variable YYY, taking the values 0 and 1
according to whether that object is warm-blooded or cold-blooded. Then
setting XXX to 0 rather than 1 changes whether Y=0Y=0Y= 0 or 1, and if
this is sufficient for causation, being a kitten rather than a lizard
causes warmbloodiness rather than coldbloodiness. If one thinks, that
there is something defective or problematic about these causal claims,
this requires, within an interventionist framework, a richer
conception of what is required for causation than what is suggested by
the setting conception of intervention. A similar point applies to the
other examples described in this section. 

Some readers will take it to be intuitively obvious that, e.g., being
a raven can be a cause of some particular organism’s being
black, that being a kitten can be a cause of warm-bloodiness and so
on. If causal claims like 

(R) “Raveness
causes blackness” 


are true, it will be an important advantage of a setting version of
interventionism over a formulation in terms of a possibility
constrained notion of intervention that the former but not the latter
is able to capture claims like (R). By contrast, others will think
that claims like (R) are, if not false, at least unclear and
unperspicuous, and that it is a point in favor of a possibility
constrained version of the interventionist account that it can capture
this. Those who take this second view will think that claims like (R)
should be replaced by claims that involve causes that are
straightforwardly manipulable. For example, (R) might be replaced by a
claim that identified the genetic factors and biochemical pathways
that are responsible for raven pigmentation—factors and pathways
for which there is a well-defined notion of manipulation and which are
such that if they were appropriately manipulated, this would lead to
changes in pigmentation. Theorists like Rubin and Holland will think
that such a replacement would be clearer and more perspicuous than the
original claim (R) Another illustration of this general idea that
replacing claims involving non-manipulable candidate causes with
claims involving candidate manipulable causes clarifies their meaning
is discussed in
 The Role of the Manipulability Theory in Clarifying Causal Claims.
 
13. Some Criticisms of Interventionist Accounts

A number of other criticisms besides the classic charges of
anthropomorphism and circularity have been advanced against
interventionist accounts. One complaint is that interventionist
accounts (at least as I have formulated them) appeal to
counterfactuals and that counterfactuals cannot be (as it is often
put) “barely true”: if a counterfactual is true, this must
be so in virtue of some “truth maker” which is not itself
modal or counterfactual. Standard candidates for such truth makers are
fundamental laws of nature or perhaps fundamental physical/chemical
processes or mechanisms. Often the further suggestion is made that we
can then explain the notion of causation in terms of such truth makers
rather than along interventionist lines—for example, the notion
of causation (as well as the truth conditions for counterfactuals)
might be explained in terms of laws (Hiddleston 2005). Thus appealing
to interventionist counterfactuals is not necessary, once we take
account of the truth conditions of such counterfactuals.

These claims raise a number of issues that can be explored only
briefly. First, let us distinguish between providing an ordinary
scientific explanation for why some counterfactual claim is true and
providing truth conditions (or identifying a truth maker) in the sense
described above, where these truth conditions are specified in
non-modal, non-counterfactual terms. The expectation that (i) whenever
some macro-level interventionist counterfactual is true, there will be
some more fundamental scientific explanation of why it is true seems
plausible and well grounded in scientific practice. By contrast, the
expectation that (ii) for every true counterfactual there must be a
truth maker that can be characterized in non-modal, non-counterfactual
terms is a metaphysical doctrine that requires some independent
argument; it does not follow just from (i). Suppose that it is true
that 

(5) if
subjects with disease DDD were to be assigned treatment via an
intervention with drug GGG, they would be more likely to recover.



Then it is very plausible that there will be some explanation, which
may or may not be known at present, that explains why
 (5)
 is true in terms of more fundamental biochemical mechanisms or
physical/chemical laws and various initial and boundary conditions.
What is less obviously correct is the further idea that we can
elucidate these underlying mechanisms/laws without appealing to
counterfactuals. It is this further idea that is appealed to when it
is claimed that it must be possible to describe a truth maker for a
counterfactual like
 (5)
 that does not itself appeal to counterfactual or modal claims. The
correctness of this idea is not guaranteed merely by the existence of
an explanation in the ordinary sense for why
 (5)
 is true; instead it seems to depend on whether a reductivist account
of laws, mechanisms, etc. in terms of non-modal primitives can be
given—a matter on which the jury is still
 out.[7]

A different line of criticism has been advanced against
interventionist accounts in several recent papers by Nancy Cartwright
(e.g., 2001, 2002). According to Cartwright such accounts are
“operationalist”. Classical operationalism is often
criticized as singling out just one possible procedure for testing
some claim of interest and contending that the claim only makes sense
or only has a truth value when that procedure can actually be carried
out. Similarly, Cartwright complains that the interventionist account
“overlooks the possibility of devising other methods for
measuring” causal relationships and also suggests that the
account leads us to 


withhold the concept [of cause] from situations that seem the same in
all other aspects relevant to its application just because our test
cannot be applied in those situations. (2002: 422)


If interventionism is formulated as above, this criticism seems
misplaced. The interventionist account does not hold that causal
concepts apply or make sense only when the appropriate interventions
can actually be carried out. Nor does it deny that there are other
ways of testing causal claims besides carrying out interventions.
Instead, interventionism holds that causal claims apply or have truth
values whenever the appropriate counterfactuals concerning what would
happen if interventions were to be performed have truth values. As
explained above, interventionists think that sometimes such
counterfactuals are true even if the interventions in question cannot
actually be performed. Similarly, interventionists can readily agree
that causal claims may be tested and confirmed by, for example, purely
observational data, not involving interventions or
manipulations—their view, though, is that what is confirmed in
this way is a claim about what would happen if certain interventions
were to be performed. In fact, thinking of causal claims in this way
helps to clarify why certain strategies for causal inference with
observational data, such as the use of instrumental variables, are
more likely to lead to reliable conclusions than alternatives
(Woodward 2015). 

In a related criticism, Cartwright contends that the interventionist
account is “monolithic”: it takes just one of the criteria
commonly thought to be relevant to whether a relationship is
causal—whether it is potentially exploitable for purposes of
manipulation—and gives it a privileged or pre-eminent place,
allowing it to trump other criteria (like spatio-temporal contiguity
or transmission of energy-momentum), when it comes into conflict with
them. By contrast, Cartwright favors a “pluralistic”
account, according to which a variety of diverse criteria are relevant
to whether a relationship is causal and which of these are most
appropriate or important will depend on the causal claim at issue.

The interventionist account is indeed mono-criterial. Whether this
feature is objectionable depends on whether there are realistic cases
in which (i) intervention-based criteria and criteria based on other
considerations come into conflict and (ii) it is clear that
the causal judgments supported by these other criteria are more
defensible than those supported by interventionist criteria.
Cartwright does not present any uncontroversial cases of this kind. We
have seen that interventionist accounts and accounts that take, e.g.,
spatio-temporal continuity to be crucial for causation do yield
conflicting judgments in some realistic cases (e.g., those involving
double prevention), but it is far from clear that the interventionist
account is mistaken in the judgments that it recommends about such
cases.

Two still more recent criticisms directed against
 M1–M4
 and possibility constrained notions of interventionism are Reutlinger
2012 and Glynn 2013. These are discussed in the supplementary document
 Additional Recent Criticisms of the Interventionist Account.
 
14. Some Recent Positive Developments.

The material above has largely focused on the use of interventionist
or manipulability based ideas to provide an interpretation of causal
claims, with little attention paid to the use of these ideas in causal
inference—that is, inference to causal relationships from
experimental and non-experimental data. The latter is an important
subject in its own right. Roughly speaking, if one thinks of causal
claims as claims about the outcomes of possible manipulations or
experiments, then this suggests distinctive ways of conceptualizing
problems of causal inference from non-experimental data: these may be
conceptualized as problems of inferring from such data (and other
assumptions) what the outcome of a possible experiment would be
without doing the experiment in question. This point of view can used
to motivate or rationalize the use of such procedures as instrumental
variables or regression discontinuity designs—see, e.g., Angrist
and Pischke 2009 for econometric applications of these ideas. 

Another important extension of interventionist ideas, also with a
focus on inference but containing conceptual innovations as well is
due to Eberhardt (Eberhardt 2007, Eberhardt and Scheines 2007).

These authors generalize the notion of intervention in two ways.
First, they consider interventions that do not deterministically fix
the value of variable(s) intervened on but rather merely impose a
probability distribution on those variables. Second, they explore the
use of what have come to be called “soft” interventions.
These are interventions that unlike the fully surgical
(“hard”) interventions considered above (both
Pearl’s setting interventions and the notion associated with
 M1–M4),
 do not completely break the previously existing relationships between
the variable XXX intervened on and its causes CCC but rather
supply an exogenous source III of variation to XXX that leaves its
relations to CCC intact but where III is uncorrelated with CCC.
Certain experiments are naturally modeled in this way. For example, in
an experiment in which subjects are randomly given various amounts of
additional income (besides whatever income they have from other
sources) this additional income functions as a soft, rather than a
hard intervention. Soft interventions may be possible in practice or
in principle in certain situations in which hard interventions are
not. Eberhardt 2007 and Eberhardt and Scheines 2007 explore what can
be learned from various combinations of soft and hard, indeterministic
and deterministic interventions together with non-experimental data in
various contexts. Unsurprisingly each kind of intervention and
associated data have both advantages and limitations from the point of
view of inference.