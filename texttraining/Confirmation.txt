Human cognition and behavior heavily relies on the notion that
evidence (data, premises) can affect the credibility of hypotheses
(theories, conclusions). This general idea seems to underlie sound and
effective inferential practices in all sorts of domains, from everyday
reasoning up to the frontiers of science. Yet it is also clear that,
even with extensive and truthful evidence available, drawing a
mistaken conclusion is more than a mere possibility. For painfully
tangible examples, one only has to consider missed medical diagnoses
(see Winters et al. 2012) or judicial errors (see Liebman et al.
2000). The Scottish philosopher David Hume (1711–1776) is
usually credited for having disclosed the theoretical roots of these
considerations in a particularly transparent way (see Howson 2000,
Lange 2011, and Varzi 2008). In most cases of interest, Hume pointed
out, many alternative candidate hypotheses remain logically compatible
with all the relevant information at one’s disposal, so that
none of the former can be singled out by the latter with full
certainty. Thus, under usual circumstances, reasoning from evidence
must remain fallible.

This fundamental insight has been the source of a lasting theoretical
challenge: if amenable to analysis, the role of evidence as supporting
(or infirming) hypotheses has to be grasped by more nuanced tools than
plain logical entailment. As emphasized in a joke attributed to
American philosopher Morris Raphael Cohen (1880–1947), logic
textbooks had to be divided in two parts: in the first part, on
deductive logic, unwarranted forms of inference (deductive fallacies)
are exposed; in the second part, on inductive logic, they are endorsed
(see Meehl 1990, 110). In contemporary philosophy, confirmation
theory can be roughly described as the area where efforts have
been made to take up the challenge of defining plausible models of
non-deductive reasoning. Its central technical term—
confirmation—has often been used more or less
interchangeably with “evidential support”,
“inductive strength”, and the like. Here we will generally
comply with this liberal usage (although more subtle conceptual and
terminological distinctions are sometimes drawn).

Confirmation theory has proven a rather difficult endeavour. In
principle, it would aim at providing understanding and guidance for
tasks such as diagnosis, prediction, and learning in virtually any
area of inquiry. Yet popular accounts of confirmation have often been
taken to run into troubles even when faced with toy philosophical
examples. Be that as it may, there is at least one real-world kind of
activity which has remained a prevalent target and benchmark, i.e.,
scientific reasoning, and especially key episodes from the history of
modern and contemporary natural science. The motivation for this is
easily figured out. Mature sciences seem to have been uniquely
effective in relying on observed evidence to establish extremely
general, powerful, and sophisticated theories. Indeed, being capable
of receiving genuine support from empirical evidence is itself a very
distinctive trait of scientific hypotheses as compared to other kinds
of statements. A philosophical characterization of what science is
would then seem to require an understanding of the logic of
confirmation. And so, traditionally, confirmation theory has come to
be a central concern of philosophers of science.

In the following, major approaches to confirmation theory are
overviewed according to a classification that is relatively standard
(see Earman and Salmon 1992; Norton 2005): confirmation by instances
(Section 1), hypothetico-deductivism and its variants (Section 2), and
probabilistic (Bayesian) approaches (Section 3).
 
1. Confirmation by instances

In a seminal essay on induction, Jean Nicod (1924) offered the
following important remark:


Consider the formula or the law: FFF entails GGG. How can a
particular proposition, or more briefly, a fact affect its
probability? If this fact consists of the presence of GGG in a case
of FFF, it is favourable to the law […]; on the contrary, if
it consists of the absence of GGG in a case of FFF, it is
unfavourable to this law. (219, notation slightly adapted)


Nicod’s work was an influential source for Carl Gustav
Hempel’s (1943, 1945) early studies in the logic of
confirmation. In Hempel’s view, the key valid message of
Nicod’s statement is that the observation report that an object
aaa displays properties FFF and GGG (e.g., that aaa is a swan
and is white) confirms the universal hypothesis that all FFF-objects
are GGG-objects (namely, that all swans are white). Apparently, it
is by means of this kind of confirmation by instances that one can
obtain supporting evidence for statements such as “sodium salts
burn yellow”, “wolves live in a pack”, or
“planets move in elliptical orbits” (also see Russell
1912, Ch. 6). We will now see the essential features of Hempel’s
analysis of confirmation.
1.1 Hempel’s theory

Hempel’s theory addresses the non-deductive relation of confirmation
between evidence and hypothesis, but relies thoroughly on standard
logic for its full technical formulation. As a consequence, it also
goes beyond Nicod’s idea in terms of clarity and rigor. 

Let LL\bL be the set of the closed sentences of a first-order
logical language LLL (finite, for simplicity) and consider h,e∈Lh,e∈Lh, e
\in \bL. Also let eee, the evidence statement, be consistent and
contain individual constants only (no quantifier), and let I(e)I(e)I(e) be
the set of all constants occurring (non-vacuously) in eee. So, for
example, if e=Qa∧Rae=Qa∧Rae = Qa \wedge Ra, then I(e)={a}I(e)={a}I(e) = \{a\}, and if e=Qa∧Qbe=Qa∧Qbe =
Qa \wedge Qb, then I(e)={a,b}I(e)={a,b}I(e) = \{a,b\}. (The non-vacuity clause is
meant to ensure that if sentence eee happens to be, say, Qa∧Qb∧(Rc∨¬Rc)Qa∧Qb∧(Rc∨¬Rc)Qa \wedge
Qb \wedge (Rc \vee \neg Rc), then I(e)I(e)I(e) still is {a,b}{a,b}\{a, b\},
for eee does not really state anything non-trivial about the
individual denoted by ccc. See Sprenger 2011a, 241–242.)
Hempel’s theory relies on the technical construct of the
development of hypothesis hhh for evidence eee, or the
eee-development of hhh, indicated by deve(h)deve(h)dev_{e}(h). Intuitively,
deve(h)deve(h)dev_{e}(h) is all that (and only what) hhh says once restricted
to the individuals mentioned (non-vacuously) in eee, i.e., exactly
those denoted by the elements of I(e)I(e)I(e).

The notion of the eee-development of hypothesis hhh can be given
an entirely general and precise definition, but we’ll not need
this level of detail here. Suffice it to say that the
eee-development of a universally quantified material conditional
∀x(Fx→Gx)∀x(Fx→Gx)\forall x(Fx \rightarrow Gx) is just as expected, that is: Fa→GaFa→GaFa
\rightarrow Ga in case I(e)={a}I(e)={a}I(e) = \{a\}; (Fa→Ga)∧(Fb→Gb)(Fa→Ga)∧(Fb→Gb)(Fa \rightarrow Ga)
\wedge (Fb \rightarrow Gb) in case I(e)={a,b}I(e)={a,b}I(e) = \{a,b\}, and so on.
Following Hempel, we will take universally quantified material
conditionals as canonical logical representations of relevant
hypotheses. So, for instance, we will count a statement of the form
∀x(Fx→Gx)∀x(Fx→Gx)\forall x(Fx \rightarrow Gx) as an adequate rendition of, say,
“all pieces of copper conduct electricity”.

In Hempel’s theory, evidence statement eee is said to confirm
hypothesis hhh just in case it entails, not hhh in its full
extension, but suitable instantiations of hhh. The
technical notion of the eee-development of hhh is devised to
identify precisely those relevant instantiations, that is, the
consequences of hhh as restricted to the individuals involved in
eee. More precisely, Hempelian confirmation can be defined as
follows:

Hempelian confirmation

For any h,e∈Lh,e∈Lh,e \in \bL such that eee is consistent and contains
individual constants only (no quantifier):


evidence eee directly Hempel-confirms hypothesis hhh
if and only if e⊨deve(h)e⊨deve(h)e \vDash dev_{e}(h); eee Hempel-confirms
hhh if and only if, for some s∈Ls∈Ls \in \bL, e⊨deve(s)e⊨deve(s)e \vDash dev_{e}(s)
and s⊨hs⊨hs \vDash h;
evidence eee directly Hempel-disconfirms hypothesis
hhh if and only if e⊨deve(¬h)e⊨deve(¬h)e \vDash dev_{e}(\neg h); eee
Hempel-disconfirms hhh if and only if, for some s∈L,e⊨deve(s)s∈L,e⊨deve(s)s \in
\bL, e \vDash dev_{e}(s) and s⊨¬hs⊨¬hs \vDash \neg h;
evidence eee is Hempel-neutral for hypothesis hhh
otherwise.



In each of clauses (i) and (ii), Hempelian confirmation
(disconfirmation, respectively) is a generalization of direct
Hempelian confirmation (disconfirmation). To retrieve the latter as a
special case of the former, one only has to posit s=hs=hs = h (¬h(¬h(\neg
h, respectively, for disconfirmation).

By direct Hempelian confirmation, evidence statement eee that, say,
object aaa is a white swan, swan(a)∧white(a)swan(a)∧white(a)swan(a) \wedge white(a), confirms
hypothesis hhh that all swans are white, ∀x(swan(x)→white(x))∀x(swan(x)→white(x))\forall x(swan(x)
\rightarrow white(x)), because the former entails the
eee-development of the latter, that is, swan(a)→white(a)swan(a)→white(a)swan(a) \rightarrow
white(a). This is a desired result, according to Hempel’s
reading of Nicod. By (indirect) Hempelian confirmation, moreover,
swan(a)∧white(a)swan(a)∧white(a)swan(a) \wedge white(a) also confirms that a particular further
object bbb will be white, if it’s a swan, i.e., swan(b)→white(b)swan(b)→white(b)swan(b)
\rightarrow white(b) (to see this, just set s=∀x(swan(x)→white(x))s=∀x(swan(x)→white(x))s = \forall x(swan(x)
\rightarrow white(x))).

The second possibility considered by Nicod (“the
absence of GGG in a case of FFF\,”) can be
accounted for by Hempelian disconfirmation. For the evidence statement
eee that aaa is a non-white swan—swan(a)∧¬white(a)swan(a)∧¬white(a)swan(a) \wedge \neg
white(a)—entails (in fact, is identical to) the
eee-development of the hypothesis that there exist non-white
swans—∃x(swan(x)∧¬white(x))∃x(swan(x)∧¬white(x))\exists x(swan(x) \wedge \neg white(x))—which in
turn is just the negation of ∀x(swan(x)→white(x))∀x(swan(x)→white(x))\forall x(swan(x) \rightarrow
white(x)). So the latter is disconfirmed by the evidence in this
case. And finally, e=swan(a)∧¬white(a)e=swan(a)∧¬white(a)e = swan(a) \wedge \neg white(a) also
Hempel-disconfirms that a particular further object bbb will be
white, if it’s a swan, i.e., swan(b)→white(b)swan(b)→white(b)swan(b) \rightarrow white(b),
because the negation of the latter, swan(b)∧¬white(b)swan(b)∧¬white(b)swan(b) \wedge \neg white(b),
is entailed by s=∀x(swan(x)∧¬white(x))s=∀x(swan(x)∧¬white(x))s = \forall x(swan(x) \wedge \neg white(x)) and e⊨deve(s)e⊨deve(s)e
\vDash dev_{e}(s).

So, to sum up, we have four illustrations of how Hempel’s theory
articulates Nicod’s basic ideas, to wit:

 (the observation report of) a white swan (directly)
Hempel-confirms that all swans are white;
 (the observation report of) a white swan also Hempel-confirms
that a further swan will be white;
 (the observation report of) a non-white swan (directly)
Hempel-disconfirms that all swans are white;
 (the observation report of) a non-white swan also
Hempel-disconfirms that a further swan will be white.

1.2 Two paradoxes and other difficulties

The ravens paradox (Hempel 1937, 1945). Consider the
following statements:

(hhh) ∀x(raven(x)→black(x))∀x(raven(x)→black(x))\forall
x(raven(x) \rightarrow black(x)), i.e., all ravens are
black;
(eee) raven(a)∧black(a)raven(a)∧black(a)raven(a)
\wedge black(a), i.e., aaa is a black raven; 
(e∗e∗e^*) ¬black(a∗)∧¬raven(a∗)¬black(a∗)∧¬raven(a∗)\neg
black(a^*) \wedge \neg raven(a^*), i.e., a∗a∗a^* is a non-black
non-raven (say, a green apple).


Is hypothesis hhh confirmed by eee and e∗e∗e^* alike? That is, is
the claim that all ravens are black equally confirmed by the
observation of a black raven and by the observation of a non-black
non-raven (e.g., a green apple)? One would want to say no, but
Hempel’s theory is unable to draw this distinction. Let’s
see why.

As we know, eee (directly) Hempel-confirms hhh, according to
Hempel’s reconstruction of Nicod. By the same token, e∗e∗e^*
(directly) Hempel-confirms the hypothesis that all non-black objects
are non-ravens, i.e., h∗=∀x(¬black(x)→¬raven(x))h∗=∀x(¬black(x)→¬raven(x))h^* = \forall x(\neg black(x) \rightarrow \neg
raven(x)). But h∗⊨hh∗⊨hh^* \vDash h (hhh and h∗h∗h^* are just
logically equivalent). So, e∗e∗e^* (the observation report of a
non-black non-raven), like eee (black raven), does (indirectly)
Hempel-confirm hhh (all ravens are black). Indeed, as ¬raven(a)¬raven(a)\neg
raven(a) entails raven(a)→black(a)raven(a)→black(a)raven(a) \rightarrow black(a), it can be shown
that hhh is (directly) Hempel-confirmed by the observation of
any object that is not a raven (an apple, a cat, a shoe),
apparently disclosing puzzling “prospects for indoor
ornithology” (Goodman 1955, 71).

BliteBliteBlite (Goodman 1955). Consider the peculiar predicate
“blitebliteblite”, defined as follows: an object is blite just
in case (i) it is black if examined at some moment ttt up to some
future time TTT (say, the next expected appearance of Halley’s
comet, in 2061) and (ii) it is white if examined afterwards. So we
posit blite(x)≡(ext≤T(x)→black(x))∧(¬ext≤T(x)→white(x))blite(x)≡(ext≤T(x)→black(x))∧(¬ext≤T(x)→white(x))blite(x) \equiv (ex_{t\le T}(x) \rightarrow black(x)) \wedge
(\neg ex_{t\le T}(x) \rightarrow white(x)). Now consider the
following statements:

(hhh) ∀x(raven(x)→black(x))∀x(raven(x)→black(x))\forall
x(raven(x) \rightarrow black(x)), i.e., all ravens are
black;
(h∗h∗h^*) ∀x(raven(x)→blite(x))∀x(raven(x)→blite(x))\forall
x(raven(x) \rightarrow blite(x)), i.e., all ravens are
blite;
(eee) e=raven(a)∧ext≤T(a)∧black(a)e=raven(a)∧ext≤T(a)∧black(a)e = raven(a)
\wedge ex_{t\le T}(a) \wedge black(a), i.e., aaa is a raven
observed no later than TTT and it is black.


Does eee confirm hypotheses hhh and h∗h∗h^* alike? That is, does
the observation of a black raven before TTT confirms equally the
claim that all ravens are black as the claim that all ravens are
blite? Here again, one would want to say no, but Hempel’s theory
is unable to draw the distinction. For one can check that the
eee-developments of hhh and h∗h∗h^* are both entailed by eee.
Thus, eee (the report of a raven examined no later than TTT and
found to be black) does Hempel-confirm h∗h∗h^* (all ravens are blite)
just as it confirms hhh (all ravens are black). Moreover, eee also
Hempel-confirms the statement that a raven will be white if examined
after TTT, because this is a logical consequence of h∗h∗h^* (which
is directly Hempel-confirmed by eee). And finally, suppose that
blurple(x)≡(ext≤T(x)→black(x))∧(¬ext≤T(x)→purple(x)).blurple(x)≡(ext≤T(x)→black(x))∧(¬ext≤T(x)→purple(x)).blurple(x) \equiv (ex_{t\le T}(x) \rightarrow black(x)) \wedge (\neg
ex_{t\le T}(x) \rightarrow purple(x)). We then have that the very
same evidence statement eee Hempel-confirms the hypothesis that all
ravens are blurple, and thus also its implication that a raven will be
purplepurplepurple if examined after TTT!

A seemingly obvious idea, here, is that there must be something
inherently wrong with predicates such as blitebliteblite or blurpleblurpleblurple (and
perhaps non-raven and non-black, too) and thus a
principled way to rule them out as “unnatural”. Then one
could restrict confirmation theory accordingly, i.e., to
“natural kinds” only (see, e.g., Quine 1970). Yet this
point turns out be very difficult to pursue coherently and it has not
borne much fruit in this discussion (Rinard 2014 is a recent
exception). After all, for all we know, it is a perfectly
“natural” feature of a token of the “natural
kind” water that it is found in one physical state for
temperatures below 0 degrees Celsius and in an entirely different
state for temperatures above that threshold. So why should the time
threshold TTT in blitebliteblite or blurpleblurpleblurple be a reason to dismiss
those predicates? (The water example comes from Howson 2000,
31–32. See Schwartz 2011, 399 ff., for a more general assessment
of this issue.)

The above, widely known “paradoxes” then suggest that
Hempel’s analysis of confirmation is too liberal: it
sanctions the existence of confirmation relations that are intuitively
very unsound (see Earman and Salmon 1992, 54, and Sprenger 2011a, 243,
for more on this). Yet the Hempelian notion of confirmation turns out
to be very restrictive, too, on other accounts. For suppose that
hypothesis hhh and evidence eee do not share any piece of
non-logical vocabulary. hhh might be, say, Newton’s law of
universal gravitation (connecting force, distances and masses), while
eee could be the description of certain spots on a telescopic image.
Throughout modern physics, significant relations of confirmation and
disconfirmation were taken to obtain between statements like these.
Indeed, telescopic sightings have been crucial evidence for
Newton’s law as applied to celestial bodies. However, as their
non-logical vocabularies are disjoint, eee and hhh must simply be
logically independent, and so must be eee and deve(h)deve(h)dev_{e}(h) (with
very minor caveats, this follows from Craig’s so-called
interpolation theorem, see Craig 1957). In such circumstances, there
can be nothing but Hempel-neutrality between evidence and hypothesis.
So Hempel’s original theory seems to lack the resources to
capture a key feature of inductive inference in science as well as in
several other domains, i.e., the kind of “vertical”
relationships of confirmation (and disconfirmation) between the
description of observed phenomena and hypotheses concerning underlying
structures, causes, and processes.

To overcome the latter difficulty, Clark Glymour (1980a) embedded a
refined version of Hempelian confirmation by instances in his analysis
of scientific reasoning. In Glymour’s revision, hypothesis hhh
is confirmed by some evidence eee even if appropriate auxiliary
hypotheses and assumptions must be involved for eee to entail the
relevant instances of hhh. This important theoretical move turns
confirmation into a three-place relation concerning the
evidence, the target hypothesis, and (a conjunction of) auxiliaries.
Originally, Glymour presented his sophisticated neo-Hempelian approach
in stark contrast with the competing traditional view of so-called
hypothetico-deductivism (HD). Despite his explicit
intentions, however, several commentators have pointed out that,
partly because of the due recognition of the role of auxiliary
assumptions, Glymour’s proposal and HD end up being plagued by
similar difficulties (see, e.g., Horwich 1983, Woodward 1983, and
Worrall 1982). In the next section, we will discuss the HD framework
for confirmation and also compare it with Hempelian confirmation. It
will thus be convenient to have a suitable extended definition of the
latter, following the remarks above. Here is one that serves our
purposes:

Hempelian confirmation (extended)

For any h,e,k∈Lh,e,k∈Lh, e,k \in \bL such that eee contains individual
constants only (no quantifier), k=deve(α)k=deve(α)k = dev_{e}(\alpha) for some
α∈Lα∈L\alpha \in \bL containing quantifiers only (no individual
constant) and such that α⊭h\alpha \not\vDash h, and e∧ke\wedge k is
consistent:


 ee directly Hempel-confirms hh relative
to kk if and only if e∧k⊨deve(h)e\wedge k \vDash dev_{e}(h); ee
Hempel-confirms hh relative to kk if and only
if, for some s∈L,e∧k⊨deve(s)s \in \bL, e\wedge k \vDash dev_{e}(s) and s∧k⊨hs\wedge
k \vDash h;
ee directly Hempel-disconfirms hh relative
to kk if and only if e∧k⊨deve(¬h)e\wedge k \vDash dev_{e}(\neg h);
ee Hempel-disconfirms hh relative to kk if
and only if, for some s∈L,e∧k⊨deve(s)s\in \bL, e\wedge k \vDash dev_{e}(s)a and
s∧k⊨¬hs\wedge k \vDash \neg h;
 ee is Hempel-neutral for hh relative to
kk otherwise.



One can see that in the above definition the auxiliary assumptions in
kk are the ee-development of further closed constant-free
hypotheses (in fact, equations as applied to specific measured values,
in typical examples from Glymour 1980a), where such hypotheses are
meant to be conjoined in a single statement (α\alpha) for
convenience. This implies that the only terms occurring
(non-vacuously) in kk are individual constants already occurring
(non-vacuously) in ee. For an empty α\alpha (that is,
tautologous: α=⊤\alpha = \top), kk must be empty too, and the
original (restricted) definition of Hempelian confirmation applies. As
for the proviso that α⊭h\alpha \not\vDash h, it rules out undesired
cases of circularity—akin to so-called “macho”
bootstrap confirmation, as discussed in Earman and Glymour 1988 (for
more on Glymour’s theory and its developments, see Douven and
Meijs 2006, and references therein).
2. Hypothetico-deductivism

The central idea of hypothetico-deductive (HD) confirmation can be
roughly described as “deduction-in-reverse”: evidence is
said to confirm a hypothesis in case the latter, while not entailed by
the former, is able to entail it, with the help of suitable auxiliary
hypotheses and assumptions. The basic version (sometimes labelled
“naïve”) of the HD notion of confirmation can be
spelled out thus:

HD-confirmation

For any h,e,k∈Lh, e, k \in \bL such that h∧kh\wedge k is consistent:


 ee HD-confirms hh relative to kk if
and only if h∧k⊨eh\wedge k \vDash e and k⊭ek \not\vDash e;
ee HD-disconfirms hh relative to kk if
and only if h∧k⊨¬eh\wedge k \vDash \neg e, and k⊭¬ek \not\vDash \neg
e;
ee is HD-neutral for hypothesis hh relative
to kk otherwise.



Note that clause (ii) above represents HD-disconfirmation as plain
logical inconsistency of the target hypothesis with the data (given
the auxiliaries) (see Hempel 1945, 98).
2.1 HD vs. Hempelian confirmation

HD-confirmation and Hempelian confirmation convey different intuitions
(see Huber 2008a for an original analysis). They are, in fact,
distinct and strictly incompatible notions. This will be effectively
illustrated by the consideration of the following conditions.

Entailment condition (EC)

For any h,e,k∈Lh,e,k \in \bL, if e∧ke\wedge k is consistent, e∧k⊨he\wedge k
\vDash h and k⊭hk \not\vDash h, then ee confirms hh relative
to kk.

Confirmation complementarity (CC)

For any h,e,k∈Lh, e, k \in \bL, ee confirms hh relative to kk if
and only if ee disconfirms ¬h\neg h relative to kk.

Special consequence condition (SCC)

For any h,e,k∈Lh, e, k \in \bL, if ee confirms hh relative to kk
and h∧k⊨h∗h\wedge k \vDash h^*, then ee confirms h∗h^* relative to
kk.

On the implicit proviso that kk is empty (that is, tautologous: k=⊤k
= \top), Hempel (1943, 1945) himself had put forward (EC) and (SCC)
as compelling adequacy conditions for any theory of confirmation, and
devised his own proposal accordingly. As for (CC), he took it as a
plain definitional truth (1943, 127). Moreover, Hempelian confirmation
(extended) satisfies all conditions above (of course, for arguments
hh, ee and kk for which it is defined). HD-confirmation, on
the contrary, violates all of them. Let us briefly discuss each one in
turn.

It is rather common for a theory of ampliative (non-deductive)
reasoning to retain classical logical entailment as a special case (a
feature sometimes called “super-classicality”; see
Strasser and Antonelli 2019). That’s essentially what (EC)
implies for confirmation. Now given appropriate ee, hh and
kk, if e∧ke\wedge k entails hh, we readily get that ee
Hempel-confirms hh relative to kk in two simple steps. First,
given that ee and kk are both quantifier-free, deve(e∧k)=e∧kdev_{e}(e\wedge
k) = e\wedge k according to Hempel’s full definition of
devdev (see Hempel 1943, 131). Then it trivially follows that
e∧k⊨deve(e∧k)e\wedge k \vDash dev_{e}(e\wedge k), so e∧ke\wedge k is
(directly) Hempel-confirmed and its logical consequence hh is
likewise confirmed (indirectly). Logical entailment is thus retained
as an instance of Hempelian confirmation in a fairly straightforward
way. HD-confirmation, on the contrary, does not fulfil (EC). Here is
one odd example (see Sprenger 2011a, 234). With k=⊤k = \top, just let
ee be the observation report that object aa is a black swan,
swan(a)∧black(a)swan(a) \wedge black(a), and hh be the hypothesis that black
swans exist, ∃x(swan(x)∧black(x))\exists x(swan(x) \wedge black(x)). Evidence ee
verifies hh conclusively, and yet it does not HD-confirm it, simply
because h⊭eh \not\vDash e. So the observation of a black swan turns
out to be HD-neutral for the hypothesis that black swans exist! The
same example shows how HD-confirmation violates (CC), too. In fact,
while HD-neutral for hh, ee HD-disconfirms its negation ¬h\neg
h that no swan is black, ∀x(swan(x)→¬black(x))\forall x(swan(x) \rightarrow \neg
black(x)), because the latter is obviously inconsistent with
(refuted by) ee.

The violation of (EC) and (CC) by HD-confirmation is arguably a reason
for concern, for those conditions seem highly plausible. The special
consequence condition (SCC), on the other hand, deserves separate and
careful consideration. As we will see later on, (SCC) is a strong
constraint, and far from sacrosanct. For now, let us point out one
major philosophical motivation in its favor. (SCC) has often been
invoked as a means to ensure the fulfilment of the following condition
(see, e.g., Hesse 1975, 88; Horwich 1983, 57):

Predictive inference condition (PIC)

For any e,k∈Le, k \in \bL, if ee confirms ∀x(Fx→Gx)\forall x(Fx \rightarrow
Gx) relative to kk, then ee confirms F(a)→G(a)F(a) \rightarrow G(a)
relative to kk. 

In fact, (PIC) readily follows from (SCC) and so it is satisfied by
Hempel’s theory. It says that, if evidence ee confirms
“all FFs are GGs”, then it also confirms that a
further object will be GG, if it is FF. Notably, this does not
hold for HD-confirmation. Here is why. Given k=Fak = Fa (i.e., the
assumption that aa comes from the FF population), we have that
e=Gae = Ga HD-confirms h=∀x(Fx→Gx)h = \forall x(Fx \rightarrow Gx), because
the latter entails the former (given kk). (That’s the HD
reconstruction of Nicod’s insight, see below.) We also have, of
course, that hh entails h∗=Fb→Gbh^* = Fb \rightarrow Gb. And yet,
contrary to (PIC), since h∗h^* does not entail ee (given kk),
it is not HD-confirmed by it either. The troubling conclusion is that
the observation that a swan is white (or that a million of them are,
for that matters) does not HD-confirm the prediction that a further
swan will be found to be white.
2.2 Back to black (ravens)

One attractive feature of HD-confirmation is that it largely eludes
the ravens paradox. As the hypothesis hh that all ravens are black
does not entail that some generally sampled object aa will be a
black raven, the HD view of confirmation is not committed to the
eminently Hempelian implication that e=raven(a)∧black(a)e = raven(a) \wedge black(a)
confirms hh. Likewise, ¬black(a)∧¬raven(a)\neg black(a) \wedge \neg raven(a) does
not HD-confirm that all non-black objects are non-raven. The
derivation of the paradox, as presented above, is thus blocked.

Indeed, HD-confirmation yields a substantially different reading of
Nicod’s insight as compared to Hempel’s theory (Okasha
2011 has an important discussion of this distinction). Here is how it
goes. If object aa is assumed to have been taken among
ravens—so that, crucially, the auxiliary assumption k=raven(a)k =
raven(a) is made—and aa is checked for color and found to
be black, then, yes, the latter evidence, black(a)black(a), HD-confirms
that all ravens are black (h)(h) relative to kk. By the same
token, ¬black(a)\neg black(a) HD-disconfirms hh relative to the same
assumption k=raven(a)k = raven(a). And, again, this is as it should be, in
line with Nicod’s mention of “the absence of GG [here,
non-black as evidence] in a case of FF [here, raven as an auxiliary
assumption]”. It is also true that an object that is found
not to be a raven HD-confirms hh, but only
relative to k=¬black(a)k = \neg black(a), that is, if aa is assumed to
have been taken among non-black objects to begin with; and this seems
acceptable too (after all, while sampling from non-black objects, one
might have found the counterinstance of a raven, but didn’t).
Unlike Hempel’s theory, moreover, HD-confirmation does not yield
the debatable implication that, by itself (that is, given k=⊤k =
\top), the observation of a non-raven aa, ¬raven(a)\neg raven(a), must
confirm hh.

Interestingly, the introduction of auxiliary hypotheses and
assumptions shows that the issues surrounding Nicod’s remarks
can become surprisingly subtle. Consider the following statements
(Maher’s 2006 example):

(α1\alpha_1) ∀x(white(x)→¬black(x))\forall
x(white(x) \rightarrow \neg black(x))

(α2\alpha_2) 
∃x(swan(x))→∃y(swan(y)∧black(y))\exists x(swan(x)) \rightarrow \exists y(swan(y) \wedge black(y))



α1\alpha_1 simply specifies that no object is both white and black,
while α2\alpha_2 says that, if there are swans at all, then there
also is some black swan. Also posit, again, e=swan(a)∧white(a)e = swan(a)
\wedge white(a). Under α1\alpha_1 and α2\alpha_2, the
observation of a white swan clearly disconfirms (indeed,
refutes) the hypothesis hh that all swans are white. Hempel’s
theory (extended) faces difficulties here, because for k=deve(α1∧α2)k =
dev_{e}(\alpha_1 \wedge \alpha_2) it turns out that e∧ke\wedge k is
inconsistent. But HD-confirmation gets this case right, thus capturing
appropriate boundary conditions for Nicod’s generally sensible
claims. For, with k=α1∧α2k = \alpha_1 \wedge \alpha_2, one has that
h∧kh\wedge k is consistent and entails ¬e\neg e (for it entails
that no swan exists), so that ee HD-disconfirms (refutes) hh
relative to kk (see Good 1967 for another famous counterexample to
Nicod’s condition).

HD-confirmation, however, is also known to suffer from distinctive
“paradoxical” implications. One of the most frustrating is
surely the following (see Osherson, Smith, and Shafir 1986, 206, for
further specific problems).

The irrelevant conjunction paradox. Suppose that ee
confirms hh relative to (possibly empty) kk. Let statement qq
be logically consistent with e∧h∧ke\wedge h\wedge k, but otherwise
entirely irrelevant for all of those conjuncts (perhaps belonging to a
completely separate domain of inquiry). Does ee confirm h∧qh\wedge
q (relative to kk) as it does with hh? One would want to say
no, and this implication can be suitably reconstructed in
Hempel’s theory. HD-confirmation, on the contrary, can not draw
this distinction: it is easy to show that, on the conditions
specified, if the HD clause for confirmation is satisfied for ee
and hh (given kk), so it is for ee and h∧qh\wedge q (given
kk). (This is simply because, if h∧k⊨eh\wedge k \vDash e, then
h∧q∧k⊨eh\wedge q\wedge k \vDash e, too, by the monotonicity of classical
logical entailment.)

Kuipers (2000, 25) suggested that one can live with the irrelevant
conjunction problem because, on the conditions specified, ee would
still not HD-confirm qq alone (given kk), so that
HD-confirmation can be “localized”: hh is the only bit
of the conjunction h∧qh\wedge q that gets any confirmation on its
own, as it were. Other authors have been reluctant to bite the bullet
and have engaged in technical refinements of the
“naïve” HD view. In these proposals, the spread of
HD-confirmation upon frivolous conjunctions can be blocked at the
expense of some additional logical machinery (see Gemes 1993, 1998;
Schurz 1991, 1994).

Finally, it should be noted that HD-confirmation offers no substantial
relief from the blite paradox. On the one hand, e=raven(a)∧ext≤T(a)∧black(a)e = raven(a) \wedge
ex_{t\le T}(a) \wedge black(a) does not, as such,
HD-confirm either h=∀x(raven(x)→black(x))h = \forall x(raven(x) \rightarrow black(x)) or
h∗=∀x(raven(x)→blite(x))h^* = \forall x(raven(x) \rightarrow blite(x)), that is, for empty
kk. On the other hand, if object aa is assumed to have been
sampled from ravens before TT (that is, given k=raven(a)∧ext≤T(a))k = raven(a) \wedge
ex_{t\le T}(a)), then black(a)black(a) is entailed by both “all
ravens are black” and “all ravens are blite” and
therefore HD-confirms each of them. So HD-confirmation, too, sanctions
the existence of confirmation relations that seem intuitively unsound
(indeed, indefinitely many of them: as we know, other variations of
h∗h^* can be conceived at will, like the “blurple” hypothesis).
One could insist that HD does handle the blite paradox after all,
because black(a)black(a) (given kk as above) does not HD-confirms that
a raven will be white if examined after TT (Kuipers 2000, 29 ff.).
Unfortunately (as pointed out by Schurz 2005, 148) black(a)black(a) does
not HD-confirm that a raven will be black if examined after TT
either (again, given kk as above). That’s because, as already
pointed out, HD-confirmation fails the predictive inference condition
(PIC) in general. So, all in all, HD-confirmation can not tell black
from blite any more than Hempel-confirmation can.
2.3 Underdetermination and the Duhemian challenge

The issues above look contrived and artificial to some people’s
taste—even among philosophers. Many have suggested a closer look
at real-world inferential practices in the sciences as a more
appropriate benchmark for assessment. For one thing, the very idea of
hypothetico-deductivism has often been said to stem from the origins
of Western science. As reported by Simplicius of Cilicia (sixth
century A.D.) in his commentary on Aristotle’s De
Caelo, Plato had challenged his pupils to identify combinations
of “ordered” motions by which one could account for
(namely, deduce) the planets’ wandering trajectories across the
heavens as observed by the Earth. As a matter of historical fact,
mathematical astronomy has engaged in just this task for centuries:
scholars have been trying to define geometrical models from which the
apparent motion of celestial bodies would derive.

It is fair to say that, at its roots, the kind of challenges that the
HD framework faces with scientific reasoning is not so different from
the main puzzles that arise from philosophical considerations of a
more formal kind. Still, the two areas turn out to be complementary in
important ways. The following statement will serve as a useful
starting point to extend the scope of our discussion.

Underdetermination Theorem (UT) for
“naïve” HD-confirmation
For any contingent h,e∈Lh, e \in \bL, if hh and ee are logically
consistent, there exists some k∈Lk \in \bL such that ee
HD-confirms hh relative to kk. 

(UT) is an elementary logical fact that has been long recognized (see,
e.g., Glymour 1980a, 36). In purely formal terms, just positing k=h→ek =
h \rightarrow e will do for a proof. To appreciate how (UT) can
spark any philosophical interest, one has to combine it with some
insightful remarks first put forward by Pierre Duhem (1906) and then
famously revived by Quine (1951) in a more radical style. (Indeed,
(UT) essentially amounts to the “entailment version” of
“Quinean underdetermination” in Laudan 1990, 274.)

Duhem (he himself a supporter of the HD view) pointed out that in
mature sciences such as physics most hypotheses or theories of real
interest can not be contradicted by any statement describing
observable states of affairs. Taken in isolation, they simply do not
logically imply, nor rule out, any observable fact, essentially
because (unlike “all ravens are black”) they involve the
mention of unobservable entities and processes. So, in effect, Duhem
emphasized that, typically, scientific hypotheses or theories
are logically consistent with any piece of checkable
evidence. Unless, of course, the logical connection is underpinned by
auxiliary hypotheses and assumptions suitably bridging the gap between
the observational and non-observational vocabulary, as it were. But
then, once auxiliaries are in play, logic alone guarantees that
some kk exists such that h∧kh\wedge k is consistent,
h∧k⊨eh\wedge k \vDash e, and k⊭ek \not\vDash e, so that confirmation
holds in naïve HD terms (that’s just the UT result above).
Apparently, when Duhem’s point applies, the uncritical supporter
of whatever hypothesis hh can legitimately claim (naïve HD)
confirmation from any ee by simply shaping kk conveniently. In
this sense, hypothesis assessment would be radically
“underdetermined” by any amount of evidence practically
available.

Influential authors such as Thomas Kuhn (1962/1970) (but see Laudan
1990, 268, for a more extensive survey) relied on Duhemian insights to
suggest that confirmation by empirical evidence is too weak a force to
drive the evaluation of theories in science, often inviting
conclusions of a relativistic flavor (see Worrall 1996 for an
illuminating reconstruction along these lines). Let us briefly
consider a classical case, which Duhem himself thoroughly analyzed:
the wave vs. particle theories of light in modern optics.
Across the decades, wave theorists were able to deduce an impressive
list of important empirical facts from their main hypothesis along
with appropriate auxiliaries, diffraction phenomena being only one
major example. But many particle theorists’ reaction was to
retain their hypothesis nonetheless and to reshape other
parts of the “theoretical maze” (i.e., kk; the term is
Popper’s, 1963, p. 330) to recover those observed facts as
consequences of their own proposal. And as we’ve seen,
if the bare logic of naïve HD was to be taken strictly,
surely they could have claimed their overall hypothesis to be
confirmed too, just as much as their opponents.

Importantly, they didn’t. In fact, it was quite clear that
particle theorists, unlike their wave-theory opponents, were striving
to remedy weaknesses rather than scoring successes (see Worrall 1990).
But why, then? Because, as Duhem himself clearly realized, the logic
of naïve HD “is not the only rule for our judgments”
(1906, 217). The lesson of (UT) and the Duhemian insight is not quite,
it seems, that naïve HD is the last word and scientific inference
is unconstrained by stringent rational principles, but rather that the
HD view has to be strengthened in order to capture the real nature of
evidential support in rational scientific inference. At least,
that’s the position of a good deal of philosophers of science
working within the HD framework broadly construed. It has even been
maintained that “no serious twentieth-century
methodologist” has ever subscribed to the naïve HD view
above “without crucial qualifications” (Laudan 1990, 278;
also see Laudan and Leplin 1991, 466).

So the HD approach to confirmation has yielded a number of more
articulated variants to meet the challenge of underdetermination.
Following (loosely) Norton (2005), we will now survey an instructive
sample of them.
2.4 The extended HD menu

Naïve HD can be enriched by a resolute form of
predictivism. According to this approach, the naïve HD
clause for confirmation is too weak because ee must have been
predicted in advance from h∧kh\wedge k. Karl Popper’s
(1934/1959) account of the “corroboration” of hypotheses
famously embedded this view, but squarely predictivist stances can be
traced back to early modern thinkers like Christiaan Huygens
(1629–1695) and Gottfried Wilhelm Leibniz (1646–1716), and
in Duhem’s work itself. The predictivist sets a high bar for
confirmation. Her favorite examples typically include stunning
episodes in which the existence of previously unknown objects,
phenomena, or whole classes of them is anticipated: the phases of
Venus for Copernican astronomy or the discovery of Neptune for
Newtonian physics, all the way up to the Higgs boson for so-called
standard model of subatomic particles.

The predictivist solution to the underdetermination problem is fairly
radical: many of the relevant factual consequences of h∧kh\wedge k
will be already known when this theory is articulated, and so unfit
for confirmation. Critics have objected that predictivism is in fact
far too restrictive. There seem to be many cases in which already
known phenomena clearly do provide support to a new hypothesis or
theory. Zahar (1973) first raised this problem of “old
evidence”, then made famous by Glymour (1980a, 85 ff.) as a
difficulty for Bayesianism (see
 Section 3
 below). Examples of this kind abound in the history of science as
elsewhere, but the textbook illustration has become the precession of
Mercury’s perihelion, a lasting anomaly for Newtonian physics:
Einstein’s general relativity calculations got this long-known
fact right, thereby gaining a remarkable piece of initial support for
the new theory. In addition to this problem with old evidence, HD
predictivism also seems to lack a principled rationale. After all, the
temporal order of the discovery of ee and of the articulation of
hh and kk may well be an entirely accidental historical
contingency. Why should it bear on the confirmation relationship among
them? (See Giere 1983 and Musgrave 1974 for classical discussions of
these issues. Douglas and Magnus 2013 and Barnes 2018 offer more
recent views and rich lists of further references.)

As a possible response to the difficulties above, naïve HD can be
enriched by the use-novelty criterion (UN) instead. The UN
reaction to the underdetermination problem is more conservative than
the temporal predictivist strategy. According to this view, to improve
on the weak naïve HD clause for confirmation one only has to rule
out one particular class of cases, i.e., those in which the
description of a known fact, ee, served as a constraint in the
construction of h∧kh\wedge k. The UN view thus comes equipped with a
rationale. If h∧kh\wedge k was shaped on the basis of ee, UN
advocates point out, then it was bound to get that state of affairs
right; the theory never ran any risk of failure, thus did not achieve
any particularly significant success either. Precisely in these cases,
and just for this reason, the evidence ee must not be
double-counted: by using it for the construction of the theory, its
confirmational power becomes “dried out”, so to speak.

The UN completion of naïve HD originated from Lakatos and some of
his collaborators (see Lakatos and Zahar 1975 and Worrall 1978; also
see Giere 1979, 161–162, and Gillies 1989 for similar views),
although important hints in the same direction can be found at least
in the work of William Whewell (1840/1847). Consider the touchstone
example of Mercury again. According to Zahar (1973), Einstein did not
need to rely on the Mercury data to define theory and auxiliaries as
to match observationally correct values for the perihelion precession
(also see Norton 2011a; and Earman and Janssen 1993 for a very
detailed, and more nuanced, account). Being already known, the fact
was not of course predicted in a strictly temporal sense, and yet, on
Zahar’s reading, it could have been: it was
“use-novel” and thus fresh for use to confirm the theory.
For a more mundane illustration, so-called cross-validation
techniques represent a routine application of the UN idea in
statistical settings (as pointed out by Schurz 2014, 92; also see
Forster 2007, 592 ff.). According to some commentators, however, the
UN criterion needs further elaboration (see Hitchcock and Sober 2004
and Lipton 2005), while others have criticized it as essentially
wrong-headed (see Howson 1990 and Mayo 1991, 2014; also see Votsis
2014). 

Yet another way to enrich naïve HD is to combine it with
eliminativism. According to this view, the naïve HD
clause for confirmation is too weak because there must have been a low
(enough) objective chance of getting the outcome ee (favorable to
hh) if hh was false, so that few possibilities exist that ee
may have occurred for some reason other than the truth of hh.
Briefly put, the occurrence of ee must be such that most
alternatives to hh can be safely ruled out. The founding figure of
eliminativism is Francis Bacon (1561–1626). John Stuart Mill
(1843/1872) is a major representative in later times, and Deborah
Mayo’s “error-statistical” approach to hypothesis
testing arguably develops this tradition (Mayo 1996 and Mayo and
Spanos 2010; see Bird 2010, Kitcher 1993, 219 ff., and Meehl 1990 for
other contemporary variations).

Eliminativism is most credible when experimentation is at issue (see,
e.g., Guala 2012). Indeed, the appeal to Bacon’s idea of
crucial experiment (instantia crucis) and related
notions (e.g., “severe testing”) is a fairly reliable mark
of eliminativist inclinations. Experimentation is, to a large extent,
precisely an array of techniques to keep undesired interfering factors
at a minimum by active manipulation and deliberate control (think of
the blinding procedure in medical trials, with hh the hypothesized
effectiveness of a novel treatment and ee a relative improvement in
clinical endpoints for a target subsample of patients thus treated).
When this kind of control obtains, popular statistical tools are
supposed to allow for the calculation of the probability of ee in
case hh is false meant as a “relative frequency in a (real or
hypothetical) series of test applications” (Mayo 1991, 529), and
to secure a sufficiently low value to validate the positive outcome of
the test. It is much less clear how firm a grip this approach can
retain when inference takes place at higher levels of generality and
theoretical commitment, where the hypothesis space is typically much
too poorly ordered to fit routine error-statistical analyses. Indeed,
Laudan (1997, 315; also see Musgrave 2010) spotted in this approach
the risk of a “balkanization” of scientific reasoning,
namely, a restricted focus on scattered pieces of experimental
inference (but see Mayo 2010 for a defense). 

Naïve HD can also be enriched by the notion of
simplicity. According to this view, the naïve HD clause
for confirmation is too weak because h∧kh\wedge k must be a simple
(enough), unified way to account for evidence ee. A classic
reference for the simplicity view is Newton’s first law of
philosophizing in the Principia (“admit no more causes
of natural things than such as are both true and sufficient to explain
their appearances”), echoing very closely Ockham’s razor.
This basic idea has never lost its appeal—even up to recent
times (see, e.g., Quine and Ullian 1970, 69 ff.; Sober 1975; Zellner,
Keuzenkamp, and McAleer 2002; Scorzato 2013).

Despite Thomas Kuhn’s (1957, 181) suggestions to the contrary,
the success of Copernican astronomy over Ptolemy’s system has
remained an influential case study fostering the simplicity view
(Martens 2009). Moreover, in ordinary scientific problems such as
curve fitting, formal criteria of model selection are applied
where the paucity of parameters can be interpreted naturally as a key
dimension of simplicity (Forster and Sober 1994). Traditionally, two
main problems have proven pressing, and frustrating, for the
simplicity approach. First, how to provide a sufficiently coherent and
illuminating explication of this multifaceted and elusive notion (see
Riesch 2010); and second, how to justify the role of simplicity as a
properly epistemic (rather than merely pragmatic)
virtue (see Kelly 2007, 2008).

Finally, naïve HD can be enriched by the appeal to
explanation. Here, the naïve HD clause for confirmation
is meant to be too weak because h∧kh\wedge k must be able (not only
to entail, but) to explain ee. By this move, the HD approach embeds
the slogan of the so-called inference to the best explanation
view: “observations support the hypothesis precisely because it
would explain them” (Lipton 2000, 185; also see Lipton 2004).
Historically, the main source for this connection between explanation
and support is found in the work of Charles Sanders Peirce
(1839–1914). Janssen (2003) offers a particularly neat
contemporary exhibit, explicitly aimed at “curing cases of the
Duhem-Quine disease” (484; also see Thagard 1978, and Douven
2017 for a relevant survey). Quite unlike eliminativist approaches,
explanationist analyses tend to focus on large-scale theories and
relatively high-level kinds of evidence. Dealing with Einstein’s
general relativity, for instance, Janssen (2003) greatly emphasizes
its explanation of the equivalence of inertial and gravitational mass
(essentially a brute fact in Newtonian physics) over the resolution of
the puzzle of Mercury’s perihelion. Explanationist accounts are
also distinctively well-equipped to address inference patterns from
non-experimental sciences (Cleland 2011). 

The problems faced by these approaches are similar to those affecting
the simplicity view. Agreement is still lacking on the nature of
scientific explanation (see Woodward 2019) and it is not clear how far
an explanationist variant of HD can go without a sound analysis of
that notion. Moreover, some critics have wondered why the relationship
of confirmation should be affected by an explanatory connection with
the evidence per se (see Salmon 2001).

The above discussion does not display an exhaustive list (nor are the
listed options mutually exclusive, for that matter: see, e.g., Baker
2003; also see Worrall 2010 for some overlapping implications in an
applied setting of real practical value). And our sketched
presentation hardly allows for any conclusive assessment. It does
suggest, however, that reports of the death of hypothetico-deductivism
(see Earman 1992, 64, and Glymour 1980b) might have been exaggerated.
For all its difficulties, HD has proven fairly resilient at least as a
basic framework to elucidate some key aspects of how hypotheses can be
confirmed by the evidence (see Betz 2013, Gemes 2005, and Sprenger
2011b for consonant points of view).
3. Bayesian confirmation theories

Bayes’s theorem is a very central element of the
probability calculus (see Joyce 2019). For historical reasons,
Bayesian has become a standard label to allude to a range of
approaches and positions sharing the common idea that probability (in
its modern, mathematical sense) plays a crucial role in rational
belief, inference, and behavior. According to Bayesian epistemologists
and philosophers of science, (i) rational agents have credences
differing in strength, which moreover (ii) satisfy the probability
axioms, and can thus be represented in probabilistic form. (In
non-Bayesian models (ii) is rejected, but (i) may well be retained:
see Huber and Schmidt-Petri 2009, Levi 2008, and Spohn 2012.)
Well-known arguments exist in favor of this position (see, e.g.,
Easwaran 2011a; Pettigrew 2016; Skyrms 1987; Vineberg 2016), although
there is no lack of difficulties and criticism (see, e.g., Easwaran
2011b; Hájek 2008; Kelly and Glymour 2004; Norton 2011b).

Beyond the core ideas above, however, the theoretical landscape of
Bayesianism is quite as hopelessly diverse as it is fertile. Surveys
and state of art presentations are already numerous, and ostensibly
growing (see, e.g., Good 1971; Joyce 2011; Oaksford and Chater 2007;
Sprenger and Hartmann 2020; Weisberg 2015). For the present purposes,
attention can be restricted to a classification that is still fairly
coarse-grained, and based on just two dimensions or criteria.

First, there is a distinction between permissivism and
impermissivism (see Meacham 2014 and Kopec and Titelbaum 2016
for this terminology). For permissive Bayesians (often otherwise
labelled “subjectivists”), accordance with the probability
axioms is the only clear-cut constraint on the credences of a rational
agent. In impermissive forms of Bayesianism (often otherwise called
“objective”), further constraints are put forward that
significantly restrict the range of rational credences, possibly up to
one single “right” probability function in any given
setting. Second, there are different attitudes towards so-called
principle of total evidence (TE) for the credences on which a
reasoner relies. TE Bayesians maintain that the relevant credences
should be represented by a probability function PP which conveys
the totality of what is known to the agent. For non-TE approaches,
depending on the circumstances, PP may (or should) be set up so
that portions of the evidence available are in fact bracketed.
(Unsurprisingly, further subtleties arise as soon as one delves a bit
further into the precise meaning and scope of TE; see Fitelson 2008
and Williamson 2002, Chs. 9–10, for important discussions.)

Of course, many intermediate positions exist between extreme forms of
permissivism and impermissivism so outlined, and more or less the same
applies for the TE issue. The above distinctions are surely rough
enough, but useful nonetheless. Impermissive TE Bayesianism has served
as a received view in early Bayesian philosophy of science (e.g.,
Carnap 1950/1962). But impermissivism is easily found in combination
with non-TE positions, too (see, e.g., Maher 1996). TE permissivism
seems a good approximation of De Finetti’s (2008) stance, while
non-TE permissivism is arguably close to a standard view nowadays
(see, e.g., Howson and Urbach 2006). No more than this will be needed
to begin our exploration of Bayesian confirmation theories.
3.1 Probabilistic confirmation as firmness

Let us posit a set P\bP of probability functions representing
possible states of belief about a domain that is described in a finite
language LL with L\bL the set of its closed sentences. From now
on, unless otherwise specified, whenever considering some h,e,k∈Lh, e, k
\in \bL and P∈PP \in \bP, we will invariably rely on the following
provisos:

 both e∧ke\wedge k and h∧kh\wedge k are consistent;
 P(e∧k),P(h∧k)>0;P(e\wedge k), P(h\wedge k) \gt 0;
 P(k)>P(h∧k)P(k) \gt P(h\wedge k) (unless k⊨hk \vDash h);
 P(e∧k)>P(e∧h∧k)P(e\wedge k) \gt P(e\wedge h\wedge k) (unless e∧k⊨he\wedge k
\vDash h); and
 P(e∧h∧k)>0P(e\wedge h\wedge k) \gt 0, as long as e∧h∧ke\wedge h\wedge k
is consistent.


(These assumptions are convenient and critical for technical reasons,
but not entirely innocent. Festa 1999 and Kuipers 2000, 44 ff.,
discuss some limiting cases that are left aside here owing to these
constraints.)

A probabilistic theory of confirmation can be spelled out through the
definition of a function CP(h,e∣k):{L3×P}→ℜC_{P}(h, e\mid k): \{\bL^3 \times \bP\}
\rightarrow \Re representing the degree of confirmation that
hypothesis hh receives from evidence ee relative to kk and
probability function PP. CP(h,e∣k)C_{P}(h,e\mid k) will then have
relevant probabilities as its building blocks, according to the
following basic postulate of probabilistic confirmation:

(P0) Formality

There exists a function gg such that, for any h,e,k∈Lh, e, k \in \bL
and any P∈PP \in \bP, CP(h,e∣k)=g[P(h∧e∣k),P(h∣k),P(e∣k)]C_{P}(h,e\mid k) = g[P(h\wedge e\mid
k),P(h\mid k),P(e\mid k)]. 

Note that the probability distribution over the algebra generated by
hh and ee, conditional on kk, is entirely determined by
P(h∧e∣k)P(h\wedge e\mid k), P(h∣k)P(h\mid k) and P(e∣k)P(e\mid k). Hence, (P0)
simply states that CP(h,e∣k)C_{P}(h, e\mid k) depends on that distribution,
and nothing else. (The label for this assumption is taken from
Tentori, Crupi, and Osherson 2007, 2010.)

Hempelian and HD confirmation, as discussed above, are
qualitative theories of confirmation. They only tell us
whether evidence ee confirms (disconfirms) hypothesis
hh given kk. However, assessments of the amount of
support that some evidence brings to a hypothesis are commonly
involved in scientific reasoning, as well as in other domains, if only
in the form of comparative judgments such as
“hypothesis hh is more strongly confirmed by e1e_{1} than
by e2e_{2}” or “ee confirms h1h_{1} to a greater
extent than h2h_{2}”. Consider, for instance, the following
principle, a veritable cornerstone of probabilistic confirmation in
all of its variations (see Crupi, Chater, and Tentori 2013 for a list
of references):

(P1) Final probability

For any h,e1,e2,k∈Lh,e_{1},e_{2},k \in \bL and any P∈PP \in \bP,
CP(h,e1∣k)⋛CP(h,e2∣k)C_{P}(h,e_{1}\mid k) \gtreqless C_{P}(h, e_{2}\mid k) if and only
if P(h∣e1∧k)⋛P(h∣e2∧k).P(h\mid e_{1} \wedge k) \gtreqless P(h\mid e_{2} \wedge k).


(P1) is itself a comparative, or ordinal, principle, stating
that, for any fixed hypothesis hh, the final (or posterior)
probability and confirmation always move in the same direction in the
light of data, ee (given kk). Interestingly, (P0) and (P1) are
already sufficient to single out one traditional class of measures of
probabilistic confirmation, if conjoined with the following (see Crupi
and Tentori 2016, 656, Schippers 2017, and also Törnebohm 1966,
81):

(P2) Local equivalence

For any h1,h2,e,k∈Lh_{1},h_{2},e,k \in \bL and any P∈PP\in \bP, if h1h_{1}
and h2h_{2} are logically equivalent given ee and kk, then
CP(h1,e∣k)=CP(h2,e∣k).C_{P}(h_{1},e\mid k) = C_{P}(h_{2}, e\mid k). 

The following can then be shown:

Theorem 1

(P0), (P1) and (P2) hold if and only if there exists a strictly
increasing function ff such that, for any h,e,k∈Lh, e, k \in \bL and
any P∈PP \in \bP, CP(h,e∣k)=f[P(h∣e∧k)]C_{P}(h, e\mid k) = f[P(h\mid e\wedge k)]. 

Theorem 1 provides a simple axiomatic characterization of the class of
confirmation functions that are strictly increasing with the final
probability of the hypothesis given the evidence (and kk) (proven
in Schippers 2017). All the functions in this class are ordinally
equivalent, meaning that they imply the same rank order of
CP(h,e∣k)C_{P}(h, e\mid k) and CP∗(h∗,e∗∣k∗)C_{P^*}(h^*,e^*\mid k^*) for any h,h∗,e,e∗,k,k∗∈Lh,
h^*,e, e^*,k, k^* \in \bL and any P,P∗∈P.P, P^* \in \bP.

By (P0), (P1) and (P2), we thus have CP(h,e∣k)=f[P(h∣e∧k)]C_{P}(h, e\mid k) = f[P(h\mid e
\wedge k)], implying that the more likely hh is given the
evidence the more it is confirmed. This approach explicates
confirmation precisely as the overall credibility of a
hypothesis (firmness is Carnap’s 1950/1962 telling
term, xvi). In this view, “Bayesian confirmation theory is
little more than the examination of [the] properties” of the
posterior probability function (Howson 2000, 179).

As we will see, the ordinal level of analysis is a solid and
convenient middleground between a purely qualitative and a thoroughly
quantitative (metric) notion of confirmation. To begin with, ordinal
notions are in general sufficient to move “upwards” to the
qualitative level as follows:

Qualitative confirmation from ordinal relations (QC)

For any h,e,k∈Lh, e, k \in \bL and any P∈PP \in \bP:


ee CPC_{P}-confirms hh relative to kk
if and only if CP(h,e∣k)>CP(¬h,e∣k);C_{P}(h, e\mid k) \gt C_{P}(\neg h, e\mid k);
ee CPC_{P}-disconfirms hh relative to
kk if and only if CP(h,e∣k)<CP(¬h,e∣k);C_{P}(h, e\mid k) \lt C_{P}(\neg h, e\mid
k);
ee is CPC_{P}-neutral for hh relative to
kk if and only if CP(h,e∣k)=CP(¬h,e∣k).C_{P}(h, e\mid k) = C_{P}(\neg h, e\mid
k).



Given Theorem 1, (P0), (P1) and (P2) can be combined with the
definitions in (QC) to derive the following qualitative notion of
probabilistic confirmation as firmness:

Confirmation as firmness (FF-confirmation,
qualitative)

For any h,e,k∈Lh, e, k \in \bL and any P∈PP \in \bP:


ee FF-confirms hh relative to kk if
and only if P(h∣e∧k)>1⁄2;P(h\mid e \wedge k) \gt \bfrac{1}{2}; 
ee FF-disconfirms hh relative to kk
if and only if P(h∣e∧k)<1⁄2;P(h\mid e \wedge k) \lt \bfrac{1}{2};
ee is FF-neutral for hh relative
to kk if and only if P(h∣e∧k)=1⁄2.P(h\mid e \wedge k) =
\bfrac{1}{2}.



The point of qualitative FF-confirmation is thus straightforward:
hh is said to be (dis)confirmed by ee (given kk) if it is
more likely than not to be true (false). (Sometimes a threshold higher
than a probability 1⁄2\bfrac{1}{2} is identified, but this
complication would add little for our present purposes.)

The ordinal notion of confirmation is of high theoretical significance
because ordinal divergences, unlike purely quantitative differences,
imply opposite comparative judgments for some evidence-hypothesis
pairs. A refinement from the ordinal to a properly quantitative level
is also be of interest, however, and much useful for tractability and
applications. For example, one can have 0 as a convenient neutrality
threshold for confirmation as firmness, provided that the following
functional representation is adopted (see Peirce 1878 for an early
occurrence): F(h,e∣k)=log[P(h∣e∧k)P(¬h∣e∧k)]=logOdds(h∣e∧k)\begin{align} F(h,e\mid k) &amp; =
\log\left[\frac{P(h\mid e \wedge k)}{P(\neg h\mid e \wedge k)}\right]
\\ &amp; = \log Odds(h\mid e \wedge k) \end{align}

(The base of the logarithm can be chosen at convenience, as long as it
is strictly greater than 1.)

A quantitative requirement that is often put forward is the following
stringent form of additivity:

Strict additivity (SA)

For any h,e1,e2,k∈Lh, e_{1},e_{2},k \in \bL and any P∈PP \in \bP,
   CP(h,e1∧e2∣k)=CP(h,e1∣k)+CP(h,e2∣e1∧k).\ \ \ C_{P}(h, e_{1} \wedge e_{2}\mid k) = C_{P}(h, e_{1}\mid k) +
C_{P}(h, e_{2}\mid e_{1} \wedge k). 

Although extraneous to FF-confirmation, Strict Additivity will
prove of use later on for the discussion of further variants of
Bayesian confirmation theory.
3.2 Strengths and infirmities of firmness

Confirmation as firmness shares a number of structural properties with
Hempelian confirmation. It satisfies the Special Consequence
Condition, thus the Predictive Inference Condition too. It satisfies
the Entailment Condition and, in virtue of (P1), extends it smoothly
to the following ordinal counterpart:

Entailment condition (ordinal extension) (EC-Ord)

For any h,e1,e2,k∈Lh, e_{1},e_{2},k\in \bL and any P∈PP \in \bP such that
k⊭hk \not\vDash h:


 if, e1∧k⊨he_{1}\wedge k \vDash h and e2∧k⊭he_{2}\wedge k \not\vDash
h, then hh is more confirmed by e1e_{1} than by e2e_{2}
relative to kk, that is, CP(h,e1∣k)>CP(h,e2∣k);C_{P}(h, e_{1}\mid k) \gt C_{P}(h,
e_{2}\mid k);
if, e1∧k⊨he_{1}\wedge k\vDash h and e2∧k⊨h,e_{2}\wedge k\vDash h, then
hh is equally confirmed by e1e_{1} and by e2e_{2} relative to
kk, that is, CP(h,e1∣k)=CP(h,e2∣k).C_{P}(h, e_{1}\mid k) = C_{P}(h, e_{2}\mid
k).



According to (EC-Ord) not only is classical entailment retained as a
case of confirmation, it also represents a limiting case: it is the
strongest possible form of confirmation that a fixed hypothesis hh
can receive.

FF-confirmation also satisfies Confirmation Complementarity and,
moreover, extends it to its appealing ordinal counterpart (see Crupi,
Festa, and Buttasi 2010, 85–86), that is:

Confirmation complementarity (ordinal extension)
(CC-Ord)

CP(¬h,e∣k)C_{P}(\neg h, e\mid k) is a strictly decreasing function of
CP(h,e∣k)C_{P}(h, e\mid k), that is, for any h,h∗,e,e∗,k∈Lh, h^*,e, e^*,k \in \bL
and any P∈P,P\in \bP, CP(h,e∣k)⋛CP(h∗,e∗∣k)C_{P}(h, e\mid k)\gtreqless C_{P}(h^*,e^*\mid
k) if and only if CP(¬h,e∣k)⋚CP(¬h∗,e∗∣k).C_{P}(\neg h, e\mid k) \lesseqgtr C_{P}(\neg
h^*,e^*\mid k). 

(CC-Ord) neatly reflects Keynes’ (1921, 80) remark that
“an argument is always as near to proving or disproving a
proposition, as it is to disproving or proving its
contradictory”. Indeed, quantitatively, the measure F(h,e∣k)F(h, e\mid
k) instantiates Confirmation Complementarity in a simple and elegant
way, that is, it satisfies CP(h,e∣k)=−CP(¬h,e∣k).C_{P}(h, e\mid k) = -C_{P}(\neg h, e\mid
k).

FF-confirmation also implies another attractive quantitative
result, alleviating the ailments of the irrelevant conjunction
paradox. In the statement below, indicating this result, the
irrelevance of qq for hypothesis hh and evidence ee
(relative to kk) is meant to amount to the probabilistic
independence of qq from h,eh, e and their conjunction (given
kk), that is, to P(h∧q∣k)=P(h∣k)P(q∣k),P(h \wedge q\mid k) = P(h\mid k)P(q\mid k),
P(e∧q∣k)=P(e∣k)P(q∣k)P(e \wedge q\mid k) = P(e\mid k)P(q\mid k), and P(h∧e∧q∣k)=P(h∧e∣k)P(q∣k)P(h \wedge e
\wedge q\mid k) = P(h \wedge e\mid k)P(q\mid k), respectively.


Confirmation upon irrelevant conjunction (ordinal
solution) (CIC)

For any h,e,q,k∈Lh, e, q, k \in \bL and any P∈P,P \in \bP, if ee
confirms hh relative to kk and qq is irrelevant for hh and
ee relative to kk, then
   CP(h,e∣k)>CP(h∧q,e∣k).\ \ \ C_{P}(h, e\mid k) \gt C_{P}(h \wedge q, e\mid k). 


So, even in case it is qualitatively preserved across the tacking of
qq onto hh, the positive confirmation afforded by ee is at
least bound to quantitatively decrease thereby.

Partly because of appealing formal features such as those mentioned so
far, there is a long list of distinguished scholars advocating the
firmness view of confirmation, from Keynes (1921) and
Hosiasson-Lindenbaum (1940) onwards, most often coupled with some form
of impermissive Bayesianism (see Hawthorne 2011 and Williamson 2011
for contemporary variations). In fact, FF-confirmation fits most
neatly a classical form of TE impermissivism à la
Carnap, where one assumes that k=⊤,k = \top, that PP is an
“objective” initial probability based on essentially
logical considerations, and that all the non-logical information
available is collected in ee. The spirit of the Carnapian project
never lost its appeal entirely (see, e.g., Festa 2003, Franklin 2001,
Maher 2010, Paris 2011). However, the idea of a “logical”
interpretation of PP got stuck into difficulties that are often
seen as insurmountable (e.g., Earman and Salmon 1992, 85–89;
Gillies 2000, Ch. 3; Hájek 2019; Howson and Urbach 2006,
59–72; van Fraassen 1989, Ch. 12; Zabell 2011). And arguably,
lacking some robust and effective impermissivist policy, the account
of confirmation as firmness ends up loosing much of its philosophical
momentum. The issues surrounding the ravens and blite paradoxes
provide a useful illustration.

Consider again h=∀x(raven(x)→black(x))h = \forall x(raven(x) \rightarrow black(x)), and
the main analyses of “the observation that aa is a black
raven” encountered so far, that is: 

 k=⊤k = \top and e=raven(a)∧black(a)e = raven(a) \wedge black(a), and
 k=raven(a)k = raven(a) and e=black(a).e = black(a). 


In both cases, whether ee FF-confirms hh or not (relative to
kk) critically depends on PP: if the prior P(h∣k)P(h\mid k) is low
enough, ee won’t do no matter what under either (i) or (ii);
and if it is high enough, hh will be FF-confirmed either way. As
a consequence, the FF-confirmation view, by itself, does not offer
any definite hint as to when, how, and why Nicod’s remarks apply
or not.

For the purposes of our discussion, the following condition reveals
another debatable aspect of the firmness explication of
confirmation.

Consistency condition (Cons)

For any h,h∗,e,k∈Lh, h^*,e, k \in \bL and any P∈PP \in \bP, if k⊨¬(h∧h∗)k \vDash
\neg(h\wedge h^*) then ee confirms hh given kk if and only
if ee disconfirms h∗h^* given kk. 

(Cons) says that evidence ee can never confirm incompatible
hypotheses. But consider, by way of illustration, a clinical case of
an infectious disease of unknown origin, and suppose that ee is the
failure of antibiotic treatment. Arguably, there is nothing wrong in
saying that, by discrediting bacteria as possible causes, the evidence
confirms (viz. provides some support for) any of a number of
alternative viral diagnoses. This judgment clashes with (Cons),
though, which then seems an overly strong constraint.

Notably, (Cons) was defended by Hempel (1945) and, in fact, one can
show that it follows from the conjunction of (qualitative)
Confirmation Complementary and the Special Consequence Condition, and
so from both Hempelian and FF-confirmation. This is but one sign of
how stringent the Special Consequence Condition is. Mainly because of
the latter, both the Hempelian and the firmness views of confirmation
must depart from the plausible HD idea that hypotheses are generally
confirmed by their verified consequences (see Hempel 1945,
103–104). We will come back to this while discussing our next
topic: a very different Bayesian explication of confirmation, based on
the notion of probabilistic relevance.
3.3 Probabilistic relevance confirmation

We’ve seen that the firmness notion of probabilistic
confirmation can be singled out through one ordinal constraint, (P2),
in addition to the fundamental principles (P0)–(P1). The
counterpart condition for the so-called relevance notion of
probabilistic confirmation is the following:

(P3) Tautological evidence

For any h1,h2,k∈Lh_{1},h_{2},k\in \bL and any P∈PP\in \bP,
CP(h1,⊤∣k)=CP(h2,⊤∣k).C_{P}(h_{1},\top \mid k) = C_{P}(h_{2},\top \mid k). 

(P3) implies that any hypothesis is equally “confirmed” by
empty evidence. We will say that CP(h,e∣k)C_{P}(h, e\mid k) represents the
probabilistic relevance notion of confirmation, or
relevance-confirmation, if and only if it satisfies (P0), (P1) and
(P3). These conditions are sufficient to derive the following, purely
qualitative principle, according to the definitional method in (QC)
above (see Crupi and Tentori 2014, 82, and Crupi 2015).

Probabilistic relevance confirmation (qualitative)

For any h,e,k∈Lh, e, k \in \bL and any P∈P:P\in \bP:

ee relevance-confirms hh relative to kk
if and only if P(h∣e∧k)>P(h∣k);P(h\mid e \wedge k)\gt P(h\mid k);
ee relevance-disconfirms hh relative to
kk if and only if P(h∣e∧k)<P(h∣k);P(h\mid e \wedge k)\lt P(h\mid k);
ee is relevance-neutral for hh relative to
kk if and only if P(h∣e∧k)=P(h∣k).P(h\mid e \wedge k) = P(h\mid k).



The point of relevance confirmation is that the credibility of a
hypothesis can be changed in either a positive (confirmation
in a strict sense) or negative way (disconfirmation) by the evidence
concerned (given kk). Confirmation (in the strict sense) thus
reflects an increase from initial to final probability, whereas
disconfirmation reflects a decrease (see Achinstein 2005 for some
diverging views on this very idea).

The qualitative notions of confirmation as firmness and as relevance
are demonstrably distinct. Unlike firmness, relevance confirmation can
not be formalized by the final probability alone, or any increasing
function thereof. To illustrate, the probability of an otherwise very
rare disease (h)(h) can be quite low even after a relevant positive
test result (e)(e); yet hh is relevance-confirmed by ee to the
extent that its probability rises thereby. By the same token, the
probability of the absence of the disease (¬h)(\neg h) can be quite
high despite the positive test result (e)(e), yet ¬h\neg h is
relevance-disconfirmed by ee to the extent that its probability
decreases thereby. Perhaps surprisingly, the distinction between
firmness and relevance confirmation—“extremely
fundamental” and yet “sometimes unnoticed”, as
Salmon (1969, 48–49) put it—had to be stressed time and
again to achieve theoretical clarity in philosophy (e.g., Popper 1954;
Peijnenburg 2012) as well as in other domains concerned, such as
artificial intelligence and the psychology of reasoning (see Horvitz
and Heckerman 1986; Crupi, Fitelson, and Tentori 2008; Shogenji
2012).

The qualitative notion of relevance confirmation already has some
interesting consequences. It implies, for instance, the following
remarkable fact:

Complementary Evidence (CompE)

For any h,e,k∈Lh, e, k\in \bL and any P∈P,P\in \bP, ee confirms hh
relative to kk if and only if ¬e\neg e disconfirms hh relative
to k.k. 

The importance of (CompE) can be illustrated as follows. Consider the
case of a father suspected of abusing his son. Suppose that the child
does claim that s/he has been abused (label this evidence ee). A
forensic psychiatrist, when consulted, declares that this confirms
guilt (h)(h). Alternatively, suppose that the child is asked and does
not report having been abused (¬e).(\neg e). As pointed out by
Dawes (2001), it may well happen that a forensic psychiatrist will
nonetheless interpret this as evidence confirming guilt
(suggesting that violence has prompted the child’s denial). One
might want to argue that, other things being equal, this kind of
“heads I win, tails you lose” judgment would be
inconsistent, and thus in principle untenable. Whoever concurs with
this line of argument (as Dawes 2001 himself did) is likely to be
relying on the relevance notion of confirmation. In fact, no other
notion of confirmation considered so far provides a general foundation
for this judgment. FF-confirmation, in particular, would not do,
for it does allow that both ee and ¬e\neg e confirm hh
(relative to kk). This is because, mathematically, it is perfectly
possible for both P(h∣e∧k)P(h\mid e \wedge k) and P(h∣¬e∧k)P(h\mid \neg e \wedge
k) to be arbitrarily high above 1⁄2.\bfrac{1}{2}. Condition (CompE),
on the contrary, ensures that only one between the
complementary statements ee and ¬e\neg e can confirm hypothesis
hh (relative to kk). (To be precise, HD-confirmation also
satisfies condition CompE, yet it would fail the above example all the
same, although for a different reason, that is, because the connection
between hh and ee is plausibly one of probabilistic dependence
but not of logical entailment.)

Remarks such as the foregoing have induced some contemporary Bayesian
theorists to dismiss the notion of confirmation as firmness
altogether, concluding with I.J. Good (1968, 134) that “if you
had P(h∣e∧k)P(h\mid e \wedge k) close to unity, but less than P(h∣k)P(h\mid
k), you ought not to say that hh was confirmed by
ee” (also see Salmon 1975, 13). Let us follow this suggestion
and proceed to consider the ordinal (and quantitative) notions of
relevance confirmation.
3.4 Differences, ratios, and partial entailment

Just as with firmness, the ordinal analysis of relevance confirmation
can be characterized axiomatically. With the relevance notion,
however, a larger set of options arises. Consider the following
principles.


(P4) Disjunction of alternative hypotheses

For any e,h1,h2,k∈Le, h_{1},h_{2},k\in \bL and any P∈P,P\in \bP, if k⊨¬(h1∧h2)k\vDash
\neg (h_{1} \wedge h_{2}), then CP(h1,e∣k)⋛CP(h1∨h2,e∣k)C_{P}(h_{1},e\mid k) \gtreqless
C_{P}(h_{1} \vee h_{2},e\mid k) if and only if P(h2∣e∧k)⋛P(h2∣k).P(h_{2}\mid e
\wedge k)\gtreqless P(h_{2}\mid k). 



(P5) Law of likelihood

For any e,h1,h2,k∈Le, h_{1}, h_{2}, k\in \bL and any P∈P,P\in \bP,
CP(h1,e∣k)⋛CP(h2,e∣k)C_{P}(h_{1}, e\mid k)\gtreqless C_{P}(h_{2}, e\mid k) if and only
if P(e∣h1∧k)⋛P(e∣h2∧k).P(e\mid h_{1} \wedge k)\gtreqless P(e\mid h_{2} \wedge k). 



(P6) Modularity (for conditionally independent data)

For any e1,e2,h,k∈Le_{1},e_{2},h, k\in \bL and any P∈P,P\in \bP, if
P(e1∣±h∧e2∧k)=P(e1∣±h∧k),P(e_{1}\mid \pm h \wedge e_{2} \wedge k)=P(e_{1}\mid \pm h \wedge
k), then CP(h,e1∣e2∧k)=CP(h,e1∣k).C_{P}(h, e_{1}\mid e_{2} \wedge k) = C_{P}(h, e_{1}\mid
k). 


All the above conditions occur more or less widely in the literature
(see Crupi, Chater, and Tentori 2013 and Crupi and Tentori 2016 for
references and discussion). Interestingly, they’re all pairwise
incompatible on the background of the Formality and the Final
Probability principles (P0 and P1 above). Indeed, they sort out the
relevance notion of confirmation into three distinct, classical
families of measures, as follows (Crupi, Chater, and Tentori 2013;
Crupi and Tentori 2016; Heckerman 1988; Sprenger and Hartmann 2020,
Ch. 1):

Theorem 2

Given (P0) and (P1):


(P4) holds if and only if CP(h,e∣k)C_{P}(h, e\mid k) is a
probability difference measure, that is, if there exists a
strictly increasing function ff such that, for any h,e,k∈Lh, e, k\in
\bL and any P∈P,P\in \bP, CP(h,e∣k)=f[P(h∣e∧k)−P(h∣k)];C_{P}(h, e\mid k) = f[P(h\mid e \wedge
k) - P(h\mid k)];
(P5) holds if and only if CP(h,e∣k)C_{P}(h, e\mid k) is a
probability ratio measure, that is, if there exists a
strictly increasing function ff such that, for any h,e,k∈Lh, e, k\in
\bL and any P∈P,P\in \bP, CP(h,e∣k)=f[P(h∣e∧k)P(h∣k)];C_{P}(h, e\mid k) =f[\frac{P(h\mid e
\wedge k)}{P(h\mid k)}];
(P6) holds if and only if CP(h,e∣k)C_{P}(h, e\mid k) is a
likelihood ratio measure, that is, if there exists a strictly
increasing function ff such that, for any h,e,k∈Lh, e, k\in \bL and
any P∈P,P\in \bP, CP(h,e∣k)=f[P(e∣h∧k)P(e∣¬h∧k)].C_{P}(h, e\mid k) =f[\frac{P(e\mid h \wedge
k)}{P(e\mid \neg h \wedge k)}].



If a strictly additive behavior (SA above) is imposed, one functional
form is singled out for the quantitative representation of
confirmation corresponding to each of the clauses above:

DP(h,e∣k)=P(h∣e∧k)−P(h∣k);D_{P}(h, e\mid k) = P(h\mid e \wedge k) - P(h\mid k);
RP(h,e∣k)=log[P(h∣e∧k)P(h∣k)];R_{P}(h, e\mid k) = \log[\frac{P(h\mid e \wedge k)}{P(h\mid
k)}];
LP(h,e∣k)=log[P(e∣h∧k)P(e∣¬h∧k)].L_{P}(h, e\mid k) = \log[\frac{P(e\mid h \wedge k)}{P(e\mid \neg
h \wedge k)}].


(The bases of the logarithms are assumed to be strictly greater than
1.)

Before discussing briefly this set of alternative quantitative
measures of relevance confirmation, we will address one further
related issue. It is a long-standing idea, going back to Carnap at
least, that confirmation theory should yield an inductive
logic that is analogous to classical deductive logic in some
suitable sense, thus providing a theory of partial entailment, and
partial refutation. Now, the deductive-logical notions of entailment
and refutation (contradiction) exhibit the following well-known
properties:


Contraposition of entailment

Entailment is contrapositive, but not commutative. That is, it holds
that ee entails hh (e⊨h)(e\vDash h) if and only if ¬h\neg h
entails ¬e\neg e (¬h⊨¬e),(\neg h\vDash \neg e), while it does not hold
that ee entails hh if and only if hh entails ee (h⊨e).(h\vDash
e).

Commutativity of refutation

Refutation, on the contrary, is commutative, but not contrapositive.
That is, it holds that ee refutes hh (e⊨¬h)(e\vDash \neg h) if and
only if hh refutes ee (h⊨¬e)(h\vDash \neg e), while it does not
hold that ee refutes hh if and only if ¬h\neg h refutes ¬e\neg
e (¬h⊨¬¬e).(\neg h \vDash \neg\neg e).


The confirmation-theoretic counterparts are fairly
straightforward:


(P7) Contraposition of confirmation

For any e,h,k∈Le, h, k\in \bL and any P∈P,P\in \bP, if ee
relevance-confirms hh relative to k,k, then CP(h,e∣k)=CP(¬e,¬h∣k).C_{P}(h, e\mid k) =
C_{P}(\neg e,\neg h\mid k).

(P8) Commutativity of disconfirmation

For any e,h,k∈Le, h, k \in \bL and any P∈P,P \in \bP, if ee
relevance-disconfirms hh relative to kk, then CP(h,e∣k)=CP(e,h∣k).C_{P}(h, e\mid
k) = C_{P}(e, h\mid k).


The following can then be proven (Crupi and Tentori 2013):

Theorem 3

Given (P0) and (P1), (P7) and (P8) hold if and only if CP(h,e∣k)C_{P}(h,
e\mid k) is a relative distance measure, that is, if there
exists a strictly increasing function ff such that, for any h,e,k∈Lh, e,
k\in \bL and any P∈P,P\in \bP, CP(h,e∣k)=f[Z(h,e∣k)],C_{P}(h, e\mid k) = f[Z(h, e\mid
k)], where:

Z(h,e∣k)={P(h∣e∧k)−P(h∣k)1−P(h∣k)if P(h∣e∧k)≥P(h∣k)P(h∣e∧k)−P(h∣k)P(h∣k)if P(h∣e∧k)<P(h∣k) Z(h,e\mid k)= \begin{cases} \dfrac{P(h\mid e \wedge k) - P(h\mid
k)}{1-P(h\mid k)} &amp; \mbox{if } P(h\mid e \wedge k) \ge P(h\mid k)
\\ \\ \dfrac{P(h\mid e \wedge k) - P(h\mid k)}{P(h\mid k)} &amp;
\mbox{if } P(h\mid e \wedge k) \lt P(h\mid k) \end{cases}  


So, despite some pessimistic suggestions (see, e.g., Hawthorne 2018,
and the discussion in Crupi and Tentori 2013), a neat
confirmation-theoretic generalization of logical entailment (and
refutation) is possible after all. Interestingly, relative distance
measures can be additive, but only for uniform pairs
of arguments – both confirmatory or both disconfirmatory (see
Milne 2014, p. 259). (Note: Crupi, Tentori, and Gonzalez 2007; Crupi,
Festa, and Buttasi 2010; and Crupi and Tentori 2013, 2014, provide
further discussions of the properties of relative distance measures
and their intuitive motivations. Also see Mura 2008 for a related
analysis.)

The plurality of alternative probabilistic measures of relevance
confirmation has prompted some scholars to be skeptical or dismissive
of the prospects for a quantitative theory of confirmation (see, e.g.,
Howson 2000, 184–185, and Kyburg and Teng 2001, 98 ff.).
However, as we will see shortly, quantitative analyses of relevance
confirmation have proved important for handling a number of puzzles
and issues that plagued competing approaches. Moreover, various
arguments in the philosophy of science and beyond have been shown to
depend critically (and sometimes unwittingly) on the choice of one
confirmation measure (or some of them) rather than others (see Festa
and Cevolani 2017, Fitelson 1999, Brössel 2013, Glass 2013, Roche
and Shogenji 2014, Rusconi et al. 2014, and van Enk
2014).

Recently, arguments have been offered by Huber (2008b) in favor of
DD, by Park (2014), Pruss (2014), and Vassend (2015) in favor of
LL (also see Morey, Romeijn, and Rouder 2016 for an important
connection with statistics), and by Crupi and Tentori (2010) in favor
of ZZ. Hájek and Joyce (2008, 123), on the other hand, have
seen different measures as possibly capturing “distinct,
complementary notions of evidential support” (also see
Schlosshauer and Wheeler 2011, Sprenger and Hartmann 2020, Ch.1, and
Steel 2007 for tempered forms of pluralism). The case of measure RR
deserves some more specific comments, however. Following Fitelson
(2007), one could see RR as conveying key tenets of so-called
“likelihoodist” position about evidential reasoning (see
Royall 1997 for a classical statement, and Chandler 2013 and Sober
1990 for consonant arguments and inclinations). There seems to be some
consensus, however, that compelling objections can be raised against
the adequacy of RR as a proper measure of relevance confirmation
(see, in particular, Crupi, Festa, and Buttasi 2010, 85–86;
Eells and Fitelson 2002; Gillies 1986, 112; and compare Milne 1996
with Milne 2010, Other Internet Resources). In what follows, too, it
will be convenient to restrict our discussion to D,LD, L and ZZ as
candidate measures. All the results to be presented below are
invariant for whatever choice among these three options, and across
ordinal equivalence with each of them (but those results do
not always extend to measures ordinally equivalent to
RR).
3.5 New evidence, old evidence, and total evidence

Let us go back to a classical HD case, where the (consistent)
conjunction h∧kh \wedge k (but not kk alone) entails e.e. The
following can be proven:

Surprising prediction theorem (SP)

For any e,h,k∈Le, h, k \in \bL and any P∈PP\in \bP such that h∧k⊨eh \wedge
k\vDash e and k⊭e:k\not\vDash e:

if P(e∣k)<1,P(e\mid k)\lt 1, then ee relevance-confirms hh
relative to kk and CP(h,e∣k)C_{P}(h, e\mid k) is a decreasing function
of P(e∣k);P(e\mid k);
if P(e∣k)=1,P(e\mid k) = 1, then ee is relevance-neutral for hh
relative to k.k.



Formally, it is fairly simple to show that (SP) characterizes
relevance confirmation (see, e.g., Crupi, Festa, and Buttasi 2010, 80;
Hájek and Joyce 2008, 123), but the philosophical import of
this result is nonetheless remarkable. For illustrative purposes, it
is useful to assume the endorsement of the principle of total evidence
(TE) as a default position for the Bayesian. This means that PP is
assumed to represent actual degrees of belief of a rational
agent, that is, given all the background information available. Then,
by clause (i) of (SP), we have that the occurrence of ee, a
consequence of h∧kh \wedge k (but not of kk alone), confirms hh
relative to kk provided that ee was initially uncertain
to some degree (even given kk). In other words: ee must have
been predicted on the basis of h∧kh \wedge k. Moreover, again by
(i), the confirmatory impact will be stronger the more surprising
(unlikely) the evidence was unless hh was conjoined to kk. So,
under TE, relevance confirmation turns out to embed a squarely
predictivist version of hypothetico-deductivism! As we know, this
neutralizes the charge of underdetermination, yet it comes at the
usual cost, namely, the old evidence problem. In fact, if TE is in
force, then clause (ii) of (SP) implies that no statement that is
known to be true (thus assigned probability 1) can ever have
confirmatory import. 

Interestingly, the Bayesian predictivist has an escape (neatly
anticipated, and criticized, by Glymour 1980a, 91–92). Consider
Einstein and Mercury once again. As effectively pointed out by Norton
(2011a, 7), Einstein was extremely careful to emphasize that the
precession phenomenon had been derived “without having to
posit any special [auxiliary] hypotheses at
all”. Why? Well, presumably because if one had allowed
herself to arbitrarily devise ad hoc auxiliaries (within
kk, in our notation) then one could have been pretty much certain
in advance to find a way to get Mercury’s data right (remember:
that’s the lesson of the underdetermination theorem). But
getting those data right with auxiliaries kk that were not thus
adjusted—that would have been a natural consequence had
the theory of general relativity been true and it would have been
surprising otherwise. Arguably, this line of argument exploits
much of the use-novelty idea within a predictivist framework. The
crucial points are (i) that the evidence implied is not a verified
empirical statement ee but the logical fact that h∧kh \wedge k
entails ee, and (ii) that the existence of this connection of
entailment was not to be obviously anticipated at all, precisely
because h∧kh \wedge k and ee are such that the latter did not
serve as a constraint to specify the former. On these conditions, it
seems that hh can be confirmed by this kind of
“second-order” (logical) evidence in line with (SP)
while TE is concurrently preserved.

At least two main problems arise, however. The first one is more
technical in nature. Modelling rational uncertainty concerning logical
facts (such as h∧k⊨eh \wedge k \vDash e) by probabilistic means is no
trivial task. Garber (1983) put forward an influential proposal, but
doubts have been raised that it might not be well-behaved (e.g., van
Fraassen 1988; a careful survey with further references can be found
in Eva and Hartmann forthcoming). Second, and more substantially, this
solution of the old evidence problem can be charged of being an
elusive change of the subject: for it was Mercury’s
data, not anything else, that had to be recovered as having
confirmed (and still confirming, some would add) Einstein’s
theory. That’s the kind of judgment that confirmation theory
must capture, and which remains unattainable for the predictivist
Bayesian. (Earman 1992, 131 voiced this complaint forcefully. Hints
for a possible rejoinder appear in Eells’s 1990 thorough
discussion; see also Skyrms 1983.)

Bayesians that are unconvinced by the predictivist position are
naturally led to dismiss TE and allow for the assignment of initial
probabilities lower than 1 even to statements that were known all
along. Of course, this brings the underdetermination problem back, for
now kk can still be concocted ad hoc to have known
evidence ee following from h∧kh \wedge k and moreover
P(e∣k)<1P(e\mid k)\lt 1 is not prevented by TE anymore, thus potentially
licencing arbitrary confirmation relations. Two moves can be combined
to handle this problem. First, unlike HD, the Bayesian framework has
the formal resources to characterize the auxiliaries themselves as
more or less likely and thus their adoption as relatively safe or
suspicious (the standard Bayesian treatment of auxiliary hypotheses is
developed along these lines in Dorling 1979 and Howson and Urbach
2006, 92–102, and it is critically discussed in Rowbottom 2010,
Strevens 2001, and Worrall 1993; also see Christensen 1997 for an
important analysis of related issues). Second, one has to provide
indications as to how TE should be relaxed. Non-TE Bayesians of the
impermissivist strand often suggest that objective likelihood values
concerning the outcome ee—P(e∣h∧k)P(e\mid h \wedge k)—can
be specified for the competing hypotheses at issue quite apart from
the fact that ee may have already occurred. Such values would
typically be diverse for different hypotheses (thus mathematically
implying P(e∣k)<1P(e\mid k)\lt 1) and serve as a basis to capture formally
the confirmatory impact of ee (see Hawthorne 2005 for an argument
along these lines). Permissivists, on the other hand, can not
coherently rely on these considerations to articulate a non-TE
position. They must invoke counterfactual degrees of belief
instead, suggesting that PP should be reconstructed as representing
the beliefs that the agent would have, had she not known that ee
was true (see Howson 1991 for a statement and discussion, and Sprenger
2015 for an original recent variant; also see Jeffrey 1995 and Wagner
2001 for relevant technical results, and Steele and Werndl 2013 for an
intriguing case-study from climate science).
3.6 Paradoxes probabilified and other elucidations

The theory of Bayesian confirmation as relevance indicates when and
why the HD idea works: if h∧kh \wedge k (but not kk) entails
ee, then hh is relevance-confirmed by ee (relative to kk)
because the latter increases the probability of the
former—provided that P(e∣k)<1P(e\mid k) \lt 1. Admittedly,
the meaning of the latter proviso partly depends on how one handles
the problem of old evidence. Yet it seems legitimate to say that
Bayesian relevance confirmation (unlike the firmness view)
retains a key point of ordinary scientific practice which is embedded
in HD and yields further elements of clarification. Consider the
following illustration.

(e1)(e_{1}) tigers
carry the ND1 gene
(e2)(e_{2}) elephants
carry the ND1 gene
(e∗2)(e_{2}^*) lions
carry the ND1 gene
(h)(h) all mammals
carry the ND1 gene


Qualitative confirmation theories comply with the idea that hh is
confirmed both by e1∧e2e_{1} \wedge e_{2} and by e1∧e∗2.e_{1} \wedge
e_{2}^*. In the HD case, it is clear that hh entails both
conjunctions, given of course kk stating that tigers, lions, and
elephants are all mammals (an Hempelian account could also be given
easily). Bayesian relevance confirmation unequivocally yields the same
qualitative verdict. There is more, however. Presumably, one might
also want to say that hh is more strongly confirmed by e1∧e2e_{1}
\wedge e_{2} than by e1∧e∗2,e_{1} \wedge e_{2}^*, because the former
offers a more varied and diverse body of positive evidence
(interestingly, on experimental investigation, this pattern prevails
in most people’s judgment, including children, see Lo et al.
2002). Indeed, the variety of evidence is a fairly central issue in
the analysis of confirmation (see, e.g., Bovens and Hartmann 2002,
Schlosshauer and Wheeler 2011, and Viale and Osherson 2000). In the
illustrative case above, higher variety is readily captured by lower
probability: it just seems a priori less likely that species
as diverse as tigers and elephants share some unspecified genetic
trait as compared to tigers and lions, that is, P(e1∧e2∣k)<P(e1∧e∗2∣k).P(e_{1} \wedge
e_{2}\mid k)\lt P(e_{1} \wedge e_{2}^*\mid k). By (SP) above, then,
one immediately gets from the relevance confirmation view the sound
implication that CP(h,e1∧e2∣k)>CP(h,e1∧e∗2∣k).C_{P}(h, e_{1} \wedge e_{2}\mid k)\gt C_{P}(h,
e_{1} \wedge e_{2}^*\mid k).

Principle (SP) is also of much use in the ravens problem. Posit h=∀x(raven(x)→black(x))h =
\forall x(raven(x)\rightarrow black(x)) once again. Just as HD,
Bayesian relevance confirmation directly implies that e=black(a)e = black(a)
confirms hh given k=raven(a)k = raven(a) and e∗=¬raven(a)e^* =\neg raven(a)
confirms hh given k∗=¬black(a)k^* =\neg black(a) (provided, as we know,
that P(e∣k)<1P(e\mid k)\lt 1 and P(e∗∣k∗)<1).P(e^*\mid k^*)\lt 1). That’s
because h∧k⊨eh \wedge k\vDash e and h∧k∗⊨e∗.h \wedge k^*\vDash e^*. But of
course, to have hh confirmed, sampling ravens and finding a black
one is intuitively more significant than failing to find a raven while
sampling the enormous set of the non-black objects. That is, it seems,
because the latter is very likely to obtain anyway, whether or not
hh is true, so that P(e∗∣k∗)P(e^*\mid k^*) is actually quite close to
unity. Accordingly, (SP) implies that hh is indeed more strongly
confirmed by black(a)black(a) given raven(a)raven(a) than it is by ¬raven(a)\neg
raven(a) given ¬black(a)\neg black(a)—that is, CP(h,e∣k)>CP(h,e∗∣k∗)C_{P}(h, e\mid
k)\gt C_{P}(h, e^*\mid k^*)—as long as the assumption
P(e∣k)<P(e∗∣k∗)P(e\mid k)\lt P(e^*\mid k^*) applies. 

What then if the sampling in not constrained (k=⊤)(k = \top) and the
evidence now amounts to the finding of a black raven, e=raven(a)∧black(a)e = raven(a)
\wedge black(a), versus a non-black non-raven, e∗=¬black(a)∧¬raven(a)e^* =\neg black(a)
\wedge \neg raven(a)? We’ve already seen that, for either
Hempelian or HD-confirmation, ee and e∗e^* are on a par: both
Hempel-confirm hh, none HD-confirms it. In the former case, the
original Hempelian version of the ravens paradox immediately arises;
in the latter, it is avoided, but at a cost: ee is declared flatly
irrelevant for hh—a bit of a radical move. Can the Bayesian
do any better? Quite so. Consider the following conditions:

 P[raven(a)∣h]=P[raven(a)]>0P[raven(a)\mid h] = P[raven(a)] \gt 0 
 P[¬raven(a)∧black(a)∣h]=P[¬raven(a)∧black(a)]P[\neg raven(a) \wedge black(a)\mid h] = P[\neg raven(a) \wedge
black(a)]


Roughly, (i) says that the size of the ravens population does not
depend on their color (in fact, on hh), and (ii) that the size of
the population of black non-raven objects also does not
depend on the color of ravens. Note that both (i) and (ii) seem fairly
sound as far as our best understanding of our actual world is
concerned. It is easy to show that, in relevance-confirmation terms,
(i) and (ii) are sufficient to imply that e=raven(a)∧black(a)e = raven(a) \wedge
black(a), but not e∗=¬raven(a)∧¬black(a)e^* = \neg raven(a) \wedge \neg
black(a), confirms hh, that is CP(h,e)>CP(h,e∗)=0C_{P}(h,e) \gt C_{P}(h,e^*) =
0 (this observation is due to Mat Coakley). So the Bayesian
relevance approach to confirmation can make a principled difference
between ee and e∗e^* in both ordinal and qualitative
terms. (A much broader analysis is provided by Fitelson and Hawthorne
2010, Hawthorne and Fitelson 2010 [Other Internet Resources]. Notably,
their results include the full specification of the sufficient and
necessary conditions for the main inequality CP(h,e)>CP(h,e∗)C_{P}(h, e) \gt
C_{P}(h, e^*).)

In general, Bayesian (relevance) confirmation theory implies that the
evidential import of an instance of some generalization will often
depend on the credence structure, and relies on its formal
representation, PP, as a tool for more systematic analyses.
Consider another instructive example. Assume that aa denotes some
company from some (otherwise unspecified) sector of the economy, and
label the latter predicate SS. So, k=Sak = Sa. You are informed
that aa increased revenues in 2019, represented as e=Rae = Ra. Does
this confirm h=∀x(Sx→Rx)h = \forall x(Sx \rightarrow Rx)? It does, at least
to some degree, one would say. For an expansion of the whole sector
(recall that you have no clue what this is) surely would account for
the data. That’s a straightforward HD kind of reasoning (and a
suitable Hempelian counterpart reconstruction would concur). But does
ee also confirm h∗=Sb→Rbh^* = Sb \rightarrow Rb for some further
company bb? Well, another obvious account of the data ee would
be that company aa has gained market shares at the expenses of some
competitor, so that ee might well seem to support ¬h∗,\neg h^*, if
anything (the revenues example is inspired by a remark in Blok, Medin,
and Osherson 2007, 1362).

It can be shown that the Bayesian notion of relevance confirmation
allows for this pattern of judgments, because (given kk) evidence
ee above increases the probability of hh but may well have the
opposite effect on h∗h^* (see Sober 1994 for important remarks along
similar lines). Notably, hh entails h∗h^* by plain instantiation,
and so contradicts ¬h∗\neg h^*. As a consequence, the implication
that CP(h,e∣k)C_{P}(h,e\mid k) is positive while CP(h∗,e∣k)C_{P}(h^*,e\mid k) is
not clashes with each of the following, and proves them unduly
restrictive: the Special Consequence Condition (SCC), the Predictive
Inference Condition (PIC), and the Consistency Condition (Cons). Note
that these principles were all evaded by HD-confirmation, but all
implied by confirmation as firmness (see above).

At the same time, the most compelling features of FF-confirmation,
which the HD model was unable to capture, are retained by confirmation
as relevance. In fact, all our measures of relevance confirmation
(D,LD, L, and ZZ) entail the ordinal extension of the Entailment
Condition (EC) as well as CP(h,e∣k)=−CP(¬h,e∣k)C_{P}(h, e\mid k) = -C_{P}(\neg h, e\mid
k) and thereby Confirmation Complementarity in all of its forms
(qualitative, ordinal, and quantitative). Moreover, the Bayesian
confirmation theorist of either the firmness or the relevance strand
can avail herself of the same quantitative strategy of “damage
control” for the main specific paradox of HD-confirmation, i.e.,
the irrelevant conjunction problem. (See statement (CIC) above, and
Crupi and Tentori 2010, Fitelson 2002. Also see Chandler 2007 for
criticism, and Moretti 2006 for a related debate.)

We’re left with one last issue to conclude our discussion, to
wit, the blite paradox. Recall that bliteblite is so defined:
blite(x)≡(ext≤T(x)→black(x))∧(¬ext≤T(x)→white(x)).blite(x) \equiv (ex_{t\le T}(x)\rightarrow black(x)) \wedge (\neg
ex_{t\le T}(x)\rightarrow white(x)).

As always heretofore, we posit h=∀x(raven(x)→black(x)),h = \forall x(raven(x)\rightarrow
black(x)), h∗=∀x(raven(x)→blite(x)).h^* = \forall x(raven(x)\rightarrow blite(x)). We
then consider the set up where k=raven(a)∧ext≤T(a),k = raven(a) \wedge ex_{t\le T}(a),
e=black(a),e= black(a), and P(e∣k)<1.P(e\mid k)\lt 1. Various authors have noted
that, with Bayesian relevance confirmation, one has that P(h∣k)>P(h∗∣k)P(h\mid
k)\gt P(h^*\mid k) is sufficient to imply that CP(h,e∣k)>CP(h∗,e∣k)C_{P}(h, e\mid
k)\gt C_{P}(h^*,e\mid k) (see Gaifman 1979, 127–128; Sober
1994, 229–230; and Fitelson 2008, 131). So, as long as the black
hypothesis is perceived as initially more credible than its blite
counterpart, the former will be more strongly confirmed than the
latter. Of course, P(h∣k)>P(h∗∣k)P(h\mid k)\gt P(h^*\mid k) is an entirely
commonsensical assumption, yet these same authors have generally, and
quite understandably, failed to see this result as philosophically
illuminating. Lacking some interesting, non-question-begging story as
to why that inequality should obtain, no solution of the paradox seems
to emerge. More modestly, one could point out that a measure of
relevance confirmation CP(h,e∣k)C_{P}(h, e\mid k) implies (i) and (ii)
below.

Necessarily (that is, for any P∈PP\in \bP), ee confirms hh
relative to kk.
Possibly (that is, for some P∈PP\in \bP), each one of the
following obtains:


ee confirms that a raven will be black if examined after TT,
that is, (raven(b)∧¬ext≤T(b))→black(b),(raven(b)\wedge \neg ex_{t\le T}(b)) \rightarrow
black(b), relative to kk; and
ee does not confirm that a raven will be white if
examined after TT, that is, (raven(b)∧¬ext≤T(b))→white(b),(raven(b)\wedge \neg ex_{t\le T}(b))
\rightarrow white(b), relative to kk.
 


Without a doubt, (i) and (ii) fall far short of a satisfactory
solution of the blite paradox. Yet it seems at least a legitimate
minimal requirement for a compelling solution (if any exists) that it
implies both. It is then of interest to note that confirmation as
firmness is inconsistent with (i), while Hempelian and HD-confirmation
are inconsistent with (ii).