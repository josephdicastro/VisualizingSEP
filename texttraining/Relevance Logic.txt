Relevance logics are non-classical logics. Called
‘relevant logics’ in Britain and Australasia, these
systems developed as attempts to avoid the paradoxes of material and
strict implication.  Among the paradoxes of material implication
are

p → (q → p).
¬p → (p → q).
(p → q)
 ∨(q
 → r).



Among the paradoxes of strict implication are the following:

(p & ¬p) → q.
p → (q → q).
 p → (q
 ∨¬q).



Many philosophers, beginning with Hugh MacColl (1908), have claimed
that these theses are counterintuitive. They claim that these formulae
fail to be valid if we interpret → as representing the concept of
implication that we have before we learn classical logic. Relevance
logicians claim that what is unsettling about these so-called
paradoxes is that in each of them the antecedent seems irrelevant to
the consequent.


In addition, relevance logicians have had qualms about certain
inferences that classical logic makes valid. For example, consider the
classically valid inference


The moon is made of green cheese. Therefore, either it is raining in
Ecuador now or it is not.


Again here there seems to be a failure of relevance. The conclusion
seems to have nothing to do with the premise. Relevance logicians have
attempted to construct logics that reject theses and arguments that
commit “fallacies of relevance”.


Relevant logicians point out that what is wrong with some of the
paradoxes (and fallacies) is that is that the antecedents and
consequents (or premises and conclusions) are on completely different
topics. The notion of a topic, however, would seem not to be something
that a logician should be interested in — it has to do with the
content, not the form, of a sentence or inference. But there is a
formal principle that relevant logicians apply to force theorems and
inferences to “stay on topic”. This is the variable
sharing principle. The variable sharing principle says that no
formula of the form A → B can be proven in a relevance logic if A
and B do not have at least one propositional variable (sometimes
called a proposition letter) in common and that no inference can be
shown valid if the premises and conclusion do not share at least one
propositional variable.


At this point some confusion is natural about what relevant logicians
are attempting to do. The variable sharing principle is only a
necessary condition that a logic must have to count as a relevance
logic. It is not sufficient. Moreover, this principle does not give us
a criterion that eliminates all of the paradoxes and fallacies. Some
remain paradoxical or fallacious even though they satisfy variable
sharing. As we shall see, however, relevant logic does provide us with
a relevant notion of proof in terms of the real use of premises (see
the section “Proof Theory” below), but it does not by
itself tell us what counts as a true (and relevant) implication. It is
only when the formal theory is put together with a philosophical
interpretation that it can do this (see the section
“Semantics for Relevant Implication” below).


In this article we will give a brief and relatively non-technical
overview of the field of relevance logic.
 
1. Semantics for Relevant Implication


Our exposition of relevant logic is backwards to most found in the
literature We will begin, rather than end, with the semantics, since
most philosophers at present are semantically inclined.


The semantics that I present here is the ternary relation semantics
due to Richard Routley and Robert K. Meyer. This semantics is a
development of Alasdair Urquhart's “semilattice semantics”
(Urquhart 1972). There is a similar semantics (which is also based on
Urquhart's ideas), due to Kit Fine, that was developed at the same
time as the Routley-Meyer theory (Fine 1974).  And there is an
algebraic semantics due to J. Michael Dunn.  Urquhart's, Fine's, and
Dunn's models are very interesting in their own right, but we do not
have room to discuss them here.


The idea behind the ternary relation semantics is rather simple.
Consider C.I. Lewis' attempt to avoid the paradoxes of material
implication. He added a new connective to classical logic, that of
strict implication. In post-Kripkean semantic terms, A
⊰ B is true at a world w if and only if for
all w′ such that w′ is accessible to
w, either A fails in w′ or B
obtains there.  Now, in Kripke's semantics for modal logic, the
accessibility relation is a binary relation. It holds between pairs of
worlds. Unfortunately, from a relevant point of view, the theory of
strict implication is still irrelevant. That is, we still make valid
formulae like p ⊰ (q ⊰ q).  We
can see quite easily that the Kripke truth condition forces this
formula on us.


Like the semantics of modal logic, the semantics of relevance logic
relativises truth of formulae to worlds. But Routley and Meyer go
modal logic one better and use a three-place relation on worlds. This
allows there to be worlds at which q → q fails
and that in turn allows worlds at which p → (q
→ q) fails. Their truth condition for → on this
semantics is the following:

A → B is true at a world a if and only
if for all worlds b and c such that Rabc
(R is the accessibility relation) either A is false
at b or B is true at c. 


For people new to the field it takes some time to get used to this
truth condition. But with a little work it can be seen to be just a
generalisation of Kripke's truth condition for strict implication
(just set b = c).


The ternary relation semantics can be adapted to be a semantics for a
wide range of logics. Placing different constraints on the relation
makes valid different formulae and inferences. For example, if we
constrain the relation so that Raaa holds for all worlds
a, then we make it true that if (A →
B) & A is true at a world, then B is
also true there. Given other features of the Routley-Meyer semantics,
this makes the thesis ((A → B) &
A) → B valid.  If we make the ternary relation
symmetrical in its first two places, that is, we constrain it so that,
for all worlds a, b, and c, if
Rabc then Rbac, then we make valid the thesis
A → ((A → B) →
B).


The ternary accessibility relation needs a philosophical
interpretation in order to give relevant implication a real meaning on
this semantics. Recently there have been three interpretations
developed based on theories about the nature of information. One
interpretation of the ternary relation, due to Dunn, develops the idea
behind Urquhart's semilattice semantics. On Urquhart's
semantics, instead of treating indices as possible (or impossible)
worlds, they are taken to be pieces of information. In the semilattice
semantics, an operator ° combines the information of two states
— a°b is the combination of the
information in a and b. The Routley-Meyer semantics
does not contain a combination or “fusion” operator on
worlds, but we can get an approximation of it using the ternary
relation. On Dunn's reading, ‘Rabc’ says
that “the combination of the information states a and
b is contained in the information state c”
(Dunn 1986).


Another interpretation is suggested in Jon Barwise (1993) and
developed in Restall (1996). On this view, worlds are taken to be
information-theoretic “sites” and
“channels”. A site is a context in which information is
received and a channel is a conduit through which information is
transferred. Thus, for example, when the BBC news appears on the
television in my living room, we can consider the living room to be a
site and the wires, satellites, and so on, that connect my television
to the studio in London to be a channel. Using channel theory to
interpret the Routley-Meyer semantics, we take Rabc to mean
that a is an information-theoretic channel between
sites b and
c. Thus, we take A → B to be true at
a if and only if, whenever a connects a site
b at which A obtains to a site c,
B obtains at c.


Similarly, Mares (1997) uses a theory of information due to David
Israel and John Perry (1990). In addition to other information a world
contains informational links, such as laws of nature, conventions, and
so on. For example, a Newtonian world will contain the information
that all matter attracts all other matter. In information-theoretic
terms, this world contains the information that two things' being
material carries the information that they attract each other. On this
view, Rabc if and only if, according to the links in
a, all the information carried by what obtains in b
is contained in c. Thus, for example, if a is a
Newtonian world and the information that x and y are
material is contained in b, then the information that
x and y attract each other is contained in
c.


Another interpretation is developed in Mares (2004). This
interpretation takes the Routley-Meyer semantics to be a formalisation
of the notion of “situated implication”. This
interpretation takes the “worlds” of the Routley-Meyer
semantics to be situations. A situation is a perhaps partial
representation of the universe. The information contained in two
situations, a and b might allow us to infer further
information about the universe that is contained in neither situation.
Thus, for example, suppose in our current situation that we have the
information contained in the laws of the theory of general relativity
(this is Einstein's theory of gravity). Then we hypothesise a
situation in which we can see a star moving in an ellipse. Then, on the
basis of the information that we have and the hypothesised situation,
we can infer that there is a situation in which there is a very heavy
body acting on this star.


We can model situated inference using a relation I (for
“implication”). Then we have IabP, where
P is a proposition, if and only if the information in
a and b together license the inference to there
being a situation in which P holds. We can think of a
proposition itself as a set of situations. We set A →
B to hold at a if and only if, for all situations
b in which A holds, Iab|B|, where
|B| is the set of situations at which B is true. We
set Rabc to hold if and only if c belongs to every
proposition P such that IabP. With the addition of
the postulate that, for any set of propositions P such that
IabP, the intersection of that set X is such that
IabX, we find that the implications that are made true on any
situation using the truth condition that appeals to I are the
same as those that are made true by the Routley-Meyer truth
condition. Thus, the notion of situated inference gives a way of
understanding the Routley-Meyer semantics.  (This is a very brief
version of the discussion of situated inference that is in chapters 2
and 3 of Mares (2004).)


By itself, the use of the ternary relation is not sufficient to
avoid all the paradoxes of implication. Given what we have said so far,
it is not clear how the semantics can avoid paradoxes such as
(p & ¬p)
→ q and p
→ (q
 ∨¬q).
 These paradoxes are avoided by the inclusion of inconsistent and
non-bivalent worlds in the semantics.  For, if there were no worlds at
which p & ¬p holds, then, according to our
truth condition for the arrow, (p & ¬p)
→ q would also hold everywhere. Likewise, if q
 ∨¬q
 held at every world, then p → (q
 ∨¬q)
 would be universally true.


An approach to relevance that does not require the ternary relation is
due to Routley and Loparic (1978) and Priest (1992) and (2008). This
semantics uses a set of worlds and a binary
relation, S. Worlds are divided into two categories: normal
worlds and non-normmal worlds. An implication A
→ B is true at a normal world a if and only if
for all worlds b, if A is true at b
then B is also true true at b. At non-normal worlds,
the truth values for implications are random. Some may be true and
others false. A formula is valid if and only if it is true on every
such model in its normal worlds. This division of worlds into
normal and non-normal and the use of random truth values for
implications at non-normal worlds enables us to find countermodels for
formulas such as p → (q → q).


Priest interprets non-normal worlds as the worlds that correspond to
“logic fictions”. In a science fiction, the laws of nature
may be different than those in our universe. Similarly, in a logic
fiction the laws of logic may be different from our laws. For
example, A → A may fail to be true in some
logic fiction. The worlds that such fictions describe are non-normal
worlds. 


One problem with the semantics without the ternary relation is that it
is difficult to use it to characterize as wide a range of logical
systems as can done with the ternary relation. In addition, the logics
determined by this semantics are quite weak. For example, they do not
have as a theorem the transitivity of implication — ((A
→ B) & (B → C)) →
(A → C).


Like the ternary relation semantics, this semantics requires some
worlds to be inconsistent and some to be non-bivalent.
2. Semantics for Negation


The use of non-bivalent and inconsistent worlds requires a
non-classical truth condition for negation. In the early 1970s,
Richard and Val Routley invented their “star operator” to
treat negation. The operator is an operator on worlds. For each
world a, there is a world a*.  And



¬A is true at a if and only if A is false
at a*.



Once again, we have the difficulty of interpreting a part of the
formal semantics. One interpretation of the Routley star is that of
Dunn (1993). Dunn uses a binary relation, C, on
worlds. Cab means that b is compatible with
a. a*, then, is the maximal world (the world
containing the most information) that is compatible with
a.


There are other semantics for negation. One, due to Dunn and
developed by Routley, is a four-valued semantics. This semantics is
treated in the entry on
 paraconsistent logics.
 Other treatments of negation, some of which have been used for
relevant logics, can be found in Wansing (2001).
3. Proof Theory


There is now a large variety of approaches to proof theory for
relevant logics. There is a sequent calculus for the negation-free
fragment of the logic R due to Gregory Mints
 (1972) and J.M. Dunn (1973) and an elegant and very general approach
called “Display Logic” developed by Nuel Belnap (1982). For the
former, see the supplementary document:

Logic R


 But here I will only deal with the natural deduction system for the
relevant logic R due to Anderson and Belnap.


Anderson and Belnap's natural deduction system is based on Fitch's
natural deduction systems for classical and intuitionistic logic. The
easiest way to understand this technique is by looking at an
example.



1. A{1}
Hyp


2. (A → B){2}
Hyp


3. B{1,2}
1,2, → E





This is a simple case of modus ponens. The numbers in set brackets
indicate the hypotheses used to prove the formula. We will call them
‘indices’. The indices in the conclusion indicate which
hypotheses are really used in the derivation of the conclusion. In the
following “proof” the second premise is not really
used:



1. A{1}
Hyp


2. B{2}
Hyp


3. (A → B){3}
Hyp


4. B{1,3}
1,3, → E





This “proof” really just shows that the inference from
A and A → B to B is
relevantly valid. Because the number 2 does not appear in the
subscript on the conclusion, the second “premise” does not
really count as a premise.


Similarly, when an implication is proven relevantly, the assumption of
the antecedent must really be used to prove the conclusion. Here is an
example of the proof of an implication:



1. A{1}
Hyp


2. (A → B){2}
Hyp


3. B{1,2}
1,2, → E


4. ((A → B) → B){1}
2,3, → I


5. A → ((A → B) →
 B)
1,4, → I





When we discharge a hypothesis, as in lines 4 and 5 of this proof,
the number of the hypothesis must really occur in the subscript of the
formula that is to become the consequent of the implication.


Now, it might seem that the system of indices allows irrelevant
premises to creep in. One way in which it might appear that
irrelevances can intrude is through the use of a rule of conjunction
introduction. That is, it might seem that we can always add in an
irrelevant premise by doing, say, the following:



1. A{1}
Hyp


2. B{2}
Hyp


3. (A & B){1,2}
1,2, &I


4. B{1,2}
3, &E


5. (B → B){1}
2,4, → I


6. A → (B → B)
1,5, → I





To a relevance logician, the first premise is completely out of
place here. To block moves like this, Anderson and Belnap give the
following conjunction introduction rule:


From Ai and Bi to infer
(A & B)i.


This rule says that two formulae to be conjoined must have the same
index before the rule of conjunction introduction can be used.


There is, of course, a lot more to the natural deduction system (see
Anderson and Belnap 1975 and Anderson, Belnap, and Dunn 1992), but
this will suffice for our purposes. The theory of relevance that is
captured by at least some relevant logics can be understood in terms of
how the corresponding natural deduction system records the real use of
premises.
4. Systems of Relevance Logic


In the work of Anderson and Belnap the central systems of relevance
logic were the logic E of relevant entailment and the
system R of relevant implication. The relationship
between the two systems is that the entailment connective of
E was supposed to be a strict (i.e. necessitated)
relevant implication. To compare the two, Meyer added a necessity
operator to R (to produce the logic
NR).  Larisa Maksimova, however, discovered that
NR and E are importantly different
— that there are theorems of NR (on the natural
translation) that are not theorems of E.  This has
left some relevant logicians with a quandary. They have to decide
whether to take NR to be the system of strict
relevant implication, or to claim that NR was somehow
deficient and that E stands as the system of strict
relevant implication. (Of course, they can accept both systems and
claim that E and R have a different
relationship to one another.)


On the other hand, there are those relevance logicians who reject both
R and E.  There are those, like
Arnon Avron, who accept logics stronger than R (Avron
1990). And there are those, like Ross Brady, John Slaney, Steve
Giambrone, Richard Sylvan, Graham Priest, Greg Restall, and others,
who have argued for the acceptance of systems weaker than
R or E.  One extremely weak system
is the logic S of Robert Meyer and Errol Martin. As
Martin has proven, this logic contains no theorems of the form
A → A. In other words, according to
S, no proposition implies itself and no argument of
the form ‘A, therefore A’ is
valid. Thus, this logic does not make valid any circular
arguments.

For more details on these logics see supplements on the
 logic E,
 logic R,
 logic NR, and
 logic S.



Among the points in favour of weaker systems is that, unlike
R or E, many of them are decidable.
Another feature of some of these weaker logics that makes them
attractive is that they can be used to construct a naïve set
theory. A naïve set theory is a theory of sets that includes as a
theorem the naïve comprehension axiom, viz., for all formulae
A(y),


∃x∀y(y ∈ x
 ↔ A(y)).




In set theories based on strong relevant logics, like
E and R, as well as in classical set
theory, if we add the naïve comprehension axiom, we are able to
derive any formula at all. Thus, naïve set theories based on
systems such as E and R are said to
be “trivial”. Here is an intuitive sketch of the proof of
the triviality of a naïve set theory using principles of
inference from the logic R. Let p be an
arbitrary proposition:


1. ∃x∀y(y ∈
x ↔ (y ∈ y → p))
Naïve Comprehension


2. ∀y(y ∈ z ↔
(y ∈ y → p))
1, Existential Instantiation


3. z ∈ z ↔ (z ∈
z → p) 
2, Universal Instantiation


4. z ∈ z → 
(z ∈ z → p)

3, df of  ↔ , &-Elimination


5. (z ∈ z → 
(z ∈ z → p))
→ (z ∈ z → p)

Axiom of Contraction


6. z ∈ z → p

4,5, Modus Ponens


7. (z ∈ z → p)) →
z ∈ z
3, df of  ↔ , &-Elimination


8. z ∈ z
6,7, Modus Ponens


9. p
6,8, Modus Ponens




Thus we show that any arbitrary proposition is derivable in this
naïve set theory. This is the infamous Curry Paradox. The
existence of this paradox has led Grishen, Brady, Restall, Priest, and
others to abandon the axiom of contraction ((A →
(A → B)) → (A →
B)).  Brady has shown that by removing contraction, plus some
other key theses, from R we obtain a logic that can
accept naïve comprehension without becoming trivial (Brady
2005).


In terms of the natural deduction system, the presence of
contraction corresponds to allowing premises to be used more than once.
Consider the following proof:



1. A → (A → B){1}
Hyp


2. A{2}
Hyp


3. A → B{1,2}
1,2, → E


4. B{1,2}
2,3, → E


5. A → B{1}
2–4, → I


6. (A → (A → B))
→ (A → B)
1–5, → I





What enables the derivation of contraction is the fact that our
subscripts are sets. We do not keep track of how many times (more than
once) that a hypothesis is used in its derivation. In order to reject
contraction, we need a way of counting the number of uses of
hypotheses. Thus natural deduction systems for contraction-free
systems use “multisets” of relevance numerals instead of
sets — these are structures in which the number of occurrences
of a particular numeral counts, but the order in which they occurs
does not.  Even weaker systems can be constructed, which keep track
also of the order in which hypotheses are used (see Read 1986 and
Restall 2000).
5. Applications of Relevance Logic


Apart from the motivating applications of providing better
formalisms of our pre-formal notions of implication and entailment and
providing a basis for naïve set theory, relevance logic has been
put to various uses in philosophy and computer science. Here I will
list just a few.


Dunn has developed a theory of intrinsic and essential properties
based on relevant logic. This is his theory of relevant
predication. Briefly put, a thing i has a property
F relevantly iff ∀x(x=i →
F(x)). Informally, an object has a property
relevantly if being that thing relevantly implies having that
property. Since the truth of the consequent of a relevant implication
is by itself insufficient for the truth of that implication, things
can have properties irrelevantly as well as relevantly. Dunn's
formulation would seem to capture at least one sense in which we use
the notion of an intrinsic property. Adding modality to the language
allows for a formalisation of the notion of an essential property as a
property that is had both necessarily and intrinsically (see Anderson,
Belnap, and Dunn 1992, §74).


Relevant logic has been used as the basis for mathematical theories
other than set theory. Meyer has produced a variation of Peano
arithmetic based on the logic R. Meyer gave a
finitary proof that his relevant arithmetic does not have 0 = 1 as a
theorem.  Thus Meyer solved one of Hilbert's central problems in the
context of relevant arithmetic; he showed using finitary means that
relevant arithmetic is absolutely consistent. This makes relevant
Peano arithmetic an extremely interesting theory. Unfortunately, as
Meyer and Friedman have shown, relevant arithmetic does not contain
all of the theorems of classical Peano arithmetic. Hence we cannot
infer from this that classical Peano arithmetic is absolutely
consistent (see Meyer and Friedman 1992).


Anderson (1967) formulated a system of deontic logic based on
R and, more recently, relevance logic has been used
as a basis for deontic logic by Mares (1992) and Lou Goble
(1999). These systems avoid some of the standard problems with more
traditional deontic logics. One problem that standard deontic logics
face is that they make valid the inference from A's
being a theorem to OA's being a theorem, where
‘OA’ means ‘it ought to be that
A’. The reason that this problem arises is that it is
now standard to treat deontic logic as a normal modal logic. On the
standard semantics for modal logic, if A is valid, then it is
true at all possible worlds. Moreover, OA is true at a world
a if and only if A is true at every world accessible
to a. Thus, if A is a valid formula, then so is
OA. But it seems silly to say that every valid formula ought
to be the case. Why should it be the case that either it is now
raining in Ecuador or it is not?  In the semantics for relevant
logics, not every world makes true every valid formula. Only a special
class of worlds (sometimes called “base worlds” and
sometimes called “normal worlds”) make true the valid
formulae. Any valid formula can fail at a world. By allowing these
“non-normal worlds” in our models, we invalidate this
problematic rule.


Other sorts of modal operators have been added to relevant logic as
well. See, Fuhrmann (1990) for a general treatment of relevant modal
logic and Wansing (2002) for a development and application of relevant
epistemic logic.


Routley and Val Plumwood (1989) and Mares and André Fuhrmann
(1995) present theories of counterfactual conditionals based on
relevant logic. Their semantics adds to the standard Routley-Meyer
semantics an accessibility relation that holds between a formula and
two worlds. On Routley and Plumwood's semantics,
A>B holds at a world a if and only if
for all worlds b such that SAab, B holds at
b.  Mares and Fuhrmann's semantics is slightly more
complex: A>B holds at a world a if and
only if for all worlds b such that SAab, A
→ B holds at b (also see Brady (ed.) 2002,
§10 for details of both semantics). Mares (2004) presents a more
complex theory of relevant conditionals that includes counterfactual
conditionals. All of these theories avoid the analogues of the
paradoxes of implication that appear in standard logics of
counterfactuals.


Relevant logics have been used in computer science as well as in
philosophy. Linear logics — a branch of logic initiated by
Jean-Yves Girard — is a logic of computational resources. Linear
logicians read an implication A → B as saying
that having a resource of type A allows us to obtain
something of type B. If we have A → (A
→ B), then, we know that we can obtain a B from
two resources of type A. But this does not mean that we can
get a B from a single resource of type A, i.e. we
don't know whether we can obtain A → B. Hence,
contraction fails in linear logic. Linear logics are, in fact,
relevant logics that lack contraction and the distribution of
conjunction over disjunction ((A & (B
 ∨C)) →
 ((A & B)
 ∨(A & C))).
 They also include two operators (! and ?) that are known as
“exponentials”. Putting an exponential in front of a
formula gives that formula the ability to act classically, so to
speak.  For example, just as in standard relevance logic, we cannot
usually merely add an extra premise to a valid inference and have it
remain valid. But we can always add a premise of the form !A
to a valid inference and have it remain valid. Linear logic also has
contraction for formulae of the form !A, i.e., it is a
theorem of these logics that (!A → (!A →
B)) → (!A → B) (see Troelstra
1992). The use of ! allows for the treatment of resources “that
can be duplicated or ignored at will” (Restall 2000, p 56). For
more about linear logic, see the entry on
 substructural logic.