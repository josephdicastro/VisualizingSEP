The term “non-monotonic logic” (in short, NML) covers a
family of formal frameworks devised to capture and represent
defeasible inference. Reasoners draw conclusions defeasibly
when they reserve the right to retract them in the light of further
information. Examples are numerous, reaching from inductive
generalizations to reasoning to the best explanation to inferences on
the basis of expert opinion, etc. We find defeasible inferences in
everyday reasoning, in expert reasoning (e.g. medical diagnosis), and
in scientific reasoning. 

Defeasible reasoning
 just like deductive reasoning, can follow complex patterns. However,
such patterns are beyond reach for classical logic (CL),
intuitionistic logic (IL) or other logics that characterize deductive
reasoning since they—by their very nature—do not allow for
a retraction of inferences. The challenge tackled in the domain of
NMLs is to provide for defeasible reasoning forms what CL or IL
provide for mathematical reasoning: namely a formally precise
account that is materially adequate, where material adequacy
concerns the question of how broad a range of examples is captured by
the framework, and the extent to which the framework can do justice to
our intuitions on the subject (at least the most entrenched ones).

 
1. Dealing with the dynamics of defeasible reasoning

Defeasible reasoning is dynamic in that it allows for a retraction of
inferences. Take, for instance, reasoning on the basis of normality or
typicality assumptions. While we infer that Tweety flies on the basis
of the information that Tweety is a bird and the background knowledge
that birds usually fly, we have good reasons to retract this inference
when learning that Tweety is a penguin or a kiwi. 

Another example is abductive reasoning
 (Aliseda 2017).
 Given the observation that the streets are wet we may infer the
explanation that it has been raining recently. However, recalling that
this very day the streets are cleaned and that the roof tops are dry,
we will retract this inference. 

As a last example take probabilistic reasoning where we infer
“X is a B” from “X is an
A and most As are Bs”. Clearly, we may
learn that X is an exceptional A with respect to being a
B and in view of this retract our previous inference. 

Our previous examples are instances of ampliative reasoning. It
is based on inferences for which the truth of the premises does not
guarantee or necessitate the truth of the conclusion as in deductive
reasoning. Instead, the premises support the conclusion defeasibly,
e.g., the conclusion may hold in most/typical/etc. cases in which the
premises hold. 

Reasoning may also turn defeasible when applied to an inconsistent
stock of information, possibly obtained via different sources.
Classical logic is not a viable option in such situations, since it
allows us to derive just any consequence. A more cautious approach is
to consider maximal consistent subsets (with respect to set inclusion)
of the given information
 (Rescher and Manor 1970).
 For instance, where ppp, qqq, and sss are logical atoms and
Γ={p∧q,¬p∧q,s}Γ={p∧q,¬p∧q,s}\Gamma = \{ p \wedge q, \neg p \wedge q, s\}, maximal consistent
subsets of ΓΓ\Gamma are Γ1={p∧q,s}Γ1={p∧q,s}\Gamma_1 = \{p \wedge q, s\} and
Γ2={¬p∧q,s}Γ2={¬p∧q,s}\Gamma_2 = \{\neg p \wedge q, s\}. Various consequence relations
have been defined on the basis of consistent subsets. We give two
examples (see
 Benferhat et al. (1997)
 for more). 

Let ΣΣ\Sigma be a possibly inconsistent set of formulas and let
MCS(Σ)MCS(Σ)\mathrm{MCS}(\Sigma) be the set of maximal consistent subsets of
ΣΣ\Sigma. The set Free(Σ)Free(Σ)\mathrm{Free}(\Sigma) of innocent
bystanders in ΣΣ\Sigma is obtained by intersecting all members
of MCS(Σ)MCS(Σ)\mathrm{MCS}(\Sigma). 

 Free consequences. ϕϕ\phi is a free consequence of
ΣΣ\Sigma, denoted by Σ|∼freeϕΣ|∼freeϕ\Sigma \nc_{\mathrm{free}} \phi, if and
only if it is (classically) entailed by the set of all the innocent
bystanders Free(Σ)Free(Σ)\mathrm{Free}(\Sigma). 
 Inevitable consequence. ϕϕ\phi is an inevitable
consequence of ΣΣ\Sigma, denoted by Σ|∼ieϕΣ|∼ieϕ\Sigma \nc_{\mathrm{ie}}
\phi, if and only if it is (classically) entailed by each member of
MCS(Σ)MCS(Σ)\mathrm{MCS}(\Sigma). 


In our example, the innocent bystander sss is both a free and
inevitable consequence, while qqq is merely an inevitable
consequence. In order to highlight the defeasible character of this
type of reasoning, consider the situation in which we obtain
additionally the information ¬s¬s\neg s. We now have the additional
two maximal consistent subsets Γ3={p∧q,¬s}Γ3={p∧q,¬s}\Gamma_{3} = \{p \wedge q, \neg s\}
and Γ4={p∧¬q,¬s}Γ4={p∧¬q,¬s}\Gamma_{4} = \{p \wedge \neg q, \neg s\} in view of which
sss is neither a free nor an inevitable consequence. E.g., although
Γ|∼freesΓ|∼frees\Gamma \nc_{\mathrm{free}} s we have Γ∪{¬s}/|∼freesΓ∪{¬s}/|∼frees\Gamma \cup \{\neg s\}
\nnc_{\mathrm{free}} s. 

This kind of dynamics is characteristic for non-monotonic logics, in
fact it is the reason for their name. They violate the Monotony
property which holds for deductive reasoning, for instance, for the
relation of logical consequence ⊨⊨\vDash of CL (see the entry on
 classical logic
 for details on the relation ⊨⊨\vDash): 

Monotony: If Σ|∼ϕΣ|∼ϕ\Sigma \nc \phi then also Σ∪Σ′|∼ϕΣ∪Σ′|∼ϕ\Sigma \cup
\Sigma' \nc \phi. 


Monotony states that consequences are robust under the addition of
information: if ϕϕ\phi is a consequence of ΣΣ\Sigma then it is
also a consequence of any set containing ΣΣ\Sigma as a subset. Most
of scholarly attention has been paid to the type of dynamics
underlying defeasible reasoning that results in violations of Montony
due to the retraction of inferences in view of conflicting new
information. It has been called the synchronic
 (Pollock 2008)
 or the external dynamics
 (Batens 2004)
 of defeasible reasoning. 

Clearly, most forms of defeasible reasoning are externally dynamic and
hence most logics for defeasible reasoning violate Monotony: they have
non-monotonic consequence relations for which consequences may not
persist when new information is obtained. This feature is so central
that the formal logical study of defeasible reasoning is often taken
to be coextensive with the domain of NML where non-monotonicity is
understood as a property of the consequence relation of a logic. 

It has been noted, that beside the external there is also a
diachronic
 (Pollock 2008)
 or internal dynamics
 (Batens 2004)
 underlying defeasible reasoning. It is the result of retracting
inferences without having available new information in terms of new
premises: by analyzing the already available information we may find
(possibly unexpected) inconsistencies. 

Let us return to non-monotonicity as a property of the consequence
relation. Given that Monotony is abandoned in NMLs, we are naturally
led to the question which formal properties are to replace Monotony
and whether some weakened forms of robustness of the consequence set
under the addition of new information is also to be expected in the
realm of defeasible reasoning. We state here two of the most central
properties considered in the literature: 

Cautious Monotony: If Σ|∼ψΣ|∼ψ\Sigma \nc \psi and Σ|∼ϕΣ|∼ϕ\Sigma \nc
\phi, then also Σ∪{ϕ}|∼ψΣ∪{ϕ}|∼ψ\Sigma \cup \{\phi\} \nc \psi. 
Rational Monotony: If Σ|∼ψΣ|∼ψ\Sigma \nc \psi and Σ/|∼¬ϕΣ/|∼¬ϕ\Sigma \nnc
\neg \phi, then also Σ∪{ϕ}|∼ψΣ∪{ϕ}|∼ψ\Sigma \cup \{\phi\} \nc \psi. 


Both Cautious and Rational Monotony are special cases of Monotony, and
are therefore not in the foreground as long as we restrict ourselves
to the classical consequence relation ⊨⊨\vDash of CL. 

Cautious Monotony is the converse of Cut: 

Cut: If Σ|∼ϕΣ|∼ϕ\Sigma \nc \phi and Σ∪{ϕ}|∼ψΣ∪{ϕ}|∼ψ\Sigma \cup \{\phi\} \nc
\psi, then Σ|∼ψΣ|∼ψ\Sigma \nc \psi. 


Cautious Montony (resp. Cut) states that adding a consequence ϕϕ\phi
to the premise-set ΣΣ\Sigma does not lead to any decrease
(resp. increase) in inferential power. Taken together these
principles express that inference is a cumulative enterprise: we can
keep drawing consequences that can in turn be used as additional
premises, without affecting the set of conclusions. In
 Gabbay (1985)
 it has been shown that some basic and intuitive assumptions about
non-monotonic derivations give rise to consequence relations which
satisfy Cautious Monotony, Cut and Reflexivity (If ϕ∈Σϕ∈Σ\phi \in \Sigma
then Σ|∼ϕΣ|∼ϕ\Sigma \nc \phi). Accordingly, these properties are commonly
taken to be central principles of
 NML.[1]


Rational Monotony states that no conclusions of ΣΣ\Sigma are lost
when adding formulas ϕϕ\phi to ΣΣ\Sigma that are not contradicted
by ΣΣ\Sigma. Rational Monotony is a more controversial property than
Cautious Monotony. For instance,
 Stalnaker (1994)
 gave a counter-example to it (see the
 supplementary document)
 in view of which it is clear that not in all application contexts
Rational Monotony is a desirable property of defeasible reasoning.

2. Dealing with conflicts

A separate issue from the formal properties of a non-monotonic
consequence relation, although one that is strictly intertwined with
it, is the issue of how conflicts between potential defeasible
conclusions are to be handled. 

We can distinguish two types of conflict handling in defeasible
reasoning both of which will be discussed in more detail below. On the
one hand, we have conflict resolution principles such as the
Specificity Principle or other measures of argument strength. On the
other hand, we have reasoning types that deal in different ways with
non-resolvable conflicts, most prominently the Credulous and the
Skeptical reasoning types. In this section we still stay on an
abstract level while concrete NMLs are discussed in the section
 Non-Monotonic Formalisms.
 
2.1 Conflict resolution

There are two different kinds of conflicts that can arise within a
given non-monotonic framework: (i) conflicts between defeasible
conclusions and “hard facts,” some of which possibly newly
learned; and (ii) conflicts between one potential defeasible
conclusion and another (many formalisms, for instance, provide some
form of defeasible inference rules, and such rules may have
conflicting conclusions). When a conflict (of either kind) arises,
steps have to be taken to preserve or restore consistency. 

Conflicts of type (i) are to be resolved in favor of the hard
facts in the sense that the conflicting defeasible conclusion is to be
retracted. More interesting are mechanisms to resolve conflicts of
type (ii). In order to analyze these, we will make use of
schematic inference graphs (similar to the ones used in
 Inheritance Networks,
 see below). For instance, our previous example featuring the bird
Tweety is illustrated as follows: 




We use the following conventions: double arrows signify deductive or
strict (i.e., non-defeasible) inferences, single arrows signify
defeasible inferences, and strikethrough arrows signify that the
negation of the pointed formula is implied. So, we can read the
diagram as follows: Penguins are birds (no exceptions); Birds usually
fly; and Penguins usually don’t fly. 

We have a conflict between the following two arguments (where
arguments are sequences of inferences): Penguin ⇒⇒\Rightarrow
Bird →→\rightarrow flies and Penguin
→→\rightarrow not-flies. Both arguments include a final
defeasible inference. What is important to notice is that a penguin is
a specific type of bird since Penguin ⇒⇒\Rightarrow
Bird (while not Bird ⇒⇒\Rightarrow Penguin).
According to the Specificity Principle an inference with a more
specific antecedent overrides a conflicting defeasible inference with
a less specific antecedent. Concerning the penguin Tweety we thus
infer that she doesn’t fly on the basis of Penguin
→→\rightarrow not-flies rather than that she flies on the
basis of Penguin ⇒⇒\Rightarrow Bird →→\rightarrow
flies. 

Logicians distinguish between strong and weak
specificity: according to strong specificity A↛CA \not\rightarrow
C overrides A⇒B→CA \Rightarrow B \rightarrow C; according weak
specificity A↛CA \not\rightarrow C overrides A→B→CA \rightarrow B
\rightarrow C. Note that the difference concerns the nature of the
link between A and B. 

A preference for one defeasible inference A →\rightarrow
B over another conflicting one C →\rightarrow
D may depend also on other factors. For instance, in an
epistemic context we may compare the strengths of A
→\rightarrow B and C →\rightarrow D by
appealing to the reliability of the source from which the respective
conditional knowledge stems. In the context of legal reasoning we may
have the principles lex superior resp. lex posterior,
according to which the higher ranked resp. the later issued law
dominates. 

Given a way to compare the strength of defeasible inference steps by
means of a preference relation ≺\prec, there is still the question
of how to compare the strength of conflicting sequences of inferences
viz. arguments. We give some examples. For a systematic survey and
classification of preference handling mechanisms in NML the interested
reader is referred to
 Delgrande et al. (2004)
 and to
 Beirlaen et al. (2018).
 

According to the Weakest Link Principle
 (Pollock 1991)
 an argument is preferred over another conflicting argument if its
weakest defeasible link is stronger than the weakest defeasible link
in the conflicting argument. Take, for example, the situation in the
following figure: 




On the left we see an inference graph with two conflicting arguments.
On the right we see the preference ordering. The argument A→B→EA
\rightarrow B \rightarrow E is stronger than C→D↛EC \rightarrow D
\not\rightarrow E since for its weakest link D↛ED \not\rightarrow E
we have D↛E≺A→BD \not\rightarrow E \prec A \rightarrow B and D↛E≺B→ED
\not\rightarrow E \prec B \rightarrow E. 

Another approach to preferences is procedural and greedy
 (Liao et al 2018).
 Roughly, it instructs to always apply the rule with the highest
priority first. (There may be various such rules with highest
priority, but for the sake of simplicity we neglect this possibility
in what follows.) Take the following example that is frequently
discussed in the literature. We have the rules 




where A→B≺A↛C≺B→CA \rightarrow B \prec A \not\rightarrow C \prec B \rightarrow
C and we take AA to be given. We can apply the defeasible rules
A→BA \rightarrow B and A↛CA \not\rightarrow C. If we operate in a
“greedy” way, we may apply A↛CA \not\rightarrow C to
derive CC before applying A→BA \rightarrow B, since A→B≺A↛CA
\rightarrow B \prec A \not\rightarrow C. Now only A→BA \rightarrow
B is applicable. So we derive BB. Although the antecedent of B→CB
\rightarrow C is already derived, we cannot apply this rule for the
sake of consistency.
 Brewka and Eiter (2000)
 argue against this greedy approach and in favor of deriving BB and
CC.
 Delgrande and Schaub (2000)
 argue that the example presents an incoherent set of rules. This is
put into question in
 Horty (2007)
 where a consistent deontic reading in terms of conditional
imperatives is presented which also challenges the procedural approach
by favoring the conclusions BB and CC. 


Ford (2004) pointed out that the order of strict and defeasible links
in arguments matters. For instance, she argues that an argument of the
form A→B⇒DA \rightarrow B \Rightarrow D may be stronger than an
argument of the form A⇒C↛DA \Rightarrow C \not\rightarrow D (where A→BA
\rightarrow B reads “Most As are Bs” and
A⇒CA \Rightarrow C reads “All As are Cs.”).
The reason is that in the former case it is not possible that no
A is a D while in the second case it is possible that no
A is a not-D. This is illustrated in the following
figure:





The left diagram demonstrates that there are distributions such that
no As are not-Ds although A⇒CA \Rightarrow C and C↛DC
\not\rightarrow D hold. The right diagram features a distribution
for A→B⇒DA \rightarrow B \Rightarrow D. Whenever the extension of
A is non-empty there will be As that are Ds. 
2.2 Reasoning with unresolved conflicts

We now discuss questions that arise in view of conflicts that are
irresolvable since no available resolution principles applies. One can
draw inferences either in a “cautious” or
“bold” fashion (also known as “skeptical” or,
respectively, “credulous”). These two options correspond
to significantly different ways to construe a given body of defeasible
knowledge, and yield different results as to what defeasible
conclusions are warranted on the basis of such a knowledge base. 

The difference between these basic attitudes comes to this. In the
presence of potentially conflicting defeasible inferences (and in the
absence of further considerations such as specificity — see
above), the credulous reasoner always commits to as many defeasible
conclusions as possible, subject to a consistency requirement, whereas
the skeptical reasoner withholds assent from potentially conflicted
defeasible conclusions. 

A well-known example from the literature, the so-called “Nixon
diamond,” will help to make the distinction clear. Suppose our
knowledge base contains (defeasible) information to the effect that a
given individual, Nixon, is both a Quaker and a Republican. Quakers,
by and large, are pacifists, whereas Republicans, by and large, are
not. This is illustrated in the following figure: 




The question is what defeasible conclusions are warranted on the basis
of this body of knowledge, and in particular whether we should infer
that Nixon is a pacifist or that he is not a pacifist. 

Neither the skeptical nor the credulous reasoner have any logical
grounds to prefer either conclusion (“Nixon is a
pacifist”; “Nixon is not a pacifist”). While the
credulous reasoner commits to both conclusions, the skeptical reasoner
refrains from either. 

A rationale behind the credulous reasoning type is to provide an
overview of possible conclusions given the conflicting defeasible
inferences in order to subsequently make a choice among them. This is
especially interesting in practical reasoning contexts in which the
choice determines a course of action and in which extra-logical
considerations (based on preferences, values, etc.) further narrow
down the choice. 

In contrast, the rationale behind the skeptical reasoning type is to
determine uncontested defeasible conclusions. The purpose may be of a
more epistemological nature such as the updating of the agent’s belief
or knowledge base with the chosen conclusions. 
2.3 Some advanced issues for skeptical reasoning

We now discuss some further issues that arise in the context of
conflicting arguments. The first issue is illustrated in the following
figure: 




Consider the argument Penguin ⇒\Rightarrow Bird
→\rightarrow has wings. Since penguins do not fly, we know
that penguins are exceptional birds, at least with respect to the
property of flying. A very cautious reasoner may take this to be a
reason to be skeptical about attributing other typical properties of
birds to penguins. NMLs that do not allow to derive has wings
are said to suffer from the Drowning Problem

 (Benferhat et al., 1993). 

The question whether the exceptional status of Penguin relative
to flies should spread also to other properties of Bird
may depend on specific relevance relations among these properties. For
instance,
 Koons (2017)
 proposes that causal relations play a role: whereas has strong
forlimb muscles is causally related to flies and hence
should not be attributed to penguins, the situation is different with
is cold-blooded. Similarly,
 Pelletier and Elio (1994)
 argue that explanatory relations play a significant role in the way
in which reasoners treat exceptional information in non-monotonic
inference. 

Another much discussed issue (e.g.,
 Ginsberg 1994,
 Makinson and Schlechta 1991,
 Horty 2002)
 concerns the question whether a conclusion that is derivable via two
conflicting arguments should be derived. Such conclusions are called
Floating Conclusions. The following figure illustrates this
with an extended version of the Nixon Diamond. 




The floating conclusion in question concerns is political which
is derivable via Nixon ⇒\Rightarrow Quaker
→\rightarrow Dove →\rightarrow is political and
via Nixon ⇒\Rightarrow Republican →\rightarrow
Hawk →\rightarrow is political. Both arguments are
super-arguments of the conflicting Nixon ⇒\Rightarrow
Quaker →\rightarrow Dove and Nixon
⇒\Rightarrow Republican →\rightarrow
Hawk.[2]Horty (1994)
 argues that floating conclusions are acceptable in reasoning contexts
in which “the value of drawing conclusions is high relative to
the costs involved if some of those conclusions turn out not to be
correct” while they should be avoided “when the cost of
error rises” (p. 123). 

We conclude our discussion with so-called Zombie-Arguments
 (Makinson and Schlechta 1991,
 Touretzky et al. 1991). Recall that a skeptical reasoner does not commit to a
conflicting argument.
 Makinson and Schlechta (1991)
 argue that super-arguments of such conflicted arguments
—although not acceptable— nevertheless still have the
power to undermine the commitment of a reasoner to an otherwise
unconflicted argument. We see an example in the following figure: 




We observe two conflicting arguments concerning DD: A→B→DA \rightarrow
B \rightarrow D and A→C↛DA \rightarrow C \not\rightarrow D. Thus, we
have ambiguous information concerning DD. We observe
further, that FF is a consequence of the (unconflicted) argument
A→C→E→FA \rightarrow C \rightarrow E \rightarrow F. It conflicts with the
zombie-argument A→B→D↛FA \rightarrow B \rightarrow D \not\rightarrow F
which is a super-argument of the conflicted A→B→DA \rightarrow B
\rightarrow D. The name refers to undead beings since an argument
such as A→B→D↛FA \rightarrow B \rightarrow D \not\rightarrow F to which
we have no commitment may still have the power to influence our
commitment to an otherwise unconflicted argument such as A→C→E→FA
\rightarrow C \rightarrow E \rightarrow F. In the literature we can
distinguish two approaches to such scenarios. In
ambiguitiy-propagating formalisms the ambiguity in DD
propagates to FF, while in ambiguity-blocking formalisms it
does not and so FF is considered a consequence in view of the
uncontested argument A→C→E→FA \rightarrow C \rightarrow E \rightarrow F
 (Stein 1992).
 
3. Non-monotonic formalisms

Pioneering work in the field of NMLs began with the realization that
in order to give a mathematically precise characterization of
defeasible reasoning CL is inadequate. Such a realization was
accompanied by the effort to reproduce the success of CL in the
representation of mathematical, or formal, reasoning. Among the
pioneers of the field in the late 1970s were J. McCarthy, D.
McDermott & J. Doyle, and R. Reiter (see
 Ginsberg (1987)
 for a collection of early papers in the field and
 Gabbay et al. (1994)
 for a collection of excellent survey papers). In 1980, the
Artificial Intelligence Journal published an issue (vol. 13,
1980) dedicated to these new formalisms, an event that has come to be
regarded as the “coming of age” of NML. 

In this section an overview will be provided on some important
formalisms. Since the evolutionary tree of NMLs has grown
extraordinarily rich, we will restrict the focus on presenting the
basic ideas behind some of the most influential and well-known
approaches. 
3.1 The closed-world assumption

If one of the goals of non-monotonic logic is to provide a materially
adequate account of defeasible reasoning, it is important to rely on a
rich supply of examples to guide and hone intuitions. Database theory
was one of the earliest sources of such examples, especially as
regards the closed world assumption. Suppose a travel agent
with access to a flight database needs to answer a client’s query
about the best way to get from Oshkosh to Minsk. The agents queries
the database and, not surprisingly, responds that there are no direct
flights. How does the travel agent know? 

It is quite clear that, in a strong sense of “know,” the
travel agent does not know that there are no such flights. What
is at work here is a tacit assumption that the database is
complete, and that since the database does not list any direct
flights between the two cities, there are none. A useful way to look
at this process is as a kind of minimization, i.e., an attempt
to minimize the extension of a given predicate
(“flight-between,” in this case). Moreover, on pain of
inconsistencies, such a minimization needs to take place not with
respect to what the database explicitly contains but with respect to
what it implies. 

The idea of minimization is at the basis of one of the earliest
non-monotonic formalisms, McCarthy’s circumscription
 (McCarthy 1980).
 Circumscription makes explicit the intuition that, all other things
being equal, extensions of certain predicates should be
minimal. Consider principles such as “all normal birds
fly”. Implicit in this principle is the idea that specimens
should not be considered to be abnormal unless there is positive
information to that effect. McCarthy’s idea was to represent this
formally, using second-order logic (SOL). In SOL, in contrast to
first-order logic (FOL), one is allowed to explicitly quantify over
predicates, forming sentences such as ∃P∀xPx\exists P \forall x Px
(“there is a universal predicate”) or ∀P(Pa≡Pb)\forall P (Pa
\equiv Pb) (“a and b are indiscernible”).


In circumscription, given predicates P and Q, we
abbreviate ∀x(Px⊃Qx)\forall x(Px \supset Qx) as P≤QP \le Q; similarly, we
abbreviate P≤Q∧¬(Q≤P)P \le Q \wedge \neg(Q \le P) as P<QP &lt; Q. If
A(P)A(P) is a formula containing occurrences of a predicate P,
then the circumscription of P in A is the second-order
sentence A⋆(P)A^{\star}(P): 


A(P)∧¬∃Q[A(Q)∧Q<P]A(P) \wedge \neg\exists Q[A(Q) \wedge Q &lt; P] 


A⋆(P)A^{\star}(P) expresses that P satisfies A, and that
no smaller predicate does. Let PxPx be the predicate “x
is abnormal,” and let A(P)A(P) be the sentence “All birds
that are not abnormal fly.” Then the sentence “Tweety is a
bird,” together with A⋆(P)A^{\star}(P) implies “Tweety
flies,” for the circumscription axiom forces the extension of
P to be empty, so that “Tweety is normal” is
automatically true. 

In terms of consequence relations, circumscription allows us to
define, for each predicate P, a non-monotonic relation A(P)|∼ϕA(P)
\nc \phi that holds precisely when A⋆(P)⊨ϕA^{\star}(P) \vDash \phi.
(This basic form of circumscription has been generalized, for, in
practice, one needs to minimize the extension of a predicate, while
allowing the extension of certain other predicates to vary.) From the
point of view of applications, however, circumscription has a major
computational shortcoming, which is due to the nature of the
second-order language in which circumscription is formulated (see the
entry on
 Second-order and Higher-order Logic
 for details). The problem is that SOL, contrary to FOL, lacks a
complete inference procedure: the price one pays for the greater
expressive power of SOL is that there are no complete axiomatizations,
as we have for FOL. It follows that there is no way to list, in an
effective manner, all SOL validities, and hence to determine whether
A(P)|∼ϕA(P) \nc \phi. 

Another influential mechanism realizing the closed world assumption is
Negation as Failure

 (or Default Negation). It can nicely be explained if we take a
look at Logic Programming. A logic program consists of a list
of rules such as: 


τ  ←  ϕ1,…,ϕn,not ψ1,…,not ψm\tau ~~ \leftarrow ~~ \phi_1, \dotsc, \phi_n, \mathit{not}~ \psi_1,
\dotsc, \mathit{not}~ \psi_m 


In basic logic programs τ\tau is a logical atom and ϕ1,…,ϕn,ψ1,…,ψm\phi_1,
\dotsc, \phi_n, \psi_1, \dotsc, \psi_m are logical literals (i.e.,
atoms or negated atoms). The logical form or rules in such programs
have been generalized in various ways (e.g.,
 Alferes et al. 1995)
 and many ways of interpreting rules have been proposed. To understand
the meaning of the default negation not we consider a concrete
example for a rule, namely: 


flies   ←  ~~\leftarrow~~ bird, not penguin



Such rules read as expected, but with a small twist. As usual, the
rule licenses its conclusion if the formulas in the antecedent (right
hand side) hold. The twist is that the falsity of (default) negated
formulas such as penguin need not be positively established:
their falsity is assumed in the absence of a proof of the opposite. In
our example, if penguin cannot be proved then not
penguin is considered to hold (“by default”). A logic program for
our Tweety example may consist of the rule above and 


not-flies   ←  ~~\leftarrow~~ penguin

bird   ←  ~~\leftarrow~~ penguin 


Suppose first all we know is bird. The latter two rules will
not be triggered. The first rule will be applicable:  bird  is
the case and we have no proof of penguin whence not
penguin is assumed. This allows us to infer flies. Now
suppose we know penguin. In this case the first rule is not
applicable since the default negation of penguin is false, but
the latter two rules are triggered and we derive bird and
not-flies. 
3.2 Inheritance networks and argument-based approaches

Whenever we have a taxonomically organized body of knowledge, we
presuppose that subclasses inherit properties from their superclasses:
dogs have lungs because they are mammals, and mammals have lungs.
However, there can be exceptions, which can interact in complex ways
as in the following example: mammals, by and large, don’t fly; since
bats are mammals, in the absence of any information to the contrary,
we are justified in inferring that bats do not fly. But if we learn
that bats are exceptional mammals, in that they do fly, the conclusion
that they don’t fly is retracted, and the conclusion that they fly is
drawn instead. Things can be more complicated still, for in turn, baby
bats are exceptional bats, in that they do not fly (does that make
them unexceptional mammals?). Here we have potentially conflicting
inferences. When we infer that Stellaluna, being a baby bat, does not
fly, we are resolving all these potential conflicts based on the
Specificity Principle. 

Non-monotonic inheritance networks were developed for the
purpose of capturing taxonomic examples such as the one above. Such
networks are collections of nodes and directed
(“is-a”) links representing taxonomic information.
When exceptions are allowed, the network is interpreted
defeasibly. The following figure gives a network representing
this state of affair: 




In such a network, links of the form A→BA \rightarrow B represent the
fact that, typically and for the most part, As are Bs,
and that therefore information about As is more specific than
information about Bs. More specific information overrides more
generic information. Research on non-monotonic inheritance focuses on
the different ways in which one can make this idea precise. 

The main issue in defeasible inheritance is to characterize the set of
assertions that are supported by a given network. It is of course not
enough to devise a representational formalism, one also needs to
specify how the formalism is to be interpreted. Such a
characterization is accomplished through the notion of an
extension of a given network. There are two competing
characterizations of extension for this kind of networks, one that
follows the credulous strategy and one that follows the skeptical one.
Both proceed by first defining the degree of a path through the
network as the length of the longest sequence of links connecting its
endpoints; extensions are then constructed by considering paths in
ascending order of their degrees. We are not going to review the
details, since many of the same issues arise in connection with
 Default Logic
 (which is discussed below), but
 Horty (1994)
 provides an extensive survey. It is worth mentioning that since the
notion of degree makes sense only in the case of acyclic networks,
special issues arise when networks contain cycles (see
 Antonelli (1997)
 for a treatment of inheritance on cyclic networks). 

Although the language of non-monotonic networks is expressively
limited by design (in that only links of the form
“is-a” — and their negations — can be
represented in a natural fashion), such networks provide an extremely
useful setting in which to test and hone one’s intuitions and methods
for handling defeasible information. Such intuitions and methods are
then applied to more expressive formalisms. 

In argument-based approaches to defeasible reasoning the notion
of a path through an inheritance network is generalized to the notion
of an argument. Abstracting from the specifics and subtleties of
formalisms proposed in the
 literature[3],
 an argument can be thought of in the following way. Given a
language L\mathcal{L}, a set of L\mathcal{L}-formulas
Γ\Gamma, a set of strict rules SRules of the form ϕ1,…,ϕn⇒ψ\phi_1,
\dotsc, \phi_n \Rightarrow \psi (where ϕi\phi_i and ψ\psi are
L\mathcal{L}-formulas) and a set of defeasible rules DRules
of the form ϕ1,…,ϕn→ψ\phi_1, \dotsc, \phi_n \rightarrow \psi (where
ϕi\phi_i and ψ\psi are L\mathcal{L}-formulas) an
argument (Θ,θ)(\Theta, \theta) for τ\tau is a proof of
τ\tau from some Θ⊆Γ\Theta \subseteq \Gamma using the rules in
SRules and DRules. 

A central notion in argument-based formalism is argumentative
attack. We can, for instance, distinguish between rebuts and
undercuts. A rebut of an argument (Θ,τ)(\Theta, \tau) is an
argument that establishes that τ\tau is not the case, viz. an
argument for ¬τ\neg\tau. An undercut of (Θ,τ)(\Theta, \tau)
establishes that Θ\Theta does not support τ\tau. For instance,
the argument that concludes that an object is red from the fact that
it looks red, is undercut by means of the observation that that object
is illuminated by red light
 (Pollock 1995).
 Note that in order to undercut an argument for τ\tau one need not
establish that τ\tau doesn’t hold. 

On an intuitive level, the basic idea is that the question whether an
argument is acceptable concerns the question whether it is
defended from its argumentative attacks.
 Dung (1995)
 proposed a way to address this question purely on the basis of the
attack relations between arguments while abstracting from the concrete
structure of the given arguments. Where Args is the set of the
arguments that are generated from Γ\Gamma by the rules in
SRules and DRules, we define an attack relation
⇝⊆Args×Args{\leadsto} \subseteq \mathit{Args} \times \mathit{Args} as
follows: a⇝ba \leadsto b if and only if aa attacks (e.g., rebuts
or undercuts) bb. This gives rise to a directed graph, the
abstract argumentation framework, where arguments are nodes and
arrows represent the attack relation. Note that at the level of the
directed graph arguments are treated in an abstract way: the concrete
structure of the arguments is not presented in the graph. 

Various argumentation semantics have been proposed for such
graphs specifying criteria for selecting sets of arguments that
represent stances of rational agents. Clearly, a selected set of
arguments S⊆ArgsS \subseteq \mathit{Args} should satisfy the following
requirements: 

SS should be conflict-free, i.e., for all a,b∈Argsa, b \in
\mathit{Args}, aa does not attack bb. 
SS should be able to defend itself from all attackers. More
precisely, SS is admissible if and only if SS is
conflict-free and for every a∈Argsa \in \mathit{Args} that attacks some
b∈Sb \in S there is a c∈Sc \in S that attacks aa. 


For instance, given the following graph, 




{a}\{a\} is admissible, while {a,b}\{a,b\} is not conflict-free and
{d}\{d\} is not admissible. 

Given these basic requirements we can define, for instance, the
following semantics which frequently appears in the literature: 

A preferred set of arguments SS is an admissible set of
arguments that is maximal in Args relative to set-inclusion.



In our example {a,d}\{a,d\} and {b,d}\{b,d\} are the two preferred sets.
This shows that the preferred semantics does not determine a unique
selection. In order to define a consequence relation we can proceed
either according to the credulous rationale or according to the
skeptical rationale. Considering an abstract argumentation framework
based on Γ\Gamma, SRules, and DRules, we give two
examples of how a consequence set can be characterized by means of the
skeptical approach
 (Prakken 2010):
 

 τ\tau is a consequence if in each preferred set SS of
arguments there is an argument a for τ\tau. 
 τ\tau is a consequence if there is an argument a for
τ\tau that is in every preferred set of arguments SS. 


Clearly, the second approach is more cautious. Intuitively, it demands
that there is a specific argument for τ that is contained in each
rational stance a reasoner can take given Γ\Gamma, DRules,
and SRules. The first option doesn’t bind the acceptability of
τ\tau to a specific argument: it is sufficient if according to each
rational stance there is some argument for τ\tau. 
3.3 Default logic

In Default Logic, the main representational tool is that of a
default rule, or simply a default. A default is a
defeasible inference rule of the form 


(γ:θ)/τ(\gamma: \theta) / \tau 


where γ,θ\gamma, \theta, and τ\tau are sentences in a given
language, respectively called the pre-requisite, the
justification and the conclusion of the default. The
interpretation of the default is that if γ\gamma is known, and
there is no evidence that θ\theta is false, then τ\tau can be
inferred. 

As is clear, an application of the rule requires that a consistency
condition be satisfied. What makes meeting the condition complicated
is the fact that rules can interact in complex ways. In particular, it
is possible that an application of some rule might cause the
consistency condition to fail for some, not necessarily distinct,
rule. For instance, if θ\theta is ¬τ\neg\tau then an application
of the rule is in a sense self-defeating, in that an application of
the rule itself causes the consistency condition to fail. 

Reiter’s default logic
 (Reiter 1980)
 uses the notion of an extension to make precise the idea that
the consistency condition has to be met both before and after the rule
is applied. Given a set Δ\Delta of defaults, an extension for
Δ\Delta represents a set of inferences that can be drawn
reasonably and consistently using defaults from
Δ\Delta. Such inferences are those that are warranted on the basis
of a maximal set of defaults whose consistency condition is met both
before and after their being triggered. 

More in particular, an extension is defined relative to a default
theory. The latter is a pair (Γ,Δ)(\Gamma, \Delta), where
Δ\Delta is a (finite) set of defaults, and Γ\Gamma is a set of
sentences (a world description). The idea is that Γ\Gamma
represents the strict or background information, whereas Δ\Delta
specifies the defeasible information. We say that Ξ\Xi is an
extension for a default theory (Γ,Δ)(\Gamma, \Delta) if and only
if 


Ξ=Ξ0∪Ξ1∪…∪Ξn∪…\Xi = \Xi_0 \cup \Xi_1 \cup \ldots \cup \Xi_n \cup \ldots 


where Ξ0=Γ\Xi_0 = \Gamma, and 


Ξi+1=Cn(Ξi)∪{τ∣(γ:θ)/τ∈Δ where ¬θ∉Ξ and γ∈Ξi}\Xi_{i+1} = \mathrm{Cn}(\Xi_i) \cup \bigl\{\tau \mid (\gamma :
\theta) / \tau \in \Delta \text{ where } \neg\theta \notin \Xi \text{
and } \gamma \in \Xi_i \bigr\} 


where Cn(⋅)\mathrm{Cn}(\cdot) is the consequence relation of CL. It is
important to notice the occurrence of the limit Ξ\Xi in the
definition of Ξi+1\Xi_{i+1}: the condition above is not a
garden-variety recursive definition, but a truly circular
characterization of extensions. 

This circularity can be made explicit by giving an equivalent
definition of extension as solution of fixpoint equations. Given a
default theory (Γ,Δ)(\Gamma, \Delta), let S\mathsf{S} be an operator
defined on sets of sentences such that for any such set Φ\Phi,
S(Φ)\mathsf{S}(\Phi) is the smallest set that satisfies the following
three requirements: 

it contains Γ\Gamma (Γ⊆S(Φ)\Gamma \subseteq \mathsf{S}(\Phi)),

it is deductively closed (i.e., if S(Φ)⊨ϕ\mathsf{S}(\Phi) \vDash
\phi then ϕ∈S(Φ)\phi \in \mathsf{S}(\Phi)), 
and it is closed under the default rules in Δ\Delta: whenever
for a default (γ:θ)/τ∈Δ(\gamma : \theta) / \tau \in \Delta both γ∈S(Φ)\gamma
\in \mathsf{S}(\Phi) and ¬θ∉Φ\neg\theta \notin \Phi, then τ∈S(Φ)\tau \in
\mathsf{S}(\Phi). 


Then one can show that Ξ\Xi is an extension for (Γ,Δ)(\Gamma,\Delta)
if and only if Θ\Theta is a fixed point of S\mathsf{S}, i.e., if
S(Ξ)=Ξ\mathsf{S}(\Xi) = \Xi. 

Neither one of the two characterizations of extension for default
logic (i.e., the fixpoint definition and the pseudo-iterative one)
provides us with a way to “construct” extensions by means
of anything resembling an iterative process. Essentially, one has to
“guess” a set of sentences Ξ\Xi, and then verify that
it satisfies the definition of an extension. 

For any given default theory, extensions need not exist, and even when
they exist, they need not be unique. We start with an example of the
former situation: let Γ=∅\Gamma = \emptyset and let Δ\Delta
comprise the single
 default[4]



(⊤:θ)/¬θ(\top : \theta) / \neg \theta 


If Ξ\Xi were an extension, then the justification θ\theta of the
default above would either be consistent with Ξ\Xi or not, and
either case is impossible. For if θ\theta were consistent with
Ξ\Xi, then the default would be applied to derive ¬θ\neg\theta in
contradiction the the consistency of Ξ\Xi with θ\theta.
Similarly, if Ξ\Xi were inconsistent with θ\theta then Ξ⊨¬θ\Xi
\vDash \neg \theta and hence, by deductive closure, ¬θ∈Θ\neg\theta \in
\Theta. Our default would not be applicable, in which case Ξ=Ξ1=Cn(∅)\Xi =
\Xi_1 = \mathrm{Cn}(\emptyset). But then ¬θ∉Ξ\neg\theta \notin
\Xi,—a contradiction. 

For normal default theories that only consist of normal
defaults, i.e., defaults of the form (γ:θ)/θ(\gamma : \theta) /
\theta, extensions always exist. 

Lukaszewicz (1988)
 presents a modified definition of extension that avoids the previous
two problems: it is defined in an iterative way and it warrants the
existence of an extension. In a nutshell the idea is to keep track of
the used justifications in the procedure. A default is applied in case
its precondition is implied by the current beliefs and its conclusion
is consistent with the given beliefs, its own justificiation, and each
of the justifications of previously applied defaults. For normal
theories Lukaszewicz’s definition of extensions is equivalent to the
definitions from above. 

Let us now consider an example of a default theory with multiple
extensions. Let Γ=∅\Gamma = \emptyset, and suppose Δ\Delta
comprises the following two defaults 


(⊤:θ)/¬τ(\top : \theta) / \neg\tau and (⊤:τ)/¬θ(\top: \tau)/\neg\theta 


This theory has exactly two extensions, one in which the first default
is applied and one in which the second one is. It is easy to see that
at least one default has to be applied in any extension, and that both
defaults cannot be applied in the same extension. 

The fact that default theories can have zero, one, or multiple
extensions raises the issue of what inferences one is warranted in
drawing from a given default theory. The problem can be presented as
follows: given a default theory (Γ,Δ)(\Gamma, \Delta), what sentences
can be regarded as defeasible consequences of the theory? 

Sometimes it may be useful to map out all the consequences that can be
drawn from all the extensions, for instance, in order to
identify extensions that give rise to undesired consequences (in view
of extralogical considerations). The credulous approach does just
that: (Γ,Δ)|∼ϕ(\Gamma, \Delta) \nc \phi if and only if ϕ\phi belongs to
any extension of the theory. Clearly, in case of multiple
extensions the consequence set will not be closed under CL and it may
be inconsistent. 

Alternatively, one can adopt the skeptical strategy according to which
(Γ,Δ)|∼ϕ(\Gamma, \Delta) \nc \phi if and only if ϕ\phi is contained in
every extension of (Γ,Δ)(\Gamma, \Delta). 

Skeptical consequence, as based on Reiter’s notion of extension, fails
to be cautiously monotonic
 (Makinson 1994).
 To see this, consider the default theory (∅,Δ)(\emptyset, \Delta),
where Δ\Delta comprises the following two defaults: 


(⊤:θ)/θ(\top: \theta)/\theta and (θ∨γ:¬θ)/¬θ(\theta \vee \gamma : \neg \theta) /
\neg \theta 


This theory has only one extension, coinciding with the deductive
closure of {θ}\{\theta\}. Hence, according to skeptical consequence
we have (∅,Δ)|∼θ(\emptyset, \Delta) \nc \theta, as well as (∅,Δ)|∼θ∨γ(\emptyset,
\Delta) \nc \theta \vee \gamma (by the deductive closure of
extensions). 

Now consider the theory ({θ∨γ},Δ)(\{\theta \vee \gamma\}, \Delta). We have
two extensions: one the same as before, but also another one
coinciding with the deductive closure of {¬θ}\{\neg\theta\}, and hence
not containing θ\theta. It follows that the intersection of the
extensions no longer contains θ\theta, so that ({θ∨γ},Δ)|∼θ(\{\theta \vee
\gamma\}, \Delta) \nc \theta fails, against Cautious
Monotony. (Notice that the same example establishes a counter-example
for Cut for the credulous strategy, when we pick the extension of
({θ∨γ},Δ)(\{\theta \vee \gamma\}, \Delta) that contains ¬θ\neg\theta.)


In
 Antonelli (1999)
 a notion of general extension for default logic is introduced,
showing that this notion yields a well-behaved relation of defeasible
consequence |∼\nc that satisfies Supraclassicality (if Γ⊨ϕ\Gamma
\vDash \phi then Γ|∼ϕ\Gamma \nc \phi) and the three central
requirements for NMLs Reflexivity, Cut, and Cautious Monotony from
 Gabbay (1985).
 The idea behind general extensions can be explained in a particularly
simple way in the case of pre-requisite free default theories
(called “categorical” in Antonelli (1999)). A
general extension for such a default theory is a pair
(Γ+,Γ−)(\Gamma^+, \Gamma^-) of sets of defaults (or conclusions thereof)
that simultaneously satisfies two fixpoint equations. The set
Γ+\Gamma^+ comprises (conclusions of) defaults that are explicitly
triggered, and the set Γ−\Gamma^- comprises (conclusions of)
defaults that are explicitly ruled out. The intuition is that defaults
that are not ruled out can still prevent other defaults from being
triggered (although they might not be triggered themselves). We thus
obtain a “3-valued” approach (not unlike that of Kripke’s
theory of truth
 (Kripke 1975)),
 in virtue of which general extensions are now endowed with a
non-trivial (i.e., not “flat”) algebraic structure. It is
then possible to pick out, in a principled way, a particular general
extension (for instance, the unique least one, which is always
guaranteed to exist) on which to base a notion of defeasible
consequence. 

A different set of issues arises in connection with the behavior of
default logic from the point of view of computation. For a given
semi-decidable set Φ\Phi of sentences, the set of all ϕ\phi that
are a consequence of Φ\Phi in FOL is itself semi-decidable (see the
entry on
 computability and complexity).
 In the case of default logic, to formulate the corresponding problem
one extends (in the obvious way) the notion of (semi-)decidability to
sets of defaults. The problem, then, is to decide, given a default
theory (Γ,Δ)(\Gamma,\Delta) and a sentence φ whether
(Γ,Δ)|∼ϕ(\Gamma,\Delta) \nc \phi, where |∼\nc is defined, say,
skeptically. Such a problem is not even semi-decidable, since, in
order to determine whether a default is triggered by a pair of sets of
sentences, one has to perform a consistency check, and such checks are
not computable. 

Default logic as defined above does not prioritize among defaults. In
 Poole (1985)
 we find an approach in which the Specificity Principle is considered.
In
 Horty (2007)
 defaults are ordered by a strict partial order ≺\prec where
(γ:θ)/τ≺(γ′:θ′)/τ′(\gamma : \theta)/\tau \prec (\gamma' : \theta') / \tau' means
that (γ′:θ′)/τ′(\gamma' : \theta') / \tau' has priority over (γ:θ)/τ(\gamma :
\theta) / \tau. The ordering ≺\prec may express —depending
on the application— specificity relations, the comparative
reliability of the conditional knowledge expressed by defaults, etc.
An ordered default theory is then a triple (Γ,Δ,≺)(\Gamma, \Delta,
\prec) where (Γ,Δ)(\Gamma, \Delta) is a default theory. We give an
example but omit a more technical explanation. Take Γ\Gamma =
{bird, penguin}, Δ\Delta = {bird
→\rightarrow flies, penguin →\rightarrow
¬flies} and bird →\rightarrow flies
≺\prec penguin →\rightarrow ¬flies, where
ϕ→ψ\phi \rightarrow \psi represents the normal default (ϕ:ψ)/ψ(\phi: \psi)
/ \psi. We have two extensions of (Γ,Δ)(\Gamma,\Delta), one in which
bird →\rightarrow flies is applied and one in which
penguin →\rightarrow ¬flies is applied. Since the
latter default is ≺\prec-preferred over the former, only the latter
extension is an extension of (Γ,Δ,≺)(\Gamma,\Delta,\prec). 
3.4 Autoepistemic logic

Another formalism closely related to default logic is Moore’s
Autoepistemic Logic
 (Moore 1985).
 It models the reasoning of an ideal agent reflecting on her own
beliefs. For instance, sometimes the absence of a belief in ϕ\phi
may give an agent a reason to infer ¬ϕ\neg\phi. Moore gives the
following example: If I had an older brother, I would know about it.
Since I don’t, I believe not to have an older brother. 

An autoepistemic theory consists of the beliefs of an agent including
her reflective beliefs about her beliefs. For the latter an
autoepistemic belief operator B\mathsf{B} is used. In our example
such a theory may contain ¬Bbrother⊃¬brother\neg \mathsf{B} \mathit{brother} \supset
\neg \mathit{brother}. Autoepistemic logic specifies ideal
properties of such theories. Following
 Stalnaker (1993),
 an autoepistemic theory Γ\Gamma should be stable: 

Γ\Gamma should be closed under classical logic: if Γ⊨ϕ\Gamma
\vDash \phi then ϕ∈Γ\phi \in \Gamma; 
Γ\Gamma should be introspectively adequate:


if ϕ∈Γ\phi \in \Gamma then Bϕ∈Γ\mathsf{B}\phi \in \Gamma; 
if ϕ∉Γ\phi \notin \Gamma then ¬Bϕ∈Γ\neg \mathsf{B} \phi \in
\Gamma. 
 


If Γ\Gamma is consistent, stability implies that 

 ϕ∈Γ\phi \in \Gamma if and only if Bϕ∈Γ\mathsf{B} \phi \in
\Gamma, and 
 ϕ∉Γ\phi \notin \Gamma if and only if ¬Bϕ∈Γ\neg \mathsf{B} \phi \in
\Gamma. 


Let us, for instance, consider the two types of consistent stable sets
that extend Ξ1={¬Bbrother⊃¬brother}\Xi_1 = \{ \neg \mathsf{B} \mathit{brother} \supset \neg
\mathit{brother} \}: 

 Γ1\Gamma_1 for which brother∈Γ1\mathit{brother} \in \Gamma_1 and by
introspection also Bbrother∈Γ1\mathsf{B} \mathit{brother} \in \Gamma_1. 
 Γ2\Gamma_2 for which brother∉Γ2\mathit{brother} \notin \Gamma_2.
Hence, ¬Bbrother∈Γ2\neg \mathsf{B} \mathit{brother} \in \Gamma_2 and by
closure, ¬brother∈Γ2\neg \mathit{brother} \in \Gamma_2. Thus, by
introspection also B¬brother∈Γ2\mathsf{B}\neg \mathit{brother} \in \Gamma_2.



The second option seems more intuitive since given only ¬Bbrother⊃¬brother\neg
\mathsf{B} \mathit{brother} \supset \neg \mathit{brother} the belief
in brother\mathit{brother} seems intuitively speaking ungrounded in the
context of Ξ1\Xi_1. To make this formally precise, Moore defines


 Γ\Gamma is grounded in a set of assumptions Ξ\Xi if
for each ψ∈Γ\psi \in \Gamma, Ξ∪{Bϕ∣ϕ∈Γ}∪{¬Bϕ∣ϕ∉Γ}⊨ψ\Xi \cup \{ \mathsf{B}\phi \mid \phi
\in \Gamma\} \cup \{\neg \mathsf{B}\phi \mid \phi \notin \Gamma\}
\vDash \psi. 


Stable theories that are grounded in a set of assumptions Ξ\Xi are
called stable expansions of Ξ\Xi or autoepistemic
extensions of Ξ\Xi. Stable expansions Γ\Gamma of Ξ\Xi can
equivalently be characterized as fixed points: 


Γ=Cn(Ξ∪{Bϕ∣ϕ∈Γ}∪{¬Bϕ∣ϕ∉Γ})\Gamma = \mathrm{Cn}\bigl( \Xi \cup \{ \mathsf{B}\phi \mid \phi \in
\Gamma\} \cup \{\neg \mathsf{B} \phi \mid \phi \notin \Gamma\}\bigr)



where Cn(⋅)\mathrm{Cn}(\cdot) is the consequence function of CL. 

Clearly, there is no stable theory that is grounded in Ξ1\Xi_1 and
that contains brother\mathit{brother} and/or Bbrother\mathsf{B}
\mathit{brother} like our Γ1\Gamma_1 above. The reason is that we
fail to derive brother\mathit{brother} from Ξ1∪{Bψ∣ψ∈Γ1}∪{¬Bψ∣ψ∉Γ1}\Xi_1 \cup \{\mathsf{B}
\psi \mid \psi \in \Gamma_1\} \cup \{\neg \mathsf{B} \psi \mid \psi
\notin \Gamma_1\}. The only stable extension of Ξ1\Xi_1 contains
¬Bbrother\neg \mathsf{B} \mathit{brother} and ¬brother\neg \mathit{brother}.


Just as in default logic, some sets of assumptions have no stable
extensions while some have multiple stable extensions. We demonstrate
the former case with Ξ2={¬Bϕ⊃ϕ}\Xi_2 = \{\neg \mathsf{B} \phi \supset
\phi\}. Suppose there is a stable extension Γ\Gamma of Ξ2\Xi_2.
First note that there is no way to ground ϕ\phi in view of
Ξ2\Xi_2. Hence ϕ∉Γ\phi \notin \Gamma which means that ¬Bϕ∈Γ\neg
\mathsf{B} \phi \in \Gamma. But then ϕ∈Γ\phi \in \Gamma by modus
ponens which is a contradiction. 

A potentially problematic property of Moore’s notion of groundedness
is that it allows for a type of epistemic bootstrapping. Take Ξ3={Bϕ⊃ϕ}\Xi_3
= \{\mathsf{B}\phi \supset \phi\}. Suppose an agent adopts the
belief that she believes ϕ\phi, i.e. Bϕ\mathsf{B}\phi. Now she
can use Bϕ⊃ϕ\mathsf{B}\phi \supset \phi to derive ϕ\phi. Hence, on
the basis of Ξ3\Xi_3 she can ground her belief in ϕ\phi on her
belief that she believes ϕ\phi. Indeed, there is a stable extension
of Ξ3\Xi_3 containing ϕ\phi and Bϕ\mathsf{B} \phi. In view of
this, weaker forms of groundedness have been proposed in
 Konolige (1988)
 that do not allow for this form of bootstrapping and according to
which we only have the extension of Ξ3\Xi_3 that contains neither
ϕ\phi nor Bϕ\mathsf{B}\phi. 

The centrality of autoepistemic logic in NML is emphasized by the fact
that several tight links to other seminal formalism have been
established. Let us mention three such links. 

First, there are close connections between autoepistemic logic and
logic programming. For instance, Gelfond’s and Lifschitz’s stable
model semantics for logic programming with
 negation as failure
 which serves as the foundation for the answer set programming
paradigm in computer science has been equivalently expressed by means
of autoepistemic logic
 (Gelfond and Lifschitz 1988).
 The result is achieved by translating clauses in logic programming



ϕ  ←  ϕ1,…,ϕn,not ψ1,…,not ψm\phi ~~ \leftarrow ~~ \phi_1, \dotsc, \phi_n, \mathit{not}~\psi_1,
\dotsc, \mathit{not}~\psi_m 


in such a way that negation as failure (not ψ\mathit{not}~\psi) gets
the meaning “it is not believed that ψ\psi” (¬Bψ\neg
\mathsf{B}\psi): 


(ϕ1∧…∧ϕn∧¬Bψ1∧…∧¬Bψm)⊃ψ(\phi_1 \wedge \ldots \wedge \phi_{n} \wedge \neg \mathsf{B} \psi_1
\wedge \ldots \wedge \neg \mathsf{B} \psi_m) \supset \psi 


A second link has been established in
 Konolige (1988)
 with default logic which has been shown inter-translatable and
equi-expressive with Konolige’s strongly grounded variant of
autoepistemic logic. Default rules (γ:θ)/τ(\gamma : \theta) / \tau are
translated by interpreting consistency conditions θ\theta by ¬B¬θ\neg
\mathsf{B} \neg \theta which can be read as “θ\theta is
consistent with the given beliefs”: 


(Bγ∧¬B¬θ)⊃τ(\mathsf{B} \gamma \wedge \neg \mathsf{B} \neg \theta) \supset
\tau 


Especially the latter link is rather remarkable since the subject
matter of the given formalisms is quite different. While default logic
deals with defeasible rules, i.e., rules that allow for exceptions
(such as ‘Birds fly’), the non-monotonicity of autoepistemic logic is
rooted in the indexicality of its autoepistemic belief operator
 (Moore 1984,
 Konolige 1988): it refers to the 
autoepistemic theory into which it is
embeded and hence its meaning may change when we add beliefs to the
theory. 

Various modal semantics have been proposed for autoepistemic logic
(see the entry on
 modal logic
 for more background on modal logics). For instance,
 Moore (1984)
 proposes an S5-based Kripkean possible world semantics and
 Lin and Shoham (1990)
 propose bi-modal preferential semantics (see Section
 Selection semantics
 below) for both autoepistemic logic and default logic. In
 Konolige (1988)
 it has been observed that the fixed point characterization of stable
expansions can be alternatively phrased only on the basis of the set
of formulas Γ0\Gamma_0 in Γ\Gamma that do not contain occurrences
of the modal operator B\mathsf{B}: 


Γ=CnK45(Ξ∪{Bϕ∣ϕ∈Γ0}∪{¬Bϕ∣ϕ∉Γ0}) \Gamma = \mathrm{Cn}_{\mathsf{K45}}\bigl( \Xi \cup \{
\mathsf{B}\phi \mid \phi \in \Gamma_0\} \cup \{\neg \mathsf{B}\phi
\mid \phi \notin \Gamma_0\}\bigr) 


where CnK45(⋅)\mathrm{Cn}_{\mathsf{K45}}(\cdot) is the consequence
function of the modal logic K45\mathsf{K45}. 
3.5 Selection semantics

In CL a formula ϕ\phi is entailed by Γ\Gamma (in signs Γ⊨ϕ\Gamma
\vDash \phi) if and only if ϕ\phi is valid in all classical
models of Γ\Gamma. An influential idea in NML is to define
non-monotonic entailment not in terms of all classical models
of Γ\Gamma, but rather in terms of a selection of these
models
 (Shoham 1987).
 Intuitively the idea is to read 


Γ|∼ϕ\Gamma \nc \phi as “ϕ\phi holds in the most
normal/natural/etc. models of Γ\Gamma.” 

3.5.1 The core properties

In the seminal paper
 Kraus et al. (1990)
 this idea is investigated systematically. The authors introduce
various semantic structures, among them preferential ones. A
preferential structure SS consists of 

a set Ω\Omega of states 
and an irreflexive and transitive relation ≺\prec on
Ω\Omega.


In the context of preferential structures one may think of states in
terms of labelled models MsM_s of classical propositional logic,
where each label ss is attached to a unique model MM but a model
may occur under various labels in
 Ω\Omega.[5]
 For the ease of demonstration we will henceforth just talk about
‘models in Ω\Omega’ and not anymore refer to states or labelled
models. 

Intuitively, M≺M′M \prec M' if MM is more normal than M′M'. The
relation ≺\prec can be employed to formally realize the idea of
defining a consequence relation in view of the most normal models,
namely by focusing on ≺\prec-minimal models. Formally, where
[ψ][\psi] is the set of all models of ψ\psi in Ω\Omega,
|∼S\nc^S, is defined as follows: 


ψ|∼Sϕ\psi \nc^S \phi if and only if ϕ\phi holds in all
≺\prec-minimal models in [ψ][\psi]. 


In order to warrant that there are such minimal states, ≺\prec is
considered to be smooth (also sometimes called
stuttered), i.e., for each MM either MM is
≺\prec-minimal or there is a ≺\prec-minimal M′M' such that
M′≺MM' \prec M. 

Preferential structures enjoy a central role in NML since they
characterize preferential consequence relations, i.e.,
non-monotonic consequence relations |∼\nc that fulfill the following
central properties, also referred to as the core properties or
the conservative core of non-monotonic reasoning systems or as
the KLM-properties (in reference to the authors of
 Kraus, Lehmann, Magidor 1990):
 

Reflexivity: ϕ|∼ϕ\phi \nc \phi. 
Cut: If ϕ∧ψ|∼τ\phi \wedge \psi \nc \tau and ϕ|∼ψ\phi \nc
\psi, then ϕ|∼τ\phi \nc \tau. 
Cautious Monotony: If ϕ|∼ψ\phi \nc \psi and ϕ|∼τ\phi \nc
\tau then ϕ∧ψ|∼τ\phi \wedge \psi \nc \tau. 
Left Logical Equivalence: If ⊨ϕ≡ψ\vDash \phi \equiv \psi
and ϕ|∼τ\phi \nc \tau, then ψ|∼τ\psi \nc \tau. 
Right Weakening: If ⊨ϕ⊃ψ\vDash \phi \supset \psi and τ|∼ϕ\tau
\nc \phi, then τ|∼ψ\tau\nc \psi. 
OR: If ϕ|∼ψ\phi \nc \psi and τ|∼ψ\tau \nc \psi, then ϕ∨τ|∼ψ\phi
\vee \tau \nc \psi. 


The former three properties we have already seen above. According to
Left Logical Equivalence, classically equivalent formulas have the
same non-monotonic consequences. Where ψ\psi is classically
entailed by ϕ\phi, Right Weakening expresses that whenever ϕ\phi
is a non-monotonic consequence of τ\tau then so is ψ\psi. 

Without further commentary we state two important derived rules: 

AND: If ϕ|∼ψ\phi \nc \psi and ϕ|∼τ\phi \nc \tau then ϕ|∼ψ∧τ\phi
\nc \psi \wedge \tau. 
S: If ϕ∧ψ|∼τ\phi \wedge \psi \nc \tau then ϕ|∼ψ⊃τ\phi \nc \psi
\supset \tau. 


In
 Kraus et al. (1990)
 it is shown that a consequence relation |∼\nc is preferential if
and only if |∼=|∼S\nc = \nc^S for some preferential structure SS.


Given a set of conditional assertions K\mathbf{K} of the type
ϕ|∼ψ\phi \nc \psi one may be interested in investigating what other
conditional assertions follow. The following two strategems lead to
the same results. The first option is to intersect all preferential
consequence relations |∼\nc that extend K\mathbf{K} (in the sense
that the conditional assertions in K\mathbf{K} hold for |∼\nc)
obtaining the Preferential Closure |∼P\nc^{\mathrm{P}} of
K\mathbf{K}. The second option is to use the five defining
properties of preferential consequence relations as deduction rules
for syntactic units of the form ϕ|∼ψ\phi \nc \psi. This way we obtain
the deductive system P with its consequence relation
⊢P\vdash^{\mathrm{P}} for which: 


K⊢Pϕ|∼ψ\mathbf{K} \vdash^{\mathrm{P}} \phi \nc \psi if and only if ϕ|∼Pψ\phi
\nc^{\mathrm{P}} \psi. 

3.5.2 Various semantics

One of the most remarkable facts in the study of NMLs is that various
other semantics have been proposed —often independently and
based on very different considerations— that also adequately
characterize preferential consequence relations. This underlines the
central status of the core properties in the formal study of
defeasible reasoning. 

Many of these approaches use structures S=(Ω,Π)S = (\Omega, \Pi) where
Ω\Omega is again a set of classical models and Π\Pi is a mapping
with the domain ℘(Ω)\wp(\Omega) (the set of subsets of Ω\Omega) and
an ordered co-domain (D,<)(D, &lt;). The exact nature of (D,<)(D, &lt;)
depends on the given approach and we give some examples below. The
basic common idea is to let ϕ|∼Sψ\phi \nc^S \psi in case Π([ϕ∧ψ])\Pi([\phi
\wedge \psi]) is preferable to Π([ϕ∧¬ψ])\Pi([\phi \wedge \neg \psi]) in
view of <&lt;. The following table lists some proposals which we
discuss some more below: 


Π\Pi
ϕ|∼Sψ\phi \nc^S \psi iff
Structures 

possibility measure
π([ϕ])=0\pi([\phi]) = 0 or
possibilistic structures 

π:℘(Ω)→[0,1]\pi: \wp(\Omega) \rightarrow [0,1]
π([ϕ∧ψ])>π([ϕ∧¬ψ])\pi([\phi \wedge \psi]) &gt; \pi([\phi \wedge
\neg \psi])
  

ordinal ranking function
κ([ϕ])=∞\kappa([\phi]) = \infty or
ordinal ranking structures 

κ:℘(Ω)→{0,1,…,∞}\kappa: \wp(\Omega) \rightarrow
\{0,1,\dotsc,\infty\}
κ([ϕ∧ψ])<κ([ϕ∧¬ψ])\kappa([\phi \wedge \psi]) &lt; \kappa([\phi
\wedge \neg \psi])
  

plausibility measure
Pl([ϕ])=⊥\mathrm{Pl}([\phi]) = \bot or
plausibility structures 

Pl:℘(Ω)→D\mathrm{Pl}: \wp(\Omega) \rightarrow D
Pl([ϕ∧ψ])>Pl([ϕ∧¬ψ])\mathrm{Pl}([\phi \wedge \psi]) &gt;
\mathrm{Pl}([\phi \wedge \neg \psi])
  


Possibility measures assign real numbers in the interval [0,1] to
propositions in order to measure their possibility, where 0
corresponds to impossible states and 1 to necessary states
 (Dubois and Prade 1990).
 Ordinal ranking functions rank propositions via natural numbers
closed with ∞
 (Goldszmidt and Pearl 1992,
 Spohn 1988). One may think of
 κ([ϕ])\kappa([\phi]) as the level of
surprise we would face were ϕ\phi to hold, where ∞ represents
maximal surprise. Finally, plausibility measures
 (Friedman and Halpern 1996,
 Rott 2013) associate propositions with 
elements in a partially
ordered domain with bottom element ⊥\bot and top element ⊤\top
in order to compare their plausibilities. Given some simple
constraints on Pl\mathrm{Pl} (such as: If Pl(X)=Pl(Y)=⊥\mathrm{Pl}(X) =
\mathrm{Pl}(Y) = \bot then Pl(X∪Y)=⊥\mathrm{Pl}(X \cup Y) = \bot) we
speak of qualitative plausibility structures. The following
statements are all equivalent which emphasizes the centrality of the
core properties in the study of NMLs: 

 K⊢Pψ\mathbf{K} \vdash^P \psi
 ϕ|∼Sψ\phi \nc^S \psi for all preferential structures SS for
which |∼S\nc^S extends K\mathbf{K} 
 ϕ|∼Sψ\phi \nc^S \psi for all possibilistic structures SS for
which |∼S\nc^S extends K\mathbf{K} 
 ϕ|∼Sψ\phi \nc^S \psi for all ordinal ranking structures SS for
which |∼S\nc^S extends K\mathbf{K} 
 ϕ|∼Sψ\phi \nc^S \psi for all qualitative plausibility structures
SS for which |∼S\nc^S extends K\mathbf{K} 


Yet another well-known semantics that characterizes preferential
consequence relations makes use of conditional probabilities.
The idea is that ϕ|∼ψ\phi \nc \psi holds in a structure if the
conditional probability P(ψ∣ϕ)P(\psi \mid \phi) is closer to 1 than an
arbitrary ϵ\epsilon, whence the name ϵ\epsilon-semantics
 (Adams 1975,
 Pearl 1989). 

The following example demonstrates that the intuitive idea of using a
threshold value such as ½ instead of infinitesimals and to
interpret ϕ|∼ψ\phi \nc \psi as P(ψ∣ϕ)P(\psi \mid \phi) > ½
does not work in a straightforward way. Let α\alpha abbreviate
“being a vegan”, β\beta abbreviate “being an
environmentalist”, and γ\gamma abbreviate “avoiding the
use of palm oil”. Further, let our knowledge base comprise the
statements “αs are usually βs,”
“(α∧β)(\alpha \wedge \beta)s are usually γs”. The
following Euler diagram illustrates the conditional probabilities in a
possible probability distribution for the given statements. 




We have for instance: P(β∣α)P(\beta \mid \alpha) = ¾, P(γ∣α∧β)P(\gamma
\mid \alpha \wedge \beta) = ⅔ and P(γ∣α)P(\gamma \mid \alpha) =
½. Hence, under the proposed reading of |∼\nc, we get
α|∼β\alpha \nc \beta and α∧β|∼γ\alpha \wedge \beta \nc \gamma while we
do not have α|∼γ\alpha \nc \gamma. This means that Cut is violated.
Similarly, it can be shown that other properties such as Or are
violated under this reading (e.g.,
 Pearl 1988).
 

In view of these difficulties it is remarkable that there is a
probabilistic account according to which ϕ|∼ψ\phi \nc \psi is
interpreted as P(ψ∣ϕ)P(\psi \mid \phi) > ½ and that
nevertheless characterizes preferential consequence relations
 (Benferhat et al. 1999).
 The idea is to restrict the focus to structures S=(Ω,P,≺)S= (\Omega, P,
\prec) that come with specific probability distributions known as
atomic bound systems or big-stepped probabilities.
First, a linear order ≺\prec is imposed on the set of classical
models in Ω\Omega over which the probability measure PP is
defined. Second, PP is required to respect this order by
“taking big steps”, i.e., in such a way that for any M∈ΩM
\in \Omega, P({M})>∑{P({M′})∣M′≺M}P(\{M\}) &gt; \sum\{P(\{M'\}) \mid M' \prec M\}.
This warrants that ϕ|∼ψ\phi \nc \psi holds if and only if the unique
≺\prec-maximal model in [ϕ][\phi] validates ψ\psi (in signs,
max[ϕ]⊨ψ\max[\phi] \models
 \psi).[6]
 Here is how this helps us with the problematic example above:
α|∼β\alpha \nc \beta means that max[α]⊨β\max[\alpha] \models \beta and
hence that max[α]=max[α∧β]\max[\alpha] = \max[\alpha \wedge \beta]. α∧β|∼γ\alpha
\wedge \beta \nc \gamma means that max[α∧β]⊨γ\max[\alpha \wedge \beta]
\models \gamma and hence max[α]⊨γ\max[\alpha] \models \gamma which
implies α|∼γ\alpha \nc \gamma. 

In
 Gilio (2002)
 an approach is presented in which conditionals α|∼β\alpha \nc \beta
are characterized by imprecise conditional probabilities 0≤τ1≤P(β∣α)≤τ2≤10
\le \tau_1 \le P(\beta \mid \alpha) \le \tau_2 \le 1 with a lower
bound τ1\tau_1 and an upper bound τ2\tau_2 on the conditional
probabilities. In this approach it is possible to determine how the
probability bounds degrade in view of applications of specific
inference rules. In
 Ford (2004)
 this is used to distinguish argument strengths (see
 above).
 
3.5.3 Beyond the core properties

Preferential consequence relations do not in general validate 

Rational Monotony: If ϕ|∼τ\phi \nc \tau and ϕ/|∼¬ψ\phi \nnc
\neg \psi, then ϕ∧ψ|∼τ\phi \wedge \psi \nc \tau. 


A preferential consequence relation |∼\nc that satisfies Rational
Monotony is called a rational consequence relation. These are
characterized by ranked structures which are preferential
structures S=(Ω,≺)S = (\Omega, \prec) for which ≺\prec is
modular, i.e., for all M,M′,M″∈ΩM, M', M'' \in \Omega, if M≺M′M \prec
M' then either M″≺M′M'' \prec M' or M≺M″M \prec M''. One can picture
this as follows: models in Ω\Omega are arranged in linearly ordered
levels and the level of a model reflects its degree of normality (its
rank). 

The seminal
 Kraus et al. (1990)
 inspired a huge variety of subsequent work. We briefly highlight some
contributions. 

While in
 Kraus et al. (1990)
 the standard of deduction was classical propositional logic, in
 Arieli and Avron (2000)
 also nonclassical monotonic core logics and variants with multiple
conclusions are considered. Various publications investigate the
preferential and rational consequence relations in a first-order
language (e.g.,
 Lehmann and Magidor 1990,
 Delgrande 1998,
 Friedman et al. 2000).
 

As we have seen, the properties of preferential or rational
consequence relations may also serve as deductive rules for syntactic
units of the form ϕ|∼ψ\phi \nc \psi under the usual readings such as
“If ϕ\phi then usually ψ\psi.” This approach can be
generalized to gain conditional logics by allowing for formulas
where a conditional assertion ϕ|∼ψ\phi \nc \psi is within the scope of
classical connectives such as ∧,∨,¬\wedge, \vee, \neg, etc. (e.g.,
 Delgrande 1987,
 Asher and Morreau 1991,
 Friedman and Halpern 1996,
 Giordano et al. 2009). We state
 one remarkable result obtained in
 Boutilier (1990)
 that closely links the study of NMLs to the study of modal logics in
the Kripkean tradition. Suppose we translate the deduction rules of
system P into Hilbert-style axiom schemes such that, for instance,
Cautious Monotony becomes 


⊢((ϕ|∼ψ)∧(ϕ|∼τ))⊃((ϕ∧ψ)|∼τ)\vdash \bigl( ( \phi \nc \psi) \wedge (\phi \nc \tau) \bigr) \supset
\bigl( ( \phi \wedge \psi) \nc \tau \bigr) 


It is shown that conditional assertions can be expressed in standard
Kripkean modal frames in such a way that system P (under this
translation) corresponds to a fragment of the well-known modal logic
S4. An analogous result is obtained for the modal logic S4.3 and the
system that results from strengthening system P with an axiom scheme
for Rational Monotony. 

Various contributions are specifically devoted to problems related to
relevancy. Consider some of the conditional assertions in the Nixon
Diamond: K\mathbf{K} = {Quaker |∼\nc Pacifist,
Republican |∼\nc ¬Pacifist}. It seems desirable to
derive e.g. Quaker ∧\wedge worker |∼\nc
Pacifist since in view of K\mathbf{K}, being a worker is
irrelevant to the assertion Quaker |∼\nc
Pacifist. Intuitively speaking, Quaker |∼\nc
¬worker should fail in which case Rational Monotony yields
Quaker ∧\wedge worker |∼\nc Pacifist in view
of Quaker |∼\nc Pacifist. Hence, prima facie we may
want to proceed as follows: let |∼R\nc^{R} be the result of
intersecting all rational consequence relations |∼\nc that extend
K\mathbf{K} (in the sense that the conditional assertions in
K\mathbf{K} hold for |∼\nc). Unfortunately it is not the
case that Quaker ∧\wedge worker |∼R\nc^{R}
Pacifist. The reason is simply that there are rational
consequence relations for which Quaker |∼\nc
¬worker and whence Rational Monotony does not yield the
desired Quaker ∧\wedge worker |∼\nc
Pacifist. Moreover, it has been shown that |∼R\nc^R is
identical to the preferential closure |∼P\nc^P. 

In
 Lehmann and Magidor (1992)
 a Rational Closure for conditional knowledge bases such as
K\mathbf{K} is proposed that yields the desired consequences. We
omit the technical details. The basic idea is to assign natural
numbers, i.e., ranks, to formulas which indicate how exceptional they
are relative to the given knowledge base K\mathbf{K}. Then the
ranks of formulas are minimized which means that each formula is
interpreted as normally as possible. A conditional assertion ϕ|∼ψ\phi
\nc \psi is in the Rational Closure of K\mathbf{K} if the rank of
ϕ∧ψ\phi \wedge \psi is strictly less than the rank of ϕ∧¬ψ\phi \wedge
\neg \psi (or ϕ\phi has no rank). The rank of a formula
α\alpha is calculated iteratively. Let m(K′)={ϕ⊃ψ∣ϕ|∼ψ∈K′}m(\mathbf{K}') = \{ \phi
\supset \psi \mid \phi \nc \psi \in \mathbf{K}'\} denote the
material counterpart of a given set of conditional assertions
K′\mathbf{K}'. Let K0=K\mathbf{K}_0 = \mathbf{K}. α\alpha has
rank 0 if it is consistent with m(K0)m(\mathbf{K}_0). Let
Ki+1\mathbf{K}_{i+1} be the set of all members ϕ|∼ψ\phi \nc \psi of
Ki\mathbf{K}_i for which the rank of ϕ\phi is not less or equal
to ii. α\alpha has rank i+1i+1 if it doesn’t have a rank
smaller or equal to ii and it is consistent with
m(Ki+1)m(\mathbf{K}_{i+1}). 

In our example Quaker ∧\wedge worker has rank 0, just like
Quaker. This is stricly less than the rank 1 of Quaker
∧\wedge ¬Pacifist and Quaker ∧\wedge worker
∧\wedge ¬Pacifist. This means that the desired
Quaker ∧\wedge worker |∼\nc Pacifist is in
the Rational Closure of our K\mathbf{K}. 

A system equivalent to Rational Closure has been independently
proposed under the name system Z based on
ϵ\epsilon-semantics in
 Pearl (1990).
 

One may consider it a drawback of Rational Closure that it suffers
from the Drowning Problem (see
 above).
 To see this consider the following conditional knowledge base
KL: 




We have the following ranks: 


formula
ll
cc
rr
ff
l∧fl \wedge f
l∧¬fl \wedge \neg f 

rank
1
0
0
0
1
1 


Since the ranks of l∧fl \wedge f and l∧¬fl \wedge \neg f are equal,
l|∼fl\nc f is not in the rational closure of KL\mathbf{KL}. 

This problem has been tackled in
 Lehmann (1995)
 with the formalism Lexicographic Closure. Rougly the idea is
to compare models by measuring the severity of violations of
assertions in the given conditional knowledge base to which they give
rise. ϕ|∼ψ\phi \nc \psi is entailed by K\mathbf{K} if the best
models of ϕ∧ψ\phi \wedge \psi are better than the best models of
ϕ∧¬ψ\phi \wedge \neg \psi. A model MM violates a conditional
assertion ϕ|∼ψ\phi \nc \psi if it validates ϕ\phi but not ψ\psi.
The violation is the more severe the higher the rank of ϕ\phi. For
instance, in our example we have the following models of l∧fl \wedge
f resp. of l∧¬fl \wedge \neg f: 


ll
ff
rr
cc
model
violation:rank 

1
1
1
1
M1M_1
l|∼¬r:1l \nc \neg r: 1 

1
1
1
0
M2M_2
l|∼¬r:1l \nc \neg r : 1, l|∼c:1l \nc c : 1


1
1
0
1
M3M_3
c|∼r:0c \nc r: 0 

1
1
0
0
M4M_4
l|∼c:1l \nc c: 1 

1
0
1
1
M5M_5
l|∼¬r:1l\nc \neg r:1, c|∼f:0c \nc f: 0 

1
0
1
0
M6M_6
l|∼¬r:1l \nc \neg r : 1, l|∼c:1l \nc c: 1 

1
0
0
1
M7M_7
c|∼r:0c \nc r : 0, c|∼f:0c \nc f : 0 

1
0
0
0
M8M_8
l|∼c:1l \nc c:1 


The best model of l∧fl \wedge f is M3M_3 since it doesn’t violate
any conditional assertion of rank higher than 0, while all other
models of l∧fl \wedge f do. For the same reason M7M_7 is the best
model of l∧¬fl \wedge \neg f. Moreover, M3M_3 violates less
conditional assertions of rank 0 than M7M_7 and is thus the
preferred interpretation. Hence, l|∼fl \nc f is in the Lexicographic
Closure. Altogether, what avoids the drowning problem in Lehmann’s
approach is a combination between specificity handling and a
quantitative rationale according to which interpretations are
preferred that violate less conditionals. 

To highlight the latter, consider a knowledge base K\mathbf{K}
consisting of 

Party |∼\nc Anne,
Party |∼\nc Phil, and 
Party |∼\nc Frank.


We expect from each, Anne, Phil, and Frank, to come to the party.
Suppose moreover we know that Party ∧\wedge ((¬
Anne ∧\wedge ¬ Phil) ∨\vee ¬
Frank). In view of this fact not all three assertions hold. At
best either the former two hold or the latter. If we try to validate
as many conditional assertions as possible we will prefer the
situation in which only the latter is violated. This happens in the
Lexicographic Closure of K\mathbf{K} which contains 

Party ∧\wedge ((¬ Anne ∧\wedge ¬
Phil) ∨\vee ¬ Frank) |∼\nc ¬Frank
and 
Party ∧\wedge ((¬ Anne ∧\wedge ¬
Phil) ∨\vee ¬ Frank) |∼\nc Anne
∧\wedge Phil. 


Similar quantitative considerations play a role in the Maximum
Entropy Approach in
 Goldzsmidt et al. (1993)
 which is based on ϵ\epsilon-semantics. The basic idea is similar
to Lexicographic Closure: ϕ|∼ψ\phi \nc \psi is entailed by
K\mathbf{K} if min({κ(M)∣M⊨ϕ∧ψ})<min({κ(M)∣M⊨ϕ∧¬ψ})\min(\{\kappa(M) \mid M \models \phi \wedge
\psi\}) &lt; \min (\{\kappa(M) \mid M \models \phi \wedge \neg
\psi\}), where κ(M)\kappa(M) outputs a weigthed sum of violations in
MM and where weights are attributed to violations in view of
specificity considerations. Similar to Lexicographic Closure the
violation of more specific conditionals weigh heavier than violations
of more general conditionals. As a consequence, just like in
Lexicographic Closure, l|∼fl \nc f is entailed in our example and so
the drowning problem is avoided. A difference to Lexicographic Closure
is, for instance, that l∧¬f|∼cl \wedge \neg f \nc c is not entailed
according to the maximal entropy approach. The reason is that the
violation of several less specific assertions may in sum
counter-balance the violation of a more specific assertion. For
instance, while model M7M_7 is preferred over model M8M_8 in the
Lexicographic approach, in the Maximum Entropy both models turn out to
be equally good and the best models of l∧¬fl \wedge \neg f. 
3.6 Assumption-based approaches

In a family of approaches defeasible inferences are encoded as
material inferences with explicit assumptions: 


[†]    (ϕ∧as)⊃ψ(\phi \wedge \mathsf{as}) \supset \psi



expresses that ϕ\phi defeasibly implies ψ\psi on the assumption
that as\mathsf{as} holds. Assumptions are interpreted as valid
“as much as possible”. There are various ways to give a
more precise meaning to this. 

One such approach is offered by Adaptive Logics
 (Batens 2007,
 Straßer 2014). An adaptive logic AL 
is given by a triple consisting of 

a lower limit logic LLL with a consequence relation
⊢\vdash that is reflexive, monotonic, satisfies Cut, and is compact
(If Γ⊢ϕ\Gamma \vdash \phi then there is a finite Γ′⊆Γ\Gamma' \subseteq
\Gamma such that Γ′⊢ϕ\Gamma' \vdash \phi); 
a set of abnormalities Ω\Omega containing formulas which
are to be interpretated “as false as much as possible”;
and 
an adaptive strategy in view of which the phrase “as
false as much as possible” will be disambiguated. 


LLL defines the deductive core of AL in that all LLL-valid inferences
are also AL-valid. AL strengthens LLL by allowing for defeasible
inferences by means of the following scheme: 


[‡]    Where ab\mathsf{ab} is an abnormal formula
in Ω\Omega: if ϕ⊢ψ∨ab\phi\vdash \psi \vee \mathsf{ab} then ψ\psi
follows defeasibly from ϕ\phi on the assumption that
ab\mathsf{ab} is false (or, equivalently, that ¬ab\neg \mathsf{ab}
is true). 


Where as=¬ab\mathsf{as} = \neg \mathsf{ab}, the antecedent of [‡]
is equivalent to ⊢(ϕ∧as)⊃ψ\vdash (\phi \wedge \mathsf{as}) \supset \psi
which is [†] above (under the classical meaning of ¬,∧\neg,
\wedge, and ∨\vee). 

Examples of concrete classes of adaptive logics are: 

Inconsistency-Adaptive Logics
 (Batens 1980,
 Batens 1999,
 Priest 1991):
 In domains in which contradictions may occur it is useful to work
with a paraconsistent core logic LLL that has a negation ∼\sim that
is non-explosive (p,∼p⊬qp, {\sim} p \nvdash q) and for which disjunctive
syllogism doesn’t hold (ϕ∨ψ,∼ϕ⊬ψ\phi \vee \psi, {\sim} \phi \nvdash \psi).
Let Ω\Omega consist of ∼\sim-contradictions in logical atoms
(p∧∼pp \wedge {\sim} p). Then we have p∨q,∼p⊢q∨abp \vee q, {\sim} p \vdash q
\vee \mathsf{ab} where ab=p∧∼p\mathsf{ab} = p \wedge {\sim}p. This
means, disjunctive syllogism can be applied on the assumption that
there is no ∼\sim-contradiction in pp. This way LLL is
significantly strengthened in a non-monotonic way. 
Adaptive Logics of Inductive Generalizations: Let LLL be CL
and consider a Ω\Omega that contains, for instance, formulas of the
form ∃xP(x)∧¬∀xP(x)\exists x P(x) \wedge \neg \forall x P(x). Then we have, for
example, P(a)⊢∀xP(x)∨abP(a) \vdash \forall x P(x) \vee \mathsf{ab} where
ab=∃xP(x)∧¬∀xP(x)\mathsf{ab} = \exists x P(x) \wedge \neg \forall x P(x). This
means we inductively generalize from P(a)P(a) to ∀xP(x)\forall x P(x)
based on the assumption that the abnormality ab\mathsf{ab} does not
hold. (This is a simplified account compared to the more subtle logics
presented in
 Batens (2011).)
 
 There are numerous adaptive logics for other defeasible reasoning
forms such as abductive reasoning, normative reasoning, belief
revision, diagnosis, etc. 


Adaptive logics implement the idea behind [‡] syntactically in
terms of a dynamic proof theory. A dynamic proof from the
premise set {P(a),¬P(b)}\{P(a), \neg P(b)\} for an adaptive logic of inductive
generalizations may look as follows: 


1.
P(a)P(a)
PREM
∅ 

✓2.
∀xP(x)\forall x P(x)
1; RC
{∃xP(x)∧¬∀xP(x)}\{\exists x P(x) \wedge \neg \forall x
P(x)\} 

3.
¬P(b)\neg P(b)
PREM
∅ 

4.
∃xP(x)∧¬∀xP(x)\exists x P(x) \wedge \neg \forall x P(x)
1,3; RU
∅ 


The last column of each line of the proof contains its condition,
i.e., a set of abnormalities COND⊆Ω\mathrm{COND} \subseteq \Omega that
encodes the assumptions used to derive the formula in the second
column of the line: each ab∈COND\mathsf{ab} \in \mathrm{COND} is assumed
to be false. The generic rule RU (rule unconditional) represents any
inference that is licenced by LLL. The generic rule RC (rule
conditional) follows scheme [‡] where ab\mathsf{ab} is pushed
to the condition of the line. Sometimes there are good reasons to
consider assumptions as violated in which case the corresponding lines
are ✓-marked as retracted. This is clearly the case if
the condition of a line is COND\mathrm{COND} while for a
{ab1,…,abn}⊆COND\{\mathsf{ab}_1, \dotsc, \mathsf{ab}_n\} \subseteq \mathrm{COND},
ab1∨ab2∨…∨abn\mathsf{ab}_1 \vee \mathsf{ab}_2 \vee \ldots \vee \mathsf{ab}_n is
derived without defeasible steps (i.e., on the condition ∅).
This means that (at least) one of the formulas in COND\mathrm{COND} is
false. Thus, line 2 is marked as retracted when we reach line 4 of the
proof. In view of this behavior, dynamic proofs are internally
dynamic: even if no new premises are introduced, the addition of new
lines may cause the retraction of previous lines of a proof. 

Not all cases of retraction are of this straightforward kind. Various
adaptive strategies come with marking mechanisms to handle more
complicated cases such as the one in the following proof: 


1.
P(a)P(a)
PREM
∅ 

2.
Q(a)Q(a)
PREM
∅ 

3.
¬P(b)∨¬Q(c)\neg P(b) \vee \neg Q(c)
PREM
∅ 

4.
∀xP(x)∨∀xQ(x)\forall x P(x) \vee \forall x Q(x)
1; RC
{∃xP(x)∧¬∀xP(x)}\{\exists x P(x) \wedge \neg \forall x
P(x)\} 

5.
∀xP(x)∨∀xQ(x)\forall x P(x) \vee \forall x Q(x)
2; RC
{∃xQ(x)∧¬∀xQ(x)}\{\exists x Q(x) \wedge \neg \forall x Q
(x)\} 

6.
(∃xP(x)∧¬∀xP(x))∨(∃xQ(x)∧¬∀xQ(x))(\exists x P(x) \wedge \neg \forall x P(x)) \vee
( \exists x Q(x) \wedge \neg \forall x Q(x))
1–3; RU
∅ 


The formula ∀xP(x)∨∀xQ(x)\forall x P(x) \vee \forall x Q(x) is derived at line
4 and 5 on two respective conditions: {∃xP(x)∧¬∀xP(x)}\{\exists x P(x) \wedge \neg
\forall x P(x)\} and {∃xQ(x)∧¬∀xQ(x)}\{\exists x Q(x) \wedge \neg \forall x
Q(x)\}. Neither ∃xP(x)∧¬∀xP(x)\exists x P(x) \wedge \neg \forall x P(x) nor
∃xQ(x)∧¬∀xQ(x)\exists x Q(x) \wedge \neg \forall x Q(x) is derivable on the
condition ∅. However, both are part of the (minimal) disjunction
of abnormalities derived at line 6. According to one strategy, the
minimal abnormality strategy, the premises are interpreted in
such a way that as many abnormalities as possible are considered to be
false, which leaves us with two interpretations: one in which
∃xP(x)∧¬∀xP(x)\exists x P(x) \wedge \neg \forall x P(x) holds while ∃xQ(x)∧¬∀xQ(x)\exists x
Q(x) \wedge \neg \forall x Q(x) is false, and another one in which
∃xQ(x)∧¬∀xQ(x)\exists x Q(x) \wedge \neg \forall x Q(x) holds while ∃xP(x)∧¬∀xP(x)\exists x
P(x) \wedge \neg \forall x P(x) is false. In both interpretations
either the assumption of line 4 or the assumption of line 5 holds
which means that in either interpretation the defeasible inference to
∀xP(x)∨∀xQ(x)\forall x P(x) \vee \forall x Q(x) goes through. Thus, according
to the minimal abnormality strategy neither line 4 nor line 5 is
marked (we omit the technical details). Another strategy, the
reliability strategy, is more cautious. According to it any
line that involves an abnormality in its condition that is part of a
minimal disjunction of abnormalities derived on the condition ∅
is marked. This means that in our example, lines 4 and 5 are marked.


Lines may get marked at specific stages of a proof just to get
unmarked at latter stages and vice versa. This mirrors the internal
dynamics of defeasible reasoning. In order to define a consequence
relation, a stable notion of derivability is needed. A formula derived
at an unmarked line l in an adaptive proof from a premise set
Γ\Gamma is considered a consequence of Γ\Gamma if any
extension of the proof in which l is marked is further
extendable so that the line is unmarked again. 

Such a consequence relation can equivalently be expressed semantically
in terms of a preferential semantics (see Section
 Selection semantics).
 Given an LLL-model MM we can identify its abnormal part
Ab(M)={ab∈Ω∣M⊨ab}Ab(M) = \{\mathsf{ab} \in \Omega \mid M \models \mathsf{ab}\} to
be the set of all abnormalities that hold in MM. The selection
semantics for minimal abnormality can be phrased as follows. We order
the LLL-models by M≺M′M \prec M' if and only if Ab(M)⊂Ab(M′)Ab(M) \subset
Ab(M'). Then we define that ϕ\phi is a semantic consequence of
Γ\Gamma if and only if for all ≺\prec-minimal LLL-models MM
of Γ\Gamma, M⊨ϕM\models \phi. (We omit selection semantics for
other strategies.) 

A similar system to adaptive logics makes use of maximally consistent
sets. In
 Makinson (2003)
 it was developed under the name default assumptions. Given a
set of assumptions Ξ\Xi, 


Γ|∼[Ξ]ϕ\Gamma \nc[\Xi] \phi if and only if Ξ′∪Γ⊨ϕ\Xi' \cup \Gamma \vDash
\phi for all Ξ′⊆Ξ\Xi' \subseteq \Xi that are maximally consistent
with Γ\Gamma (i.e., Ξ′∪Γ\Xi' \cup \Gamma is consistent and there is
no Ξ″⊆Ξ\Xi'' \subseteq \Xi for which Ξ′⊂Ξ″\Xi' \subset \Xi'' and
Ξ″∪Γ\Xi'' \cup \Gamma is consistent). 


If we take Ξ\Xi to be {¬ab∣ab∈Ω}\{\neg \mathsf{ab} \mid \mathsf{ab} \in
\Omega\} then we have an equivalent characterization of adaptive
logics with the minimal abnormality strategy and the set of
abnormalities Ω\Omega
 (Van De Putte 2013).
 

Conditional Entailment is another assumption-based approach
 (Geffner and Pearl 1992).
 Suppose we start with a theory T=(Δ,Γ,Λ)T = (\Delta, \Gamma, \Lambda)
where Δ={ϕi→ψi∣i∈I}\Delta = \{\phi_i \rightarrow \psi_i \mid i \in I\} consists
of default rules, Γ\Gamma consists of necessary facts, while
Λ\Lambda consists of contingent facts. It is translated into an
assumption-based theory T′=(Δ′,Γ′,Λ)T' = (\Delta', \Gamma', \Lambda) as
follows: 

For each ϕi→ψi∈Δ\phi_i \rightarrow \psi_i \in \Delta we introduce a
designated assumption constant πi\pi_i and encode ϕi→ψi\phi_i
\rightarrow \psi_i by ϕi∧πi⊃ψi\phi_i \wedge \pi_i \supset \psi_i. The
former is just our scheme [†] while the latter makes sure that
assumptions are —by default— considered to hold. 
The set of defaults Δ′\Delta' is {ϕi→πi∣i∈I}\{\phi_i \rightarrow \pi_i
\mid i \in I\} and our background knowledge becomes Γ′=Γ∪{ϕi∧πi⊃ψi∣i∈I}\Gamma' =
\Gamma \cup \{\phi_i \wedge \pi_i \supset \psi_i \mid i \in I\}.



Just as in the adaptive logic approach, models are compared with
respect to their abnormal parts. For a classical model MM of
Γ′∪Λ\Gamma' \cup \Lambda, Ab(M)Ab(M) is the set of all πi\pi_i for
which M⊨¬πiM \models \neg \pi_i. One important aspect that
distinguishes conditional entailment from adaptive logics and default
assumptions, is the fact that it implements the Specificity Principle.
For this, assumptions are ordered by means of a (smooth) relation
<. Models are then compared as follows: 


M⋖M′M \lessdot M' if and only if Ab(M)≠Ab(M′)Ab(M) \neq Ab(M') and for all
πi∈Ab(M)∖Ab(M′)\pi_i \in Ab(M)\setminus Ab(M') there is a πj∈Ab(M′)∖Ab(M)\pi_j \in Ab(M')
\setminus Ab(M) for which πi<πj\pi_i &lt; \pi_j. 


The idea is: MM is preferred over M′M' if every assumption
πi\pi_i that doesn't hold in MM but that holds in M′M' is
‘compensated for’ by a more specific assumption πj\pi_j that holds
in MM but that doesn’t hold in M′M'. 

For this to work, < has to include specificity relations among
assumptions. Such orders < are called admissible relative to
the background knowledge Γ′\Gamma' if they satisfy the following
property: for every set of assumptions Π⊆{πi∣i∈I}\Pi \subseteq \{\pi_i \mid i
\in I\}, if Π\Pi violates some default ϕj→πj\phi_j \rightarrow
\pi_j in view of the given background knowledge Γ′\Gamma' (in
signs, Π,ϕj,Γ′⊨¬πj\Pi, \phi_j, \Gamma' \models \neg \pi_j) then there is a
πk∈Π\pi_k \in \Pi for which πk<πj\pi_k &lt; \pi_j. 

This is best understood when put into action. Take the case with
Tweety the penguin. We have Δ′={p→π1,b→π2}\Delta' = \{ p \rightarrow \pi_1, b
\rightarrow \pi_2\}, Γ′={p⊃b,p∧π1⊃¬f,b∧π2⊃f}\Gamma' = \{ p \supset b, p \wedge \pi_1
\supset \neg f, b \wedge \pi_2 \supset f\}, and Λ={p}\Lambda = \{p\}.
Let Π={π2}\Pi = \{\pi_2\}. Then Π,Γ′,p⊨¬π1\Pi, \Gamma', p \models \neg \pi_1
and thus for < to be admissible, π2<π1\pi_2 &lt; \pi_1. We have two
types of models of Γ′∪Λ\Gamma' \cup \Lambda: models M1M_1 for which
M1⊨π1M_1 \models \pi_1 and therefore M1⊨¬fM_1 \models \neg f and models
M2M_2 for which M2⊨π2M_2 \models \pi_2 and thus M2⊨fM_2 \models f.
Note that M1⋖M2M_1 \lessdot M_2 since for the only assumption in
Ab(M1)Ab(M_1) —namely π2\pi_2— there is π1∈Ab(M2)∖Ab(M1)\pi_1 \in
Ab(M_2) \setminus Ab(M_1) and π2<π1\pi_2 &lt; \pi_1. 

Analogous to adaptive logics with the minimal abnormality strategy,
conditional entailment is defined via ⋖\lessdot-minimal models:



(Δ′,Γ′,Λ)|∼ϕ(\Delta', \Gamma', \Lambda) \nc \phi if and only if for each
admissible < (relative to Γ′\Gamma') and all ⋖\lessdot-minimal
models MM of Γ′∪Λ\Gamma' \cup \Lambda, M⊨ϕM \models \phi. 


In our example, ¬f\neg f is a conditionally entailed since all
⋖\lessdot-minimal models have the same abnormal part as M1M_1.


A consequence of expressing defeasible inferences via material
implication in assumption-based approaches is that defeasible
inferences are contrapositable. Clearly, if ϕ∧π⊃ψ\phi \wedge \pi
\supset \psi then ¬ψ∧π⊃¬ϕ\neg \psi \wedge \pi \supset \neg \phi. As a
consequence, formalisms such as default logic have a more greedy style
of applying default rules. We demonstrate this with conditional
entailment. Consider a theory consisting of the defaults p1→p2p_1
\rightarrow p_2, p2→p3p_2 \rightarrow p_3, p3→p4p_3 \rightarrow p_4
and the factual information Λ={p1,¬p4}\Lambda = \{p_1, \neg p_4\} (where
pip_i are logical atoms). In assumption-based approaches such as
conditional entailment the defeasible rules will be encoded as p1∧π1⊃p2p_1
\wedge \pi_1 \supset p_2, p2∧π2⊃p3p_2 \wedge \pi_2 \supset p_3, and
p3∧π3⊃p4p_3 \wedge \pi_3 \supset p_4. It can easily be seen that < =
∅ is an admissible ordering which means that for instance a
model MM with Ab(M)={π1}Ab(M) = \{\pi_1\} is ⋖\lessdot-minimal. In
such a model we have M⊨¬p3M \models \neg p_3 and M⊨¬p2M \models \neg p_2
by reasoning backwards via contraposition from ¬p4∧π3\neg p_4 \wedge
\pi_3 to ¬p3\neg p_3 and from ¬p3∧π2\neg p_3 \wedge \pi_2 to ¬p2\neg
p_2. This means that neither p2p_2 nor p3p_3 is conditionally
entailed. 

The situation is different in default logic where both p2p_2 and
p3p_3 are derivable. The reasoning follows a greedy policy in
applying default rules: whenever a rule is applicable (i.e., its
antecedent holds by the currently held beliefs Ξ\Xi and its
consequent doesn’t contradict with Ξ\Xi) it is applied. There is
disagreement among scholars whether and when contraposition is a
desirable property for defeasible inferences (e.g.,
 Caminada 2008,
 Prakken 2012). 
4. Non-monotonic logic and human reasoning

In view of the fact that test subjects seem to perform very poorly in
various paradigmatic reasoning tests (e.g., Wason’s Selection Task
 (Wason 1966)
 or the Supression Task
 (Byrne 1989)),
 main streams in the psychology of reasoning have traditionally
ascribed to logic at best a subordinate role in human reasoning. In
recent years this assessment has been criticized as the result of
evaluating performances in tests against the standard of classical
logic whereas other standards based on probabilistic considerations or
on NMLs have been argued to be more appropriate. 

This resulted in the rise of a new probabilistic paradigm
 (Oaksford and Chater 2007,
 Pfeifer and Douven 2014) where 
probability theory provides a calculus for
rational belief update. Although the program is sometimes phrased in
decidedly anti-logicist
 terms,[7]
 logic is here usually understood as monotonic and deductive. The
relation to NML is less clear and it has been argued that there are
close connections especially to probabilistic accounts of NML
 (Over 2009,
 Pfeifer and Kleiter 2009).
 Politzer and Bonnefon 2009
 warn against the premature acceptance of the probabilistic paradigm
in view of the rich variety of alternatives such as possibility
measures, plausibility measures, etc.).
 

Another argument for the relevance of NML is advocated in
 Stenning and Van Lambalgen (2008)
 who distinguish between reasoning to and reasoning from
an interpretation. In the former process agents establish a logical
form that is relative both to the specific context in which the
reasoning takes place and to the agent’s goals. When establishing a
logical form agents choose—inter alia—a formal language, a
semantics (e.g., extensional vs. intensional), a notion of validity,
etc. Once a logical form is established, agents engage in lawlike
rule-based inferences which are based on this form. It is argued that
in the majority of cases in standard reasoning tasks, subjects use
non-monontonic logical forms that are based on closed world
assumptions. 

Non-monotonic logicians often state that their motivation stems from
observing the defeasible structure of actual commonsense reasoning.
Empirical studies have been explicitly cited as both inspiration for
working on NMLs and as standards against which to evaluate NMLs.
However, it has also been noted that logicians often rely too much on
their own intuitions without critically assessing them against the
background of empirical studies
 (Pelletier and Elio 1997).
 

Various studies investigate their test subjects’ tendency to reason
according to specific inference principles of NMLs. Most studies
support the descriptive adequacy of the rules of system P. There are,
however, some open or controversial issues. For instance, while some
studies report results suggestive of the adequacy of weakened monotony
principles such as Cautious Monotony
 (Schurz 2005,
 Neves et al. 2002,
 Pfeifer and Kleiter 2005)
 and Rational Monotony
 (Neves et al. 2002),
 Benferhat et al. (2005) report mixed results. Specificity considerations play a
role in the reasoning process of test subjects in
 Schurz (2005),
 whereas according to
 Ford and Billington (2000)
 they do not.
 Benferhat et al. (2005)
 are specifically interested in the question whether the responses of
their test subjects corresponded better to Lexicographic Closure or to
Rational Closure. While the results were not fully conclusive they
still suggest a preference for the former. 

Pelletier and Elio (1994)
 investigate various relevant factors that influence subjects’
reasoning about exceptions of defaults or inheritance relations. Their
study makes use of the benchmark problems for defeasible reasoning
proposed in
 Lifschitz (1989).
 It is, for instance, observed that the exceptional status of an
object A with respect to some default is more likely to spread
to other objects if they share properties with A that may play
a role in explaining the exceptional status. For example, when
confronted with a student club that violates the default that student
clubs only allow for student members, subjects are more likely to
ascribe this exceptional status also to another club if they learn
that both clubs have been struggling to maintain minimum membership
requirements. 

The question of the descriptive adequacy of NMLs to human reasoning is
also related to questions concerning the nature and limits of
cognitive modules in view of which agents are capable of logical
reasoning. For instance, the question arises, whether such modules
could be realized on a neurological level. Concerning the former
question there are successful representations of NMLs in terms of
neural networks (see
 Stenning and Van Lambalgen (2008),
 Garcez et al (2009),
 Hölldobler and Kalinke (1994)
 for
 logic programming
 with closed world assumptions,
 Besold et al (2017)
 for input/output logic, and
 Leitgeb (2001)
 for NMLs in the tradition of
 Selection semantics).
 
5. Conclusion

There are three major issues connected with the development of logical
frameworks that can adequately represent defeasible reasoning:
(i) material adequacy; (ii) formal properties; and
(iii) complexity. A non-monotonic formalism is materially
adequate to the extent to which it captures examples of defeasible
reasoning and to the extent to which it has intuitive properties. The
question of formal properties has to do with the degree to which the
formalism gives rise to a consequence relation that satisfies
desirable theoretic properties such as the above mentioned
Reflexivity, Cut, and Cautious Monotony. The third set of issues has
to do with computational complexity of the most basic questions
concerning the framework. 

There is a potential tension between (i) and (ii): the
desire to capture a broad range of intuitions can lead to ad
hoc solutions that can sometimes undermine the desirable formal
properties of the framework. In general, the development of NMLs and
related formalisms has been driven, since its inception, by
consideration (i) and has relied on a rich and well-chosen
array of examples. Of course, there is some question as to whether any
single framework can aspire to be universal in this respect. 

More recently, researchers have started paying attention to
consideration (ii), looking at the extent to which NMLs have
generated well-behaved relations of logical consequence. As
 Makinson (1994)
 points out, practitioners of the field have encountered mixed
success. In particular, one abstract property, Cautious Monotony,
appears at the same time to be crucial and elusive for many of the
frameworks to be found in the literature. This is a fact that is
perhaps to be traced back, at least in part, to the above-mentioned
tension between the requirement of material adequacy and the need to
generate a well-behaved consequence relation. 

The complexity issue appears to be the most difficult among the ones
that have been singled out. NMLs appear to be stubbornly intractable
with respect to the corresponding problem for classical logic. This is
clear in the case of default logic, given the ubiquitous consistency
checks. But besides consistency checks, there are other, often
overlooked, sources of complexity that are purely combinatorial. Other
forms of non-monotonic reasoning, besides default logic, are far from
immune from these combinatorial roots of intractability. Although some
important work has been done trying to make various non-monotonic
formalisms more tractable, this is perhaps the problem on which
progress has been slowest in coming.