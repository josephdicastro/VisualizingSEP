<!DOCTYPE html><!--[if lt IE 7]> <html class="ie6 ie"> <![endif]--><!--[if IE 7]>    <html class="ie7 ie"> <![endif]--><!--[if IE 8]>    <html class="ie8 ie"> <![endif]--><!--[if IE 9]>    <html class="ie9 ie"> <![endif]--><!--[if !IE]> --><html xmlns="http://www.w3.org/1999/xhtml"><!-- <![endif]--><head>
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>
Evolutionary Game Theory (Stanford Encyclopedia of Philosophy/Winter 2019 Edition)
</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="robots" content="noarchive, noodp" />
<meta property="citation_title" content="Evolutionary Game Theory" />
<meta property="citation_author" content="Alexander, J. McKenzie" />
<meta property="citation_publication_date" content="2002/01/14" />
<meta name="DC.title" content="Evolutionary Game Theory" />
<meta name="DC.creator" content="Alexander, J. McKenzie" />
<meta name="DCTERMS.issued" content="2002-01-14" />
<meta name="DCTERMS.modified" content="2009-07-19" />

<!-- NOTE: Import webfonts using this link: -->
<link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,300,600,200&amp;subset=latin,latin-ext" rel="stylesheet" type="text/css" />

<link rel="stylesheet" type="text/css" media="screen,handheld" href="../../css/bootstrap.min.css" />
<link rel="stylesheet" type="text/css" media="screen,handheld" href="../../css/bootstrap-responsive.min.css" />
<link rel="stylesheet" type="text/css" href="../../css/font-awesome.min.css" />
<!--[if IE 7]> <link rel="stylesheet" type="text/css" href="../../css/font-awesome-ie7.min.css"> <![endif]-->
<link rel="stylesheet" type="text/css" media="screen,handheld" href="../../css/style.css" />
<link rel="stylesheet" type="text/css" media="print" href="../../css/print.css" />
<link rel="stylesheet" type="text/css" href="../../css/entry.css" />
<!--[if IE]> <link rel="stylesheet" type="text/css" href="../../css/ie.css" /> <![endif]-->
<script type="text/javascript" src="../../js/jquery-1.9.1.min.js"></script>
<script type="text/javascript" src="../../js/bootstrap.min.js"></script>

<!-- NOTE: Javascript for sticky behavior needed on article and ToC pages -->
<script type="text/javascript" src="../../js/jquery-scrolltofixed-min.js"></script>
<script type="text/javascript" src="../../js/entry.js"></script>

<!-- SEP custom script -->
<script type="text/javascript" src="../../js/sep.js"></script>
</head>

<!-- NOTE: The nojs class is removed from the page if javascript is enabled. Otherwise, it drives the display when there is no javascript. -->
<body class="archive article" id="pagetopright">
<div id="container">
<div id="header-wrapper">
  <div id="header">
    <div id="branding">
      <div id="site-logo"><a href="../../index.html"><img src="../../symbols/sep-man-red.png" alt="SEP logo" /></a></div>
      <div id="site-title"><a href="../../index.html">Stanford Encyclopedia of Philosophy Archive<div id="site-subtitle">Winter 2019 Edition</div></a></div>
    </div>
    <div id="navigation">
      <div class="navbar">
        <div class="navbar-inner">
          <div class="container">
            <button class="btn btn-navbar collapsed" data-target=".collapse-main-menu" data-toggle="collapse" type="button"> <i class="icon-reorder"></i> Menu </button>
            <div class="nav-collapse collapse-main-menu collapse">
              <ul class="nav">
                <li class="dropdown"><a id="drop1" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-book"></i> Browse</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop1">
                    <li><a href="../../contents.html">Table of Contents</a></li>
                    <li><a href="../../new.html">New in this Archive</a></li>
                    
                    <li><a href="../../published.html">Chronological</a></li>
                    <li><a href="../../../../archives/">Archives <i class="icon-external-link"></i></a></li>
                  </ul>
                </li>
                <li class="dropdown"><a id="drop2" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-info-sign"></i> About</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop2">
                    <li><a href="../../info.html">Editorial Information</a></li>
                    <li><a href="../../about.html">About the SEP</a></li>
                    <li><a href="../../board.html">Editorial Board</a></li>
                    <li><a href="../../cite.html">How to Cite the SEP</a></li>
                    <li><a href="../../special-characters.html">Special Characters</a></li>
                    
                    <li><a href="../../../../contact.html">Contact <i class="icon-external-link"></i></a></li>
                  </ul>
                </li>
                <li class="dropdown"><a id="drop3" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-leaf"></i> Support SEP</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop3">
                    <li><a href="../../../../support/">Support the SEP</a></li>
                    <li><a href="../../../../support/friends.html">PDFs for SEP Friends</a></li>
                    <li><a href="../../../../support/donate.html">Make a Donation</a></li>
                    <li><a href="../../../../support/sepia.html">SEPIA for Libraries</a></li>
                  </ul>
                </li>
              </ul>
            </div>
          </div>
        </div>
      </div>
    </div>
    <!-- End navigation -->
    
    <div id="search">
      <form id="search-form" method="get" action="../../../../search/searcher.py">
        <input type="search" name="query" placeholder="Search this archive" />
<input type="hidden" name="archive" value="win2019" />

        <div class="search-btn-wrapper"><button class="btn search-btn" type="submit"><i class="icon-search"></i></button></div>
      </form>
    </div>
    <!-- End search --> 
    
  </div>
  <!-- End header --> 
</div>
<!-- End header wrapper -->

<div id="content">

<!-- Begin article sidebar -->
<div id="article-sidebar" class="sticky" style="z-index: 999;">
  <div class="navbar">
    <div class="navbar-inner">
      <div class="container">
        <button class="btn btn-navbar collapsed" data-target=".collapse-sidebar" data-toggle="collapse" type="button"> <i class="icon-reorder"></i> Entry Navigation </button>
        <div id="article-nav" class="nav-collapse collapse-sidebar collapse">
          <ul class="nav">
            <li><a href="#toc">Entry Contents</a></li>
            <li><a href="#Bib">Bibliography</a></li>
            <li><a href="#Aca">Academic Tools</a></li>
            <li><a href="https://leibniz.stanford.edu/friends/preview/game-evolutionary/">Friends PDF Preview <i class="icon-external-link"></i></a></li>
            <li><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=game-evolutionary&amp;archive=win2019">Author and Citation Info <i class="icon-external-link"></i></a> </li>
            <li><a href="#pagetopright" class="back-to-top">Back to Top <i class="icon-angle-up icon2x"></i></a></li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</div><div></div>
<!-- End article sidebar --> 

<!-- NOTE: Article content must have two wrapper divs: id="article" and id="article-content" -->
<div id="article">
<div id="article-content">

<!-- BEGIN ARTICLE HTML -->


<div id="aueditable"><!--DO NOT MODIFY THIS LINE AND ABOVE-->

<h1>Evolutionary Game Theory</h1><div id="pubinfo"><em>First published Mon Jan 14, 2002; substantive revision Sun Jul 19, 2009</em></div>

<div id="preamble">

<p>

Evolutionary game theory originated as an application of the
mathematical theory of games to biological contexts, arising from the
realization that frequency dependent fitness introduces a strategic
aspect to evolution. Recently, however, evolutionary game theory has
become of increased interest to economists, sociologists, and
anthropologists--and social scientists in general--as well as
philosophers. The interest among social scientists in a theory with
explicit biological roots derives from three facts. First, the
‘evolution’ treated by evolutionary game theory need not be
biological evolution. ‘Evolution’ may, in this context,
often be understood as <em>cultural</em> evolution, where this refers
to changes in beliefs and norms over time. Second, the rationality
assumptions underlying evolutionary game theory are, in many cases,
more appropriate for the modelling of social systems than those
assumptions underlying the traditional theory of games. Third,
evolutionary game theory, as an explicitly dynamic theory, provides an
important element missing from the traditional theory. In the preface
to <em>Evolution and the Theory of Games</em>, Maynard Smith notes that
“[p]aradoxically, it has turned out that game theory is more readily
applied to biology than to the field of economic behaviour for which it
was originally designed.” It is perhaps doubly paradoxical, then, that
the subsequent development of <em>evolutionary</em> game theory has
produced a theory which holds great promise for social scientists, and
is as readily applied to the field of economic behaviour as that for
which it was originally designed. </p>

</div>

<div id="toc">
<!--Entry Contents-->
<ul>
<li><a href="#HisDev">1. Historical Development</a></li>
<li><a href="#TwoAppEvoGamThe">2. Two Approaches to Evolutionary Game Theory</a>
   <ul>
   <li><a href="#DefEvoSta">2.1 Definitions of evolutionary stability </a></li>
   <li><a href="#SpeDynForPop">2.2 Specifying dynamics for the population</a></li>
   </ul></li>
<li><a href="#WhyEvoGamThe">3. Why Evolutionary Game Theory?</a>
   <ul>
   <li><a href="#EquSelPro">3.1 The equilibrium selection problem</a></li>
   <li><a href="#ProHypAge">3.2 The problem of hyperrational agents</a></li>
   <li><a href="#LacDynTheTraTheGam">3.3 The lack of a dynamical theory in the traditional theory of games</a></li>
   </ul></li>
<li><a href="#AppEvoGamThe">4. Applications of Evolutionary Game Theory</a>
   <ul>
   <li><a href="#SenFai">4.1 A sense of fairness</a></li>
   <li><a href="#EmeLan">4.2 The emergence of language.</a></li>
   </ul></li>
<li><a href="#PhiProEvoGamThe">5. Philosophical Problems of Evolutionary Game Theory</a>
   <ul>
   <li><a href="#MeaFitCulEvoInt">5.1 The meaning of fitness in cultural evolutionary interpretations</a></li>
   <li><a href="#ExpIrrEvoGamThe">5.2 The explanatory irrelevance of evolutionary game theory</a></li>
   <li><a href="#ValLadEvoGamTheExp">5.3 The value-ladenness of evolutionary game theoretic explanations</a></li>
   </ul></li>
<li><a href="#Bib">Bibliography</a></li>
<li><a href="#Aca">Academic Tools</a></li>
<li><a href="#Oth">Other Internet Resources</a></li>
<li><a href="#Rel">Related Entries</a></li>
</ul>
<!--Entry Contents-->

<hr />

</div>

<div id="main-text">

<h2><a name="HisDev">1. Historical Development</a></h2>

<p>

Evolutionary game theory was first developed by R. A. Fisher [see
<em>The Genetic Theory of Natural Selection</em> (1930)] in his attempt
to explain the approximate equality of the sex ratio in mammals. The
puzzle Fisher faced was this: why is it that the sex ratio is
approximately equal in many species where the majority of males never
mate? In these species, the non-mating males would seem to be excess
baggage carried around by the rest of the population, having no real
use. Fisher realized that if we measure individual fitness in terms of
the expected number of <em>grandchildren</em>, then individual fitness
depends on the distribution of males and females in the population.
When there is a greater number of females in the population, males have
a higher individual fitness; when there are more males in the
population, females have a higher individual fitness. Fisher pointed
out that, in such a situation, the evolutionary dynamics lead to the
sex ratio becoming fixed at equal numbers of males and females. The
fact that individual fitness depends upon the relative frequency of
males and females in the population introduces a strategic element into
evolutions.</p>

<p>

Fisher's argument can be understood game theoretically, but he did
not state it in those terms. In 1961, R. C. Lewontin made the
first explicit application of
 <a href="../game-theory/">game theory</a>
to evolutionary biology in “Evolution and the Theory of Games” (not to
be confused with the Maynard Smith work of the same name). In 1972,
Maynard Smith defined the concept of an <em>evolutionarily stable
strategy</em> (hereafter ESS) in the article “Game Theory and the
Evolution of Fighting.” However, it was the publication of “The Logic
of Animal Conflict,” by Maynard Smith and Price in 1973 that introduced
the concept of an ESS into widespread circulation. In 1982, Maynard
Smith's seminal text <em>Evolution and the Theory of Games</em>
appeared, followed shortly thereafter by Robert Axelrod's famous work
<em>The Evolution of Cooperation</em> in 1984. Since then, there has
been a veritable explosion of interest by economists and social
scientists in evolutionary game theory (see the bibliography
below).</p>

<h2><a name="TwoAppEvoGamThe">2. Two Approaches to Evolutionary Game Theory</a></h2>

<p>

There are two approaches to evolutionary game theory. The first
approach derives from the work of Maynard Smith and Price and employs
the concept of an evolutionarily stable strategy as the principal tool
of analysis. The second approach constructs an explicit model of the
process by which the frequency of strategies change in the population
and studies properties of the evolutionary dynamics within that
model.</p>

<p>
The first approach can thus be thought of as providing a static
conceptual analysis of evolutionary stability. “Static” because,
although definitions of evolutionary stability are given, the
definitions advanced do not typically refer to the underlying process
by which behaviours (or strategies) change in the population.  The
second approach, in contrast, does not attempt to define a notion of
evolutionary stability: once a model of the population dynamics has
been specified, all of the standard stability concepts used in the
analysis of dynamical systems can be brought to bear.
</p>

<h3><a name="DefEvoSta">2.1 Definitions of evolutionary stability </a></h3>

<p>

As an example of the first approach, consider the problem of the
Hawk-Dove game, analyzed by Maynard Smith and Price in “The Logic of
Animal Conflict.” In this game, two individuals compete for a resource
of a fixed value <em>V</em>. (In biological contexts, the value
<em>V</em> of the resource corresponds to an increase in the Darwinian
fitness of the individual who obtains the resource; in a cultural
context, the value <em>V</em> of the resource would need to be given an
alternate interpretation more appropriate to the specific model at
hand.) Each individual follows exactly one of two strategies described
below:</p>

<blockquote>
<table>
<tbody><tr>
<td valign="top"><strong>Hawk</strong></td>
<td>Initiate aggressive behaviour, not stopping until injured or until
one's opponent backs down.</td>
</tr>

<tr>
<td valign="top"><strong>Dove</strong></td>
<td>Retreat immediately if one's opponent initiates aggressive
behaviour.</td>
</tr>
</tbody></table>
</blockquote>

<p>

If we assume that (1) whenever two individuals both initiate
aggressive behaviour, conflict eventually results and the two
individuals are equally likely to be injured, (2) the cost of the
conflict reduces individual fitness by some constant value <em>C</em>,
(3) when a Hawk meets a Dove, the Dove immediately retreats and the
Hawk obtains the resource, and (4) when two Doves meet the resource is
shared equally between them, the fitness payoffs for the Hawk-Dove game
can be summarized according to the following matrix:</p>

<blockquote>
<table cellpadding="2">
<tbody><tr>
<td></td>
<td align="center"><strong>Hawk</strong></td>
<td align="center"><strong>Dove</strong></td>
</tr>

<tr>
<td><strong>Hawk</strong></td>
<td align="center">½(<em>V</em> - <em>C</em>)</td>
<td align="center"><em>V</em></td>
</tr>

<tr>
<td><strong>Dove</strong></td>
<td align="center">0</td>
<td align="center"><em>V</em>/2</td>
</tr>
</tbody></table>

<br />
<strong>Figure 1:</strong> The Hawk-Dove Game</blockquote>

<p>

(The payoffs listed in the matrix are for that of a player
<em>using</em> the strategy in the appropriate row, playing against
someone using the strategy in the appropriate column. For example, if
you play the strategy Hawk against an opponent who plays the strategy
Dove, your payoff is <em>V</em>; if you play the strategy Dove against
an opponent who plays the strategy Hawk, your payoff is 0.)</p>

<p>

In order for a strategy to be evolutionarily stable, it must have
the property that if almost every member of the population follows it,
no mutant (that is, an individual who adopts a novel strategy) can
successfully invade. This idea can be given a precise characterization
as follows: Let
 Δ<em>F</em>(<em>s</em><font size="-1"><sub>1</sub></font>,<em>s</em><font size="-1"><sub>2</sub></font>)
denote the change in fitness for an individual following
strategy <em>s</em><font size="-1"><sub>1</sub></font> against an
opponent following strategy
<em>s</em><font size="-1"><sub>2</sub></font>, and let
<em>F</em>(<em>s</em>) denote the total fitness of an individual
following strategy <em>s</em>; furthermore, suppose that each
individual in the population has an initial fitness
of <em>F</em><font size="-1"><sub>0</sub></font>. If σ is an
evolutionarily stable strategy and μ a mutant attempting to invade
the population, then</p>

<blockquote><em>F</em>(σ) = <em>F</em><sub>0</sub> +
(1−<em>p</em>)Δ<em>F</em>(σ,σ)
+ <em>p</em>Δ<em>F</em>(σ,μ)

<p>

<em>F</em>(μ) = <em>F</em><sub>0</sub> +
(1−<em>p</em>)Δ<em>F</em>(μ,σ)
+ <em>p</em>Δ<em>F</em>(μ,μ)</p>
</blockquote>

<p>

where <em>p</em> is the proportion of the population following the
mutant strategy
 μ.</p>

<p>

Since σ is evolutionarily stable, the fitness of an individual
following σ must be greater than the fitness of an individual
following μ (otherwise the mutant following μ would be able to
invade), and so <em>F</em>(σ) &gt; <em>F</em>(μ). Now,
as <em>p</em> is very close to 0, this requires that <em>either</em>
that</p>

<blockquote>Δ<em>F</em>(σ,σ) &gt;
 Δ<em>F</em>(μ,σ)</blockquote>

<em>or</em> that 

<blockquote>Δ<em>F</em>(σ,σ) =
 Δ<em>F</em>(μ,σ) and
 Δ<em>F</em>(σ,μ) &gt;
 Δ<em>F</em>(μ,μ)</blockquote>

(This is the definition of an ESS that Maynard Smith and Price give.)
In other words, what this means is that a strategy σ is an ESS
if one of two conditions holds: (1) σ does better playing
against σ than any mutant does playing against σ, or (2)
some mutant does just as well playing against σ as σ, but
σ does better playing against the mutant than the mutant does.

<p>

Given this characterization of an evolutionarily stable strategy,
one can readily confirm that, for the Hawk-Dove game, the strategy Dove
is not evolutionarily stable because a pure population of Doves can be
invaded by a Hawk mutant. If the value <em>V</em> of the resource is
greater than the cost <em>C</em> of injury (so that it is worth risking
injury in order to obtain the resource), then the strategy Hawk is
evolutionarily stable. In the case where the value of the resource is
<em>less</em> than the cost of injury, there is no evolutionarily
stable strategy if individuals are restricted to following pure
strategies, although there is an evolutionarily stable strategy if
players may use mixed
 strategies.<sup>[<a href="notes.html#1" name="note-1">1</a>]</sup></p>

<p>
In the years following the original work of Maynard Smith and Price,
alternate analytic solution concepts have been proposed.  Of these,
two important ones are the idea of an <i>evolutionarily stable set</i>
(see Thomas 1984, 1985a,b), and the idea of a “limit ESS” (see Selten
1983, 1988).  The former provides a setwise generalization of the
concept of an evolutionarily stable strategy, and the latter extends
the concept of an evolutionarily stable strategy to the context of
two-player extensive form games.
</p>

<h3><a name="SpeDynForPop">2.2 Specifying dynamics for the population</a></h3>

<p>

As an example of the second approach, consider the well-known
Prisoner's Dilemma. In this game, individuals choose one of two
strategies, typically called “Cooperate” and
“Defect.” Here is the general form of the payoff matrix
for the prisoner's dilemma:</p>

<blockquote>
<table border="0">
<tbody><tr>
<td></td>
<td align="center"><strong>Cooperate</strong></td>
<td align="center"><strong>Defect</strong></td>
</tr>

<tr>
<td><strong>Cooperate</strong></td>
<td align="center">(<em>R,R′</em>)</td>
<td align="center">(<em>S,T′</em>)</td>
</tr>

<tr>
<td><strong>Defect</strong></td>
<td align="center">(<em>T,S′</em>)</td>
<td align="center">(<em>P,P′</em>)</td>
</tr>
</tbody></table>

<br />
<strong>Figure 2:</strong> Payoff Matrix for the Prisoner's Dilemma.
<br />
 Payoffs listed as (row, column).

</blockquote>

<p>where <em>T</em> &gt; <em>R</em> &gt; <em>P</em> &gt; <em>S</em> and
<em>T</em>′ &gt; <em>R</em>′ &gt; <em>P</em>′ &gt;
<em>S</em>′. (This form does not require that the payoffs for
each player be symmetric, only that the proper ordering of the payoffs
obtains.) In what follows, it will be assumed that the payoffs for the
Prisoner's Dilemma are the same for everyone in the population.</p>
 
<p>

How will a population of individuals that repeatedly plays the
Prisoner's Dilemma evolve? We cannot answer that question without
introducing a few assumptions concerning the nature of the population.
First, let us assume that the population is quite large. In this case,
we can represent the state of the population by simply keeping track of
what proportion follow the strategies Cooperate and Defect. Let
<em>p<sub>c</sub></em> and <em>p<sub>d</sub></em> denote these
proportions. Furthermore, let us denote the average fitness of
cooperators and defectors by <em>W<sub>C</sub></em> and
<em>W<sub>D</sub></em>, respectively, and let
 <span style="text-decoration:overline;"><em>W</em></span>
 denote the average
fitness of the entire population. The values of <em>W<sub>C</sub></em>,
<em>W<sub>D</sub></em>, and
 <span style="text-decoration:overline;"><em>W</em></span>
 can be expressed in terms of the population
proportions and payoff values as follows:</p>

<blockquote>

<em>W</em><sub><em>C</em></sub> = <em>F</em><sub>0</sub> +
<em>p</em><sub><em>c</em></sub>Δ<em>F</em>(<em>C,C</em>) +
<em>p</em><sub><em>d</em></sub>Δ<em>F</em>(<em>C,D</em>)

<br />

 <em>W</em><sub><em>D</em></sub> = <em>F</em><sub>0</sub> +
<em>p</em><sub><em>c</em></sub>Δ<em>F</em>(<em>D,C</em>) +
<em>p</em><sub><em>d</em></sub>Δ<em>F</em>(<em>D,D</em>)

<br />

 <span style="text-decoration:overline;"><em>W</em></span>
 =
<em>p</em><sub><em>c</em></sub><em>W</em><sub><em>C</em></sub> +
<em>p</em><sub><em>d</em></sub><em>W</em><sub><em>D</em></sub>

</blockquote>

<p>Second, let us assume that the proportion of the population following
the strategies Cooperate and Defect in the next generation is related
to the proportion of the population following the strategies Cooperate
and Defect in the current generation according to the rule:</p>

<blockquote>
<table cellpadding="0">
<tbody><tr valign="middle">
<td align="right"><img alt="image" src="img50.jpg" /></td>
<td>       </td>
<td align="right"><img alt="image" src="img52.jpg" /></td>
</tr>
</tbody></table>
</blockquote>

We can rewrite these expressions in the following form:
 
<blockquote>
<table cellpadding="0">
<tbody><tr valign="middle">
<td align="right"><img alt="image" src="img60.jpg" /></td>
<td>       </td>
<td align="right"><img alt="image" src="img62.jpg" /></td>
</tr>
</tbody></table>
</blockquote>

If we assume that the change in the strategy frequency from one
generation to the next are small, these difference equations may be
approximated by the differential equations:
 
<blockquote>
<table cellpadding="0">
<tbody><tr valign="middle">
<td align="right"><img alt="image" src="img64.jpg" /></td>
<td>       </td>
<td align="right"><img alt="image" src="img66.jpg" /></td>
</tr>
</tbody></table>
</blockquote>

<p>

These equations were offered by Taylor and Jonker (1978) and Zeeman
(1979) to provide continuous dynamics for evolutionary game theory and
are known as the <em>replicator dynamics</em>.</p>

<p>

The replicator dynamics may be used to model a population of
individuals playing the Prisoner's Dilemma. For the Prisoner's Dilemma,
the expected fitness of Cooperating and Defecting are:</p>

<blockquote>
<table>
<tbody><tr>
<td align="right"><em>W</em><sub><em>C</em></sub></td>
<td align="left">= <em>F</em><sub>0</sub> +
<em>p</em><sub><em>c</em></sub>Δ<em>F</em>(<em>C</em>,<em>C</em>) +
<em>p</em><sub><em>d</em></sub>Δ<em>F</em>(<em>C</em>,<em>D</em>)</td>
</tr>

<tr>
<td> </td>
<td align="left">= <em>F</em><sub>0</sub> +
<em>p</em><sub><em>c</em></sub><em>R</em> +
<em>p</em><sub><em>d</em></sub><em>S</em></td>
</tr>
</tbody></table>
</blockquote>

and 

<blockquote>
<table>
<tbody><tr>
<td align="right"><em>W</em><sub><em>D</em></sub></td>
<td align="left">= <em>F</em><sub>0</sub> +
<em>p</em><sub><em>c</em></sub>Δ<em>F</em>(<em>D</em>,<em>C</em>) +
<em>p</em><sub><em>d</em></sub>Δ<em>F</em>(<em>D</em>,<em>D</em>)</td>
</tr>

<tr>
<td> </td>
<td align="left">= <em>F</em><sub>0</sub> +
<em>p</em><sub><em>c</em></sub><em>T</em> +
<em>p</em><sub><em>d</em></sub><em>P</em>.</td>
</tr>
</tbody></table>
</blockquote>

Since <em>T</em> &gt; <em>R</em> and <em>P</em> &gt; <em>S</em>, it
follows that <em>W</em><sub><em>D</em></sub> &gt;
<em>W</em><sub><em>C</em></sub> and hence
<em>W</em><sub><em>D</em></sub> &gt;
 <span style="text-decoration:overline;"><em>W</em></span>
 &gt;
<em>W</em><sub><em>C</em></sub>. This means that 

<blockquote><img alt="image" src="WD-WbarOWbar.jpg" /></blockquote>

and 

<blockquote><img alt="image" src="WC-WbarOWbar.jpg" /></blockquote>

Since the strategy frequencies for Defect and Cooperate in the next
generation are given by 

<blockquote><img alt="image" src="ppd.jpg" /></blockquote>

and 

<blockquote><img alt="image" src="ppc.jpg" /></blockquote>

respectively, we see that over time the proportion of the population
choosing the strategy Cooperate eventually becomes extinct. Figure 3
illustrates one way of representing the replicator dynamical model of
the prisoner's dilemma, known as a state-space diagram. 

<blockquote><img alt="image" src="img82.gif" />
<br />
<strong>Figure 3:</strong> The Replicator Dynamical Model of the
Prisoner's Dilemma</blockquote>

<p>

We interpret this diagram as follows: the leftmost point represents
the state of the population where everyone defects, the rightmost point
represents the state where everyone cooperates, and intermediate points
represent states where some proportion of the population defects and
the remainder cooperates. (One maps states of the population onto
points in the diagram by mapping the state when <em>N</em>% of the
population defects onto the point of the line <em>N</em>% of the way to
the leftmost point.) Arrows on the line represent the evolutionary
trajectory followed by the population over time. The open circle at the
rightmost point indicates that the state where everybody cooperates is
an unstable equilibrium, in the sense that if a small portion of the
population deviates from the strategy Cooperate, then the evolutionary
dynamics will drive the population away from that equilibrium. The
solid circle at the leftmost point indicates that the state where
everybody Defects is a stable equilibrium, in the sense that if a small
portion of the population deviates from the strategy Defect, then the
evolutionary dynamics will drive the population back to the original
equilibrium state.</p>

<p>

At this point, one may see little difference between the two
approaches to evolutionary game theory. One can confirm that, for the
Prisoner's Dilemma, the state where everybody defects is the only ESS.
Since this state is the only stable equilibrium under the replicator
dynamics, the two notions fit together quite neatly: the only stable
equilibrium under the replicator dynamics occurs when everyone in the
population follows the only ESS. In general, though, the relationship
between ESSs and stable states of the replicator dynamics is more
complex than this example suggests. Taylor and Jonker (1978), as well
as Zeeman (1979), establish conditions under which one may infer the
existence of a stable state under the replicator dynamics given an
evolutionarily stable strategy. Roughly, if only two pure strategies
exist, then given a (possibly mixed) evolutionarily stable strategy,
the corresponding state of the population is a stable state under the
replicator dynamics. (If the evolutionarily stable strategy is a mixed
strategy <em>S</em>, the corresponding state of the population is the
state in which the proportion of the population following the first
strategy equals the probability assigned to the first strategy by
<em>S</em>, and the remainder follow the second strategy.) However,
this can fail to be true if more than two pure strategies exist.</p>

<p>

The connection between ESSs and stable states under an evolutionary
dynamical model is weakened further if we do not model the dynamics by
the replicator dynamics. For example, suppose we use a local
interaction model in which each individual plays the prisoner's dilemma
with his or her neighbors. Nowak and May (1992, 1993), using a spatial
model in which local interactions occur between individuals occupying
neighboring nodes on a square lattice, show that stable population
states for the prisoner's dilemma depend upon the specific form of the
payoff
 matrix.<sup>[<a href="notes.html#2" name="note-2">2</a>]</sup></p>

<p>

When the payoff matrix for the population has the values <em>T</em>
= 2.8, <em>R</em> = 1.1, <em>P</em> = 0.1, and <em>S</em> = 0, the
evolutionary dynamics of the local interaction model agree with those
of the replicator dynamics, and lead to a state where each individual
follows the strategy Defect--which is, as noted before, the only
evolutionarily stable strategy in the prisoner's dilemma. The figure
below illustrates how rapidly one such population converges to a state
where everyone defects.</p>

<!--pdf include
<br/>
<br/>
<br/>
pdf include-->

<blockquote>
<table cellpadding="3">
<tbody><tr>
<td align="center"><img alt="image" width="136" align="bottom" border="1" src="img91.gif" /></td>
<td align="center"><img alt="image" width="136" align="bottom" border="1" src="img92.gif" /></td>
<td align="center"><img alt="image" width="136" align="bottom" border="1" src="img93.gif" /></td>
</tr>

<tr>
<td align="center">Generation 1</td>
<td align="center">Generation 2</td>
<td align="center">Generation 3</td>
<td align="center"> </td>
</tr>

<tr>
<td align="center"><img alt="image" width="141" height="141" align="bottom" border="1" src="img94.gif" /></td>
<td align="center"><img alt="image" width="141" height="141" align="bottom" border="1" src="img95.gif" /></td>
<td align="center"><img alt="image" width="141" height="141" align="bottom" border="0" src="img96.gif" /></td>
</tr>

<tr>
<td align="center">Generation 4</td>
<td align="center">Generation 5</td>
<td align="center">Generation 6</td>
</tr>
</tbody></table>

<br />
<strong>Figure 4:</strong> Prisoner's Dilemma: All Defect
<br />
 <a href="pd-defect.gif">[View a movie of this model]</a></blockquote>

<p>However, when the payoff matrix has values of <em>T</em> = 1.2,
<em>R</em> = 1.1, <em>P</em> = 0.1, and <em>S</em> = 0, the
evolutionary dynamics carry the population to a stable cycle
oscillating between two states. In this cycle cooperators and defectors
coexist, with some regions containing “blinkers” oscillating between
defectors and cooperators (as seen in generation 19 and 20). </p>

<table cellpadding="3">
<tbody><tr>
<td align="center"><img alt="image" width="136" align="bottom" border="1" src="img101.gif" /></td>
<td align="center"><img alt="image" width="136" align="bottom" border="1" src="img102.gif" /></td>
<td align="center"><img alt="image" width="136" align="bottom" border="1" src="img103.gif" /></td>
<td align="center"><img alt="image" width="136" align="bottom" border="1" src="img104.gif" /></td>
</tr>

<tr>
<td align="center">Generation 1</td>
<td align="center">Generation 2</td>
<td align="center">Generation 19</td>
<td align="center">Generation 20</td>
</tr>
</tbody></table>

<br />
<strong>Figure 5:</strong> Prisoner's Dilemma: Cooperate
<br />
 <a href="pd-cooperate.gif">[View a movie of this model]</a>

<p>Notice that with these particular settings of payoff values, the
evolutionary dynamics of the local interaction model differ
significantly from those of the replicator dynamics. Under these
payoffs, the stable states have no corresponding analogue in either the
replicator dynamics nor in the analysis of evolutionarily stable
strategies. </p>

<p>

A phenomenon of greater interest occurs when we choose payoff values
of <em>T</em> = 1.61, <em>R</em> = 1.01, <em>P</em> = 0.01, and
<em>S</em> = 0. Here, the dynamics of local interaction lead to a
world constantly in flux: under these values regions occupied
predominantly by Cooperators may be successfully invaded by Defectors,
and regions occupied predominantly by Defectors may be successfully
invaded by Cooperators. In this model, there is no “stable strategy” in
the traditional dynamical
 sense.<sup>[<a href="notes.html#3" name="note-3">3</a>]</sup></p>

<table cellpadding="3">
<tbody><tr>
<td align="center"><img alt="image" width="136" align="bottom" border="1" src="img111.gif" /></td>
<td align="center"><img alt="image" width="136" align="bottom" border="1" src="img112.gif" /></td>
<td align="center"><img alt="image" width="136" align="bottom" border="1" src="img113.gif" /></td>
<td align="center"><img alt="image" width="136" align="bottom" border="1" src="img114.gif" /></td>
</tr>

<tr>
<td align="center">Generation 1</td>
<td align="center">Generation 3</td>
<td align="center">Generation 5</td>
<td align="center">Generation 7</td>
</tr>

<tr>
<td align="center"><img alt="image" width="136" align="bottom" border="1" src="img115.gif" /></td>
<td align="center"><img alt="image" width="136" align="bottom" border="1" src="img116.gif" /></td>
<td align="center"><img alt="image" width="136" align="bottom" border="1" src="img117.gif" /></td>
<td align="center"><img alt="image" width="136" align="bottom" border="1" src="img118.gif" /></td>
</tr>

<tr>
<td align="center">Generation 9</td>
<td align="center">Generation 11</td>
<td align="center">Generation 13</td>
<td align="center">Generation 15</td>
</tr>
</tbody></table>

<br />
<strong>Figure 6:</strong> Prisoner's Dilemma: Chaotic
<br />
 <a href="pd-chaotic.gif">[view a movie of this model]</a>

<p>

These models demonstrate that, although numerous cases exist in
which both approaches to evolutionary game theory arrive at the same
conclusion regarding which strategies one would expect to find present
in a population, there are enough differences in the outcomes of the
two modes of analysis to justify the development of each program.</p>

<h2><a name="WhyEvoGamThe">3. Why Evolutionary Game Theory?</a></h2>

Although evolutionary game theory has provided numerous insights to
particular evolutionary questions, a growing number of social
scientists have become interested in evolutionary game theory in hopes
that it will provide tools for addressing a number of deficiencies in
the traditional theory of games, three of which are discussed below. 

<h3><a name="EquSelPro">3.1 The equilibrium selection problem</a></h3>

The concept of a Nash equilibrium (see the entry on
 <a href="../game-theory/">game theory</a>)
 has been the most used solution
concept in game theory since its introduction by John Nash in 1950. A
selection of strategies by a group of agents is said to be in a Nash
equilibrium if each agent's strategy is a best-response to the
strategies chosen by the other players. By best-response, we mean that
no individual can improve her payoff by switching strategies unless at
least one other individual switches strategies as well. This need not
mean that the payoffs to each individual are optimal in a Nash
equilibrium: indeed, one of the disturbing facts of the prisoner's
dilemma is that the only Nash equilbrium of the game--when both agents
defect--is
 suboptimal.<sup>[<a href="notes.html#4" name="note-4">4</a>]</sup>
 
<p>

Yet a difficulty arises with the use of Nash equilibrium as a
solution concept for games: if we restrict players to using pure
strategies, not every game has a Nash equilbrium. The game “Matching
Pennies” illustrates this problem.</p>

<blockquote>
<table>
<tbody><tr>
<td align="left"></td>
<td align="center"><strong>Heads</strong></td>
<td align="center"><strong>Tails</strong></td>
</tr>

<tr>
<td align="left"><strong>Heads</strong></td>
<td align="center">(0,1)</td>
<td align="center">(1,0)</td>
</tr>

<tr>
<td align="left"><strong>Tails</strong></td>
<td align="center">(1,0)</td>
<td align="center">(0,1)</td>
</tr>
</tbody></table>

<br />
 <strong>Figure 7:</strong> Payoff matrix for the game of Matching
Pennies
<br />
 (Row wins if the two coins do not match, whereas Column wins if the
two coins match).</blockquote>

<p>

While it is true that every noncooperative game in which players may
use mixed strategies has a Nash equilibrium, some have questioned the
significance of this for real agents. If it seems appropriate to
require rational agents to adopt only pure strategies (perhaps because
the cost of implementing a mixed strategy runs too high), then the game
theorist must admit that certain games lack solutions.</p>

<p>

A more significant problem with invoking the Nash equilibrium as the
appropriate solution concept arises because games exist which have
multiple Nash equilibria (see the section on
 <a href="../game-theory/index.html#SolConEqu">Solution Concepts and Equilibria</a>,
 in the entry on game theory). When there are several
different Nash equilibria, how is a rational agent to decide which of
the several equilibria is the “right one” to settle
 upon?<sup>[<a href="notes.html#5" name="note-5">5</a>]</sup>
 Attempts to resolve this problem have produced a number of possible
refinements to the concept of a Nash equilibrium, each refinement
having some intuitive purchase. Unfortunately, so many refinements of
the notion of a Nash equilibrium have been developed that, in many
games which have multiple Nash equilibria, each equilibrium could be
justified by some refinement present in the literature. The problem
has thus shifted from choosing among multiple Nash equilibria to
choosing among the various refinements. Some (see Samuelson (1997),
<em>Evolutionary Games and Equilibrium Selection</em>) hope that
further development of evolutionary game theory can be of service in
addressing this issue.</p>

<h3><a name="ProHypAge">3.2 The problem of hyperrational agents</a></h3>

The traditional theory of games imposes a very high rationality
requirement upon agents. This requirement originates in the development
of the theory of utility which provides game theory's underpinnings
(see Luce (1950) for an introduction). For example, in order to be able
to assign a cardinal utility function to individual agents, one
typically assumes that each agent has a well-defined, consistent set of
preferences over the set of “lotteries” over the outcomes which may
result from individual choice. Since the number of different lotteries
over outcomes is uncountably infinite, this requires each agent to have
a well-defined, consistent set of uncountably infinitely many
preferences. 

<p>

Numerous results from experimental economics have shown that these
strong rationality assumptions do not describe the behavior of real
human subjects. Humans are rarely (if ever) the hyperrational agents
described by traditional game theory. For example, it is not uncommon
for people, in experimental situations, to indicate that they prefer
<em>A</em> to <em>B</em>, <em>B</em> to <em>C</em>, and <em>C</em> to
<em>A</em>. These “failures of the transitivity of preference” would
not occur if people had a well-defined consistent set of preferences.
Furthermore, experiments with a class of games known as a “beauty
pageant” show, quite dramatically, the failure of common knowledge
assumptions typically invoked to solve
 games.<sup>[<a href="notes.html#6" name="note-6">6</a>]</sup>
 Since evolutionary game
theory successfully explains the predominance of certain behaviors of
insects and animals, where strong rationality assumptions clearly fail,
this suggests that rationality is not as central to game theoretic
analyses as previously thought. The hope, then, is that evolutionary
game theory may meet with greater success in describing and predicting
the choices of human subjects, since it is better equipped to handle
the appropriate weaker rationality assumptions.</p>

<h3><a name="LacDynTheTraTheGam">3.3 The lack of a dynamical theory in the traditional theory of games</a></h3>

<p>At the end of the first chapter of <em>Theory of Games and Economic
Behavior</em>, von Neumann and Morgenstern write: </p>
 
<blockquote>We repeat most emphatically that our theory is thoroughly
static. A dynamic theory would unquestionably be more complete and
therefore preferable. But there is ample evidence from other branches
of science that it is futile to try to build one as long as the static
side is not thoroughly understood. (Von Neumann and Morgenstern, 1953,
p. 44)</blockquote>

<p>The theory of evolution is a dynamical theory, and the second approach
to evolutionary game theory sketched above explicitly models the
dynamics present in interactions among individuals in the population.
Since the traditional theory of games lacks an explicit treatment of
the dynamics of rational deliberation, evolutionary game theory can be
seen, in part, as filling an important lacuna of traditional game
theory. </p>

<p>

One may seek to capture some of the dynamics of the decision-making
process in traditional game theory by modeling the game in its
extensive form, rather than its normal form. However, for most games of
reasonable complexity (and hence interest), the extensive form of the
game quickly becomes unmanageable. Moreover, even in the extensive form
of a game, traditional game theory represents an individual's strategy
as a specification of what choice that individual would make at each
information set in the game. A selection of strategy, then, corresponds
to a selection, prior to game play, of what that individual will do at
any possible stage of the game. This representation of strategy
selection clearly presupposes hyperrational players and fails to
represent the process by which one player observes his opponent's
behavior, learns from these observations, and makes the best move in
response to what he has learned (as one might expect, for there is no
need to model learning in hyperrational individuals). The inability to
model the dynamical element of game play in traditional game theory,
and the extent to which evolutionary game theory naturally incorporates
dynamical considerations, reveals an important virtue of evolutionary
game theory.</p>

<h2><a name="AppEvoGamThe">4. Applications of Evolutionary Game Theory</a></h2>

<p>Evolutionary game theory has been used to explain a number of
aspects of human behavior.  A small sampling of topics which have been
analysed from the evolutionary perspective include:
<b>altruism</b> (Fletcher and Zwick, 2007; Gintis <em>et al</em>.,
2003; Sanchez and Cuesta, 2005; Trivers, 1971), <b>behavior in public
goods game</b> (Clemens and Riechmann, 2006; Hauert, 2006;
Hauert <em>et al</em>., 2002, 2006; Huberman and Glance,
1995), <b>empathy</b> (Page and Nowak, 2002; Fishman, 2006), <b>human
culture</b> (Enquist and Ghirlanda, 2007; Enquist <em>et al</em>.,
2008), <b>moral behaviour</b> (Alexander, 2007; Boehm, 1982; Harms and
Skyrms, 2008; Skyrms 1996, 2004), <b>private property</b> (Gintis,
2007), <b>signaling systems and other proto-linguistic behaviour</b>
(Barrett, 2007; Hausken and Hirshleirfer, 2008; Hurd, 1995; Jager,
2008; Nowak <em>et al</em>., 1999; Pawlowitsch, 2007, 2008; Skyrms,
forthcoming; Zollman, 2005), <b>social learning</b> (Kameda and
Nakanishi, 2003; Nakahashi, 2007; Rogers, 1988; Wakano and Aoki, 2006;
Wakano <em>et al</em>., 2004), and <b>social norms</b> (Axelrod, 1986;
Bicchieri, 2006; Binmore and Samuelson, 1994; Chalub <em>et al</em>.,
2006; Kendal <em>et al</em>., 2006; Ostrum, 2000). </p>

<p>The following subsections provide a brief illustration of the use
of evolutionary game theoretic models to explain two areas of human
behavior.  The first concerns the tendency of people to share equally
in perfectly symmetric situations.  The second shows how populations
of pre-linguistic individuals may coordinate on the use of a simple
signaling system even though they lack the ability to communicate.
These two models have been pointed to as preliminary explanations of
our sense of fairness and language, respectively.  They were selected
for inclusion here primarily because of the relative simplicity of the
model and apparent success at explaining the phenomenon in
question.</p>

<h3><a name="SenFai">4.1 A sense of fairness</a></h3>

<p>
One natural game to use for investigating the evolution of fairness
is <em>divide-the-cake</em> (this is the simplest version of the Nash
bargaining game). In chapter 1 of <em>Evolution of the Social
Contract</em>, Skyrms presents the problem as follows:</p>

<blockquote>
Here we start with a very simple problem; we are to divide a chocolate
cake between us. Neither of us has any special claim as against the
other. Out positions are entirely symmetric. The cake is a windfall
for us, and it is up to us to divide it. But if we cannot agree how to
share it, the cake will spoil and we will get nothing. (Skyrms, 1996,
pp. 3–4)
</blockquote>

<p>More formally, suppose that two individuals are presented with a
resource of size <em>C</em> by a third party. A <em>strategy</em> for
a player, in this game, consists of an amount of cake that he would
like.  The set of possible strategies for a player is thus any amount
between 0 and <em>C</em>.  If the sum of strategies for each player is
less than or equal to <em>C</em>, each player receives the amount he
asked for.  However, if the sum of strategies exceeds <em>C</em>, no
player receives anything.  Figure 8 illustrates the feasible set for
this game.</p>

<blockquote>

<table cellpadding="3">
<tbody><tr>
<td align="center"><img alt="image" width="400" align="bottom" border="1" src="dtd.gif" /></td>
</tr>
</tbody></table>
<br />
<strong>Figure 8:</strong> The feasible set for the game of
Divide-the-Cake.  In this figure, the cake is of size <em>C</em>=10
but all strategies between 0 and 10 inclusive are permitted for either
player (including fractional demands).

</blockquote>

<p>We have a clear intuition that the “obvious” strategy for each
player to select is <em>C/2</em>; the philosophical problem lies in
explaining <em>why</em> agents would choose that strategy rather than
some other one.  Even in the perfectly symmetric situation, answering
this question is more difficult than it first appears.  To see this,
first notice that there are an infinite number of Nash equilibria for
this game.  If player 1 asks for <em>p</em> of the cake, where <em>0
≤ p ≤ C</em>, and player 2 asks for <em>C − p</em>, then
this strategy profile is a Nash equilibrium for any value
of <em>p</em> ∈ [0,C].  (Each player's strategy is a best
response given what the other has chosen, in the sense that neither
player can increase her payoff by changing her strategy.)  However,
the equal split is only one of infinitely many Nash equilibria.</p>

<p>One might propose that both players should choose that strategy
which maximizes their expected payoff on the assumption they are
uncertain as to whether they will be assigned the role of Player 1 or
Player 2.  This proposal, Skyrms notes, is essentially that of
Harsanyi (1953). The problem with this is that if players only care
about their expected payoff, and they think that it is equally likely
that they will be assigned the role of Player 1 or Player 2, then
this, too, fails to select uniquely the equal split.  Consider the
strategy profile ⟨<em>p, C − p</em>⟩ which assigns
Player 1 <em>p</em> slices and Player 2 <em>C − p</em> slices.
If a player thinks it is equally likely that he will be assigned the
role of Player 1 or Player 2, then his expected utility is
½<em>p</em> + ½(<em>C−p</em>) = <em>C</em>/2, for
all values <em>p</em> ∈ [0, <em>C</em>].</p>

<p>Now consider the following evolutionary model: suppose we have a
population of individuals who pair up and repeatedly play the game of
divide-the-cake, modifying their strategies over time in a way which
is described by the replicator dynamics.  For convenience, let us
assume that the cake is divided into 10 equally sized slices and that
each player's strategy conforms to one of the following 11 possible
types: Demand 0 slices, Demand 1 slice, … , Demand 10 slices.
For the replicator dynamics, the state of the population is
represented by a vector
⟨<em>p</em><sub>0</sub>, <em>p</em><sub>1</sub>, …,
<em>p</em><sub>10</sub>⟩ where each <em>p<sub>i</sub></em>
denotes the frequency of the strategy “Demand <em>i</em> slices” in
the population.</p>

<p>The replicator dynamics allows us to model how the distribution of
strategies in the population changes over time, beginning from a
particular initial condition.  Figure 9 below shows two evolutionary
outcomes under the continuous replicator dynamics.  Notice that
although fair division can evolve, as in Figure 9(a), it is not the
only evolutionary outcome, as Figure 9(b) illustrates.</p>

<blockquote>

<table>
<tbody><tr>
<td align="center"><img alt="image" width="500" align="bottom" border="1" src="dtd-fig-1.gif" /></td>
</tr>

<tr>
<td align="center">(a) The evolution of fair division.</td>
</tr>
</tbody></table>

<table>
<tbody><tr>
<td align="center"><img alt="image" width="500" align="bottom" border="1" src="dtd-fig-2.gif" /></td>
</tr>

<tr>
<td align="center">(b) The evolution of an unequal division rule.</td>
</tr>
</tbody></table>

<br />
<strong>Figure 9:</strong> Two evolutionary outcomes under the
continuous replicator dynamics for the game of divide-the-cake.  Of
the eleven strategies present, only three are colour-coded so as to be
identifiable in the plot (see the legend).  The initial conditions for
the solution shown in (a) was the point ⟨0.0544685, 0.236312,
0.0560727, 0.0469244, 0.0562243, 0.0703294, 0.151136, 0.162231,
0.0098273, 0.111366, 0.0451093⟩, and the initial conditions for
the solution shown in (b) was the point ⟨0.410376, 0.107375,
0.0253916, 0.116684, 0.0813494, 0.00573677, 0.0277155, 0.0112791,
0.0163166, 0.191699, 0.00607705⟩.

</blockquote>

<p>Recall that the task at hand was to explain why we think the
“obvious” strategy choice in a perfectly symmetric resource allocation
problem is for both players to ask for half of the resource.  What the
above shows is that, in a population of boundedly rational agents who
modify their behaviours in a manner described by the replicator
dynamics, fair division is one, although not the only, evolutionary
outcome.  The tendency of fair division to emerge, assuming that any
initial condition is equally likely, can be measured by determining
the size of the
 <a href="http://mathworld.wolfram.com/BasinofAttraction.html" target="other">basin of attraction</a>
 of the state where everyone in the population uses 
the strategy Demand 5 slices.  Skyrms (1996) measures the size of the
basin of attraction of fair division
using <a href="http://mathworld.wolfram.com/MonteCarloMethod.html" target="other">Monte Carlo methods</a>,
 finding that fair division evolves roughly 62% of the time.</p>

<p>However, it is important to realise that the replicator dynamics
assumes any pairwise interaction between individuals is equally
likely.  In reality, quite often interactions between individuals
are <em>correlated</em> to some extent.  Correlated interaction can
occur as a result of spatial location (as shown above for the case of
the spatial prisoner's dilemma), the structuring effect of social
relations, or ingroup/outgroup membership effects, to list a few
causes.</p>

<p>When correlation is introduced, the frequency with which fair
division emerges changes drastically. Figure 10 illustrates how the
basin of attraction of All Demand 5 changes as the correlation
coefficient ε increases from 0 to
 0.2.<sup>[<a href="notes.html#7" name="note-7">7</a>]</sup> 
 Once the amount of correlation present in the interactions reaches
ε = 0.2, fair division is virtually an evolutionary certainty.
Note that this does not depend on there only being three strategies
present: allowing for some correlation between interactions increases
the probability of fair division evolving even if the initial
conditions contain individuals using any of the eleven possible
strategies.</p>

<blockquote>

<table cellpadding="3">
<tbody><tr>
<td><img alt="image" align="bottom" width="275" src="nash-4-5-6-simplex-nobox.gif" /></td>
<td><img alt="image" align="bottom" width="275" src="nash-4-5-6-corr-1.gif" /></td>
</tr>

<tr>
<td align="center">(a) ε = 0</td>
<td align="center">(b) ε = 0.1</td>
</tr>
</tbody></table>

<table>
<tbody><tr>
<td><img alt="image" align="bottom" width="300" src="nash-4-5-6-corr-2.gif" /></td>
</tr>

<tr>
<td align="center">(c) ε = 0.2</td>
</tr>
</tbody></table>

<br />
<strong>Figure 10:</strong> Three diagrams showing how, as the amount
of correlation among interactions increases, fair division is more
likely to evolve.
</blockquote>

<p>
What, then, can we conclude from this model regarding the evolution of
fair division?  It all depends, of course, on how accurately the
replicator dynamics models the primary evolutionary forces (cultural
or biological) acting on human populations.  Although the replicator
dynamics are a “simple” mathematical model, it does suffice for
modelling both a type of biological evolution (see Taylor and Jonker,
1978) and a type of cultural evolution (see Börgers and Sarin,
1996; Weibull, 1995).  As Skyrms (1996) notes:</p>

<blockquote>
In a finite population, in a finite time, where there is some random
element in evolution, some reasonable amount of divisibility of the
good and some correlation, we can say that it is likely that something
close to share and share alike should evolve in dividing-the-cake
situations. This is, perhaps, a beginning of an explanation of the
origin of our concept of justice.
</blockquote>

<p>This claim, of course, has not gone without comment.  For a
selection of some discussion see, in particular, D'Arms (1996, 2000);
D'Arms <em>et al</em>., 1998; Danielson (1998); Bicchieri (1999);
Kitcher (1999); Gintis (2000); Harms (2000); Krebs (2000); Alexander
and Skyrms (1999); and Alexander (2000, 2007).</p>

<h3><a name="EmeLan">4.2 The emergence of language.</a></h3>

<p>In his seminal work <em>Convention</em>, David Lewis developed the
idea of sender-receiver games. Such games have been used to explain
how language, and semantic content, can emerge in a community which
originally did not possess any language
 whatsoever.<sup>[<a href="notes.html#8" name="note-8">8</a>]</sup>
 His original definition is as follows (with portions of extraneous
commentary deleted for concision and points enumerated for clarity and
later reference):</p>

<blockquote>
A <em>two-sided signaling problem</em> is a situation <em>S</em>
involving an agent called the <em>communicator</em> and one or more
other agents called the <em>audience</em>, such that it is true that,
and it is common knowledge for the communicator and the audience that:

<ol>

<li>Exactly one of several alternative states of
affairs <em>s</em><sub>1</sub>, …, <em>s<sub>m</sub></em>
holds. The communicator, but not the audience, is in a good position
to tell which one it is.
</li>

<li>Each member of the audience can do any one of several alternative
actions <em>r</em><sub>1</sub>, …, <em>r<sub>m</sub></em>
called <em>responses</em>. Everyone involved wants the audience's
responses to depend in a certain way upon the state of affairs that
holds.  There is a certain one-to-one function <em>F</em> from
{<em>s<sub>i</sub></em>} onto {<em>r<sub>j</sub></em>} such that
everyone prefers that each member of the audience
do <em>F</em>(<em>s<sub>i</sub></em>) on condition
that <em>s<sub>i</sub></em> holds, for each <em>s<sub>i</sub></em>.
</li>

<li>The communicator can do any one of several alternative actions
σ<sub>1</sub>, …, σ<em><sub>n</sub></em>
(<em>n</em> ≥ <em>m</em>) called <em>signals</em>. The audience is
in a good position to tell which one he does.  No one involved has any
preference regarding these actions which is strong enough to outweigh
his preference for the dependence <em>F</em> of audience's responses
upon states of affairs. […]
</li>

<li>A <em>communicator's contingency plan</em> is any possible way in
which the communicator's signal may depend upon the state of affairs
that he observes to hold.  It is a function <em>Fc</em> from
{<em>s<sub>i</sub></em>} into {σ<em><sub>k</sub></em>}. […]
</li>

<li>Similarly, an <em>audience's contingency plan</em> is any possible
way in which the response of a member of the audience may depend upon
the signal he observes the communicator to give. It is a one-to-one
function <em>Fa</em> from part of {σ<sub><em>k</em></sub>} into
{<em>r<sub>j</sub></em>}. […]
</li>

</ol>

<p>Whenever <em>Fc</em> and <em>Fa</em> combine […] to give the
preferred dependence of the audience's response upon the state of
affairs, we call ⟨<em>Fc</em>, <em>Fa</em>⟩ a <em>signaling
system</em>. (Lewis, 1969, pp. 130–132) </p>

</blockquote>

<p>Since the publication of <em>Convention</em>, it is more common to
refer to the communicator as the <em>sender</em> and the members of
the audience as <em>receivers</em>.  The basic idea behind
sender-receiver games is the following: Nature selects which state of
the world obtains.  The person in the role of Sender observes this
state of the world (correctly identifying it), and sends a signal to
the person in the role of Receiver.  The Receiver, upon receipt of
this signal, performs a response.  If what the Receiver does is the
correct response, given the state of the world, then both players
receive a payoff of 1; if the Receiver performed an incorrect
response, then both players receive a payoff of 0.  Notice that, in
this simplified model, no chance of error exists at any stage.  The
Sender always observes the true state of the world and always sends
the signal he intended to send.  Likewise, the Receiver always
receives the signal sent by the Sender (i.e., the channel is not
noisy), and the Receiver always performs the response he intended
to.</p>

<p>Whereas Lewis allowed the “audience” to consist of more than one
person, it is more common to consider sender-receiver games played
between two people, so that there is only a single receiver (or, in
Lewisian terms, a single member of the
 audience).<sup>[<a href="notes.html#9" name="note-9">9</a>]</sup>
 For simplicity, in the following we will consider a two-player,
sender-receiver game with two states of the world
{<em>S</em><sub>1</sub>, <em>S</em><sub>2</sub>}, two signals
{σ<sub>1</sub>, σ<sub>2</sub>}, and two responses
{<em>r</em><sub>1</sub>, <em>r</em><sub>2</sub>}.  (We shall see later
why larger sender-receiver games are increasingly difficult to
analyse.)</p>

<p>Notice that, in point (2) of his definition of sender-receiver
games, Lewis requires two things: that there be a unique best response
to the state of the world (this is what requiring <em>F</em> to be
one-to-one amounts to) and that everyone in the audience agrees that
this is the case.  Since we are considering the case where there is
only a single responder, the second requirement is otiose.  For the
case of two states of the world and two responses, there are only two
ways of assigning responses to states of the world which satisfy
Lewis's requirement.  These are as follows (where <em>X</em>
⇒ <em>Y</em> denotes “in state of the world <em>X</em>, the best
response is to do <em>Y</em>”):</p>

<blockquote>
<ol>
<li>
<em>S</em><sub>1</sub> ⇒ <em>r</em><sub>1</sub>,
<em>S</em><sub>2</sub> ⇒ <em>r</em><sub>2</sub>.
</li>
<li>
<em>S</em><sub>1</sub> ⇒ <em>r</em><sub>2</sub>,
<em>S</em><sub>2</sub> ⇒ <em>r</em><sub>1</sub>.
</li>
</ol>
</blockquote>

<p>It makes no real difference for the model which one of these we
choose, so pick the intuitive one: in state of the
world <em>S<sub>i</sub></em>, the best response
is <em>r<sub>i</sub></em> (i.e., function 1).</p>

<p>A <em>strategy for the sender</em> (what Lewis called a
“communicator's contingency plan”) consists of a function specifying
what signal he sends given the state of the world.  It is, as Lewis
notes, a function from the set of states of the world <em>into</em>
the set of signals.  This means that it is possible that a sender may
send the <em>same</em> signal in two different states of the
world. Such a strategy makes no sense, from a rational point of view,
because the receiver would not get enough information to be able to
identify the correct response for the state of the world.  However, we
do not exclude these strategies from consideration because they are
logically possible strategies.</p>

<p>How many sender strategies are there?  Because we allow for the
possibility of the same signal to be sent for multiple states of the
world, there are two choices for which signal to send given
state <em>S</em><sub>1</sub> and two choices for which signal to send
given state <em>S</em><sub>2</sub>.  This means there are four
possible sender strategies.  These strategies are as follows (where
'<em>X</em> → <em>Y</em>' means that when the state of the world
is <em>X</em> the sender will send signal <em>Y</em>):</p>

<blockquote>
<b>Sender 1: </b>
<em>S</em><sub>1</sub> → σ<sub>1</sub>,
<em>S</em><sub>2</sub> → σ<sub>1</sub>. 
<br />
<b>Sender 2: </b>
<em>S</em><sub>1</sub> → σ<sub>1</sub>,
<em>S</em><sub>2</sub> → σ<sub>2</sub>.
<br />
<b>Sender 3: </b>
<em>S</em><sub>1</sub> → σ<sub>2</sub>,
<em>S</em><sub>2</sub> → σ<sub>1</sub>.
<br />
<b>Sender 4: </b>
<em>S</em><sub>1</sub> → σ<sub>2</sub>,
<em>S</em><sub>2</sub> → σ<sub>2</sub>.
</blockquote>

<p>What is a strategy for a receiver?  Here, it proves useful to
deviate from Lewis's original definition of the “audience's
contingency plan”. Instead, let us take a receiver's strategy to be a
function from the set of signals into the set of responses.  As in the
case of the sender, we allow the receiver to perform the same response
for more than one signal.  By symmetry, this means there are <b>4</b>
possible receiver strategies.  These receiver strategies are:</p>

<blockquote>
<b>Receiver 1: </b>
σ<sub>1</sub> → <em>r</em><sub>1</sub>,
σ<sub>2</sub> → <em>r</em><sub>1</sub>.
<br />
<b>Receiver 2: </b>
σ<sub>1</sub> → <em>r</em><sub>1</sub>,
σ<sub>2</sub> → <em>r</em><sub>2</sub>.
<br />
<b>Receiver 3: </b>
σ<sub>1</sub> → <em>r</em><sub>2</sub>,
σ<sub>2</sub> → <em>r</em><sub>1</sub>.
<br />
<b>Receiver 4: </b>
σ<sub>1</sub> → <em>r</em><sub>2</sub>,
σ<sub>2</sub> → <em>r</em><sub>2</sub>.
<br />
</blockquote>

<p>If the roles of Sender and Receiver are permanently assigned to
individuals — as Lewis envisaged — then there are only two possible
signaling systems: ⟨Sender 2, Receiver 2⟩ and ⟨Sender
3, Receiver 3⟩.  All other possible combinations of strategies
result in the players failing to coordinate. The coordination failure
occurs because the Sender and Receiver only pair the appropriate
action with the state of the world in one instance, as with
⟨Sender 1, Receiver 1⟩, or not at all, as with ⟨Sender
2, Receiver 3⟩.</p>

<p>What if the roles of Sender and Receiver are not permanently
assigned to individuals? That is, what if nature flips a coin and
assigns one player to the role of Sender and the other player to the
role of Receiver, and then has them play the game? In this case, a
player's strategy needs to specify what he will do when assigned the
role of Sender, as well as what he will do when assigned the role of
Receiver.  Since there are four possible strategies to use as Sender
and four possible strategies to use as Receiver, this means that there
are a total of <b>16</b> possible strategies for the sender-receiver
game when roles are not permanently assigned to individuals.  Here, a
player's strategy consists of an ordered pair (Sender <em>X</em>,
Receiver <em>Y</em>), where <em>X</em>, <em>Y</em> ∈ {1, 2, 3,
4}.</p>

<p>It makes a difference whether one considers the roles of Sender and
Receiver to be permanently assigned or not. If the roles are assigned
at random, there are four signaling systems amongst two
 players<sup>[<a href="notes.html#10" name="note-10">10</a>]</sup>:</p>

<ol>
<li><b>Player 1: </b> (Sender 2, Receiver 2), <b>Player 2: </b> (Sender 2, Receiver 2)</li>
<li><b>Player 1: </b> (Sender 3, Receiver 3), <b>Player 2: </b> (Sender 3, Receiver 3)</li>
<li><b>Player 1: </b> (Sender 2, Receiver 3), <b>Player 2: </b> (Sender 3, Receiver 2)</li>
<li><b>Player 1: </b> (Sender 3, Receiver 2), <b>Player 2: </b> (Sender 2, Receiver 3)</li>
</ol>

<p>
Signaling systems 3 and 4 are curious.  System 3 is a case where, for
example, I speak in French but listen in German, and you speak German
but listen in French.  (System 4 swaps French and German for both you
and me.)  Notice that in systems 3 and 4 the players are able to
correctly coordinate the response with the state of the
world <em>regardless</em> of who gets assigned the role of Sender or
Receiver.</p>

<p>The problem, of course, with signaling systems 3 and 4 is that
neither Player 1 nor Player 2 would do well when pitted against a
clone of himself.  They are cases where the signaling system would not
work in a population of players who are pairwise randomly assigned to
play the sender-receiver game.  In fact, it is straightforward to show
that the strategies (Sender 2, Receiver 2) and (Sender 3, Receiver 3)
are the only evolutionarily stable strategies (see Skyrms 1996,
89–90).</p>

<p>As a first approach to the dynamics of sender-receiver games, let
us restrict attention to the four strategies (Sender 1, Receiver 1),
(Sender 2, Receiver 2), (Sender 3, Receiver 3), and (Sender 4,
Receiver 4).  Figure 11 illustrates the state space under the
continuous replicator dynamics for the sender-receiver game consisting
of two states of the world, two signals, and two responses, where
players are restricted to using one of the previous four strategies.
One can see that evolution leads the population in almost all
 cases<sup>[<a href="notes.html#11" name="note-11">11</a>]</sup>
 to converge to one of the two signaling
 systems.<sup>[<a href="notes.html#12" name="note-12">12</a>]</sup></p>

<blockquote>
<table cellpadding="3">
<tbody><tr>
<td><img alt="image" align="bottom" width="275" src="sr-N2-fig01.gif" /></td>
<td><img alt="image" align="bottom" width="275" src="sr-N2-fig02.gif" /></td>
</tr>

<tr>
<td><img alt="image" align="bottom" width="300" src="sr-N2-fig03.gif" /></td>
</tr>
</tbody></table>
<br />
<strong>Figure 11:</strong> The evolution of signaling systems.  
</blockquote>

<p>
Figure 12 illustrates the outcome of one run of the replicator
dynamics (for a single population model) where all sixteen possible
strategies are represented. We see that eventually the population, for
this particular set of initial conditions, converges to one of the
pure Lewisian signalling systems identified above.</p>

<blockquote>
<table cellpadding="3">
<tbody><tr>
<td align="center">
<img alt="image" align="bottom" width="550" src="sender-receiver-1.gif" />
</td>
</tr>
</tbody></table>
<br />
<strong>Figure 12:</strong> The evolution of a signalling system under the replicator dynamics.
</blockquote>

<p>
When the number of states of the world, the number of signals, and the
number of actions increase from 2, the situation rapidly becomes much
more complex. If there are <em>N</em> states of the world, <em>N</em>
signals, and <em>N</em> actions, the total number of possible
strategies equals <em>N<sup>2N</sup></em>. For <em>N</em>=2, this
means there are 16 possible strategies, as we have
seen. For <em>N</em>=3, there are 729 possible strategies, and a
signalling problem where <em>N</em>=4 has 65,536 possible
strategies. Given this, one might think that it would prove difficult
for evolution to settle upon an optimal signalling system.</p>

<p>
Such an intuition is correct. Hofbauer and Hutteger (2008) show that,
quite often, the replicator dynamics will converge to a suboptimal
outcome in signalling games.  In these suboptimal outcomes,
a <em>pooling</em> or <em>partial pooling</em> equilibrium will
emerge. A pooling equilibrium occurs when the Sender uses the same
signal regardless of the state of the world. A partial pooling
equilibrium occurs when the Sender is capable of differentiating
between some states of the world but not others. As an example of a
partial pooling equilibrium, consider the following strategies for the
case where <em>N=3</em>: Suppose that the Sender sends signal 1 in
state of the world 1, and signal 2 in states of the world 2 and 3.
Furthermore, suppose that the Receiver performs action 1 upon receipt
of signal 1, and action 2 upon receipt of signals 2 and 3. If all
states of the world are equiprobable, this is a partial pooling
equilibrium.  Given that the Sender does not differentiate states of
the world 2 and 3, the Receiver cannot improve his payoffs by
responding differently to signal 2. Given the particular response
behaviour of the Receiver, the Sender cannot improve her payoffs by
attempting to differentiate states of the world 2 and 3.
</p>

<h2><a name="PhiProEvoGamThe">5. Philosophical Problems of Evolutionary Game Theory</a></h2>

The growing interest among social scientists and philosophers in
evolutionary game theory has raised several philosophical questions,
primarily stemming from its application to human subjects. 

<h3><a name="MeaFitCulEvoInt">5.1 The meaning of fitness in cultural evolutionary interpretations</a></h3>

<p>

As noted previously, evolutionary game theoretic models may often be
given both a biological and a cultural evolutionary interpretation. In
the biological interpretation, the numeric quantities which play a role
analogous to “utility” in traditional game theory correspond to the
fitness (typically Darwinian fitness) of
 individuals.<sup>[<a href="notes.html#13" name="note-13">13</a>]</sup>
 How does one
interpret “fitness” in the cultural evolutionary interpretation?</p>

<p>

In many cases, fitness in cultural evolutionary interpretations of
evolutionary game theoretic models directly measures some objective
quantity of which it can be safely assumed that (1) individuals always
want more rather than less and (2) interpersonal comparisons are
meaningful. Depending on the particular problem modeled, money, slices
of cake, or amount of land would be appropriate cultural evolutionary
interpretations of fitness. Requiring that fitness in cultural
evolutionary game theoretic models conform to this interpretative
constraint severely limits the kinds of problems that one can address.
A more useful cultural evolutionary framework would provide a more
general theory which did not require that individual fitness be a
linear (or strictly increasing) function of the amount of some real
quantity, like amount of food.</p>

<p>

In traditional game theory, a strategy's fitness was measured by the
expected utility it had for the individual in question. Yet
evolutionary game theory seeks to describe individuals of limited
rationality (commonly known as “boundedly rational” individuals), and
the utility theory employed in traditional game theory assumes highly
rational individuals. Consequently, the utility theory used in
traditional game theory cannot simply be carried over to evolutionary
game theory. One must develop an alternate theory of utility/fitness,
one compatible with the bounded rationality of individuals, that is
sufficient to define a utility measure adequate for the application of
evolutionary game theory to cultural evolution.</p>

<h3><a name="ExpIrrEvoGamThe">5.2 The explanatory irrelevance of evolutionary game theory</a></h3>

<p>

Another question facing evolutionary game theoretic explanations of
social phenomena concerns the kind of explanation it seeks to give.
Depending on the type of explanation it seeks to provide, are
evolutionary game theoretic explanations of social phenomena irrelevant
or mere vehicles for the promulgation of pre-existing values and
biases? To understand this question, recognize that one must ask
whether evolutionary game theoretic explanations target the etiology of
the phenomenon in question, the persistence of the phenomenon, or
various aspects of the normativity attached to the phenomenon. The
latter two questions seem deeply connected, for population members
typically enforce social behaviors and rules having normative force by
sanctions placed on those failing to comply with the relevant norm; and
the presence of sanctions, if suitably strong, explains the persistence
of the norm. The question regarding a phenomenon's etiology, on the
other hand, can be considered independent of the latter questions.</p>

<p>

If one wishes to explain how some currently existing social
phenomenon came to be, it is unclear why approaching it from the point
of view of evolutionary game theory would be particularily
illuminating. The etiology of any phenomenon is a unique historical
event and, as such, can only be discovered empirically, relying on the
work of sociologists, anthropologists, archaeologists, and the like.
Although an evolutionary game theoretic model may exclude certain
historical sequences as possible histories (since one may be able to
show that the cultural evolutionary dynamics preclude one sequence from
generating the phenomenon in question), it seems unlikely that an
evolutionary game theoretic model would indicate a unique historical
sequence suffices to bring about the phenomenon. An empirical inquiry
would then still need to be conducted to rule out the extraneous
historical sequences admitted by the model, which raises the question
of what, if anything, was gained by the construction of an evolutionary
game theoretic model in the intermediate stage. Moreover, even if an
evolutionary game theoretic model indicated that a single historical
sequence was capable of producing a given social phenomenon, there
remains the important question of why we ought to take this result
seriously. One may point out that since nearly any result can be
produced by a model by suitable adjusting of the dynamics and initial
conditions, all that the evolutionary game theorist has done is provide
one such model. Additional work needs to be done to show that the
underlying assumptions of the model (both the cultural evolutionary
dynamics and the initial conditions) are empirically supported. Again,
one may wonder what has been gained by the evolutionary model--would it
not have been just as easy to determine the cultural dynamics and
initial conditions beforehand, constructing the model afterwards? If
so, it would seem that the contributions made by evolutionary game
theory in this context simply are a proper part of the parent social
science--sociology, anthropology, economics, and so on. If so, then
there is nothing <em>particular</em> about evolutionary game theory
employed in the explanation, and this means that, contrary to
appearances, evolutionary game theory is really irrelevant to the given
explanation.</p>

<p>

If evolutionary game theoretic models do not explain the etiology of
a social phenomenon, presumably they explain the persistence of the
phenomenon or the normativity attached to it. Yet we rarely need an
evolutionary game theoretic model to identify a particular social
phenomenon as stable or persistent as that can be done by observation
of present conditions and examination of the historical records; hence
the charge of irrelevancy is raised again. Moreover, most of the
evolutionary game theoretic models developed to date have provided the
crudest approximations of the real cultural dynamics driving the social
phenomenon in question. One may well wonder why, in these cases, we
should take seriously the stability analysis given by the model;
answering this question would require one engage in an empirical study
as previously discussed, ultimately leading to the charge of
irrelevance again.</p>

<h3><a name="ValLadEvoGamTheExp">5.3 The value-ladenness of evolutionary game theoretic explanations</a></h3>

If one seeks to use an evolutionary game theoretic model to explain the
normativity attached to a social rule, one must explain how such an
approach avoids committing the so-called “naturalistic fallacy” of
inferring an ought-statement from a conjunction of
 is-statements.<sup>[<a href="notes.html#14" name="note-14">14</a>]</sup>
 Assuming that the explanation does not
commit such a fallacy, one argument charges that it must then be the
case that the evolutionary game theoretic explanation merely repackages
certain key value claims tacitly assumed in the construction of the
model. After all, since any argument whose conclusion is a normative
statement must have at least one normative statement in the premises,
any evolutionary game theoretic argument purporting to show how certain
norms acquire normative force must contain--at least implicitly--a
normative statement in the premises. Consequently, this application of
evolutionary game theory does not provide a neutral analysis of the
norm in question, but merely acts as a vehicle for advancing particular
values, namely those smuggled in the premises. 

<p>

This criticism seems less serious than the charge of irrelevancy.
Cultural evolutionary game theoretic explanations of norms need not
“smuggle in” normative claims in order to draw normative conclusions.
The theory already contains, in its core, a proper subtheory having
normative content--namely a theory of rational choice in which
boundedly rational agents act in order to maximize, as best as they
can, their own self-interest. One may challenge the suitability of this
as a foundation for the normative content of certain claims, but this
is a different criticism from the above charge. Although cultural
evolutionary game theoretic models do act as vehicles for promulgating
certain values, they wear those minimal value commitments on their
sleeve. Evolutionary explanations of social norms have the virtue of
making their value commitments explicit and also of showing how other
normative commitments (such as fair division in certain bargaining
situations, or cooperation in the prisoner's dilemma) may be derived
from the principled action of boundedly rational, self-interested
agents.
</p>

</div>

<div id="bibliography">

<h2><a name="Bib">Bibliography</a></h2>

<ul>

<li>Ackley, David and Michael Littman (1994). “Interactions
Between Learning and Evolution,” in Christopher G. Langton,
ed., <em>Artificial Life III</em>. Reading, MA: Addison-Wesley,
pp. 487–509.</li>

<li>Adachi, N. and Matsuo, K. (1991). “Ecological Dynamics Under
Different Selection Rules in Distributed and Iterated Prisoner's
Dilemma Games,” <em>Parallel Problem Solving From Nature</em> (Lecture
Notes in Computer Science: Volume 496), Berlin: Springer-Verlag, pp.
388–394.</li>

<li>Alexander, J. McKenzie (2000). “Evolutionary Explanations of
Distributive Justice,” <em>Philosophy of Science</em>, 67:
490–516.</li>

<li>––– (2007). <em>The Structural Evolution of
Morality</em>, Cambridge: Cambridge University Press.</li>

<li>Alexander, Jason and Brian Skyrms (1999). “Bargaining with
Neighbors: Is Justice Contagious?” <em>Journal of Philosophy</em>,
96 (11): 588–598.</li>

<li>Axelrod, R. (1984). <em>The Evolution of Cooperation</em>. New York:
Basic Books.</li>

<li>––– (1986). “An evolutionary approach to norms,”
<em>American Political Science Review</em>, 80(4): 1095–1111.</li>

<li>Axelrod, Robert M. and Dion, Douglas (1988). ‘The Further
Evolution of Cooperation’, <em>Science</em>, 242 (4884):
1385–1390.</li>

<li>Axelrod, Robert M. and Hamilton, William D. (1981). ‘The Evolution
of Cooperation’, <em>Science</em>, 211 (4489): 1390–1396.</li>

<li>Banerjee, Abhijit V. and Weibull, Joergen W. (1993). “Evolutionary
Selection with Discriminating Players,” Working Paper #375, Research
Institute of Industrial Economics, University of Stockholm.</li>

<li>Barrett, Jeffrey A. (2007). “Dynamic Partitioning and the
Conventionality of Kinds,” <em>Philosophy of Science</em>, 74 (4):
527–546.</li>

<li>Bergin, J. and Lipman, B. (1996). “Evolution with State-Dependent
Mutations,” <em>Econometrica</em>, 64: 943–956. </li>

<li>Bicchieri, Cristina (2006). <em>The Grammar of Society</em>,
Cambridge: Cambridge University Press.</li>

<li>Binmore, Ken and Samuelson, Larry (1991). “Evolutionary Stability in
Repeated Games Played By Finite Automata,” <em>Journal of Economic
Theory</em>, 57: 278–305.</li>

<li>––– (1994). “An Economist's Perspective on the
Evolution of Norms,” <em>Journal of Institutional and Theoretical
Economics</em>, 150 (1): 45–63.</li>

<li>Björnerstedt, J. and Weibull, J. (1993). “Nash Equilibrium and
Evolution by Imitation,” in Arrow, K. and Colombatto, E. (eds.),
<em>Rationality in Economics</em>, New York: Macmillan.</li>

<li>Blume, L. (1993). “The Statistical Mechanics of Strategic
Interaction,” <em>Games and Economic Behaviour</em>, 5: 387–424.</li>

<li>Blume, Lawrence E. (1997). “Population Games,” in W. Brian Arthur,
Steven N. Durlauf, and David A. Lane (eds.), <em>The Economy as an
Evolving Complex System II</em> (SFI Studies in the Sciences of
Complexity: Volume 27), Reading, MA: Addison-Wesley, , pp. 425-460.</li>

<li>Boehm, C. (1982). “The evolutionary development of morality as an
effect of dominance behavior and conflict interference,” <em>Journal
of Social and Biological Structures</em>, 5: 413–421.
</li>

<li>Bögers, Tilman and Sarin, R. (1996). “Naive Reinforcement and
Replicator Dynamics,” Working Paper, Centre for Economic Learning and
Social Evolution, University College London.</li>

<li>––– (1997). “Learning Through Reinforcement and
Replicator Dynamics,” <em>Journal of Economic Theory</em>, 77(1):
1–14.</li>

<li>Boyd, Robert and Lorberbaum, Jeffrey P. (1987). “No Pure Strategy is
Evolutionarily Stable in the Repeated Prisoner's Dilemma Game,”
<em>Nature</em>, 32(7) (May 7): 58–59.</li>

<li>Boylan, Richard T. (1991). “Laws of Large Numbers for Dynamical
Systems with Randomly Matched Individuals,” <em>Journal of Economic
Theory</em>, 57: 473–504.</li>

<li>Busch, Marc L. and Reinhardt, Eric R. (1993). “Nice Strategies in a
World of Relative Gains: The Problem of Co-operation under Anarchy,”
<em>Journal-of-Conflict-Resolution</em>, 37(3): 427-445.</li>

<li>Cabrales, A. and Ponti, G. (1996). “Implementation, Elimination of
Weakly Dominated Strategies and Evolutionary Dynamics,” Working Paper,
Centre for Economic Learning and Social Evolution, University College
London.</li>

<li>Canning, David (1988). “Rationality and Game Theory When Players
are Turing Machines,” ST/ICERD Discussion Paper 88/183, London: London
School of Economics.</li>

<li>Canning, David (1990c). “Rationality, Computability and the Limits
of Game Theory,” Economic Theory Discussion Paper Number 152,
Department of Applied Economics, University of Cambridge, July.</li>

<li>Canning, David (1992). “Rationality, Computability and Nash
Equilibrium,” <em>Econometrica</em>, 60(4): 877–888.</li>

<li>Chalub, F.A.C.C., Santos, F.C. and J.M. Pacheco (2006). “The
evolution of norms,” <em>Journal of Theoretical Biology</em>,
241: 233–240.</li>

<li>Cho, I.-K. and Kreps, David M. (1987). “Signaling Games and
Stable Equilibria,” <em>Quarterly Journal of Economics</em>, 102
(1): 179–221.</li>

<li>Clemens, Christiane and Thomas Riechmann (2006). “Evolutionary
Dynamics in Public Goods Games,” <em>Computational Economics</em>, 28:
399–420.</li>

<li>Cowan, Robin A. and Miller, John H. (1990). “Economic Life on a
Lattice: Some Game Theoretic Results,” Working Paper 90-010, Economics
Research Program, Santa Fe Institute, New Mexico.</li>

<li>D'Arms, Justin, Robert Batterman, and Krzyzstof Górny (1998).
“Game Theoretic Explanations and the Evolution of Justice,”
<em>Philosophy of Science</em>, 65: 76–102.</li>

<li>D'Arms, Justin (1996). “Sex, Fairness, and the Theory of Games,”
<em>Journal of Philosophy</em>, 93 (12): 615–627.</li>

<li>––– (2000). “When Evolutionary Game Theory
Explains Morality, What Does It Explain?” <em>Journal of Consciousness
Studies</em> 7(1–2): 296–299.</li>

<li>Danielson, P. (1992). <em>Artificial Morality: Virtuous Robots for
Virtual Games</em>, London: Routledge.</li>

<li>––– (1998). “Critical Notice: <em>Evolution of the
Social Contract</em>,” <em>Canadian Journal of Philosophy</em>, 28 (4):
627–652.</li>

<li>Dekel, Eddie and Scotchmer, Suzanne (1992). “On the Evolution of
Optimizing Behavior,” <em>Journal of Economic Theory</em>, 57:
392–406.</li>

<li>Eaton, B. C. and Slade, M. E. (1990). “Evolutionary Equilibrium in
Market Supergames,” Discussion Paper 90-30 (November 1989), Department
of Economics, University of British Columbia.</li>

<li>Ellingsen, Tore (1997). “The Evolution of Bargaining Behavior,”
<em>The Quarterly Journal of Economics</em>, 112 (1): 581–602.</li>

<li>Ellison, G. (1993). “Learning, Local Interaction and Coordination,”
<em>Econometrica</em>, 61: 1047–1071.</li>

<li>Enquist, Magnus and Stefano Ghirlanda (2007). “Evolution of Social
Learning Does Not Explain the Origin of Human Cumulative
Culture,” <em>Journal of Theoretical Biology</em>, 246: 129–135.</li>

<li>Enquist, M., Ghirlanda, S., Jarrick, A., and Wachtmeister,
C. A. (2008). “Why Does Human Culture Increase
Exponentially?” <em>Theoretical Population Biology</em>, 74:
46–55.</li>

<li>Epstein, Joshua A. (1998). “Zones of Cooperation in Demographic
Prisoner's Dilemma,” <em>Complexity</em>, 4 (2): 36–48.</li>

<li>Eshel, Ilan, Larry Samuelson, and Avner Shaked (1998). “Altruists,
Egoists, and Hooligans in a Local Interaction Model,” <em>The American
Economic Review</em>, 88 (1): 157–179.</li>

<li>Fishman, Michael A. (2006). “Involuntary defection and the
evolutionary origins of empathy,” <em>Journal of Theoretical
Biology</em>, 242: 873–879.</li>

<li>Fisher, R. A. (1930). <em>The Genetic Theory of Natural
Selection</em>, Oxford, Clarendon Press.</li>

<li>Fletcher, Jeffrey A. and Martin Zwick (2007). “The evolution of
altruism: Game theory in multilevel selection and inclusive
fitness,” <em>Journal of Theoretical Biology</em>, 245: 26–36.</li>

<li>Fogel, David B. (1993). “Evolving Behaviours in the Iterated
Prisoner's Dilemma,” <em>Evolutionary Computation</em>, 1 (1):
77–97.</li>

<li>Forrest, Stephanie and Mayer-Kress, G. (1991). “Genetic Algorithms,
Nonlinear Dynamical Systems, and Global Stability Models,” in L. Davis,
 (ed.), <em>The Handbook of Genetic Algorithms</em>, New York: Van
Nostrand Reinhold.</li>

<li>Foster, Dean and Young, H. Peyton (1990). “Stochastic Evolutionary
Game Dynamics,” <em>Journal of Theoretical Biology</em>, 38:
219–232.</li>

<li>Friedman, Daniel (1991). “Evolutionary Games in Economics,”
<em>Econometrica</em>, 59 (3): 637–666.</li>

<li>Fudenberg, Drew and Maskin, Eric (1990). “Evolution and Cooperation
in Noisy Repeated Games,” <em>American Economic Review (Papers and
Proceedings)</em>, 80 (2): 274–279.</li>

<li>Gintis, Herbert (2000). “Classical Versus Evolutionary Game Theory,”
<em>Journal of Consciousness Studies</em>, 7 (1–2): 300–304.</li>

<li>––– (2007). “The evolution of private
property,” <em>Journal of Economic Behavior &amp; Organization</em>,
64: 1–16.</li>

<li>Gintis, Herbert, Samuel Bowles, Robert Boyd and Ernst Fehr (2003).
“Explaining altruistic behavior in humans,” <em>Evolution and Human
Behavior</em>, 24: 153–172.</li>

<li>Guth, Werner and Kliemt, Hartmut (1994). “Competition or
Co-operation — On the Evolutionary Economics of Trust,
Exploitation and Moral Attitudes,” <em>Metroeconomica</em>, 45:
155–187.</li>

<li>Guth, Werner and Kliemt, Hartmut (1998). “The Indirect Evolutionary
Approach: Bridging the Gap Between Rationality and Adaptation,”
<em>Rationality and Society</em>, 10 (3): 377–399.</li>

<li>Hamilton, W. D. (1963). “The Evolution of Altruistic Behavior,”
<em>The American Naturalist</em>, 97: 354–356.</li>

<li>––– (1964). “The Genetical Evolution of
Social Behavior. I,” <em>Journal of Theoretical Biology</em>, 7:
1–16.</li>

<li>––– (1964). “The Genetical Evolution of
Social Behavior. II,” <em>Journal of Theoretical Biology</em>,
7: 17–52.</li>

<li>Hammerstein, P. and Selten, R. (1994). “Game Theory and
Evolutionary Biology,” in R. Auman and S. Hart
(eds.), <em>Handbook of Game Theory with Economic Applications</em>
(Volume 2), Amsterdam: Elsevier Science, pp.  931–962.</li>

<li>Hansen, R. G. and Samuelson, W. F. (1988). “Evolution in
Economic Games,” <em>Journal of Economic Behavior and
Organization</em>, 10 (3): 315–338.</li>

<li>Harms, William (1997). “Evolution and Ultimatum Bargaining,”
<em>Theory and Decision</em>, 42: 147–175.</li>

<li>––– (2000). “The Evolution of Cooperation
in Hostile Environments,” <em>Journal of Consciousness
Studies</em>, 7 (1–2): 308–313.</li>

<li>Harms, William and Brian Skyrms (2008). “Evolution of Moral Norms,”
in <em>The Oxford Handbook of Philosophy of Biology</em>, Oxford:
Oxford University Press.</li>

<li>Harsanyi, J. (1953). “Cardinal Utility in Welfare Economics and the
Theory of Risk Taking,” <em>Journal of Political Economy</em>, 61:
434–435.</li>

<li>Harrald, Paul G. (in press). “Evolving Behaviour in Repeated Games
via Genetic Algorithms,” in P. Stampoultzsis (ed.), <em>The
Applications Handbook of Genetic Algorithms</em>, Boca Raton, FA: CRC
Publishers.</li>

<li>Hassell, Michael P., Hugh N. Comins, and Robert M. May (1991).
“Spatial structure and chaos in insect population dynamics,”
<em>Nature</em>, 353: 255–258.</li>

<li>Hauert, Christoph (2006). “Spatial Effects in Social
Dilemmas,” <em>Journal of Theoretical Biology</em>, 240:
627–636.</li>

<li>Hauert, Christoph, Franziska Michor, Martin A. Nowak, and Michael
Doebeli (2006). “Synergy and discounting of cooperation in
social dilemmas,” <em>Journal of Theoretical Biology</em>, 239:
195–202.</li>

<li>Hauert, Christoph, Silvia De Monte, Josef Hofbauer and Karl
Sigmund (2002). “Replicator Dynamics for Optional Public Goods
Games,” <em>Journal of Theoretical Biology</em>, 218:
187–194.</li>

<li>Hausken, Kjell, and Jack Hirshleifer (2008). “Truthful
Signalling, the Heritability Paradox, and the Malthusian Equi-Marginal
Principle,” <em>Theoretical Population Biology</em>, 73:
11–23.</li>

<li>Hegselmann, Rainer (1996). “Social Dilemmas in Lineland and
Flatland,” in Liebrand and Messick (eds.), <em>Frontiers in Social
Dilemmas Research</em>, Berlin: Springer, pp. 337–361.</li>

<li>Hiebeler, David (1997). “Stochastic Spatial Models: From Simulations
to Mean Field and Local Structure Approximations,” <em>Journal of
Theoretical Biology</em>, 187: 307–319.</li>

<li>Hines, W. G. (1987). “Evolutionary Stable Strategies: A Review of
Basic Theory,” <em>Theoretical Population Biology</em>,
31: 195–272.</li>

<li>Hirshleifer, Jack and Martinez-Coll, Juan Carlos (1988). “What
Strategies can Support the Evolutionary Emergence of 
 <span style="white-space:nowrap;">Cooperation?,”</span>
<em>Journal of Conflict Resolution</em>, 32 (2): 367–398.</li>

<li>Hirshleifer, Jack and Martinez-Coll, Juan Carlos (1992).
“Selection, Mutation and the Preservation of Diversity in
Evolutionary Games,” Papers on Economics and Evolution, #9202,
edited by the European Study Group for Evolutionary Economics.</li>

<li>Howard, J. V. (1988). “Cooperation in the Prisoner's Dilemma,”
<em>Theory and Decision</em>, 24: 203–213.</li>

<li>Huberman, Bernardo A. and Glance, Natalie S. (1993). “Evolutionary
Games and Computer Simulations,” <em>Proceedings of the National
Academy of Sciences of the USA</em>, 90 (16): 7716–7718.</li>

<li>––– (1995). “The Dynamics of Collective Action,” 
<em>Computational Economics</em>, 8: 27–46.</li>

<li>Hurd, Peter L. (1995). “Communication in Discrete Action-Response
Games,” <em>Journal of Theoretical Biology</em>, 174: 217–222.</li>

<li>Ikegami, Takashi (1993). “Ecology of Evolutionary Game
Strategies,” in <em>Self Organization and Life: From Simple
Rules to Global Complexity</em> (Proceedings of the Second European
Conference on Artificial Life, Brussels, Belgium 24–26 May
1993), Cambridge, MA: MIT Press, pp. 527–536.</li>

<li>Jäger, Gerhard (2008). “Evolutionary Stability Conditions for
Signaling Games with Costly Signals,” <em>Journal of Theoretical
Biology</em>, 253: 131–141.</li>

<li>Kameda, Tatsuya and Daisuke Nakanishi (2003). “Does social/cultural
learning increase human adaptability? Rogers's question
revisited,” <em>Evolution and Human Behavior</em>, 24: 242–260.</li>

<li>Kandori, Michihiro, Mailath, George J. and Rob, Rafael (1993).
“Learning, Mutation, and Long Run Equilibria in Games,”
<em>Econometrica</em>, 61: 29–56.</li>

<li>Kendal, Jeremy, Marcus W. Feldman, and Kenichi Aoki (2006).
“Cultural coevolution of norm adoption and enforcement when punishers
are rewarded or non-punishers are punished,” <em>Theoretical
Population Biology</em>, 70: 10–25.</li>

<li>Kreps, David M. (1990). <em>Game Theory and Economic Modelling</em>,
Oxford: Clarendon Press.</li>

<li>Kreps, David M. and Fudenberg, Drew (1988). <em>Learning,
Experimentation, and Equilibrium in Games</em>, Cambridge, MA: MIT
Press.</li>

<li>Iwasa, Yoh, Mayuko Nakamaru, and Simon A. Levin (1998).
“Allelopathy of bacteria in a lattice population: Competition between
colicin-sensitive and colicin-producing strains,” <em>Evolutionary
Ecology</em>, 12: 785–802.</li>

<li>Kandori, Michihiro, George J. Mailath, and Rafael Rob (1993).
“Learning, Mutation, and Long Run Equilibria in Games,”
<em>Econometrica</em>, 61(1): 29–56.</li>

<li>Kaneko, Kunihiko and Junji Suzuki (1994). “Evolution to the Edge of
Chaos in an Imitation Game,” in Christopher G. Langton (ed.),
<em>Artificial Life III</em>, Reading, MA: Addison-Wesley,
pp. 43–53.</li>

<li>Kephart, Jeffrey O. (1994). “How Topology Affects Population
Dynamics,” in Christopher G. Langton (ed.), <em>Artificial Life
III</em>, Reading, MA: Addison-Wesley, pp. 447-463.</li>

<li>Kitcher, Philip (1999). “Games Social Animals Play: Commentary on
Brian Skyrms' <em>Evolution of the Social Contract</em>,”
<em>Philosophy and Phenomenological Research</em>, 59(1):
221–228.</li>

<li>Krebs, Dennis (2000). “Evolutionary Games and
Morality,” <em>Journal of Consciousness Studies</em>, 7
(1–2): 313–321.</li>

<li>Levin, B. R. (1988). “Frequency-dependent selection in bacterial
populations,” <em>Philosophical Transactions of the Royal Society of
London</em> (Series B), 319: 469–472.</li>

<li>Lewontin, R. C. (1961). “Evolution and the Theory of Games”
<em>Journal of Theoretical Biology</em>, 1: 382–403.</li>

<li>Liebrand, Wim B. G. and Messick, David M. (eds.) (1996).
<em>Frontiers in Social Dilemmas Research</em>, Berlin:
Springer-Verlag.</li>

<li>Lindgren, Kristian (1990). “Evolution in a Population of Mutating
Strategies,” Preprint 90/22 S, Copenhagen: Nordic Institute for
Theoretical Physics.</li>

<li>Lindgren, Kristian and Nordahl, Mats G. (1993). “Evolutionary
Dynamics of Spatial Games,” in <em>Self Organization and Life: From
Simple Rules to Global Complexity</em> (Proceedings of the Second European
Conference on Artificial Life, Brussels, Belgium 24–26 May 1993),
Cambridge, MA: MIT Press, pp. 604–616.</li>

<li>Lindgren, Kristian and Mats G. Nordahl (1994). “Evolutionary
dynamics of spatial games,” <em>Physica D</em>, 75: 292–309.</li>

<li>Lindgren, K. (1991). “Evolutionary phenomena in simple dynamics,” in
C.G. Langton, J.D. Farmer, S. Rasmussen, and C. Taylor (eds.),
<em>Artificial Life II</em>, Redwood City, CA: Addison-Wesley, pp.
295–312.</li>

<li>Lomborg, Bjorn (1992). “Cooperation in the Iterated Prisoner's
Dilemma,” Papers on Economics and Evolution, #9302, edited by the
European Study Group for Evolutionary Economics.</li>

<li>Lomborg, Bjorn (1996). “Nucleus and Shield: The Evolution of Social
Structure in the Interated Prisoner's Dilemma,” <em>American
Sociological Review</em>, 61: 278–307.</li>

<li>Macy, Michael (1989). “Walking Out of Social Traps: A Stochastic
Learning Model for the Prisoner's Dilemma,” <em>Rationality and
Society</em>, 1 (2): 197–219.</li>

<li>Mailath, George J. (1992). “Introduction: Symposium on Evolutionary
Game Theory,” <em>Journal of Economic Theory</em>, 57: 259–277.</li>

<li>Mailath, George J., Samuelson, Larry and Shaked, Avner (1992).
“Evolution and Endogenous Interaction,” Draft Paper, Department of
Economics, University of Pennsylvania, latest version 24 August
1995.</li>

<li>Matsui, Akihiko (1993). “Evolution and Rationalizability,” Working
Paper: 93–19 (May 1993), Center for Analytic Research in Economics and
the Social Sciences (CARESS), University of Pennsylvania.</li>

<li>Mar, Gary (2000). “Evolutionary Game Theory, Morality, and
Darwinism” <em>Journal of Consciousness Studies</em>, 7 (1–2):
322–326.</li>

<li>May, R. M., Bohoeffer, S. and Nowak, Martin A. (1995). “Spatial
Games and the Evolution of Cooperation,” in F. Moran, A. Moreno,
J.J. Merelo and P. Chacon, P. (eds.), <em>Advances in Artificial Life:
Proceedings of the Third European Conference on Artificial Life
(ECAL95)</em>, Berlin: Sprnger-Verlag, pp. 749-759.</li>

<li>Maynard-Smith, John (1976). “Evolution and the Theory of Games,”
<em>American Scientist</em>, 64 (1): 41–45.</li>

<li>Maynard-Smith, John (1982). <em>Evolution and the Theory of
Games</em>, Cambridge: Cambridge University Press.</li>

<li>Maynard Smith, John and George Price (1973). “The Logic of Animal
Conflict” <em>Nature</em>, 146: 15–18.</li>

<li>Miller, John H. (1988). “The Evolution of Automata in the Repeated
Prisoner's Dilemma,” in <em>Two Essays on the Economics of Imperfect
Information</em>, Ph.D. Dissertation, Department of Economics,
University of Michigan/Ann Arbor.</li>

<li>––– (1996). “The Coevolution of Automata in the Repeated
Prisoner's Dilemma,” <em>Journal of Economic Behavior and
Organization</em>, 29 (1): 87–112.</li>

<li>Miller, John H. and Shubik, Martin (1994). “Some Dynamics of a
Strategic Market Game with a Large Number of Agents,” <em>Journal of
Economics</em>, 60: 1–28.</li>

<li>Miller, J. H. and J. Andreoni (1991). “Can Evolutionary Dynamics
Explain Free Riding in Experiments?” <em>Economic Letters</em>, 36:
9–15.</li>

<li>Nachbar, John H. (1990). “'Evolutionary’ Selection Dynamics
in Games: Convergence and Limit Properties,” <em>International Journal
of Game Theory</em>, 19: 59–89.</li>

<li>Nachbar, John H. (1992). “Evolution in the Finitely Repeated
Prisoner's Dilemma: A Methodological Comment and Some Simulations,”
<em>Journal of Economic Behaviour and Organization</em>,
19 (3): 307–326.</li>

<li>Nakahashi, Wataru (2007). “The Evolution of Conformist
Transmission in Social Learning when the Environment Changes
Periodically,” <em>Theoretical Population Biology</em>, 72:
52–66.</li>

<li>Neyman, A. (1985). “Bounded Complexity Justifies Cooperation in
the Finitely Repeated Prisoner's Dilemma,” <em>Economics Letters</em>,
19: 227–229.</li>

<li>Nowak, Martin A. and May, Robert M. (1992). “Evolutionary Games
and Spatial Chaos,” <em>Nature</em>, 359 (6398): 826–829.</li>

<li>Nowak, Martin A., Joshua B. Plotkin, and David C. Krakauer
(1999). “The Evolutionary Language Game,” <em>Journal of Theoretical
Biology</em>, 200: 147–162.</li>

<li>Nowak, Martin A. and Sigmund, K. (1992). “Tit For Tat in
Heterogenous Populations,” <em>Nature</em>, 359: 250–253.</li>

<li>Nowak, Martin A. and May, Robert M. (1993). “The Spatial Dilemmas
of Evolution,” <em>International Journal of Bifurcation and
Chaos</em>, 3: 35–78.</li>

<li>Nowak, Martin A., Sebastian Bonhoeffer, and Robert M. May (1994).
“More Spatial Games,” <em>International Journal of Bifurcation and
Chaos</em>, 4 (1): 33–56.</li>

<li>Ockenfels, Peter (1993). “Cooperation in Prisoner's Dilemma — An
Evolutionary Approach,” <em>European Journal of Political Economy</em>,
9: 567–579.</li>

<li>Ostrom, Elinor (2000). “Collective Action and the Evolution of
Social Norms,” <em>Journal of Economic Perspectives</em>, 14 (3):
137–158.</li>

<li>Page, K. M. and M. A. Nowak (2002). “Empathy leads to
fairness,” <em>Bulletin of Mathematical Biology</em>, 64:
1101–1116.</li>

<li>Pawlowitsch, C. (2007). “Finite populations choose an optimal
language,” <em>Journal of Theoretical Biology</em>, 249: 606–616.</li>

<li>––– (2008). “Why evolution does not always lead
to an optimal signaling system,” <em>Games and Economic Behavior</em>,
63: 203–226.</li>

<li>Reijnders, L. (1978). “On the Applicability of Game Theory to
Evolution,” <em>Journal of Theoretical Biology</em>, 75 (1):
245–247.</li>

<li>Robles, J. (1998). “Evolution with Changing Mutation Rates,”
<em>Journal of Economic Theory</em>, 79: 207–223. </li>

<li>Robson, Arthur J. (1990). “Efficiency in Evolutionary Games:
Darwin, Nash and the Secret Handshake,” <em>Journal of Theoretical
Biology</em>, 144: 379–396.</li>

<li>Rogers, A. R. (1988). “Does biology constrain culture?”
<em>American Anthropologist</em>, 90: 819–831.</li>

<li>Samuelson, Larry and J. Zhang (1992). “Evolutionary Stability in
Asymmetric Games,” <em>Journal of Economic Theory</em>, 57:
363–391.</li>

<li>Samuelson, Larry (1993). “Does Evolution Eliminate Dominated Strategies?” in
Kenneth G. Binmore, A. Kirman, and P. Tani (eds.), <em>Frontiers of Game
Theory</em>, Cambridge, MA: MIT Press, pp. 213–235.</li>

<li>––– (1997). <em>Evolutionary Games and
Equilibrium Selection</em>. (Series: Economic Learning and Social
Evolution), Cambridge, Massachusetts: MIT Press.</li>

<li>Sánchez, Angel and José A. Cuesta (2005). “Altruism
may arise from individual selection,” <em>Journal of Theoretical
Biology</em>, 235: 233–240.</li>

<li>Schlag, Karl H. (1998). “Why Imitate, and If So, How? A Boundedly
Rational Approach to Multi-armed Bandits,” <em>Journal of Economic
Theory</em>, 78: 130–156.</li>

<li>Schuster, P. and Sigmund, K. (1983). “Replicator Dynamics,”
<em>Journal of Theoretical Biology</em>, 100 (3): 533–538.</li>

<li>Selten, Reinhard (1983). “Evolutionary Stability in Extensive
Two-Person Games,” <em>Mathematical Social Sciences</em>, 5:
269–363.</li>

<li>––– (1988). “Evolutionary Stability in Extensive
Two-Person Games -- Correction and Further Development,” <em>
Mathematical Social Sciences</em>, 16 (3): 223–266.</li>

<li>Selten, Reinhard (ed.) (1991). <em>Game Equilibrium Models I:
Evolution and Game Dynamics</em>, New York: Springer-Verlag.</li>

<li>Selten, Reinhard (1993). “Evolution, Learning, and Economic
Behaviour,” <em>Games and Economic Behaviour</em>, 3 (1):
3–24.</li>

<li>Sinclair, P. J. N. (1990). “The Economics of Imitation,”
<em>Scottish Journal of Political Economy</em>, 37(2):
113–144.</li>

<li>Skyrms, Brian (1992). “Chaos in Game Dynamics,” <em>Journal of
Logic, Language, and Information</em>, 1: 111–130.</li>

<li>––– (1994). “Chaos and the Explanatory
Significance of Equilibrium: Strange Attractors in Evolutionary Game
Dynamics,” in <em>Proceedings of the 1992 PSA</em> (Volume 2),
Philosophy of Science Association, pp. 374–394.</li>

<li>––– (1994a). “Darwin Meets <em>The Logic of
Decision</em>: Correlation in Evolutionary Game
Theory,” <em>Philosophy of Science</em>, 61: 503–528.</li>

<li>––– (1994b). “Sex and Justice,” <em>Journal of
Philosophy</em>, 91: 305–320.</li>

<li>––– (1996). <em>Evolution of the Social
Contract</em>, Cambridge: Cambridge University Press.</li>

<li>––– (1997). “Game Theory, Rationality and
Evolution,” in M. L. Dalla Chiara <em>et al</em>.
(eds.), <em>Structures and Norms in Science</em>, Dordrecht: Kluwer
Academic Publishers, pp. 73–85.</li>

<li>––– (1998). “Salience and symmetry-breaking in
the evolution of convention,” <em>Law and Philosophy</em>, 17:
411–418.</li>

<li>––– (1999). “Précis of <em>Evolution of
the Social Contract</em>,” <em>Philosophy and Phenomenological
Research</em>, 59 (1): 217–220.</li>

<li>––– (2000). “Game Theory, Rationality and
Evolution of the Social Contract,” <em>Journal of Consciousness
Studies</em>, 7 (1–2): 269–284.</li>

<li>––– (2000). “Adaptive Dynamic Models and the
Social Contract,” <em>Journal of Consciousness Studies</em>, 7 (1–2):
335–339.</li>

<li>––– (2004). <em>The Stag Hunt and the Evolution
of Social Structure</em>, Cambridge: Cambridge University Press.</li>

<li>––– (forthcoming). “Evolution of Signaling
Systems with Multiple Senders and Receivers,” <em>Philosophical
Transactions of the Royal Society of London</em> (Series B).</li>

<li>Smale, Steve (1980). “The Prisoner's Dilemma and Dynamical Systems
Associated to Non-cooperative Games,” <em>Econometrica</em>, 48:
1617–1634.</li>

<li>Maynard Smith, John and George Price (1973). “The Logic of Animal
Conflict,” <em>Nature</em>, 246: 15–18.</li>

<li>Maynard Smith, John (1982). <em>Evolution and the Theory of
Games</em>. Cambridge: Cambridge University Press.</li>

<li>Stanley, E. Ann, Dan Ashlock, and Leigh Tesfatsion
(1994). “Iterated Prisoner's Dilemma with Choice and Refusal of
Partners,” in Christopher G. Langton (ed.), <em>Artificial Life
III</em> (Proceedings of the Workshop on Artificial Life, held June
1992 in Santa Fe, New Mexico), Reading, MA: Addison-Wesley, pp.
131–175.</li>

<li>Suleiman, Ramzi and Ilan Fischer (1996). “The Evolution of
Cooperation in a Simulated Inter-Group Conflict,” in Liebrand and
Messick (eds.), <em>Frontiers in Social Dilemmas Research</em>,
Berlin: Springer.</li>

<li>Taylor, Peter D. and Leo B. Jonker (1978). “Evolutionary Stable
Strategies and Game Dynamics,” <em>Mathematical Biosciences</em>, 40:
145–156.</li>

<li>Thomas, B. (1984). “Evolutionary Stability: States and
Strategies,” <em>Theoretical Population Biology</em>, 26: 49–67.</li>

<li>––– (1985a). “Evolutionary Stable Sets in
Mixed-Strategist Models,” <em>Theoretical Population Biology</em>,
28: 332–341.</li>

<li>––– (1985b). “On Evolutionary Stable
Sets,” <em>Journal of Mathematical Biology</em>, 22: 105–115.</li>

<li>Tomochi, Masaki and Mitsuo Kono (1998). “Social Evolution Based on
Prisoner's Dilemma with Generation Dependent Payoff Matrices,”
<em>Research on Policy Studies</em>, 3: 79–91.</li>

<li>Trivers, Robert L. (1971). “The evolution of reciprocal altruism,”
<em>The Quarterly Review of Biology</em>, 46: 35–57.</li>

<li>Vanderschraaf, Peter (2000). “Game Theory, Evolution, and Justice,”
<em>Philosophy and Public Affairs</em>, 28 (4): 325–358.</li>

<li>Vega-Redondo, Fernando (1996). <em>Evolution, Games, and Economic
Behaviour</em>, Oxford: Oxford University Press.</li>

<li>Vega-Redondo, Fernando (1997). “The Evolution of Walrasian
Behavior,” <em>Econometrica</em>, 65 (2): 375–384.</li>

<li>Wakano, Joe Yuichiro, Kenichi Aoki and Marcus W. Feldman
(2004). “Evolution of social learning: a mathematical analysis,”
<em>Theoretical Population Biology</em>, 66: 249–258.</li>

<li>Wakano, Joe Yuichiro and Kenichi Aoki (2006). “A mixed strategy
model for the emergence and intensification of social learning in a
periodically changing natural environment,” <em> Theoretical
Population Biology</em>, 70: 486–497.</li>

<li>Weibull, Juergen W. (1995). <em>Evolutionary Game Theory</em>,
Cambridge, MA: The MIT Press.</li>

<li>Witt, Ulrich (1989a). “The Evolution of Economic Institutions as a
Propagation Process,” <em>Public Choice</em>, 62 (2): 155–172.</li>

<li>Young, H. Peyton. (1993). “An Evolutionary Model of Bargaining,”
<em>Journal of Economic Theory</em>, 59: 145–168.</li>

<li>––– (1993). “The Evolution of Conventions,”
<em>Econometrica</em>, 61 (1): 57–84.</li>

<li>––– (2001). <em>Individual Strategy and Social
Strategy: An Evolutionary Theory of Institutions</em>, Princeton:
Princeton University Press.</li>

<li>Zollman, Kevin (2005). “Talking to Neighbors: The Evolution of
Regional Meaning,” <em>Philosophy of Science</em>, 72: 69–85.</li>

</ul>

</div>

<div id="academic-tools">

<h2><a id="Aca">Academic Tools</a></h2>

<blockquote>
<table>
<tbody><tr><td valign="top"><img src="../../symbols/sepman-icon.jpg" alt="sep man icon" /></td>
<td><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=game-evolutionary&amp;archive=win2019" target="other">How to cite this entry</a>.</td>
</tr>
<tr><td valign="top"><img src="../../symbols/sepman-icon.jpg" alt="sep man icon" /></td>
<td><a href="https://leibniz.stanford.edu/friends/preview/game-evolutionary/" target="other">Preview the PDF version of this entry</a> at the <a href="https://leibniz.stanford.edu/friends/" target="other">Friends of the SEP Society</a>.</td>
</tr>
<tr><td valign="top"><img src="../../symbols/inpho.png" alt="inpho icon" /></td>
<td><a href="https://www.inphoproject.org/entity?sep=game-evolutionary&amp;redirect=True" target="other">Look up this entry topic</a> at the <a href="https://www.inphoproject.org/" target="other">Indiana Philosophy Ontology Project</a> (InPhO).</td>
</tr>
<tr><td valign="top"><img src="../../symbols/pp.gif" alt="phil papers icon" /></td>
<td><a href="http://philpapers.org/sep/game-evolutionary/" target="other">Enhanced bibliography for this entry</a> at <a href="http://philpapers.org" target="other">PhilPapers</a>, with links to its database.</td>
</tr>
</tbody></table>
</blockquote>

</div>

<div id="other-internet-resources">

<h2><a name="Oth">Other Internet Resources</a></h2>

<ul>

<li><a href="http://www.ethics.ubc.ca/eame/" target="other">Evolving Artificial Moral Ecologies</a>,
 (with interactive simulators), by Peter Danielson (U. British Columbia) and
 William Harms (Bowling Green State).</li>

<li><a href="http://www.brookings.edu/dynamics.aspx" target="other">Brookings Center on Social and Economic Dynamics</a>.</li>
 
<li><a href="http://www-personal.umich.edu/~axe/ComplexCoop.html" target="other">Complexity of Cooperation</a>,
  website on Robert Axelrod's book.</li>

</ul>

</div>

<div id="related-entries">

<h2><a name="Rel">Related Entries</a></h2>

<p>

 <a href="../evolution-cultural/">evolution: cultural</a> |
 <a href="../game-theory/">game theory</a> |
 <a href="../prisoner-dilemma/">prisoner’s dilemma</a>

</p>

</div>

</div><!-- #aueditable --><!--DO NOT MODIFY THIS LINE AND BELOW-->

<!-- END ARTICLE HTML -->

</div> <!-- End article-content -->

  <div id="article-copyright">
    <p>
 <a href="../../info.html#c">Copyright © 2009</a> by

<br />
J. McKenzie Alexander
&lt;<a href="mailto:jalex%40lse%2eac%2euk"><em>jalex<abbr title=" at ">@</abbr>lse<abbr title=" dot ">.</abbr>ac<abbr title=" dot ">.</abbr>uk</em></a>&gt;
    </p>
  </div>

</div> <!-- End article -->

<!-- NOTE: article banner is outside of the id="article" div. -->
<div id="article-banner" class="scroll-block">
     <div id="article-banner-content">
  <a href="../../fundraising/">
  Open access to the SEP is made possible by a world-wide funding initiative.<br />
  Please Read How You Can Help Keep the Encyclopedia Free</a>
 </div>


</div> <!-- End article-banner -->

    </div> <!-- End content -->

    <div id="footer">

      <div id="footer-menu">
        <div class="menu-block">
          <h4><i class="icon-book"></i> Browse</h4>
          <ul role="menu">
            <li><a href="../../contents.html">Table of Contents</a></li>
            <li><a href="../../new.html">New in this Archive</a></li>
            
            <li><a href="../../published.html">Chronological</a></li>
            <li><a href="../../../../archives/">Archives <i class="icon-external-link"></i></a></li>
          </ul>
        </div>
        <div class="menu-block">
          <h4><i class="icon-info-sign"></i> About</h4>
          <ul role="menu">
            <li><a href="../../info.html">Editorial Information</a></li>
            <li><a href="../../about.html">About the SEP</a></li>
            <li><a href="../../board.html">Editorial Board</a></li>
            <li><a href="../../cite.html">How to Cite the SEP</a></li>
            <li><a href="../../special-characters.html">Special Characters</a></li>
            
            <li><a href="../../../../contact.html">Contact <i class="icon-external-link"></i></a></li>
          </ul>
        </div>
        <div class="menu-block">
          <h4><i class="icon-leaf"></i> Support SEP</h4>
          <ul role="menu">
            <li><a href="../../../../support/">Support the SEP</a></li>
            <li><a href="../../../../support/friends.html">PDFs for SEP Friends</a></li>
            <li><a href="../../../../support/donate.html">Make a Donation</a></li>
            <li><a href="../../../../support/sepia.html">SEPIA for Libraries</a></li>
          </ul>
        </div>
      </div> <!-- End footer menu -->

      <div id="mirrors">
        <div id="mirror-info">
          <h4><i class="icon-globe"></i> Mirror Sites</h4>
          <p>View this site from another server:</p>
        </div>
                <div class="btn-group">
<a class="btn dropdown-toggle" data-toggle="dropdown" href="https://plato.stanford.edu/"><span class="flag flag-usa"></span> USA (Main Site) <span class="caret"></span><span class="mirror-source">CSLI, Stanford University</span></a>          <ul class="dropdown-menu">
            <li><a href="https://stanford.library.sydney.edu.au/archives/win2019/entries/game-evolutionary/"><span class="flag flag-australia"></span> Australia <span class="mirror-source">Library, University of Sydney</span></a>           </li>
            <li><a href="https://seop.illc.uva.nl/archives/win2019/entries/game-evolutionary/"><span class="flag flag-netherlands"></span> Netherlands <span class="mirror-source">ILLC, University of Amsterdam</span></a>           </li>
          </ul>
        </div>
      </div> <!-- End mirrors -->
      
      <div id="site-credits">
        <p class="csli-logo"><a href="https://www-csli.stanford.edu/"><img src="../../symbols/SU_csli.png" width="355" alt="Stanford Center for the Study of Language and Information" /></a></p>
        <p>The Stanford Encyclopedia of Philosophy is <a href="../../info.html#c">copyright © 2016</a> by <a href="http://mally.stanford.edu/">The Metaphysics Research Lab</a>, Center for the Study of Language and Information (CSLI), Stanford University</p>
        <p>Library of Congress Catalog Data: ISSN 1095-5054</p>
      </div> <!-- End site credits -->

    </div> <!-- End footer -->

  </div> <!-- End container -->

   <!-- NOTE: Script required for drop-down button to work (mirrors). -->
  <script>
    $('.dropdown-toggle').dropdown();
  </script>





</body></html>