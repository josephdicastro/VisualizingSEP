<!DOCTYPE html><!--[if lt IE 7]> <html class="ie6 ie"> <![endif]--><!--[if IE 7]>    <html class="ie7 ie"> <![endif]--><!--[if IE 8]>    <html class="ie8 ie"> <![endif]--><!--[if IE 9]>    <html class="ie9 ie"> <![endif]--><!--[if !IE]> --><html xmlns="http://www.w3.org/1999/xhtml"><!-- <![endif]--><head>
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>
Game Theory and Ethics (Stanford Encyclopedia of Philosophy/Winter 2019 Edition)
</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="robots" content="noarchive, noodp" />
<meta property="citation_title" content="Game Theory and Ethics" />
<meta property="citation_author" content="Verbeek, Bruno" />
<meta property="citation_author" content="Morris, Christopher" />
<meta property="citation_publication_date" content="2004/10/16" />
<meta name="DC.title" content="Game Theory and Ethics" />
<meta name="DC.creator" content="Verbeek, Bruno" />
<meta name="DC.creator" content="Morris, Christopher" />
<meta name="DCTERMS.issued" content="2004-10-16" />
<meta name="DCTERMS.modified" content="2010-06-08" />

<!-- NOTE: Import webfonts using this link: -->
<link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,300,600,200&amp;subset=latin,latin-ext" rel="stylesheet" type="text/css" />

<link rel="stylesheet" type="text/css" media="screen,handheld" href="../../css/bootstrap.min.css" />
<link rel="stylesheet" type="text/css" media="screen,handheld" href="../../css/bootstrap-responsive.min.css" />
<link rel="stylesheet" type="text/css" href="../../css/font-awesome.min.css" />
<!--[if IE 7]> <link rel="stylesheet" type="text/css" href="../../css/font-awesome-ie7.min.css"> <![endif]-->
<link rel="stylesheet" type="text/css" media="screen,handheld" href="../../css/style.css" />
<link rel="stylesheet" type="text/css" media="print" href="../../css/print.css" />
<link rel="stylesheet" type="text/css" href="../../css/entry.css" />
<!--[if IE]> <link rel="stylesheet" type="text/css" href="../../css/ie.css" /> <![endif]-->
<script type="text/javascript" src="../../js/jquery-1.9.1.min.js"></script>
<script type="text/javascript" src="../../js/bootstrap.min.js"></script>

<!-- NOTE: Javascript for sticky behavior needed on article and ToC pages -->
<script type="text/javascript" src="../../js/jquery-scrolltofixed-min.js"></script>
<script type="text/javascript" src="../../js/entry.js"></script>

<!-- SEP custom script -->
<script type="text/javascript" src="../../js/sep.js"></script>
</head>

<!-- NOTE: The nojs class is removed from the page if javascript is enabled. Otherwise, it drives the display when there is no javascript. -->
<body class="archive article" id="pagetopright">
<div id="container">
<div id="header-wrapper">
  <div id="header">
    <div id="branding">
      <div id="site-logo"><a href="../../index.html"><img src="../../symbols/sep-man-red.png" alt="SEP logo" /></a></div>
      <div id="site-title"><a href="../../index.html">Stanford Encyclopedia of Philosophy Archive<div id="site-subtitle">Winter 2019 Edition</div></a></div>
    </div>
    <div id="navigation">
      <div class="navbar">
        <div class="navbar-inner">
          <div class="container">
            <button class="btn btn-navbar collapsed" data-target=".collapse-main-menu" data-toggle="collapse" type="button"> <i class="icon-reorder"></i> Menu </button>
            <div class="nav-collapse collapse-main-menu collapse">
              <ul class="nav">
                <li class="dropdown"><a id="drop1" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-book"></i> Browse</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop1">
                    <li><a href="../../contents.html">Table of Contents</a></li>
                    <li><a href="../../new.html">New in this Archive</a></li>
                    
                    <li><a href="../../published.html">Chronological</a></li>
                    <li><a href="../../../../archives/">Archives <i class="icon-external-link"></i></a></li>
                  </ul>
                </li>
                <li class="dropdown"><a id="drop2" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-info-sign"></i> About</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop2">
                    <li><a href="../../info.html">Editorial Information</a></li>
                    <li><a href="../../about.html">About the SEP</a></li>
                    <li><a href="../../board.html">Editorial Board</a></li>
                    <li><a href="../../cite.html">How to Cite the SEP</a></li>
                    <li><a href="../../special-characters.html">Special Characters</a></li>
                    
                    <li><a href="../../../../contact.html">Contact <i class="icon-external-link"></i></a></li>
                  </ul>
                </li>
                <li class="dropdown"><a id="drop3" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-leaf"></i> Support SEP</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop3">
                    <li><a href="../../../../support/">Support the SEP</a></li>
                    <li><a href="../../../../support/friends.html">PDFs for SEP Friends</a></li>
                    <li><a href="../../../../support/donate.html">Make a Donation</a></li>
                    <li><a href="../../../../support/sepia.html">SEPIA for Libraries</a></li>
                  </ul>
                </li>
              </ul>
            </div>
          </div>
        </div>
      </div>
    </div>
    <!-- End navigation -->
    
    <div id="search">
      <form id="search-form" method="get" action="../../../../search/searcher.py">
        <input type="search" name="query" placeholder="Search this archive" />
<input type="hidden" name="archive" value="win2019" />

        <div class="search-btn-wrapper"><button class="btn search-btn" type="submit"><i class="icon-search"></i></button></div>
      </form>
    </div>
    <!-- End search --> 
    
  </div>
  <!-- End header --> 
</div>
<!-- End header wrapper -->

<div id="content">

<!-- Begin article sidebar -->
<div id="article-sidebar" class="sticky" style="z-index: 999;">
  <div class="navbar">
    <div class="navbar-inner">
      <div class="container">
        <button class="btn btn-navbar collapsed" data-target=".collapse-sidebar" data-toggle="collapse" type="button"> <i class="icon-reorder"></i> Entry Navigation </button>
        <div id="article-nav" class="nav-collapse collapse-sidebar collapse">
          <ul class="nav">
            <li><a href="#toc">Entry Contents</a></li>
            <li><a href="#Bib">Bibliography</a></li>
            <li><a href="#Aca">Academic Tools</a></li>
            <li><a href="https://leibniz.stanford.edu/friends/preview/game-ethics/">Friends PDF Preview <i class="icon-external-link"></i></a></li>
            <li><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=game-ethics&amp;archive=win2019">Author and Citation Info <i class="icon-external-link"></i></a> </li>
            <li><a href="#pagetopright" class="back-to-top">Back to Top <i class="icon-angle-up icon2x"></i></a></li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</div><div></div>
<!-- End article sidebar --> 

<!-- NOTE: Article content must have two wrapper divs: id="article" and id="article-content" -->
<div id="article">
<div id="article-content">

<!-- BEGIN ARTICLE HTML -->


<div id="aueditable"><!--DO NOT MODIFY THIS LINE AND ABOVE-->

<h1>Game Theory and Ethics</h1><div id="pubinfo"><em>First published Sat Oct 16, 2004; substantive revision Tue Jun 8, 2010</em></div>

<div id="preamble">

<p>

Game theory is the systematic study of <em>interdependent</em>
rational choice. It should be distinguished from decision theory, the
systematic study of individual (practical and epistemic) choice in
parametric contexts (i.e., where the agent is choosing or deliberating
independently of other agents). Decision theory has several
applications to ethics (see Dreier 2004; Mele and Rawlings 2004).</p>

<p>

Game theory may be used to explain, to predict, and to evaluate
human behavior in contexts where the outcome of action depends on what
several agents choose to do and where their choices depend on what
others choose to do. (See the entry on
 <a href="../game-theory/">game theory</a>)
 Game theory consequently is relevant to ethics, and it is
used in moral and political philosophy in a variety of ways.</p>

<p>

We shall concentrate on the influence and use of game theory in
ethics and those parts of political theory involving norms or
principles of justice, ignoring questions about political and legal
institutions on the one hand and questions about issues dealing with
moral virtues on the other.</p>

<p>

One can distinguish three distinctive kinds of inquiries in the
literature. The first we shall call <em>functionalist</em>: game theory
is used to identify the <em>function</em> of morality. It is used to
describe the problem(s) that would occur in the absence of morality,
and inferences about the remedial or ameliorative function of morality
are drawn from this description. The second approach,
<em>contractarianism</em>, uses game theory (especially bargaining
theory) to formalize social contract theory. This older tradition
understands political institutions or norms to be justified to the
extent that rational agents would agree to them under suitable
conditions. Bargaining theory has been used to establish, first, that
there will be agreement in such conditions and, secondly, to predict
the outcome of this bargaining process. Third and finally, game theory,
especially evolutionary game theory, is used to “recover”
many traditional moral norms or practices. In what follows, we shall
consider each of these approaches and the results and problems they
have encountered. We shall start with some historical background.</p>

</div>

<div id="toc">
<!--Entry Contents-->
<ul>
<li><a href="#1">1. History</a></li>

<li><a href="#2">2. Functionalism</a></li>

<li><a href="#3">3. Problems with functionalism</a></li>

<li><a href="#4">4. Bargaining theory and contractarianism</a></li>

<li><a href="#5">5. Morals by agreement</a></li>

<li><a href="#6">6. Some problems with the contractarian approach</a></li>

<li><a href="#7">7. Evolutionary game theory and ethics</a></li>

<li><a href="#8">8. Some remarks on the evolutionary approach</a></li>

<li><a href="#9">9. Some abstract implications of the use of game theory in ethics</a></li>

<li><a href="#10">10. Conclusion</a></li>

<li><a href="#Bib">Bibliography</a></li>

<li><a href="#Aca">Academic Tools</a></li>
<li><a href="#Oth">Other Internet Resources</a></li>

<li><a href="#Rel">Related Entries</a></li>
</ul>
<!--Entry Contents-->

<hr />

</div>

<div id="main-text">

<h2><a name="1">1. History</a></h2>

<p>

In 1954 the British philosopher Richard Braithwaite gave his
inaugural lecture entitled <em>Theory of Games as a Tool for the Moral
Philosopher</em> (Braithwaite 1955). In his lecture Braithwaite argued
that many questions about distributive justice have the same structure
as “the bargaining problem”. This problem had been analyzed
some years before by John Nash, the later Nobel Prize winner, using
game theory (Nash 1950). Braithwaite predicted that game theory would
fundamentally change moral philosophy. His prediction came less than
ten years after the publication of John von Neumann and Oskar
Morgenstern's <em>Theory of Games and Economic Behaviour</em>—a
book that started a completely new branch of social science and applied
mathematics (Von Neumann and Morgenstern 1944).</p>

<p>

The introduction of game theory in ethics was not entirely a new
development. Game-theoretic ideas can be found, for instance, in the
work of Thomas Hobbes and David Hume (see Gauthier 1969; Kavka 1986;
Hampton 1986; Vanderschraaf 1998)). Nevertheless, Braithwaite's
prediction has not come true. Game theory has not (yet) fundamentally
changed ethics. Ten years after Braithwaite, Brian Barry
published <em>Political Argument,</em> and a few years later David
Lewis' seminal work <em>Convention</em> came out (Barry 1965; Lewis
1969). In the late 60's, the first of a series of publications by
David Gauthier appeared. In these he used game theory to develop his
moral theory (Gauthier 1967). However, until recently, the influence
of game theory in ethics has not been anywhere as great as in the
social sciences in general. Notwithstanding this faltering start, the
introduction of game theory in moral philosophy has produced a
steadily increasing flow of important publications.</p>

<h2><a name="2">2. Functionalism</a></h2>

<p>

Game theory has been used to analyze the <em>function</em> of
morality. A good example is Edna Ullmann-Margalit's <em>The Emergence
of Norms</em>, in which she argues that moral norms enable agents to
cooperate and coordinate their actions in situations where the pursuit
of self-interest prevents this (Ullmann-Margalit 1977). Her now classic
example is that of two artillerymen who face the choice to flee from
the advancing enemy or stay and operate their gun. Their gun is located
in a strategically important pass. If both stay, they have a
significant chance of being injured, but it is certain that the advance
of the enemy will be halted. If both flee, the enemy will be able to
take the mountain pass, overtake and capture them. If just one of them
stays while the other flees, the brave artillerist will die in battle,
but the other gunner will have just enough time to escape safely.
Supposing that both try to survive this ordeal, preferably unhurt, each
soldier has reason to flee. The reason for this is that they are
engaged in a
 <a href="../prisoner-dilemma/">prisoner's dilemma</a>
 (see Figure 1). Each gunner has the choice between fleeing and
staying and fighting. This choice is represented in the rows for
gunner #1 and the columns for gunner #2. Each cell in the matrix
represents the outcome of each possible pair of choices. Each cell has
a pair of numbers. The number in the lower left corner of each cell
represents how gunner #1 ranks this outcome, relative to the other
possible outcomes—ranks represented by “utility”
numbers. The number in the upper right corner represents the ranking
of this outcome by #2.</p>

<blockquote><img src="figure1.gif" width="274" height="165" alt="Figure 1" />
<br />
<strong>Figure 1</strong></blockquote>

<p>

Consider the case for #1. Suppose #2 decides to stay and fight. In
that case, #1 is best off by fleeing. He will survive without getting
hurt. In the formal representation of the matrix, he will secure a
higher ranking (3 rather than 2). Suppose #2 decides to flee. Again,
#1 does best by fleeing. He will survive the battle, although he will
be imprisoned for the duration of the war. If he were to stay and
fight, he would certainly die; by fleeing he will secure a higher
ranking (1 rather than 0). Gunner #2 is in the same position as #1:
for him as well, whatever the other does, he fares best by fleeing. In
short, each individual gunner would be better off fleeing, regardless
of what the other does. However, it remains true—and to some,
paradoxical—that both would be better off if both stood their
ground. The outcome of individually rational action is
Pareto-inefficient (or sub-optimal).</p>

<p>

Suppose that both understand the structure of their predicament.
Since they would see that each has good reasons to flee, they could try
to rule out this possibility. For example, they could chain each other
to the gun, thus preventing flight. Ullmann-Margalit argued that the
situation of the gunners (i.e., the prisoner's dilemma) is structurally
equivalent to many everyday interactions governed by morality.
Furthermore, just as the mutual chaining commits the gunners to stay
and fight, morality commits agents to avoid Pareto-inefficient or
sub-optimal outcomes. Morality binds individuals to their guns, as it
were. On this view, the function of morality is to prevent the failures
of rationality (Mackie 1977).</p>

<h2><a name="3">3. Problems with functionalism</a></h2>

<p>

There are several problems with this functional analysis of
morality. First, there are some well-known problems with functionalist
explanations in the social sciences. The fact that a practice or an
institution has a particular function need not explain either its
emergence or its maintenance. It might be argued, for instance, that
the function of the public education system is to educate the young,
the function of the state to serve the interests of the ruling classes,
or that of religion to serve as the opiate of the masses. However,
until it can be shown that these apparent functions are causally
effective in bringing into existence and maintaining the educational
system, the state, or religion respectively, no explanation has been
provided. Similarly, even if moral norms and practices serve to bring
about Pareto-superior outcomes not realizable through uncoordinated
individually rational action, no explanation of the existence and
persistence of morality is provided unless it is shown that this
function somehow motivates human action and or in some other way is
causally effective in bringing about mutually beneficial outcomes.</p>

<p>

Secondly, it is open to question whether morality coincides with
mutually advantageous or Pareto-superior outcomes in the manner
suggested. Many thinkers have argued that we often are morally required
to act in ways which are disadvantageous to all. An obvious example is
the often-affirmed prohibition against selling oneself into slavery. It
might very well be advantageous to both slave and master (the slave
would be able to pay off his debts and the master would have a
practical solution for the daily housework), yet it is morally and
legally prohibited.</p>

<p>

Third, the functionalist account clearly assumes that the demands of
morality conflict with individual rationality. Morality is supposed to
correct problems of threatening Pareto-inefficiency which would be the
result of unfettered (interdependent) individual rational action. On
the functionalist account the moral agent seems <em>ipso facto</em> to
be irrational (barring considerations of guilt-avoidance or regret).
This then begs the question ‘why be moral?’. Functionalism
precludes an answer to this question.</p>

<p>

Fourth and finally, the objective of functionalist accounts is of
limited interest to moral theorists. Functionalism appears to seek
<em>explanations</em> of the emergence and persistence of moral norms
and practices. Moral theorists are not interested principally in such
explanations. Rather, they usually seek to understand morality with the
aim of ascertaining what we should do or what we are obligated to do.
It is morality as a guide to action and to life that is the principal
interest of the moral philosopher. Morality here is <em>normative</em>,
a source of guidance. Suppose that there were a plausible functional
explanation of particular moral norms. Does that explanation show that
I am, in fact, <em>obligated</em> to follow these norms when they apply
to me? There seems to be a difference between (a) determining the
function(s) of morality and (b) ascertaining whether a particular set
of norms and practices are, in fact, the ones we should follow. It is
not clear how this question is answered by functionalist accounts.</p>

<h2><a name="4">4. Bargaining theory and contractarianism</a></h2>

<p>

As we saw above, one of the criticisms of functionalism is that it
does not explain the connection between individual choice and the
emergence and persistence of moral norms. Morality is introduced as
something outside of individual rational choice. In response to this
difficulty, many theorists have tried to understand morality as the
result of individual rational choice. Roughly, we can distinguish two
strategies. First, there are those who model morality as the result of
a one-time choice of a very large collection of agents, the moral
community. Secondly, there are those who approach morality as the
result of a series of repeated small-scale interactions. We will
discuss this second approach in section 7. Here we discuss the approach
that regards morality as the intended result of the interactions
between rational agents under equally ideal circumstances. This is an
old idea in moral and political philosophy: it is the idea of the
<em>social contract</em> (see the entry on
 <a href="../contractarianism/">contractarianism</a>).
 Morality is interpreted as the outcome of a bargaining process.</p>

<p>

The introduction of game theory, especially those parts of the
theory that are concerned with bargaining (so-called cooperative game
theory and bargaining theory), has stimulated interest in social
contract theory over the last decades. John Harsanyi, Richard
Braithwaite, John Rawls, Brian Barry, and David Gauthier have used the
game and decision theory to formulate versions of the theory (Harsanyi
1955; Braithwaite 1955; Barry 1965; Rawls 1971; Gauthier 1986).
Invoking bargaining theory, they attempted to show (1) that rational
agents in a suitably idealized bargaining situation will agree on a
specific, unique distribution of the benefits of cooperation, (2) what
this distribution looks like, (3) that this distribution determines
what is just, and (4), in case of Gauthier, that rational agents will
comply with the terms of the bargain.</p>

<p>

It is important for these theories exactly how the bargaining
situation is characterized. Gauthier, as well as many others, thinks of
it as a prisoner's dilemma. That is, the predicament of the parties in
the ideal bargaining position is structurally equivalent to the
situation of the artillerists as we described above. Without any
cooperation the gunners are doomed to flee and spend the remainder of
the war in captivity. Suppose that it is possible to make binding
agreements in this situation. Does this solve the problem of
threatening Pareto-inefficiency? It does not because it is not obvious
<em>how</em> the benefits of cooperation will be distributed. It might
seem that in this case there is only one way in which these can be
distributed, but appearances deceive. The artillerists could decide to
follow a <em>mixed strategy</em>. A mixed strategy is a lottery over
the available strategies of each individual. For example, the gunners
could decide to flee with a probability of, say,
<sup>1</sup>/<sub>3</sub> and stay and fight with a probability of
<sup>2</sup>/<sub>3</sub>. (It should be noted that the idea of a mixed
strategy usually is introduced in the context of so-called <em>cardinal
utilities</em>. Whereas before the numbers in the matrix (0, 1, 2 and
3) only signified the <em>ranking</em> of the outcome, here it is
assumed that the numbers provide some information about the
<em>relative ranking</em> of the outcome. For example, the utility of
“2” of the cooperative outcome means that the agent is
indifferent between this outcome and a gamble which offers her
“0” (the worst outcome) with probability <sup>1</sup>/<sub>3</sub> and
“3” (her best outcome) with probability <sup>2</sup>/<sub>3</sub>. (For a
detailed discussion of cardinal utility theory see Section 3.5 of the
entry on
 <a href="../probability-interpret/">interpretations of probability</a>).
<!-- as well as the entry on the
 <a href="../paradox-stpetersburg/">St. Petersburg Paradox</a>).-->
 From here onwards, we assume that the numbers in the matrix are such
cardinal utilities.)</p>

<p>

The gunners realize that they each individually can realize at least
the one but worst outcome of non-cooperation. This means that the
outcome of their agreement should be at least as good as the
non-cooperative outcome. Therefore, the distribution that they will
agree to should at least be 1. Suppose that the gunners have a pair of
dice. Now they can realize cooperative distributions other than 2 each.
For example, if they agree to throw both dice and if a total of 6 or
less comes up #1 will flee (thus realizing a utility value of 3).
However, if the total of both dice is more than 6, #1 will stay and
fight the enemy (realizing his worst outcome of 0). The expected
utility of this deal for #1 is <sup>5</sup>/<sub>12</sub>·3 +
<sup>7</sup>/<sub>12</sub>·0 = 1.25, while #2 can expect 1.75
from this deal. In this way the gunners can realize a whole range of
outcomes by varying the chances that improves on the non-cooperative
outcome. These outcomes form the bargaining area (see Figure 2).</p>

<blockquote><img src="figure2.gif" width="287" height="189" alt="Figure 2" />
<br />
<strong>Figure 2</strong></blockquote>

<p>

Intuitively it may seem straightforward that the outcome of the
agreement between #1 and #2 will be (2,2). Formally this is anything
but straightforward. Every outcome that gives each gunner an expected
utility of more than 1 seems rationally acceptable. Which one will
rational gunners select? Within bargaining theory, the part of game
theory that deals with these problems, there are two approaches that
seek to answer this question (Binmore 1998, chapter 1). First, there is
the traditional <em>axiomatic approach</em> as developed in the context
of cooperative game theory. This branch of game theory assumes that,
once rational agents have come to an agreement, they will comply with
it. The task of the theorist is to consider the bargaining area and
determine which outcome(s) would satisfy a number of reasonable
requirements of a rational outcome of the negotiations. Things such as
the names of the parties concerned should not matter for the result,
whereas their preferences do matter. This approach has been very
influential in game-theoretic social contract theory. Harsanyi, Rawls,
Barry, and Gauthier all have used axiomatic approaches to justify their
favorite version. Their verdict in the case of the gunners is the same:
the rational thing to agree to is a distribution that gives each gunner
an expected utility of 2. (Note that this verdict does not tell the
gunners <em>how</em> they should realize this outcome. There are two
ways in which they could secure an expected outcome of (2, 2). They
could both stay and fight or they could flip a fair coin to decide who
gets to stay and who is allowed to flee.)</p>

<p>

The axiomatic approach pays no attention to the structure of the
process of negotiation. All it requires as input is information about
the pay-offs of the parties. Whereas it is true that sometimes it does
not really matter how exactly the negotiation process is structured,
sometimes it is very important. For example, if it is the case that #1
can make a claim and all #2 can do is to accept or refuse, #1 does best
by offering #2 an expected utility of 1.00001 and claim 2.99999 for
himself. Given the rules of the negotiation process #2 will have to
accept this since the alternative is (slightly) worse. On the other
hand, if the rules allow for exchanges of claims and offers the
situation is quite different. Therefore, if you want to predict what
the result of the negotiation process between rational agents will be,
it is crucial to know the rules of negotiation in detail as well as the
bargaining area. In addition, it is important to know whether the
parties will keep to the agreement. For if this is not the case, it is
unlikely that the parties concerned will accept the agreement instead
of an agreement that will turn out to be binding.</p>

<p>

Therefore, it is better to think of the bargaining process as a
series of possible moves in a game that precedes the game that the
gunners face. This is the second approach, which regards bargaining
processes as <em>non-cooperative games</em>. The solution to such a
game then corresponds to the solution of the bargaining process. On
this approach, one needs to pay a lot of attention to detail.
Consequently the analysis is complicated and often messy. (This is
another reason why the axiomatic approach is so attractive to
some.)</p>

<p>

However, it is very well possible that the solution to the game and
the solution based on the axiomatic approach are identical. In fact,
this is what you would expect if the proposed axiomatic solution is at
all plausible. This intuition is the driving force of the so-called
<em>Nash program</em> (Nash 1950). This program aims at evaluating
axiomatic solutions by checking whether the outcome of a negotiation
game leads to the same outcome. The success of the Nash program is
crucial for the plausibility of the classic axiomatic theories of the
social contract. Such theories regard morality as the result of
(hypothetical) negotiations between ideally rational agents but do not
bother to spell out exactly <em>how</em> the parties reach this result.
Consequently, if there is not at least the promise of such a detailed
analysis, as is promised by the Nash program, the result they present
lacks plausibility. (See also Rubinstein 1982 and Binmore 1998 for more
recent treatments of the bargaining problem.)</p>

<h2><a name="5">5. Morals by agreement</a></h2>

<p>

One of the most influential contractarian theories currently around
is that of David Gauthier. His theory, however, is different from other
contractarian approaches, not only in its extensive use of game- and
bargaining theory, but also in the following respect. One of the
difficulties we signaled with regards to the functionalist approach is
that it provides no answer to the question “Why be moral?”
It is here that Gauthier's contractarian theory distinguishes itself
from those of Rawls, Harsanyi, and others. Gauthier not only uses
bargaining theory to determine, as Rawls and Harsanyi sought to do, the
content of fundamental moral principles; he also tries to show that
rational agents will act morally. For this reason we discuss it in more
detail than the others.</p>

<p>

Gauthier's moral theory, “morals by agreement” (Gauthier
1986), is a theory about the nature and rationality of morality. (See
also Section 3 of the entry on
 <a href="../contractarianism/">contractarianism</a>).
 It consists of four
parts. The first is an account of practical reason and the natural
condition of humankind, much of it familiar to rational choice
theorists and to contractarian moral theorists (Gauthier 1986, chapters
2–4). Next is an account of the principles of conduct that rational
agents would hypothetically agree to—a kind of “social
contract” (Gauthier 1986, chapter 5). The third element is a
controversial revisionist account of practical rationality essential to
his argument aiming to show that virtually everyone under normal
circumstances has reason to accept and to abide by the constraints
imposed by these principles (Gauthier 1986, chapter 6). Lastly,
Gauthier argues that the principles in question are principles of
morality, an argument which makes implicit reference to a functionalist
account of moral norms (Gauthier 1986, chapters 7–8). The third part is
Gauthier's answer to the question “Why be moral?”. It
touches upon some very fundamental issues in game- and decision theory,
which is why we discuss it a bit further here.</p>

<p>

As Hobbes already realized, it is one thing to come to an agreement;
it is quite another thing to perform one's part of an agreement.
Morality, at least as it is traditionally conceived, often requires us
to sacrifice our interests or aims. This is, at least on the face of
it, contrary to what rationality requires. Gauthier's response to this
is to argue that we misconceive practical rationality, even
instrumental rationality, if we think the aim of rationality determines
in any straightforward way the manner in which we should reason or
deliberate. The <em>aim</em> of rationality—to do as well as
possible—does not necessarily determine our <em>principle of
decision</em>—for instance, to choose the best alternative at
each moment of choice. In terms of the utility-maximizing conception of
rationality which he has accepted until recently (Gauthier,
forthcoming), Gauthier argues that the aim of maximizing utility does
not mean that we should, at each decision point, maximize utility.
Instead we should reason in ways which are utility maximizing. Just as
it is sometimes the case that we do best or at least well by not aiming
to do best or well, so it may sometimes be that the utility maximizing
course of action is not to maximize utility at each decision point.
Given that our mode of reasoning or deliberation itself affects our
prospects, our aims or purposes are sometimes best served by our not
seeking to do best at every decision point.</p>

<p>

Gauthier's discussion in <em>Morals by Agreement</em> is conducted
in terms of “dispositions to choose” and specifically of
“constrained maximization”, the disposition to cooperate
with other cooperators even in circumstances where defecting is more
advantageous. In later work Gauthier develops his revisionist account
of practical rationality in terms of rational plans and intentions and
of modes of deliberation. If we grant that agents may do better in any
number of circumstances by acting in ways that are not
“straightforwardly maximizing”, the problem is to determine
how acting as a constrained maximizer is rational. In the book Gauthier
assumes that if our dispositions to choose is rational, then our
choices determined by these dispositions are also rational. A number of
theorists have followed Thomas Schelling in arguing that it is often
rational to do things that are irrational, but they argue that the
latter do not in the circumstances cease being irrational. Gauthier
thinks that if a course of action is better than any other in its
effects, then it may under certain conditions be rational to adopt it
and to intend to carry out its element even if some of them are not,
from the standpoint of the moment of execution, the best thing to do in
terms of one's aims or purposes. He seeks therefore to establish that
if a mode of deliberation or a plan of action is rational, then acting
according to it can be rational even if so acting requires doing things
that are not, considered from the standpoint of the moment of action,
optimal. Principled action constrains one's action, and it is rational
to be so constrained. Thus, if Gauthier is right, it can be rational to
abide by certain norms or principles, even when they require acting in
ways that are not best from the standpoint of the time of action. Much
of Gauthier's work since <em>Morals by Agreement</em> develops and
defends this revisionist account of practical rationality. (See
Gauthier 1994, 1996, 1998a and b. For an alternative revisionist
account, see McClennen 1990).</p>

<p>

Gauthier's defense of “constrained maximization”
constitutes a major revision of standard game- and decision theory.
Orthodox theory focuses upon the rationality of actions at the time of
choice. The mode of deliberation itself about actions falls out of the
scope of the theory. (Or rather, orthodox theory presents itself as
such a mode of deliberation.) Some critics have argued against
including the mode of deliberation in the scope of the theory (for
example, Velleman 1997). Most game theorists, however, argue instead
that if it is feasible to choose the mode of deliberation, this choice
itself can be modeled as a move in a more complex decision game, thus
including Gauthier's proposal into standard theory (for example,
Binmore 1994, p. 179–182).</p>

<h2><a name="6">6. Some problems with the contractarian approach.</a></h2>

<p>

The contractarian approach—and Gauthier's theory is not
different in this respect—presumes a fundamental connection
between rationality and morality, just like functionalism. However,
unlike the functionalist project, the contractarian approach has a
sophisticated argument as to why this should be so. Moral norms (or
institutions, or whatever is the object of the theory in question) are
rationally acceptable according to the contractarian tradition only if
there is no feasible alternative arrangement where all parties
concerned would be better off. We can make this claim more vivid.
Imagine that parties are bargaining over what norm to use to share a
cake. Rational parties would not agree to a norm that would leave some
cake on the table going to waste. Similarly with moral norms: rational
agents would not agree to a norm that could be expected to leave mutual
advantages unexploited. Therefore, according to the contractarian's
conception of morality, it is necessarily the case that the correct
morality leads to Pareto-efficient outcomes. For this reason, rational
choice contractarianism is often regarded as revisionist in its
implications. The claim is not that common sense or ordinary morality
leads to Pareto-efficient results (if followed). Instead, the claim of
rational choice contractarianism is that the correct account of binding
moral norms is one that implies that if these norms are followed, the
outcomes will be Pareto-efficient.</p>

<p>

Critics have long argued that it's not clear why the outcome of
<em>hypothetical</em> agreement should influence what agents outside of
the idealized circumstances of “the social contract” should
do. Some have argued that hypothetical contracts (or promises) do not
bind. However, this is to misunderstand the nature of these theories;
hypothetical rational agreement is not meant to be <em>promissory</em>.
Rather, it is first of all <em>heuristic</em>, a mechanism designed to
determine the nature and content of mutually beneficial, fair
principles.</p>

<p>

Whereas the remarks above address all forms of contractarianism,
there are some specific problems with versions that rely as heavily on
game-theoretic bargaining theory as that of Gauthier and the others.
The most fundamental seems to be the plausibility of the Nash program:
is there really a rational solution to all bargaining problems that can
be specified and tested with the use of non-cooperative game theory?
Similarly, how can we be sure that there is always one unique solution,
or are bargaining problems to some extent underdetermined? The
plurality of bargaining solution concepts that are discussed in
bargaining theory is a bad omen in this regard. There are reasons to
doubt that the game-theoretic approach to bargaining can really help us
predict the outcome of the negotiations of rational agents. Both the
axiomatic approach and the non-cooperative game approach proceed from
the assumption that there is a unique, rational outcome of such
negotiations. While that may be plausible in some situations, it is far
from obvious that this is always the case. That is, the outcome of
negotiations often seems rationally underdetermined (Sugden 1991).
Non-rational factors, such as salience, precedence, etc., are far more
important for determining the result of such negotiations than standard
bargaining and game theory lead us to believe.</p>

<h2><a name="7">7. Evolutionary game theory and ethics</a></h2>

<p>

There is also another kind of worry, one which leads naturally to
the third major movement in game theory and ethics. Contractarians like
Gauthier understand the fundamental norms that govern us as issuing
from a (hypothetical) choice situation which would have a very large
number of agents bargaining over different principles or social
arrangements. However, it is an open question whether that is an
appropriate way to model the rational choice process that leads to the
emergence of morality.</p>

<p>

At this point, there is a fundamental difference with the third way
in which game theory had been applied to ethics. This third way is
 <a href="../game-evolutionary/">evolutionary game-theory</a>.
 Rather than
regarding morality as the intended result of a complex large scale
bargaining process between fully informed and fully rational agents,
the evolutionary approach moves away from all these assumptions. First,
morality is seen as the unintended side-effect of the interactions of
agents. Secondly, morality emerges from a series of repeated
interactions between small groups of agents (most models deal with
two-person interactions only). To put this in functionalist terms:
morality is not to solve one problem, but frequently re-occurring
problems. Third, rather than assuming full information and full
rationality, evolutionary game theory makes less demanding assumptions
of the cognitive and deliberative skills of the agents. This can lead
to fundamentally different results.</p>

<p>

We can illustrate this as follows. Rousseau describes the state of
nature as one that resembles the so-called Stag Hunt (Rousseau 1964, p.
166–167). (See Skyrms 2004 for a contemporary treatment of this game.)
Imagine two hunters who can choose to hunt for hare. Their chances of
catching a hare are not affected by the actions of others. However,
both prefer to have venison for dinner, but if they were to hunt for
stag, they will only be successful if the other does so as well.</p>

<blockquote><img src="figure3.gif" width="254" height="165" alt="Figure 3" />
<br />
 <strong>Figure 3: The stag hunt</strong></blockquote>

<p>

Suppose #1 and #2 coordinate on (Hare, Hare). This equilibrium is
strictly Pareto-inferior to (Stag, Stag). Whereas contractarian choice
would have it that (Stag, Stag) is the correct norm to settle upon,
evolutionary game theory teaches us that it is unlikely that the
Pareto-efficient equilibrium will be selected in a process of repeated
interactions. What is more, the Pareto-efficient equilibrium is
unstable: occasional deviations from this equilibrium will lead the
population as a whole to coordinate on (hare, hare) rather than (stag,
stag).</p>

<p>

Presumably this is true of some of our actual norms—social,
legal, or moral. They may be deficient relative to other norms,
especially those that issue from the sorts of idealized social choice
situations of contractarian moral theory. However, most of our actual
norms are often stable, and it is not clear that we have reason to
depart from them. Therefore, we are left wondering if the norms
discovered by game theoretic bargaining theory are norms that are
feasible for most societies, communities and groups. Since
“ought” implies “can”, we have reason to doubt
that the contractarian approach gives us a correct account of the
morality we ought to follow.</p>

<p>

The main result of the evolutionary approach so far is the
“recovery” of many existing moral intuitions and norms.
Thus, evolutionary game theorists writing about ethics (as well as
moral philosophers using evolutionary game theory) have shown that
among not-so-fully rational agents many of the norms of coordination
and cooperation can emerge that are the object of inquiry of the more
traditional moral theories. (For example, Sugden 1986; Binmore 1994,
1998; Skyrms 1996.) Furthermore, Skyrms (1996) and others have
demonstrated that otherwise self-interested agents will develop
reasoning heuristics such as the <em>Golden Rule</em> (do to others as
you want to be done by) and a version of Gauthier's “constraint
maximization” under appropriate circumstances. That is, they show
that evolution favors not only the emergence of patterns of behavior
that conform to moral standards, but also favor the development of
cognitive heuristics that have all the characteristics of moral
reasoning.</p>

<h2><a name="8">8. Some remarks on the evolutionary approach</a></h2>

<p>

Most authors who have embraced the evolutionary approach, are quick
to point out that this approach avoids much of the criticism raised
against the previous two approaches. First, the evolutionary approach
provides a genuine explanation of the emergence and persistence of
moral norms. Norms are the unintended side-effect of the actions of
(boundedly) rational agents and emerge in the process of repeated
interactions. On the evolutionary approach, the “function”
of a moral norm is to select a stable equilibrium, in a situation in
which there is more than one. Thus stable norms can be
Pareto-inefficient. There is no fundamental link between efficiency and
morality on the evolutionary approach. Its focus is on equilibrium and
not on efficiency. This is also the reason why an agent in such a
population should follow that norm. That is, the fact that the other
members of a population follow a norm explains why, and justifies that,
an individual in such a population will do so as well. As a
consequence, the evolutionary approach provides an answer to the
question “Why be moral?” Following an existing norm is
individually rational. Furthermore, no unorthodox revisions of choice
theory need to be accepted to achieve this result, which is a big
advantage over Gauthier's claims for “constrained
maximization”.</p>

<p>

However, there is also some reason to be wary of the success of the
evolutionary approach. For just like the functionalist approach and
unlike the contractarian project, its focus is on explanation.
Evolutionary game theory is primarily used to explain the emergence and
stability of existing norms. It does not supply the instruments to be
critical of the content of these norms. It provides no justification of
a code of conduct as one that is decidedly moral (however, see Binmore
1994, 1998).</p>

<p>

This tendency is especially worrisome when we see in the literature
on the evolution of behavior explanations for nasty dispositions such
as the propensity of men to rape, the human inclination to make status
distinctions based on race, and the like. So it is not clear to what
extend this approach provides an alternative to existing moral
theories. It is probably best understood as a form of social theory,
albeit one that is ambivalent as to whether it is an empirically
informed theory or a form of <em>a priori</em> theorizing (Sugden
2001). Of course, one may come to think that evolutionary game theory
is not an alternative to moral theory as much as a vehicle for
undermining or debunking moral claims. If the source of our moral
dispositions and judgments is essentially the same as the nasty
inclinations mentioned above, then perhaps we should conclude that our
moral judgments are false or unjustified and our moral dispositions
untrustworthy. Evolutionary game theory, on this interpretation, would
support a kind of moral skepticism (see Section 1 of the entry on
 <a href="../skepticism-moral/">moral skepticism</a>).
 Some answers to this
skepticism may be found, for instance, in Gibbard (1990).</p>

<h2><a name="9">9. Some abstract implications of the use of game theory in ethics</a></h2>

<p>

Regardless of the merits of the three approaches we discussed above,
there are some remarkable insights that the application of game theory
offers to the moral theorist. As we noted above, there are many games
with multiple equilibria. This is especially the case with iterated
plays of particular games such as the prisoner's dilemma. One of the
implications of this fact is that insofar as these games are helpful
representations or models of our social interactions, we have reason to
expect much indeterminacy in the world. As a consequence, we have
reason to be wary of moral theorists that claim universality and
generality for their specific normative recommendations (Hardin 1988,
2003).</p>

<p>

Secondly, game theory makes clear that in any sufficiently large
population we can expect determinate mixes of behavioral dispositions.
Consider the well-known Hawk-Dove game (Smith 1982):</p>

<blockquote><img src="figure4.gif" width="269" height="170" alt="Figure 4" />
<br />
<strong>Figure 4: the Hawk-Dove game</strong></blockquote>

<p>

The two equilibria in pure strategies in the simple 2 X 2 game
result from each player adopting a different strategy. If we think of
“Hawk” and “Dove” strategies as representing
moral dispositions or characters, then we may have reason to expect
that human populations will consist of agents with different
characters, so to speak (see also Frank 1988; Smith 1982; Skyrms 1996).
What is more, given this analysis it is far from clear that the moral
theorist is in any position to recommend the same disposition, i.e.,
the same virtue, for all agents in this population: some should be
“Hawks” others “Doves” (see also Kuhn
2004).</p>

<p>

Whereas the latter two observations point to original insights for
moral theorists, we cannot avoid mentioning some of the criticisms that
have been formulated against the application of game theory to ethics.
The most fundamental ones concern the implicit anthropology of the
rational agent. The question is whether everything that is relevant for
moral theory about the agent can be captured by the rather
one-dimensional picture of rational man as proposed by game theory. The
agent is supposed to be completely characterized by his preference
rankings over outcomes and his beliefs at each stage of the game.
However, morally important distinctions—e.g., between
differences in character—have no place in this
characterization.</p>

<p>

We can illustrate this worry with the way the concept of reputation
is used in models of altruistic cooperation. Recent game theory has
made use of the notion of a player's <em>reputation</em> in efforts to
explain cooperation in iterated plays of games such as the prisoner's
dilemma (Kreps and Wilson 1982). In many repeated prisoner dilemma
games it pays to have a reputation to be cooperative. However, it is
not clear what exactly it means to have a <em>reputation</em> in these
contexts. Ordinarily, a reputation is what is generally believed about
a person's <em>character</em>. In these models, on the other hand, a
reputation is simply a history of the player's <em>moves</em> in
similar games. There is a morally relevant difference between the two.
What do we believe when we learn that a merchant is honest? Ordinarily
we suppose this means that he is the kind of person who will not cheat
others, for instance, customers, even in situations where it might pay
him to do so. Why might the merchant do this? While another merchant
doesn't cheat because (or when) it does not pay, our merchant is honest
and does not cheat because of his honesty, that is, his character.
Ordinarily, this makes a big difference in how we would judge on these
two merchants. Both behave cooperatively, but only the latter is
praiseworthy for his honesty. Game theory and utility theory generally
has no room for this distinction (see Morris 1999). (Of relevance here
is Brennan and Pettit, 2004.)</p>

<h2><a name="10">10. Conclusion</a></h2>

<p>

Most contemporary authors in ethics who use game theory in their
work are either contractarians or evolutionary theorists. The two
approaches represent two different combinations of game theory and
ethics. The contractarian tradition, with its emphasis on fully
rational agents and bargaining, represents a more traditional use of
game theory. The evolutionary approach, on the other hand, with its
emphasis on bounded rational agents and repeated interactions, is a
more recent arrival. To most experts in the field a synthesis of these
approaches seems highly desirable. (Binmore 1994, 1998 is to date the
only attempt.)</p>

</div>

<div id="bibliography">

<h2><a name="Bib">Bibliography</a></h2>

<ul class="hanging">
<li>Barry, Brian. 1965. <em>Political Argument</em>, <em>International
library of philosophy and scientific method.</em> London: Routledge
&amp; Kegan Paul.</li>

<li>Binmore, Ken. 1994. <em>Playing Fair (Game Theory and the Social
Contract; vol 1)</em>. Cambridge: The MIT Press.</li>

<li>–––. 1998. <em>Just Playing (Game Theory and the
Social Contract, vol. 2)</em>. Cambridge: The MIT Press.</li>

<li>–––. 2005. <em>Natural Justice</em>. New York:
Oxford University Press.</li>

<li>Braithwaite, Richard Bevan. 1955. <em>Theory of games as a tool for
the moral philosopher</em>. Cambridge: Cambridge University Press.</li>

<li>Brennan, Geoffrey and Philip Pettit. 2004. <em>The Economy of
Esteem: An Essay on Civil and Political Society</em>. Oxford: Oxford
University Press.</li>

<li>Dreier, James. 2004. Decision Theory and Morality. In <em>The Oxford Handbook of Rationality</em>. Oxford: Oxford University Press.</li>

<li>Frank, Robert. 1988. <em>Passions within Reason</em>. London: W. W.
Norton &amp; Company, Inc.</li>

<li>Gauthier, David. 1967. Morality and Advantage. <em>Philosophical
Review</em> 76: 460–475.</li>

<li>–––. 1969. <em>The Logic of
‘Leviathan’: the Moral and Political Theory of Thomas
Hobbes</em>. Oxford: Clarendon Press.</li>

<li>–––. 1986. <em>Morals by Agreement</em>. Oxford:
Clarendon Press.</li>

<li>–––. 1994. Assure and Threaten. <em>Ethics</em>
104: 690–721.</li>

<li>–––. 1996. Commitment and Choice: An Essay on
the Rationality of Plans. In <em>Ethics, Rationality, and Economic
Behaviour</em>, edited by F. Farina, F. Hahn, and S. Vannucci,
pp. 217–244. Oxford, Oxford University Press.</li>

<li>–––. 1998a. Intention and
Deliberation. In <em>Modeling Rationality, Morality, and
Evolution</em>, edited by P. Danielson, pp. 41–54.  Oxford:
Oxford University Press.</li>

<li>–––. 1998b. Rethinking the Toxin
Puzzle. In <em>Rational Commitment and Social Justice: Essays for
Gregory Kavka</em>, edited by J. Coleman and C. Morris,
pp. 47–58. Cambridge: Cambridge University Press.</li>

<li>–––. 2008. Friends, Reasons and
Morals. In <em>Reasons and Intentions</em>, edited by Bruno
Verbeek, pp.17–36. Aldershott: Ashgate.</li>

<li>Gibbard, Allan. 1990. <em>Wise Choices, Apt Feelings: A Theory of
Normative Judgment</em>. Cambridge, MA, Harvard University Press.</li>

<li>Hampton, Jean. 1986. <em>Hobbes and the Social Contract Tradition</em>. Cambridge: Cambridge University Press.</li>

<li>Hardin, Russell. 1988. Bargaining For Justice. <em>Social
Philosophy and Policy</em> 5: 65–74.</li>

<li>–––. 2003. <em>Indeterminacy and
Society</em>. Princeton: Princeton University Press.</li>

<li>Harsanyi, John C. 1955. Cardinal Welfare, Individualistic Ethics,
and Interpersonal Comparisons of Utility. <em>Journal of Political
Economy</em> 63: 309–321.</li>

<li>Kavka, Gregory. 1986. <em>Hobbesian Moral and Political Theory</em>. Princeton: Princeton University Press.</li>

<li>Kreps, David M., and Robert Wilson. 1982. Reputation and Imperfect
Information. <em>Journal of Economic Theory</em> 27(2): 253–79.</li>

<li>Kuhn, Steven T. 2004. Reflections on Ethics and Game Theory.
<em>Synthese</em> 141(1): 1–44.</li>

<li>Lewis, David. 1969. <em>Convention: A Philosophical Study</em>.
Cambridge: Harvard University Press.</li>

<li>Mackie, John. 1977. <em>Ethics</em>. London: Penguin Books
Ltd.</li>

<li>McClennen, Edward F. 1990. <em>Rationality and Dynamic Choice:
Foundational Explorations</em>. Cambridge: Cambridge University
Press.</li>

<li>Mele, Alfred, and Piers Rawlings, eds. 2004. <em>The Oxford
Handbook of Rationality</em>. Oxford: Oxford University Press.</li>

<li>Morris, Christopher W. 1999. What is this Thing Called
‘Reputation’? <em>Business Ethics Quarterly</em> 9(1): 87–102.</li>

<li>Nash, John. 1950. The Bargaining Problem. <em>Econometrica</em> 18(2): 155–162.</li>

<li>Rawls, John. 1971. <em>A Theory of Justice</em>. Cambridge: Harvard
University Press.</li>

<li>Rousseau, Jean-Jacques. 1964. <em>Discours sur l'origine et les
fondements de l'inégalité parmi les hommes</em>. Vol.
III, <em>Oeuvres complètes</em>. Paris: Éditions
Gallimard.</li>

<li>Rubinstein, Ariel. 1982. Perfect Equilibrium in a Bargaining Model.
<em>Econometrica</em> 50(1): 97–109.</li>

<li>Skyrms, Brian. 1996. <em>Evolution of the Social Contract</em>.
Cambridge: Cambridge University Press.</li>

<li>–––. 2004. <em>The Stag Hunt and the Evolution
of Social Structure</em>. Cambridge: Cambridge University Press.</li>

<li>Smith, John Maynard. 1982. <em>Evolution and the Theory of
Games</em>. Cambridge: Cambridge University Press.</li>

<li>Sugden, Robert. 1986. <em>The Economics of Rights, Co-operation and
Welfare</em>. Oxford: Basil Blackwell.</li>

<li>–––. 1991. Rational
Bargaining. In <em>Foundations of Decision Theory</em>, edited by
M. Bacharach and S. Hurley. Oxford: Basil Blackwell.</li>

<li>–––. 2001. The Evolutionary Turn in Game
Theory. <em>Journal of Economic Methodology</em> 8(1): 113–30.</li>

<li>Ullmann-Margalit, Edna. 1977. <em>The Emergence of Norms</em>.
Oxford: Oxford University Press.</li>

<li>Vanderschraaf, Peter. 1998. The Informal Game Theory in Hume's
Account of Convention. <em>Economics and Philosophy</em> 14(2): 215–247.</li>

<li>Velleman, J. David. 1997. Deciding how to Decide. In <em>Ethics
and Practical Reason</em>, edited by G. Culitty and B. Gaut,
pp. 29–52. Oxford: Oxford University Press.</li>

<li>Verbeek, Bruno. 2002. <em>Instrumental Rationality and Moral
Philosophy: an essay on the virtues of cooperation</em>. Dordrecht:
Kluwer Academic Publishers.</li>

<li>–––. 2007. The Authority of Norms. <em>American
Philosophical Quarterly</em> 44(3): 245–258.</li>

<li>–––. 2008. Conventions and Moral Norms: the
Legacy of Lewis. <em>Topoi</em> 27(1–2): 73–86.</li>

<li>Von Neumann, John, and Oskar Morgenstern. 1944. <em>Theory of Games
and Economic Behavior</em>. Princeton: Princeton University Press.</li>
</ul>

</div>

<div id="academic-tools">

<h2><a id="Aca">Academic Tools</a></h2>

<blockquote>
<table>
<tbody><tr><td valign="top"><img src="../../symbols/sepman-icon.jpg" alt="sep man icon" /></td>
<td><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=game-ethics&amp;archive=win2019" target="other">How to cite this entry</a>.</td>
</tr>
<tr><td valign="top"><img src="../../symbols/sepman-icon.jpg" alt="sep man icon" /></td>
<td><a href="https://leibniz.stanford.edu/friends/preview/game-ethics/" target="other">Preview the PDF version of this entry</a> at the <a href="https://leibniz.stanford.edu/friends/" target="other">Friends of the SEP Society</a>.</td>
</tr>
<tr><td valign="top"><img src="../../symbols/inpho.png" alt="inpho icon" /></td>
<td><a href="https://www.inphoproject.org/entity?sep=game-ethics&amp;redirect=True" target="other">Look up this entry topic</a> at the <a href="https://www.inphoproject.org/" target="other">Indiana Philosophy Ontology Project</a> (InPhO).</td>
</tr>
<tr><td valign="top"><img src="../../symbols/pp.gif" alt="phil papers icon" /></td>
<td><a href="http://philpapers.org/sep/game-ethics/" target="other">Enhanced bibliography for this entry</a> at <a href="http://philpapers.org" target="other">PhilPapers</a>, with links to its database.</td>
</tr>
</tbody></table>
</blockquote>

</div>

<div id="other-internet-resources">

<h2><a name="Oth">Other Internet Resources</a></h2>

<ul>

<li>Binmore, Ken. 2006. 
 “<a href="https://www.econstor.eu/bitstream/10419/31845/1/522542425.pdf" target="other">The Origins of Fair Play</a>,” 
 Papers on Economics and Evolution, No. 0614, Max-Planck-Institute
 für Ökonomik, Jea
<!-- cf. http://hdl.handle.net/10419/31845 -->
</li>

<li><a href="https://web.archive.org/web/20150417194529/http://www.hss.cmu.edu/philosophy/vanderschraaf/resources.htm#moral" target="other">Game Theory in Moral and Political Philosophy</a>,
 was maintained by Peter Vanderschraaf (Philosophy, Carnegie Mellon now at UC Merced)</li>

<li><a href="http://faculty.lebow.drexel.edu/McCainR/top/eco/game/game.html" target="other">Game Theory: An Introductory Sketch</a>,
  Roger A. McCain (Economics, Drexel University)</li>

<li><a href="https://stanford.edu/~alroth/alroth.html" target="other">Game Theory, Experimental Economics, and Market Design Page</a>,
  Al Roth (Economics, Stanford University)</li>

<li><a href="http://www.dklevine.com/general/whatis.htm" target="other">What is Game Theory?</a>,
  David K. Levine (Economics, UCLA)</li>


</ul>

</div>

<div id="related-entries">

<h2><a name="Rel">Related Entries</a></h2>

<p>

 <a href="../contractarianism/">contractarianism</a> |
 <a href="../functionalism/">functionalism</a> |
 <a href="../game-theory/">game theory</a> |
 <a href="../game-evolutionary/">game theory: evolutionary</a> |
 <a href="../prisoner-dilemma/">prisoner’s dilemma</a>

</p>

</div>

</div><!-- #aueditable --><!--DO NOT MODIFY THIS LINE AND BELOW-->

<!-- END ARTICLE HTML -->

</div> <!-- End article-content -->

  <div id="article-copyright">
    <p>
 <a href="../../info.html#c">Copyright © 2010</a> by

<br />
Bruno Verbeek
<br />
<a href="http://www.philosophy.umd.edu/people/morris" target="other">Christopher Morris</a>

    </p>
  </div>

</div> <!-- End article -->

<!-- NOTE: article banner is outside of the id="article" div. -->
<div id="article-banner" class="scroll-block">
     <div id="article-banner-content">
  <a href="../../fundraising/">
  Open access to the SEP is made possible by a world-wide funding initiative.<br />
  Please Read How You Can Help Keep the Encyclopedia Free</a>
 </div>


</div> <!-- End article-banner -->

    </div> <!-- End content -->

    <div id="footer">

      <div id="footer-menu">
        <div class="menu-block">
          <h4><i class="icon-book"></i> Browse</h4>
          <ul role="menu">
            <li><a href="../../contents.html">Table of Contents</a></li>
            <li><a href="../../new.html">New in this Archive</a></li>
            
            <li><a href="../../published.html">Chronological</a></li>
            <li><a href="../../../../archives/">Archives <i class="icon-external-link"></i></a></li>
          </ul>
        </div>
        <div class="menu-block">
          <h4><i class="icon-info-sign"></i> About</h4>
          <ul role="menu">
            <li><a href="../../info.html">Editorial Information</a></li>
            <li><a href="../../about.html">About the SEP</a></li>
            <li><a href="../../board.html">Editorial Board</a></li>
            <li><a href="../../cite.html">How to Cite the SEP</a></li>
            <li><a href="../../special-characters.html">Special Characters</a></li>
            
            <li><a href="../../../../contact.html">Contact <i class="icon-external-link"></i></a></li>
          </ul>
        </div>
        <div class="menu-block">
          <h4><i class="icon-leaf"></i> Support SEP</h4>
          <ul role="menu">
            <li><a href="../../../../support/">Support the SEP</a></li>
            <li><a href="../../../../support/friends.html">PDFs for SEP Friends</a></li>
            <li><a href="../../../../support/donate.html">Make a Donation</a></li>
            <li><a href="../../../../support/sepia.html">SEPIA for Libraries</a></li>
          </ul>
        </div>
      </div> <!-- End footer menu -->

      <div id="mirrors">
        <div id="mirror-info">
          <h4><i class="icon-globe"></i> Mirror Sites</h4>
          <p>View this site from another server:</p>
        </div>
                <div class="btn-group">
<a class="btn dropdown-toggle" data-toggle="dropdown" href="https://plato.stanford.edu/"><span class="flag flag-usa"></span> USA (Main Site) <span class="caret"></span><span class="mirror-source">CSLI, Stanford University</span></a>          <ul class="dropdown-menu">
            <li><a href="https://stanford.library.sydney.edu.au/archives/win2019/entries/game-ethics/"><span class="flag flag-australia"></span> Australia <span class="mirror-source">Library, University of Sydney</span></a>           </li>
            <li><a href="https://seop.illc.uva.nl/archives/win2019/entries/game-ethics/"><span class="flag flag-netherlands"></span> Netherlands <span class="mirror-source">ILLC, University of Amsterdam</span></a>           </li>
          </ul>
        </div>
      </div> <!-- End mirrors -->
      
      <div id="site-credits">
        <p class="csli-logo"><a href="https://www-csli.stanford.edu/"><img src="../../symbols/SU_csli.png" width="355" alt="Stanford Center for the Study of Language and Information" /></a></p>
        <p>The Stanford Encyclopedia of Philosophy is <a href="../../info.html#c">copyright © 2016</a> by <a href="http://mally.stanford.edu/">The Metaphysics Research Lab</a>, Center for the Study of Language and Information (CSLI), Stanford University</p>
        <p>Library of Congress Catalog Data: ISSN 1095-5054</p>
      </div> <!-- End site credits -->

    </div> <!-- End footer -->

  </div> <!-- End container -->

   <!-- NOTE: Script required for drop-down button to work (mirrors). -->
  <script>
    $('.dropdown-toggle').dropdown();
  </script>





</body></html>