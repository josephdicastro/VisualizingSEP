<!DOCTYPE html><!--[if lt IE 7]> <html class="ie6 ie"> <![endif]--><!--[if IE 7]>    <html class="ie7 ie"> <![endif]--><!--[if IE 8]>    <html class="ie8 ie"> <![endif]--><!--[if IE 9]>    <html class="ie9 ie"> <![endif]--><!--[if !IE]> --><html xmlns="http://www.w3.org/1999/xhtml"><!-- <![endif]--><head>
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>
Philosophy of Statistics (Stanford Encyclopedia of Philosophy/Winter 2019 Edition)
</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="robots" content="noarchive, noodp" />
<meta property="citation_title" content="Philosophy of Statistics" />
<meta property="citation_author" content="Romeijn, Jan-Willem" />
<meta property="citation_publication_date" content="2014/08/19" />
<meta name="DC.title" content="Philosophy of Statistics" />
<meta name="DC.creator" content="Romeijn, Jan-Willem" />
<meta name="DCTERMS.issued" content="2014-08-19" />
<meta name="DCTERMS.modified" content="2014-08-19" />

<!-- NOTE: Import webfonts using this link: -->
<link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,300,600,200&amp;subset=latin,latin-ext" rel="stylesheet" type="text/css" />

<link rel="stylesheet" type="text/css" media="screen,handheld" href="../../css/bootstrap.min.css" />
<link rel="stylesheet" type="text/css" media="screen,handheld" href="../../css/bootstrap-responsive.min.css" />
<link rel="stylesheet" type="text/css" href="../../css/font-awesome.min.css" />
<!--[if IE 7]> <link rel="stylesheet" type="text/css" href="../../css/font-awesome-ie7.min.css"> <![endif]-->
<link rel="stylesheet" type="text/css" media="screen,handheld" href="../../css/style.css" />
<link rel="stylesheet" type="text/css" media="print" href="../../css/print.css" />
<link rel="stylesheet" type="text/css" href="../../css/entry.css" />
<!--[if IE]> <link rel="stylesheet" type="text/css" href="../../css/ie.css" /> <![endif]-->
<script type="text/javascript" src="../../js/jquery-1.9.1.min.js"></script>
<script type="text/javascript" src="../../js/bootstrap.min.js"></script>

<!-- NOTE: Javascript for sticky behavior needed on article and ToC pages -->
<script type="text/javascript" src="../../js/jquery-scrolltofixed-min.js"></script>
<script type="text/javascript" src="../../js/entry.js"></script>

<!-- SEP custom script -->
<script type="text/javascript" src="../../js/sep.js"></script>
<style type="text/css">.MathJax_Hover_Frame {border-radius: .25em; -webkit-border-radius: .25em; -moz-border-radius: .25em; -khtml-border-radius: .25em; box-shadow: 0px 0px 15px #83A; -webkit-box-shadow: 0px 0px 15px #83A; -moz-box-shadow: 0px 0px 15px #83A; -khtml-box-shadow: 0px 0px 15px #83A; border: 1px solid #A6D ! important; display: inline-block; position: absolute}
.MathJax_Menu_Button .MathJax_Hover_Arrow {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 4px; -webkit-border-radius: 4px; -moz-border-radius: 4px; -khtml-border-radius: 4px; font-family: 'Courier New',Courier; font-size: 9px; color: #F0F0F0}
.MathJax_Menu_Button .MathJax_Hover_Arrow span {display: block; background-color: #AAA; border: 1px solid; border-radius: 3px; line-height: 0; padding: 4px}
.MathJax_Hover_Arrow:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_Hover_Arrow:hover span {background-color: #CCC!important}
</style><style type="text/css">#MathJax_About {position: fixed; left: 50%; width: auto; text-align: center; border: 3px outset; padding: 1em 2em; background-color: #DDDDDD; color: black; cursor: default; font-family: message-box; font-size: 120%; font-style: normal; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; border-radius: 15px; -webkit-border-radius: 15px; -moz-border-radius: 15px; -khtml-border-radius: 15px; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_About.MathJax_MousePost {outline: none}
.MathJax_Menu {position: absolute; background-color: white; color: black; width: auto; padding: 2px; border: 1px solid #CCCCCC; margin: 0; cursor: default; font: menu; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
.MathJax_MenuItem {padding: 2px 2em; background: transparent}
.MathJax_MenuArrow {position: absolute; right: .5em; padding-top: .25em; color: #666666; font-size: .75em}
.MathJax_MenuActive .MathJax_MenuArrow {color: white}
.MathJax_MenuArrow.RTL {left: .5em; right: auto}
.MathJax_MenuCheck {position: absolute; left: .7em}
.MathJax_MenuCheck.RTL {right: .7em; left: auto}
.MathJax_MenuRadioCheck {position: absolute; left: 1em}
.MathJax_MenuRadioCheck.RTL {right: 1em; left: auto}
.MathJax_MenuLabel {padding: 2px 2em 4px 1.33em; font-style: italic}
.MathJax_MenuRule {border-top: 1px solid #CCCCCC; margin: 4px 1px 0px}
.MathJax_MenuDisabled {color: GrayText}
.MathJax_MenuActive {background-color: Highlight; color: HighlightText}
.MathJax_MenuDisabled:focus, .MathJax_MenuLabel:focus {background-color: #E8E8E8}
.MathJax_ContextMenu:focus {outline: none}
.MathJax_ContextMenu .MathJax_MenuItem:focus {outline: none}
#MathJax_AboutClose {top: .2em; right: .2em}
.MathJax_Menu .MathJax_MenuClose {top: -10px; left: -10px}
.MathJax_MenuClose {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; font-family: 'Courier New',Courier; font-size: 24px; color: #F0F0F0}
.MathJax_MenuClose span {display: block; background-color: #AAA; border: 1.5px solid; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; line-height: 0; padding: 8px 0 6px}
.MathJax_MenuClose:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_MenuClose:hover span {background-color: #CCC!important}
.MathJax_MenuClose:hover:focus {outline: none}
</style><style type="text/css">.MathJax_Preview .MJXf-math {color: inherit!important}
</style><style type="text/css">.MJX_Assistive_MathML {position: absolute!important; top: 0; left: 0; clip: rect(1px, 1px, 1px, 1px); padding: 1px 0 0 0!important; border: 0!important; height: 1px!important; width: 1px!important; overflow: hidden!important; display: block!important; -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none}
.MJX_Assistive_MathML.MJX_Assistive_MathML_Block {width: 100%!important}
</style><style type="text/css">#MathJax_Zoom {position: absolute; background-color: #F0F0F0; overflow: auto; display: block; z-index: 301; padding: .5em; border: 1px solid black; margin: 0; font-weight: normal; font-style: normal; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; -webkit-box-sizing: content-box; -moz-box-sizing: content-box; box-sizing: content-box; box-shadow: 5px 5px 15px #AAAAAA; -webkit-box-shadow: 5px 5px 15px #AAAAAA; -moz-box-shadow: 5px 5px 15px #AAAAAA; -khtml-box-shadow: 5px 5px 15px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_ZoomOverlay {position: absolute; left: 0; top: 0; z-index: 300; display: inline-block; width: 100%; height: 100%; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
#MathJax_ZoomFrame {position: relative; display: inline-block; height: 0; width: 0}
#MathJax_ZoomEventTrap {position: absolute; left: 0; top: 0; z-index: 302; display: inline-block; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
</style><style type="text/css">.MathJax_Preview {color: #888}
#MathJax_Message {position: fixed; left: 1px; bottom: 2px; background-color: #E6E6E6; border: 1px solid #959595; margin: 0px; padding: 2px 8px; z-index: 102; color: black; font-size: 80%; width: auto; white-space: nowrap}
#MathJax_MSIE_Frame {position: absolute; top: 0; left: 0; width: 0px; z-index: 101; border: 0px; margin: 0px; padding: 0px}
.MathJax_Error {color: #CC0000; font-style: italic}
</style><style type="text/css">.MJXp-script {font-size: .8em}
.MJXp-right {-webkit-transform-origin: right; -moz-transform-origin: right; -ms-transform-origin: right; -o-transform-origin: right; transform-origin: right}
.MJXp-bold {font-weight: bold}
.MJXp-italic {font-style: italic}
.MJXp-scr {font-family: MathJax_Script,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-frak {font-family: MathJax_Fraktur,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-sf {font-family: MathJax_SansSerif,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-cal {font-family: MathJax_Caligraphic,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-mono {font-family: MathJax_Typewriter,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-largeop {font-size: 150%}
.MJXp-largeop.MJXp-int {vertical-align: -.2em}
.MJXp-math {display: inline-block; line-height: 1.2; text-indent: 0; font-family: 'Times New Roman',Times,STIXGeneral,serif; white-space: nowrap; border-collapse: collapse}
.MJXp-display {display: block; text-align: center; margin: 1em 0}
.MJXp-math span {display: inline-block}
.MJXp-box {display: block!important; text-align: center}
.MJXp-box:after {content: " "}
.MJXp-rule {display: block!important; margin-top: .1em}
.MJXp-char {display: block!important}
.MJXp-mo {margin: 0 .15em}
.MJXp-mfrac {margin: 0 .125em; vertical-align: .25em}
.MJXp-denom {display: inline-table!important; width: 100%}
.MJXp-denom &gt; * {display: table-row!important}
.MJXp-surd {vertical-align: top}
.MJXp-surd &gt; * {display: block!important}
.MJXp-script-box &gt; *  {display: table!important; height: 50%}
.MJXp-script-box &gt; * &gt; * {display: table-cell!important; vertical-align: top}
.MJXp-script-box &gt; *:last-child &gt; * {vertical-align: bottom}
.MJXp-script-box &gt; * &gt; * &gt; * {display: block!important}
.MJXp-mphantom {visibility: hidden}
.MJXp-munderover {display: inline-table!important}
.MJXp-over {display: inline-block!important; text-align: center}
.MJXp-over &gt; * {display: block!important}
.MJXp-munderover &gt; * {display: table-row!important}
.MJXp-mtable {vertical-align: .25em; margin: 0 .125em}
.MJXp-mtable &gt; * {display: inline-table!important; vertical-align: middle}
.MJXp-mtr {display: table-row!important}
.MJXp-mtd {display: table-cell!important; text-align: center; padding: .5em 0 0 .5em}
.MJXp-mtr &gt; .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mtr:first-child &gt; .MJXp-mtd {padding-top: 0}
.MJXp-mlabeledtr {display: table-row!important}
.MJXp-mlabeledtr &gt; .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mlabeledtr:first-child &gt; .MJXp-mtd {padding-top: 0}
.MJXp-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 1px 3px; font-style: normal; font-size: 90%}
.MJXp-scale0 {-webkit-transform: scaleX(.0); -moz-transform: scaleX(.0); -ms-transform: scaleX(.0); -o-transform: scaleX(.0); transform: scaleX(.0)}
.MJXp-scale1 {-webkit-transform: scaleX(.1); -moz-transform: scaleX(.1); -ms-transform: scaleX(.1); -o-transform: scaleX(.1); transform: scaleX(.1)}
.MJXp-scale2 {-webkit-transform: scaleX(.2); -moz-transform: scaleX(.2); -ms-transform: scaleX(.2); -o-transform: scaleX(.2); transform: scaleX(.2)}
.MJXp-scale3 {-webkit-transform: scaleX(.3); -moz-transform: scaleX(.3); -ms-transform: scaleX(.3); -o-transform: scaleX(.3); transform: scaleX(.3)}
.MJXp-scale4 {-webkit-transform: scaleX(.4); -moz-transform: scaleX(.4); -ms-transform: scaleX(.4); -o-transform: scaleX(.4); transform: scaleX(.4)}
.MJXp-scale5 {-webkit-transform: scaleX(.5); -moz-transform: scaleX(.5); -ms-transform: scaleX(.5); -o-transform: scaleX(.5); transform: scaleX(.5)}
.MJXp-scale6 {-webkit-transform: scaleX(.6); -moz-transform: scaleX(.6); -ms-transform: scaleX(.6); -o-transform: scaleX(.6); transform: scaleX(.6)}
.MJXp-scale7 {-webkit-transform: scaleX(.7); -moz-transform: scaleX(.7); -ms-transform: scaleX(.7); -o-transform: scaleX(.7); transform: scaleX(.7)}
.MJXp-scale8 {-webkit-transform: scaleX(.8); -moz-transform: scaleX(.8); -ms-transform: scaleX(.8); -o-transform: scaleX(.8); transform: scaleX(.8)}
.MJXp-scale9 {-webkit-transform: scaleX(.9); -moz-transform: scaleX(.9); -ms-transform: scaleX(.9); -o-transform: scaleX(.9); transform: scaleX(.9)}
.MathJax_PHTML .noError {vertical-align: ; font-size: 90%; text-align: left; color: black; padding: 1px 3px; border: 1px solid}
</style><style type="text/css">.MathJax_Display {text-align: center; margin: 1em 0em; position: relative; display: block!important; text-indent: 0; max-width: none; max-height: none; min-width: 0; min-height: 0; width: 100%}
.MathJax .merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 1px 3px; font-style: normal; font-size: 90%}
.MathJax .MJX-monospace {font-family: monospace}
.MathJax .MJX-sans-serif {font-family: sans-serif}
#MathJax_Tooltip {background-color: InfoBackground; color: InfoText; border: 1px solid black; box-shadow: 2px 2px 5px #AAAAAA; -webkit-box-shadow: 2px 2px 5px #AAAAAA; -moz-box-shadow: 2px 2px 5px #AAAAAA; -khtml-box-shadow: 2px 2px 5px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true'); padding: 3px 4px; z-index: 401; position: absolute; left: 0; top: 0; width: auto; height: auto; display: none}
.MathJax {display: inline; font-style: normal; font-weight: normal; line-height: normal; font-size: 100%; font-size-adjust: none; text-indent: 0; text-align: left; text-transform: none; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; padding: 0; margin: 0}
.MathJax:focus, body :focus .MathJax {display: inline-table}
.MathJax.MathJax_FullWidth {text-align: center; display: table-cell!important; width: 10000em!important}
.MathJax img, .MathJax nobr, .MathJax a {border: 0; padding: 0; margin: 0; max-width: 5000em; max-height: 5000em; min-width: 0; min-height: 0; vertical-align: 0; line-height: normal; text-decoration: none}
img.MathJax_strut {border: 0!important; padding: 0!important; margin: 0!important; vertical-align: 0!important}
.MathJax span {display: inline; position: static; border: 0; padding: 0; margin: 0; vertical-align: 0; line-height: normal; text-decoration: none}
.MathJax nobr {white-space: nowrap!important}
.MathJax img {display: inline!important; float: none!important}
.MathJax * {transition: none; -webkit-transition: none; -moz-transition: none; -ms-transition: none; -o-transition: none}
.MathJax_Processing {visibility: hidden; position: fixed; width: 0; height: 0; overflow: hidden}
.MathJax_Processed {display: none!important}
.MathJax_ExBox {display: block!important; overflow: hidden; width: 1px; height: 60ex; min-height: 0; max-height: none}
.MathJax .MathJax_EmBox {display: block!important; overflow: hidden; width: 1px; height: 60em; min-height: 0; max-height: none}
.MathJax_LineBox {display: table!important}
.MathJax_LineBox span {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MathJax .MathJax_HitBox {cursor: text; background: white; opacity: 0; filter: alpha(opacity=0)}
.MathJax .MathJax_HitBox * {filter: none; opacity: 1; background: transparent}
#MathJax_Tooltip * {filter: none; opacity: 1; background: transparent}
@font-face {font-family: MathJax_Main; src: url('https://plato.stanford.edu/archives/win2019/MathJax/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff?V=2.7.2') format('woff'), url('https://plato.stanford.edu/archives/win2019/MathJax/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf?V=2.7.2') format('opentype')}
@font-face {font-family: MathJax_Main-bold; src: url('https://plato.stanford.edu/archives/win2019/MathJax/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff?V=2.7.2') format('woff'), url('https://plato.stanford.edu/archives/win2019/MathJax/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf?V=2.7.2') format('opentype')}
@font-face {font-family: MathJax_Main-italic; src: url('https://plato.stanford.edu/archives/win2019/MathJax/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff?V=2.7.2') format('woff'), url('https://plato.stanford.edu/archives/win2019/MathJax/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf?V=2.7.2') format('opentype')}
@font-face {font-family: MathJax_Math-italic; src: url('https://plato.stanford.edu/archives/win2019/MathJax/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff?V=2.7.2') format('woff'), url('https://plato.stanford.edu/archives/win2019/MathJax/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf?V=2.7.2') format('opentype')}
@font-face {font-family: MathJax_Caligraphic; src: url('https://plato.stanford.edu/archives/win2019/MathJax/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff?V=2.7.2') format('woff'), url('https://plato.stanford.edu/archives/win2019/MathJax/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf?V=2.7.2') format('opentype')}
@font-face {font-family: MathJax_Size1; src: url('https://plato.stanford.edu/archives/win2019/MathJax/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff?V=2.7.2') format('woff'), url('https://plato.stanford.edu/archives/win2019/MathJax/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf?V=2.7.2') format('opentype')}
@font-face {font-family: MathJax_Size2; src: url('https://plato.stanford.edu/archives/win2019/MathJax/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff?V=2.7.2') format('woff'), url('https://plato.stanford.edu/archives/win2019/MathJax/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf?V=2.7.2') format('opentype')}
@font-face {font-family: MathJax_Size3; src: url('https://plato.stanford.edu/archives/win2019/MathJax/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff?V=2.7.2') format('woff'), url('https://plato.stanford.edu/archives/win2019/MathJax/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf?V=2.7.2') format('opentype')}
@font-face {font-family: MathJax_Size4; src: url('https://plato.stanford.edu/archives/win2019/MathJax/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff?V=2.7.2') format('woff'), url('https://plato.stanford.edu/archives/win2019/MathJax/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf?V=2.7.2') format('opentype')}
.MathJax .noError {vertical-align: ; font-size: 90%; text-align: left; color: black; padding: 1px 3px; border: 1px solid}
</style><style type="text/css">@font-face {font-family: MathJax_AMS; src: url('https://plato.stanford.edu/archives/win2019/MathJax/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff?V=2.7.2') format('woff'), url('https://plato.stanford.edu/archives/win2019/MathJax/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf?V=2.7.2') format('opentype')}
</style><script type="text/javascript" src="https://plato.stanford.edu/archives/win2019/MathJax/jax/output/HTML-CSS/autoload/mtable.js?V=2.7.2"></script></head>

<!-- NOTE: The nojs class is removed from the page if javascript is enabled. Otherwise, it drives the display when there is no javascript. -->
<body class="archive article" id="pagetopright"><div style="visibility: hidden; overflow: hidden; position: absolute; top: 0px; height: 1px; width: auto; padding: 0px; border: 0px; margin: 0px; text-align: left; text-indent: 0px; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal;"><div id="MathJax_Hidden"></div></div><div id="MathJax_Message" style="display: none;"></div>
<div id="container">
<div id="header-wrapper">
  <div id="header">
    <div id="branding">
      <div id="site-logo"><a href="../../index.html"><img src="../../symbols/sep-man-red.png" alt="SEP logo" /></a></div>
      <div id="site-title"><a href="../../index.html">Stanford Encyclopedia of Philosophy Archive<div id="site-subtitle">Winter 2019 Edition</div></a></div>
    </div>
    <div id="navigation">
      <div class="navbar">
        <div class="navbar-inner">
          <div class="container">
            <button class="btn btn-navbar collapsed" data-target=".collapse-main-menu" data-toggle="collapse" type="button"> <i class="icon-reorder"></i> Menu </button>
            <div class="nav-collapse collapse-main-menu collapse">
              <ul class="nav">
                <li class="dropdown"><a id="drop1" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-book"></i> Browse</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop1">
                    <li><a href="../../contents.html">Table of Contents</a></li>
                    <li><a href="../../new.html">New in this Archive</a></li>
                    
                    <li><a href="../../published.html">Chronological</a></li>
                    <li><a href="../../../../archives/">Archives <i class="icon-external-link"></i></a></li>
                  </ul>
                </li>
                <li class="dropdown"><a id="drop2" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-info-sign"></i> About</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop2">
                    <li><a href="../../info.html">Editorial Information</a></li>
                    <li><a href="../../about.html">About the SEP</a></li>
                    <li><a href="../../board.html">Editorial Board</a></li>
                    <li><a href="../../cite.html">How to Cite the SEP</a></li>
                    <li><a href="../../special-characters.html">Special Characters</a></li>
                    
                    <li><a href="../../../../contact.html">Contact <i class="icon-external-link"></i></a></li>
                  </ul>
                </li>
                <li class="dropdown"><a id="drop3" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-leaf"></i> Support SEP</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop3">
                    <li><a href="../../../../support/">Support the SEP</a></li>
                    <li><a href="../../../../support/friends.html">PDFs for SEP Friends</a></li>
                    <li><a href="../../../../support/donate.html">Make a Donation</a></li>
                    <li><a href="../../../../support/sepia.html">SEPIA for Libraries</a></li>
                  </ul>
                </li>
              </ul>
            </div>
          </div>
        </div>
      </div>
    </div>
    <!-- End navigation -->
    
    <div id="search">
      <form id="search-form" method="get" action="../../../../search/searcher.py">
        <input type="search" name="query" placeholder="Search this archive" />
<input type="hidden" name="archive" value="win2019" />

        <div class="search-btn-wrapper"><button class="btn search-btn" type="submit"><i class="icon-search"></i></button></div>
      </form>
    </div>
    <!-- End search --> 
    
  </div>
  <!-- End header --> 
</div>
<!-- End header wrapper -->

<div id="content">

<!-- Begin article sidebar -->
<div id="article-sidebar" class="sticky" style="z-index: 999;">
  <div class="navbar">
    <div class="navbar-inner">
      <div class="container">
        <button class="btn btn-navbar collapsed" data-target=".collapse-sidebar" data-toggle="collapse" type="button"> <i class="icon-reorder"></i> Entry Navigation </button>
        <div id="article-nav" class="nav-collapse collapse-sidebar collapse">
          <ul class="nav">
            <li><a href="#toc">Entry Contents</a></li>
            <li><a href="#Bib">Bibliography</a></li>
            <li><a href="#Aca">Academic Tools</a></li>
            <li><a href="https://leibniz.stanford.edu/friends/preview/statistics/">Friends PDF Preview <i class="icon-external-link"></i></a></li>
            <li><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=statistics&amp;archive=win2019">Author and Citation Info <i class="icon-external-link"></i></a> </li>
            <li><a href="#pagetopright" class="back-to-top">Back to Top <i class="icon-angle-up icon2x"></i></a></li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</div><div></div>
<!-- End article sidebar --> 

<!-- NOTE: Article content must have two wrapper divs: id="article" and id="article-content" -->
<div id="article">
<div id="article-content">

<!-- BEGIN ARTICLE HTML -->


<div id="aueditable"><!--DO NOT MODIFY THIS LINE AND ABOVE-->

<h1>Philosophy of Statistics</h1><div id="pubinfo"><em>First published Tue Aug 19, 2014</em></div>

<div id="preamble">

<p>Statistics investigates and develops specific methods for
evaluating hypotheses in the light of empirical facts. A method is
called statistical, and thus the subject of study in statistics, if it
relates facts and hypotheses of a particular kind: the empirical facts
must be codified and structured into data sets, and the hypotheses
must be formulated in terms of probability distributions over possible
data sets. The philosophy of statistics concerns the foundations and
the proper interpretation of statistical methods, their input, and
their results.  Since statistics is relied upon in almost all
empirical scientific research, serving to support and communicate
scientific findings, the philosophy of statistics is of key importance
to the philosophy of science. It has an impact on the philosophical
appraisal of scientific method, and on the debate over the epistemic
and ontological status of scientific theory.</p>

<p>The philosophy of statistics harbors a large variety of topics and
debates. Central to these is the 
 <a href="../induction-problem/">problem of induction</a>,
which concerns the justification of inferences or procedures that
extrapolate from data to predictions and general facts. Further
debates concern the
 <a href="../probability-interpret/">interpretation of the probabilities</a>
that are used in statistics, and the wider theoretical framework
that may ground and justify the correctness of statistical methods. A
general introduction to these themes is given in
 <a href="#StaInd">Section 1</a> and
 <a href="#FouInt">Section 2</a>. 
 <a href="#ClaSta">Section 3</a> and 
 <a href="#BaySta">Section 4</a> provide an account of how
these themes play out in the two major theories of statistical method,
classical and Bayesian statistics respectively.
 <a href="#StaMod">Section 5</a>
directs attention to the notion of a statistical model, covering model
selection and simplicity, but also discussing statistical techniques
that do not rely on statistical models. 
 <a href="#RelTop">Section 6</a> briefly
mentions relations between the philosophy of statistics and several
other themes from the philosophy of science, including 
 <a href="../confirmation/">confirmation theory</a>,
 <a href="../evidence/">evidence</a>, 
 causality, measurement, and scientific
methodology in general.</p>

</div>

<div id="toc">
<!--Entry Contents-->
<ul>
<li><a href="#StaInd">1. Statistics and induction</a></li>
<li><a href="#FouInt">2. Foundations and interpretations</a>
   <ul>
   <li><a href="#PhyProClaSta">2.1 Physical probability and classical statistics</a></li>
   <li><a href="#EpiProStaThe">2.2 Epistemic probability and statistical theory</a>
      <ul>
      <li><a href="#TypEpiPro">2.2.1 Types of epistemic probability</a></li>
      <li><a href="#StaThe">2.2.2 Statistical theories</a></li>
      </ul></li>
   </ul></li>
<li><a href="#ClaSta">3. Classical statistics</a>
   <ul>
   <li><a href="#BasClaSta">3.1 Basics of classical statistics</a>
      <ul>
      <li><a href="#HypTes">3.1.1 Hypothesis testing</a></li>
      <li><a href="#Est">3.1.2 Estimation</a></li>
      </ul></li>
   <li><a href="#ProForClaSta">3.2 Problems for classical statistics</a>
      <ul>
      <li><a href="#IntBel">3.2.1 Interface with belief</a></li>
      <li><a href="#NatEvi">3.2.2 The nature of evidence</a></li>
      <li><a href="#ExcOptSto">3.2.3 Excursion: optional stopping</a></li>
      </ul></li>
   <li><a href="#ClaStaResCri">3.3 Responses to criticism</a>
      <ul>
      <li><a href="#StrEvi">3.3.1 The strength of evidence</a></li>
      <li><a href="#TheDev">3.3.2 Theoretical developments </a></li>
      <li><a href="#ExcFidArg">3.3.3 Excursion: the fiducial argument</a></li>
      </ul></li>
   </ul></li>
<li><a href="#BaySta">4. Bayesian statistics</a>
   <ul>
   <li><a href="#BasPatInf">4.1 Basic pattern of inference</a>
      <ul>
      <li><a href="#FinMod">4.1.1 Finite model</a></li>
      <li><a href="#ConMod">4.1.2 Continuous model</a></li>
      </ul></li>
   <li><a href="#ProBayApp">4.2 Problems with the Bayesian approach</a>
      <ul>
      <li><a href="#IntProOveHyp">4.2.1 Interpretations of the probability over hypotheses</a></li>
      <li><a href="#DetPri">4.2.2 Determination of the prior</a></li>
      </ul></li>
   <li><a href="#BayStaResCri">4.3 Responses to criticism</a>
      <ul>
      <li><a href="#StrButEmpInfSub">4.3.1 Strict but empirically informed subjectivism </a></li>
      <li><a href="#ExcRepThe">4.3.2 Excursion: the representation theorem</a></li>
      <li><a href="#BayStaLog">4.3.3 Bayesian statistics as logic</a></li>
      <li><a href="#ExcIndLogSta">4.3.4 Excursion: inductive logic and statistics</a></li>
      <li><a href="#ObjPri">4.3.5 Objective priors</a></li>
      <li><a href="#CirPri">4.3.6 Circumventing priors</a></li>
      </ul></li>
   </ul></li>
<li><a href="#StaMod">5. Statistical models</a>
   <ul>
   <li><a href="#ModCom">5.1 Model comparisons</a>
      <ul>
      <li><a href="#AkaInfCri">5.1.1 Akaike's information criterion</a></li>
      <li><a href="#BayEvaMod">5.1.2 Bayesian evaluation of models</a></li>
      </ul></li>
   <li><a href="#StaWitMod">5.2 Statistics without models</a>
      <ul>
      <li><a href="#DatRedTec">5.2.1 Data reduction techniques</a></li>
      <li><a href="#ForLeaThe">5.2.2 Formal learning theory</a></li>
      </ul></li>
   </ul></li>
<li><a href="#RelTop">6. Related topics</a></li>
<li><a href="#Bib">Bibliography</a></li>
<li><a href="#Aca">Academic Tools</a></li>
<li><a href="#Oth">Other Internet Resources</a></li>
<li><a href="#Rel">Related Entries</a></li>
</ul>

<!--Entry Contents-->
<hr />
</div>

<div id="main-text">

<h2><a id="StaInd">1. Statistics and induction</a></h2>

<p>
Statistics is a mathematical and conceptual discipline that focuses on the relation
between data and hypotheses. The <em>data</em> are recordings of
observations or events in a scientific study, e.g., a set of
measurements of individuals from a population. The data actually
obtained are variously called the <em>sample</em>, the <em>sample
data</em>, or simply the <em>data</em>, and all possible samples from
a study are collected in what is called a <em>sample
space</em>. The <em>hypotheses</em>, in turn, are general
statements about the target system of the scientific study, e.g.,
expressing some general fact about all individuals in the population.
A <em>statistical hypothesis</em> is a general statement that can
be expressed by a probability distribution over sample space, i.e., it
determines a probability for each of the possible samples. </p>

<p>Statistical methods provide the mathematical and conceptual means
to evaluate statistical hypotheses in the light of a sample. To this
aim they employ probability theory, and incidentally generalizations
thereof. The evaluations may determine how believable a hypothesis is,
whether we may rely on the hypothesis in our decisions, how strong the
support is that the sample gives to the hypothesis, and so on. Good
introductions to statistics abound (e.g., Barnett 1999, Mood and
Graybill 1974, Press 2002).</p>

<p>To set the stage an example, taken from Fisher (1935), will be
helpful.</p>

<blockquote>
<strong>The tea tasting lady</strong>.<br />  Consider a lady who
claims that she can, by taste, determine the order in which milk and
tea were poured into the cup. Now imagine that we prepare five cups of
tea for her, tossing a fair coin to determine the order of milk and
tea in each cup. We ask her to pronounce the order, and we find that
she is correct in all cases! Now if she is guessing the order blindly
then, owing to the random way we prepare the cups, she will answer
correctly 50% of the time. This is our statistical hypothesis,
referred to as the null hypothesis. It gives a probability of <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1"><span class="MJXp-mn" id="MJXp-Span-2">1</span><span class="MJXp-mrow" id="MJXp-Span-3"><span class="MJXp-mo" id="MJXp-Span-4" style="margin-left: 0.111em; margin-right: 0.111em;">/</span></span><span class="MJXp-mn" id="MJXp-Span-5">2</span></span></span><span class="MathJax MathJax_Processed" id="MathJax-Element-1-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1"><span style="display: inline-block; position: relative; width: 0em; height: 0px; font-size: 103%;"><span style="position: absolute;"><span class="mrow" id="MathJax-Span-2"><span class="mn" id="MathJax-Span-3" style="font-family: MathJax_Main;">1</span><span class="texatom" id="MathJax-Span-4"><span class="mrow" id="MathJax-Span-5"><span class="mo" id="MathJax-Span-6" style="font-family: MathJax_Main;">/</span></span></span><span class="mn" id="MathJax-Span-7" style="font-family: MathJax_Main;">2</span></span></span></span></span></nobr></span><script type="math/tex" id="MathJax-Element-1">1/2</script>
to a correct guess and hence a probability of <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-6"><span class="MJXp-mn" id="MJXp-Span-7">1</span><span class="MJXp-mrow" id="MJXp-Span-8"><span class="MJXp-mo" id="MJXp-Span-9" style="margin-left: 0.111em; margin-right: 0.111em;">/</span></span><span class="MJXp-mn" id="MJXp-Span-10">2</span></span></span><span class="MathJax MathJax_Processed" id="MathJax-Element-2-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-8"><span style="display: inline-block; position: relative; width: 0em; height: 0px; font-size: 103%;"><span style="position: absolute;"><span class="mrow" id="MathJax-Span-9"><span class="mn" id="MathJax-Span-10" style="font-family: MathJax_Main;">1</span><span class="texatom" id="MathJax-Span-11"><span class="mrow" id="MathJax-Span-12"><span class="mo" id="MathJax-Span-13" style="font-family: MathJax_Main;">/</span></span></span><span class="mn" id="MathJax-Span-14" style="font-family: MathJax_Main;">2</span></span></span></span></span></nobr></span><script type="math/tex" id="MathJax-Element-2">1/2</script> to an incorrect
one. The sample space consists of all strings of answers the lady
might give, i.e., all series of correct and incorrect guesses, but our
actual data sits in a rather special corner in this space. On the
assumption of our statistical hypothesis, the probability of the
recorded events is a mere 3%, or <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-11"><span class="MJXp-mn" id="MJXp-Span-12">1</span><span class="MJXp-mrow" id="MJXp-Span-13"><span class="MJXp-mo" id="MJXp-Span-14" style="margin-left: 0.111em; margin-right: 0.111em;">/</span></span><span class="MJXp-msubsup" id="MJXp-Span-15"><span class="MJXp-mn" id="MJXp-Span-16" style="margin-right: 0.05em;">2</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-17" style="vertical-align: 0.5em;"><span class="MJXp-mn" id="MJXp-Span-18">5</span></span></span></span></span><span class="MathJax MathJax_Processed" id="MathJax-Element-3-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-15"><span style="display: inline-block; position: relative; width: 0em; height: 0px; font-size: 103%;"><span style="position: absolute;"><span class="mrow" id="MathJax-Span-16"><span class="mn" id="MathJax-Span-17" style="font-family: MathJax_Main;">1</span><span class="texatom" id="MathJax-Span-18"><span class="mrow" id="MathJax-Span-19"><span class="mo" id="MathJax-Span-20" style="font-family: MathJax_Main;">/</span></span></span><span class="msubsup" id="MathJax-Span-21"><span style="display: inline-block; position: relative; width: 0.929em; height: 0px;"><span style="position: absolute; clip: rect(3.159em, 1000.45em, 4.178em, -1000em); top: -4.001em; left: 0em;"><span class="mn" id="MathJax-Span-22" style="font-family: MathJax_Main;">2</span><span style="display: inline-block; width: 0px; height: 4.001em;"></span></span><span style="position: absolute; top: -4.394em; left: 0.5em;"><span class="texatom" id="MathJax-Span-23"><span class="mrow" id="MathJax-Span-24"><span class="mn" id="MathJax-Span-25" style="font-size: 70.7%; font-family: MathJax_Main;">5</span></span></span><span style="display: inline-block; width: 0px; height: 4.001em;"></span></span></span></span></span></span></span></span></nobr></span><script type="math/tex" id="MathJax-Element-3">1/2^{5}</script> more precisely. On this
ground, we may decide to reject the hypothesis that the lady is
guessing.</blockquote>

<p>According to the so-called <em>null hypothesis test</em>, such a
decision is warranted if the data actually obtained are included in a
particular region within sample space, whose total probability does
not exceed some specified limit, standardly set at 5%. Now consider
what is achieved by the statistical test just outlined. We started
with a hypothesis on the actual tea tasting abilities of the lady,
namely, that she did not have any. On the assumption of this
hypothesis, the sample data we obtained turned out to be surprising
or, more precisely, highly improbable. We therefore decided that the
hypothesis that the lady has no tea tasting abilities whatsoever can
be rejected. The sample points us to a negative but general conclusion
about what the lady can, or cannot, do.</p>

<p>The basic pattern of a statistical analysis is thus familiar from
inductive inference: we input the data obtained thus far, and the
statistical procedure outputs a verdict or evaluation that transcends
the data, i.e, a statement that is not entailed by the data alone. If
the data are indeed considered to be the only input, and if the
statistical procedure is understood as an inference, then statistics
is concerned with <em>ampliative</em> inference: roughly speaking, we
get out more than we have put in. And since the ampliative inferences
of statistics pertain to future or general states of affairs, they are
inductive.  However, the association of statistics with ampliative and
inductive inference is contested, both because statistics is
considered to be non-inferential by some (see 
 <a href="#ClaSta">Section 3</a>) and
non-ampliative by others (see 
 <a href="#BaySta">Section 4</a>).</p>

<p>Despite such disagreements, it is insightful to view statistics as
a response to the problem of induction (cf. Howson 2000 and the
 entry on the
 <a href="../induction-problem/">problem of induction</a>). 
This problem, first discussed by Hume in his <em>Treatise of Human
Nature</em> (Book I, part 3, section 6) but prefigured already by
ancient sceptics like Sextus Empiricus (see the entry on
 <a href="../skepticism-ancient/">ancient skepticism</a>), 
is that there is no proper justification for
inferences that run from given experience to expectations about the
future. Transposed to the context of statistics, it reads that there
is no proper justification for procedures that take data as input and
that return a verdict, an evaluation, or some other piece of advice
that pertains to the future, or to general states of affairs. Arguably,
much of the philosophy of statistics is about coping with this
challenge, by providing a foundation of the procedures that statistics
offers, or else by reinterpreting what statistics delivers so as to
evade the challenge.</p>

<p>It is debatable that philosophers of statistics are ultimately
concerned with the delicate, even ethereal issue of the justification
of induction. In fact, many philosophers and scientists accept the
fallibility of statistics, and find it more important that statistical
methods are understood and applied correctly. As is so often the case,
the fundamental philosophical problem serves as a catalyst: the
problem of induction guides our investigations into the workings, the
correctness, and the conditions of applicability of statistical
methods. The philosophy of statistics, understood as the general
header under which these investigations are carried out, is thus not
concerned with ephemeral issues, but presents a vital and concrete
contribution to the philosophy of science, and to science itself.</p>

<h2><a id="FouInt">2. Foundations and interpretations</a></h2>

<p> While there is large variation in how statistical procedures and
inferences are organized, they all agree on the use of modern
measure-theoretic probability theory (Kolmogorov ), or a near
kin, as the means to express hypotheses and relate them to data. By
itself, a probability function is simply a particular kind of
mathematical function, used to express the measure of a set
(cf. Billingsley 1995). </p>

<p>Let <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-19"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-20">W</span></span></span><span class="MathJax MathJax_Processed" id="MathJax-Element-4-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-26"><span style="display: inline-block; position: relative; width: 0em; height: 0px; font-size: 103%;"><span style="position: absolute;"><span class="mrow" id="MathJax-Span-27"><span class="mi" id="MathJax-Span-28" style="font-family: MathJax_Math-italic;">W<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.104em;"></span></span></span></span></span></span></nobr></span><script type="math/tex" id="MathJax-Element-4">W</script> be a set with elements <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-21"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-22">s</span></span></span><span class="MathJax MathJax_Processed" id="MathJax-Element-5-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-29"><span style="display: inline-block; position: relative; width: 0em; height: 0px; font-size: 103%;"><span style="position: absolute;"><span class="mrow" id="MathJax-Span-30"><span class="mi" id="MathJax-Span-31" style="font-family: MathJax_Math-italic;">s</span></span></span></span></span></nobr></span><script type="math/tex" id="MathJax-Element-5">s</script>, and consider an initial
collection of subsets of <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-23"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-24">W</span></span></span><span class="MathJax MathJax_Processed" id="MathJax-Element-6-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-32"><span style="display: inline-block; position: relative; width: 0em; height: 0px; font-size: 103%;"><span style="position: absolute;"><span class="mrow" id="MathJax-Span-33"><span class="mi" id="MathJax-Span-34" style="font-family: MathJax_Math-italic;">W<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.104em;"></span></span></span></span></span></span></nobr></span><script type="math/tex" id="MathJax-Element-6">W</script>, e.g., the singleton sets <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-25"><span class="MJXp-mo" id="MJXp-Span-26" style="margin-left: 0em; margin-right: 0em;">{</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-27">s</span><span class="MJXp-mo" id="MJXp-Span-28" style="margin-left: 0em; margin-right: 0em;">}</span></span></span><span class="MathJax MathJax_Processed" id="MathJax-Element-7-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-35"><span style="display: inline-block; position: relative; width: 0em; height: 0px; font-size: 103%;"><span style="position: absolute;"><span class="mrow" id="MathJax-Span-36"><span class="mo" id="MathJax-Span-37" style="font-family: MathJax_Main;">{</span><span class="mi" id="MathJax-Span-38" style="font-family: MathJax_Math-italic;">s</span><span class="mo" id="MathJax-Span-39" style="font-family: MathJax_Main;">}</span></span></span></span></span></nobr></span><script type="math/tex" id="MathJax-Element-7">\{ s
\}</script>. Now consider the operation of taking the complement <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-29"><span class="MJXp-mrow" id="MJXp-Span-30"><span class="MJXp-munderover" id="MJXp-Span-31"><span><span class="MJXp-over"><span class="" style="margin-bottom: -0.92em;"><span class="MJXp-mo" id="MJXp-Span-33" style="margin-left: 0px; margin-right: 0px;">ˉ</span></span><span class=""><span class="MJXp-mi MJXp-italic" id="MJXp-Span-32">R</span></span></span></span></span></span></span></span><span class="MathJax MathJax_Processed" id="MathJax-Element-8-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-40"><span style="display: inline-block; position: relative; width: 0em; height: 0px; font-size: 103%;"><span style="position: absolute;"><span class="mrow" id="MathJax-Span-41"><span class="texatom" id="MathJax-Span-42"><span class="mrow" id="MathJax-Span-43"><span class="munderover" id="MathJax-Span-44"><span style="display: inline-block; position: relative; width: 0.759em; height: 0px;"><span style="position: absolute; clip: rect(3.142em, 1000.75em, 4.199em, -1000em); top: -4.001em; left: 0em;"><span class="mi" id="MathJax-Span-45" style="font-family: MathJax_Math-italic;">R</span><span style="display: inline-block; width: 0px; height: 4.001em;"></span></span><span style="position: absolute; clip: rect(3.235em, 1000.43em, 3.634em, -1000em); top: -4.287em; left: 0.213em;"><span class="mo" id="MathJax-Span-46" style="font-family: MathJax_Main;">¯</span><span style="display: inline-block; width: 0px; height: 4.001em;"></span></span></span></span></span></span></span></span></span></span></nobr></span><script type="math/tex" id="MathJax-Element-8">\bar{R}</script>
of a given set <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-34"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-35">R</span></span></span><span class="MathJax MathJax_Processed" id="MathJax-Element-9-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-47"><span style="display: inline-block; position: relative; width: 0em; height: 0px; font-size: 103%;"><span style="position: absolute;"><span class="mrow" id="MathJax-Span-48"><span class="mi" id="MathJax-Span-49" style="font-family: MathJax_Math-italic;">R</span></span></span></span></span></nobr></span><script type="math/tex" id="MathJax-Element-9">R</script>: the complement <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-36"><span class="MJXp-mrow" id="MJXp-Span-37"><span class="MJXp-munderover" id="MJXp-Span-38"><span><span class="MJXp-over"><span class="" style="margin-bottom: -0.92em;"><span class="MJXp-mo" id="MJXp-Span-40" style="margin-left: 0px; margin-right: 0px;">ˉ</span></span><span class=""><span class="MJXp-mi MJXp-italic" id="MJXp-Span-39">R</span></span></span></span></span></span></span></span><span class="MathJax MathJax_Processed" id="MathJax-Element-10-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-50"><span style="display: inline-block; position: relative; width: 0em; height: 0px; font-size: 103%;"><span style="position: absolute;"><span class="mrow" id="MathJax-Span-51"><span class="texatom" id="MathJax-Span-52"><span class="mrow" id="MathJax-Span-53"><span class="munderover" id="MathJax-Span-54"><span style="display: inline-block; position: relative; width: 0.759em; height: 0px;"><span style="position: absolute; clip: rect(3.142em, 1000.75em, 4.199em, -1000em); top: -4.001em; left: 0em;"><span class="mi" id="MathJax-Span-55" style="font-family: MathJax_Math-italic;">R</span><span style="display: inline-block; width: 0px; height: 4.001em;"></span></span><span style="position: absolute; clip: rect(3.235em, 1000.43em, 3.634em, -1000em); top: -4.287em; left: 0.213em;"><span class="mo" id="MathJax-Span-56" style="font-family: MathJax_Main;">¯</span><span style="display: inline-block; width: 0px; height: 4.001em;"></span></span></span></span></span></span></span></span></span></span></nobr></span><script type="math/tex" id="MathJax-Element-10">\bar{R}</script> contains exactly and
all those <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-41"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-42">s</span></span></span><span class="MathJax MathJax_Processed" id="MathJax-Element-11-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-57"><span style="display: inline-block; position: relative; width: 0em; height: 0px; font-size: 103%;"><span style="position: absolute;"><span class="mrow" id="MathJax-Span-58"><span class="mi" id="MathJax-Span-59" style="font-family: MathJax_Math-italic;">s</span></span></span></span></span></nobr></span><script type="math/tex" id="MathJax-Element-11">s</script> that are not included in <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-43"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-44">R</span></span></span><span class="MathJax MathJax_Processed" id="MathJax-Element-12-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-60"><span style="display: inline-block; position: relative; width: 0em; height: 0px; font-size: 103%;"><span style="position: absolute;"><span class="mrow" id="MathJax-Span-61"><span class="mi" id="MathJax-Span-62" style="font-family: MathJax_Math-italic;">R</span></span></span></span></span></nobr></span><script type="math/tex" id="MathJax-Element-12">R</script>. Next consider the join
<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-45"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-46">R</span><span class="MJXp-mo" id="MJXp-Span-47" style="margin-left: 0.267em; margin-right: 0.267em;">∪</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-48">Q</span></span></span><span class="MathJax MathJax_Processed" id="MathJax-Element-13-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-63"><span style="display: inline-block; position: relative; width: 0em; height: 0px; font-size: 103%;"><span style="position: absolute;"><span class="mrow" id="MathJax-Span-64"><span class="mi" id="MathJax-Span-65" style="font-family: MathJax_Math-italic;">R</span><span class="mo" id="MathJax-Span-66" style="font-family: MathJax_Main; padding-left: 0.222em;">∪</span><span class="mi" id="MathJax-Span-67" style="font-family: MathJax_Math-italic; padding-left: 0.222em;">Q</span></span></span></span></span></nobr></span><script type="math/tex" id="MathJax-Element-13">R \cup Q</script> given sets <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-49"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-50">R</span></span></span><span class="MathJax MathJax_Processed" id="MathJax-Element-14-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-68"><span style="display: inline-block; position: relative; width: 0em; height: 0px; font-size: 103%;"><span style="position: absolute;"><span class="mrow" id="MathJax-Span-69"><span class="mi" id="MathJax-Span-70" style="font-family: MathJax_Math-italic;">R</span></span></span></span></span></nobr></span><script type="math/tex" id="MathJax-Element-14">R</script> and <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-51"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-52">Q</span></span></span><span class="MathJax MathJax_Processed" id="MathJax-Element-15-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-71"><span style="display: inline-block; position: relative; width: 0em; height: 0px; font-size: 103%;"><span style="position: absolute;"><span class="mrow" id="MathJax-Span-72"><span class="mi" id="MathJax-Span-73" style="font-family: MathJax_Math-italic;">Q</span></span></span></span></span></nobr></span><script type="math/tex" id="MathJax-Element-15">Q</script>: an element <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-53"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-54">s</span></span></span><span class="MathJax MathJax_Processed" id="MathJax-Element-16-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-74"><span style="display: inline-block; position: relative; width: 0em; height: 0px; font-size: 103%;"><span style="position: absolute;"><span class="mrow" id="MathJax-Span-75"><span class="mi" id="MathJax-Span-76" style="font-family: MathJax_Math-italic;">s</span></span></span></span></span></nobr></span><script type="math/tex" id="MathJax-Element-16">s</script> is a member
of <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-55"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-56">R</span><span class="MJXp-mo" id="MJXp-Span-57" style="margin-left: 0.267em; margin-right: 0.267em;">∪</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-58">Q</span></span></span><span class="MathJax MathJax_Processed" id="MathJax-Element-17-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-77"><span style="display: inline-block; position: relative; width: 0em; height: 0px; font-size: 103%;"><span style="position: absolute;"><span class="mrow" id="MathJax-Span-78"><span class="mi" id="MathJax-Span-79" style="font-family: MathJax_Math-italic;">R</span><span class="mo" id="MathJax-Span-80" style="font-family: MathJax_Main; padding-left: 0.222em;">∪</span><span class="mi" id="MathJax-Span-81" style="font-family: MathJax_Math-italic; padding-left: 0.222em;">Q</span></span></span></span></span></nobr></span><script type="math/tex" id="MathJax-Element-17">R \cup Q</script> precisely when it is a member of <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-59"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-60">R</span></span></span><span class="MathJax MathJax_Processed" id="MathJax-Element-18-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-82"><span style="display: inline-block; position: relative; width: 0em; height: 0px; font-size: 103%;"><span style="position: absolute;"><span class="mrow" id="MathJax-Span-83"><span class="mi" id="MathJax-Span-84" style="font-family: MathJax_Math-italic;">R</span></span></span></span></span></nobr></span><script type="math/tex" id="MathJax-Element-18">R</script>, <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-61"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-62">Q</span></span></span><span class="MathJax MathJax_Processed" id="MathJax-Element-19-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-85"><span style="display: inline-block; position: relative; width: 0em; height: 0px; font-size: 103%;"><span style="position: absolute;"><span class="mrow" id="MathJax-Span-86"><span class="mi" id="MathJax-Span-87" style="font-family: MathJax_Math-italic;">Q</span></span></span></span></span></nobr></span><script type="math/tex" id="MathJax-Element-19">Q</script>, or
both. The collection of sets generated by the operations of complement
and join is called an
<em>algebra</em>, denoted <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-63"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-64">S</span></span></span><span class="MathJax MathJax_Processed" id="MathJax-Element-20-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-88"><span style="display: inline-block; position: relative; width: 0em; height: 0px; font-size: 103%;"><span style="position: absolute;"><span class="mrow" id="MathJax-Span-89"><span class="mi" id="MathJax-Span-90" style="font-family: MathJax_Math-italic;">S<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.032em;"></span></span></span></span></span></span></nobr></span><script type="math/tex" id="MathJax-Element-20">S</script>. In statistics we interpret <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-65"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-66">S</span></span></span><span class="MathJax MathJax_Processed" id="MathJax-Element-21-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-91"><span style="display: inline-block; position: relative; width: 0em; height: 0px; font-size: 103%;"><span style="position: absolute;"><span class="mrow" id="MathJax-Span-92"><span class="mi" id="MathJax-Span-93" style="font-family: MathJax_Math-italic;">S<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.032em;"></span></span></span></span></span></span></nobr></span><script type="math/tex" id="MathJax-Element-21">S</script> as
the set of samples, and we can associate sets <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-67"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-68">R</span></span></span><span class="MathJax MathJax_Processed" id="MathJax-Element-22-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-94"><span style="display: inline-block; position: relative; width: 0em; height: 0px; font-size: 103%;"><span style="position: absolute;"><span class="mrow" id="MathJax-Span-95"><span class="mi" id="MathJax-Span-96" style="font-family: MathJax_Math-italic;">R</span></span></span></span></span></nobr></span><script type="math/tex" id="MathJax-Element-22">R</script> with specific
events or observations. A specific sample <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-69"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-70">s</span></span></span><span class="MathJax MathJax_Processed" id="MathJax-Element-23-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-97"><span style="display: inline-block; position: relative; width: 0em; height: 0px; font-size: 103%;"><span style="position: absolute;"><span class="mrow" id="MathJax-Span-98"><span class="mi" id="MathJax-Span-99" style="font-family: MathJax_Math-italic;">s</span></span></span></span></span></nobr></span><script type="math/tex" id="MathJax-Element-23">s</script> includes a record of
the event denoted with <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-71"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-72">R</span></span></span><span class="MathJax MathJax_Processed" id="MathJax-Element-24-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-100"><span style="display: inline-block; position: relative; width: 0em; height: 0px; font-size: 103%;"><span style="position: absolute;"><span class="mrow" id="MathJax-Span-101"><span class="mi" id="MathJax-Span-102" style="font-family: MathJax_Math-italic;">R</span></span></span></span></span></nobr></span><script type="math/tex" id="MathJax-Element-24">R</script> exactly when <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-73"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-74">s</span><span class="MJXp-mo" id="MJXp-Span-75" style="margin-left: 0.333em; margin-right: 0.333em;">∈</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-76">R</span></span></span><span class="MathJax MathJax_Processed" id="MathJax-Element-25-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-103"><span style="display: inline-block; position: relative; width: 0em; height: 0px; font-size: 103%;"><span style="position: absolute;"><span class="mrow" id="MathJax-Span-104"><span class="mi" id="MathJax-Span-105" style="font-family: MathJax_Math-italic;">s</span><span class="mo" id="MathJax-Span-106" style="font-family: MathJax_Main; padding-left: 0.278em;">∈</span><span class="mi" id="MathJax-Span-107" style="font-family: MathJax_Math-italic; padding-left: 0.278em;">R</span></span></span></span></span></nobr></span><script type="math/tex" id="MathJax-Element-25">s \in R</script>. We take the
algebra of sets like <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-77"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-78">R</span></span></span><span class="MathJax MathJax_Processed" id="MathJax-Element-26-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-108"><span style="display: inline-block; position: relative; width: 0em; height: 0px; font-size: 103%;"><span style="position: absolute;"><span class="mrow" id="MathJax-Span-109"><span class="mi" id="MathJax-Span-110" style="font-family: MathJax_Math-italic;">R</span></span></span></span></span></nobr></span><script type="math/tex" id="MathJax-Element-26">R</script> as a language for making claims about the
samples.</p>

<p>A <em>probability function</em> is defined as an additive
normalized measure over the algebra: a function

    <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-79"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-80">P</span><span class="MJXp-mo" id="MJXp-Span-81" style="margin-left: 0.111em; margin-right: 0.167em;">:</span><span class="MJXp-mrow" id="MJXp-Span-82"><span class="MJXp-mi MJXp-cal" id="MJXp-Span-83">S</span></span><span class="MJXp-mo" id="MJXp-Span-84" style="margin-left: 0.333em; margin-right: 0.333em;">→</span><span class="MJXp-mo" id="MJXp-Span-85" style="margin-left: 0em; margin-right: 0em;">[</span><span class="MJXp-mn" id="MJXp-Span-86">0</span><span class="MJXp-mo" id="MJXp-Span-87" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mn" id="MJXp-Span-88">1</span><span class="MJXp-mo" id="MJXp-Span-89" style="margin-left: 0em; margin-right: 0em;">]</span></span></span><div class="MathJax_Display MathJax_Processed"><span class="MathJax" id="MathJax-Element-27-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-111"><span style="display: inline-block; position: relative; width: 0em; height: 0px; font-size: 103%;"><span style="position: absolute;"><span class="mrow" id="MathJax-Span-112"><span class="mi" id="MathJax-Span-113" style="font-family: MathJax_Math-italic;">P<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.109em;"></span></span><span class="mo" id="MathJax-Span-114" style="font-family: MathJax_Main; padding-left: 0.278em;">:</span><span class="texatom" id="MathJax-Span-115" style="padding-left: 0.278em;"><span class="mrow" id="MathJax-Span-116"><span class="mi" id="MathJax-Span-117" style="font-family: MathJax_Caligraphic;">S<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.036em;"></span></span></span></span><span class="mo" id="MathJax-Span-118" style="font-family: MathJax_Main; padding-left: 0.278em;">→</span><span class="mo" id="MathJax-Span-119" style="font-family: MathJax_Main; padding-left: 0.278em;">[</span><span class="mn" id="MathJax-Span-120" style="font-family: MathJax_Main;">0</span><span class="mo" id="MathJax-Span-121" style="font-family: MathJax_Main;">,</span><span class="mn" id="MathJax-Span-122" style="font-family: MathJax_Main; padding-left: 0.167em;">1</span><span class="mo" id="MathJax-Span-123" style="font-family: MathJax_Main;">]</span></span></span></span></span></nobr></span></div><script type="math/tex; mode=display" id="MathJax-Element-27"> P: {\cal S} \rightarrow [0, 1] </script>  

such that <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-90"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-91">P</span><span class="MJXp-mo" id="MJXp-Span-92" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-93">R</span><span class="MJXp-mo" id="MJXp-Span-94" style="margin-left: 0.267em; margin-right: 0.267em;">∪</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-95">Q</span><span class="MJXp-mo" id="MJXp-Span-96" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-97" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-98">P</span><span class="MJXp-mo" id="MJXp-Span-99" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-100">R</span><span class="MJXp-mo" id="MJXp-Span-101" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-102" style="margin-left: 0.267em; margin-right: 0.267em;">+</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-103">P</span><span class="MJXp-mo" id="MJXp-Span-104" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-105">Q</span><span class="MJXp-mo" id="MJXp-Span-106" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax MathJax_Processed" id="MathJax-Element-28-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-124"><span style="display: inline-block; position: relative; width: 0em; height: 0px; font-size: 103%;"><span style="position: absolute;"><span class="mrow" id="MathJax-Span-125"><span class="mi" id="MathJax-Span-126" style="font-family: MathJax_Math-italic;">P<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.109em;"></span></span><span class="mo" id="MathJax-Span-127" style="font-family: MathJax_Main;">(</span><span class="mi" id="MathJax-Span-128" style="font-family: MathJax_Math-italic;">R</span><span class="mo" id="MathJax-Span-129" style="font-family: MathJax_Main; padding-left: 0.222em;">∪</span><span class="mi" id="MathJax-Span-130" style="font-family: MathJax_Math-italic; padding-left: 0.222em;">Q</span><span class="mo" id="MathJax-Span-131" style="font-family: MathJax_Main;">)</span><span class="mo" id="MathJax-Span-132" style="font-family: MathJax_Main; padding-left: 0.278em;">=</span><span class="mi" id="MathJax-Span-133" style="font-family: MathJax_Math-italic; padding-left: 0.278em;">P<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.109em;"></span></span><span class="mo" id="MathJax-Span-134" style="font-family: MathJax_Main;">(</span><span class="mi" id="MathJax-Span-135" style="font-family: MathJax_Math-italic;">R</span><span class="mo" id="MathJax-Span-136" style="font-family: MathJax_Main;">)</span><span class="mo" id="MathJax-Span-137" style="font-family: MathJax_Main; padding-left: 0.222em;">+</span><span class="mi" id="MathJax-Span-138" style="font-family: MathJax_Math-italic; padding-left: 0.222em;">P<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.109em;"></span></span><span class="mo" id="MathJax-Span-139" style="font-family: MathJax_Main;">(</span><span class="mi" id="MathJax-Span-140" style="font-family: MathJax_Math-italic;">Q</span><span class="mo" id="MathJax-Span-141" style="font-family: MathJax_Main;">)</span></span></span></span></span></nobr></span><script type="math/tex" id="MathJax-Element-28">P(R \cup Q) = P(R) + P(Q)</script> if <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-107"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-108">R</span><span class="MJXp-mo" id="MJXp-Span-109" style="margin-left: 0.267em; margin-right: 0.267em;">∩</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-110">Q</span><span class="MJXp-mo" id="MJXp-Span-111" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mi" id="MJXp-Span-112">∅</span></span></span><span class="MathJax MathJax_Processed" id="MathJax-Element-29-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-142"><span style="display: inline-block; position: relative; width: 0em; height: 0px; font-size: 103%;"><span style="position: absolute;"><span class="mrow" id="MathJax-Span-143"><span class="mi" id="MathJax-Span-144" style="font-family: MathJax_Math-italic;">R</span><span class="mo" id="MathJax-Span-145" style="font-family: MathJax_Main; padding-left: 0.222em;">∩</span><span class="mi" id="MathJax-Span-146" style="font-family: MathJax_Math-italic; padding-left: 0.222em;">Q</span><span class="mo" id="MathJax-Span-147" style="font-family: MathJax_Main; padding-left: 0.278em;">=</span><span class="mi" id="MathJax-Span-148" style="font-family: MathJax_Main; padding-left: 0.278em;">∅</span></span></span></span></span></nobr></span><script type="math/tex" id="MathJax-Element-29">R \cap Q = \emptyset</script>
and <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-113"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-114">P</span><span class="MJXp-mo" id="MJXp-Span-115" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-116">W</span><span class="MJXp-mo" id="MJXp-Span-117" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-118" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mn" id="MJXp-Span-119">1</span></span></span><span class="MathJax MathJax_Processed" id="MathJax-Element-30-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-149"><span style="display: inline-block; position: relative; width: 0em; height: 0px; font-size: 103%;"><span style="position: absolute;"><span class="mrow" id="MathJax-Span-150"><span class="mi" id="MathJax-Span-151" style="font-family: MathJax_Math-italic;">P<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.109em;"></span></span><span class="mo" id="MathJax-Span-152" style="font-family: MathJax_Main;">(</span><span class="mi" id="MathJax-Span-153" style="font-family: MathJax_Math-italic;">W<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.104em;"></span></span><span class="mo" id="MathJax-Span-154" style="font-family: MathJax_Main;">)</span><span class="mo" id="MathJax-Span-155" style="font-family: MathJax_Main; padding-left: 0.278em;">=</span><span class="mn" id="MathJax-Span-156" style="font-family: MathJax_Main; padding-left: 0.278em;">1</span></span></span></span></span></nobr></span><script type="math/tex" id="MathJax-Element-30">P(W) = 1</script>. The <em>conditional probability</em> <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-120"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-121">P</span><span class="MJXp-mo" id="MJXp-Span-122" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-123">Q</span><span class="MJXp-mo" id="MJXp-Span-124" style="margin-left: 0.333em; margin-right: 0.333em;">∣</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-125">R</span><span class="MJXp-mo" id="MJXp-Span-126" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax MathJax_Processed" id="MathJax-Element-31-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-157"><span style="display: inline-block; position: relative; width: 0em; height: 0px; font-size: 103%;"><span style="position: absolute;"><span class="mrow" id="MathJax-Span-158"><span class="mi" id="MathJax-Span-159" style="font-family: MathJax_Math-italic;">P<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.109em;"></span></span><span class="mo" id="MathJax-Span-160" style="font-family: MathJax_Main;">(</span><span class="mi" id="MathJax-Span-161" style="font-family: MathJax_Math-italic;">Q</span><span class="mo" id="MathJax-Span-162" style="font-family: MathJax_Main; padding-left: 0.278em;">∣</span><span class="mi" id="MathJax-Span-163" style="font-family: MathJax_Math-italic; padding-left: 0.278em;">R</span><span class="mo" id="MathJax-Span-164" style="font-family: MathJax_Main;">)</span></span></span></span></span></nobr></span><script type="math/tex" id="MathJax-Element-31">P(Q \mid R)</script>
is defined as

<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-127"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-128">P</span><span class="MJXp-mo" id="MJXp-Span-129" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-130">Q</span><span class="MJXp-mo" id="MJXp-Span-131" style="margin-left: 0.333em; margin-right: 0.333em;">∣</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-132">R</span><span class="MJXp-mo" id="MJXp-Span-133" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mspace" id="MJXp-Span-134" style="width: 0.278em; height: 0em;"></span><span class="MJXp-mo" id="MJXp-Span-135" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mspace" id="MJXp-Span-136" style="width: 0.278em; height: 0em;"></span><span class="MJXp-mfrac" id="MJXp-Span-137" style="vertical-align: 0.25em;"><span class="MJXp-box"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-138">P</span><span class="MJXp-mo" id="MJXp-Span-139" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-140">Q</span><span class="MJXp-mo" id="MJXp-Span-141" style="margin-left: 0.267em; margin-right: 0.267em;">∩</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-142">R</span><span class="MJXp-mo" id="MJXp-Span-143" style="margin-left: 0em; margin-right: 0em;">)</span></span><span class="MJXp-box" style="margin-top: -0.9em;"><span class="MJXp-denom"><span><span class="MJXp-rule" style="height: 1em; border-top: none; border-bottom: 1px solid; margin: 0.1em 0px;"></span></span><span><span class="MJXp-box"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-144">P</span><span class="MJXp-mo" id="MJXp-Span-145" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-146">R</span><span class="MJXp-mo" id="MJXp-Span-147" style="margin-left: 0em; margin-right: 0em;">)</span></span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-148" style="margin-left: 0em; margin-right: 0.222em;">,</span></span></span><div class="MathJax_Display MathJax_Processed"><span class="MathJax" id="MathJax-Element-32-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-165"><span style="display: inline-block; position: relative; width: 0em; height: 0px; font-size: 103%;"><span style="position: absolute;"><span class="mrow" id="MathJax-Span-166"><span class="mi" id="MathJax-Span-167" style="font-family: MathJax_Math-italic;">P<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.109em;"></span></span><span class="mo" id="MathJax-Span-168" style="font-family: MathJax_Main;">(</span><span class="mi" id="MathJax-Span-169" style="font-family: MathJax_Math-italic;">Q</span><span class="mo" id="MathJax-Span-170" style="font-family: MathJax_Main; padding-left: 0.278em;">∣</span><span class="mi" id="MathJax-Span-171" style="font-family: MathJax_Math-italic; padding-left: 0.278em;">R</span><span class="mo" id="MathJax-Span-172" style="font-family: MathJax_Main;">)</span><span class="mspace" id="MathJax-Span-173" style="height: 0em; vertical-align: 0em; width: 0.278em; display: inline-block; overflow: hidden;"></span><span class="mo" id="MathJax-Span-174" style="font-family: MathJax_Main; padding-left: 0.278em;">=</span><span class="mspace" id="MathJax-Span-175" style="height: 0em; vertical-align: 0em; width: 0.278em; display: inline-block; overflow: hidden;"></span><span class="mfrac" id="MathJax-Span-176" style="padding-left: 0.278em;"><span style="display: inline-block; position: relative; width: 4.31em; height: 0px; margin-right: 0.12em; margin-left: 0.12em;"><span style="position: absolute; clip: rect(3.075em, 1004.1em, 4.428em, -1000em); top: -4.738em; left: 50%; margin-left: -2.095em;"><span class="mrow" id="MathJax-Span-177"><span class="mi" id="MathJax-Span-178" style="font-family: MathJax_Math-italic;">P<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.109em;"></span></span><span class="mo" id="MathJax-Span-179" style="font-family: MathJax_Main;">(</span><span class="mi" id="MathJax-Span-180" style="font-family: MathJax_Math-italic;">Q</span><span class="mo" id="MathJax-Span-181" style="font-family: MathJax_Main; padding-left: 0.222em;">∩</span><span class="mi" id="MathJax-Span-182" style="font-family: MathJax_Math-italic; padding-left: 0.222em;">R</span><span class="mo" id="MathJax-Span-183" style="font-family: MathJax_Main;">)</span></span><span style="display: inline-block; width: 0px; height: 4.001em;"></span></span><span style="position: absolute; clip: rect(3.075em, 1002.19em, 4.428em, -1000em); top: -3.264em; left: 50%; margin-left: -1.144em;"><span class="mrow" id="MathJax-Span-184"><span class="mi" id="MathJax-Span-185" style="font-family: MathJax_Math-italic;">P<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.109em;"></span></span><span class="mo" id="MathJax-Span-186" style="font-family: MathJax_Main;">(</span><span class="mi" id="MathJax-Span-187" style="font-family: MathJax_Math-italic;">R</span><span class="mo" id="MathJax-Span-188" style="font-family: MathJax_Main;">)</span></span><span style="display: inline-block; width: 0px; height: 4.001em;"></span></span><span style="position: absolute; clip: rect(0.809em, 1004.31em, 1.236em, -1000em); top: -1.279em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 4.31em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.059em;"></span></span></span></span><span class="mo" id="MathJax-Span-189" style="font-family: MathJax_Main;">,</span></span></span></span></span></nobr></span></div><script type="math/tex; mode=display" id="MathJax-Element-32"> P(Q \mid R) \; = \; \frac{P(Q \cap R)}{P(R)} , </script>

whenever <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-149"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-150">P</span><span class="MJXp-mo" id="MJXp-Span-151" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-152">R</span><span class="MJXp-mo" id="MJXp-Span-153" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-154" style="margin-left: 0.333em; margin-right: 0.333em;">&gt;</span><span class="MJXp-mn" id="MJXp-Span-155">0</span></span></span><span class="MathJax MathJax_Processed" id="MathJax-Element-33-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-190"><span style="display: inline-block; position: relative; width: 0em; height: 0px; font-size: 103%;"><span style="position: absolute;"><span class="mrow" id="MathJax-Span-191"><span class="mi" id="MathJax-Span-192" style="font-family: MathJax_Math-italic;">P<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.109em;"></span></span><span class="mo" id="MathJax-Span-193" style="font-family: MathJax_Main;">(</span><span class="mi" id="MathJax-Span-194" style="font-family: MathJax_Math-italic;">R</span><span class="mo" id="MathJax-Span-195" style="font-family: MathJax_Main;">)</span><span class="mo" id="MathJax-Span-196" style="font-family: MathJax_Main; padding-left: 0.278em;">&gt;</span><span class="mn" id="MathJax-Span-197" style="font-family: MathJax_Main; padding-left: 0.278em;">0</span></span></span></span></span></nobr></span><script type="math/tex" id="MathJax-Element-33">P(R) &gt; 0</script>. It determines the relative size of the set
<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-156"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-157">Q</span></span></span><span class="MathJax MathJax_Processed" id="MathJax-Element-34-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-198"><span style="display: inline-block; position: relative; width: 0em; height: 0px; font-size: 103%;"><span style="position: absolute;"><span class="mrow" id="MathJax-Span-199"><span class="mi" id="MathJax-Span-200" style="font-family: MathJax_Math-italic;">Q</span></span></span></span></span></nobr></span><script type="math/tex" id="MathJax-Element-34">Q</script> within the set <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-158"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-159">R</span></span></span><span class="MathJax MathJax_Processed" id="MathJax-Element-35-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-201"><span style="display: inline-block; position: relative; width: 0em; height: 0px; font-size: 103%;"><span style="position: absolute;"><span class="mrow" id="MathJax-Span-202"><span class="mi" id="MathJax-Span-203" style="font-family: MathJax_Math-italic;">R</span></span></span></span></span></nobr></span><script type="math/tex" id="MathJax-Element-35">R</script>. It is often read as the probability of the
event <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-160"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-161">Q</span></span></span><span class="MathJax MathJax_Processed" id="MathJax-Element-36-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-204"><span style="display: inline-block; position: relative; width: 0em; height: 0px; font-size: 103%;"><span style="position: absolute;"><span class="mrow" id="MathJax-Span-205"><span class="mi" id="MathJax-Span-206" style="font-family: MathJax_Math-italic;">Q</span></span></span></span></span></nobr></span><script type="math/tex" id="MathJax-Element-36">Q</script> <em>given that</em> the event <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-162"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-163">R</span></span></span><span class="MathJax MathJax_Processed" id="MathJax-Element-37-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-207"><span style="display: inline-block; position: relative; width: 0em; height: 0px; font-size: 103%;"><span style="position: absolute;"><span class="mrow" id="MathJax-Span-208"><span class="mi" id="MathJax-Span-209" style="font-family: MathJax_Math-italic;">R</span></span></span></span></span></nobr></span><script type="math/tex" id="MathJax-Element-37">R</script> occurs. Recall that
the set <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-164"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-165">R</span></span></span><span class="MathJax MathJax_Processed" id="MathJax-Element-38-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-210"><span style="display: inline-block; position: relative; width: 0em; height: 0px; font-size: 103%;"><span style="position: absolute;"><span class="mrow" id="MathJax-Span-211"><span class="mi" id="MathJax-Span-212" style="font-family: MathJax_Math-italic;">R</span></span></span></span></span></nobr></span><script type="math/tex" id="MathJax-Element-38">R</script> consists of all samples <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-166"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-167">s</span></span></span><span class="MathJax MathJax_Processed" id="MathJax-Element-39-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-213"><span style="display: inline-block; position: relative; width: 0em; height: 0px; font-size: 103%;"><span style="position: absolute;"><span class="mrow" id="MathJax-Span-214"><span class="mi" id="MathJax-Span-215" style="font-family: MathJax_Math-italic;">s</span></span></span></span></span></nobr></span><script type="math/tex" id="MathJax-Element-39">s</script> that include a record of
the event associated with <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-168"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-169">R</span></span></span><span class="MathJax MathJax_Processed" id="MathJax-Element-40-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-216"><span style="display: inline-block; position: relative; width: 0em; height: 0px; font-size: 103%;"><span style="position: absolute;"><span class="mrow" id="MathJax-Span-217"><span class="mi" id="MathJax-Span-218" style="font-family: MathJax_Math-italic;">R</span></span></span></span></span></nobr></span><script type="math/tex" id="MathJax-Element-40">R</script>. By looking at <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-170"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-171">P</span><span class="MJXp-mo" id="MJXp-Span-172" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-173">Q</span><span class="MJXp-mo" id="MJXp-Span-174" style="margin-left: 0.333em; margin-right: 0.333em;">∣</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-175">R</span><span class="MJXp-mo" id="MJXp-Span-176" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax MathJax_Processed" id="MathJax-Element-41-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-219"><span style="display: inline-block; position: relative; width: 0em; height: 0px; font-size: 103%;"><span style="position: absolute;"><span class="mrow" id="MathJax-Span-220"><span class="mi" id="MathJax-Span-221" style="font-family: MathJax_Math-italic;">P<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.109em;"></span></span><span class="mo" id="MathJax-Span-222" style="font-family: MathJax_Main;">(</span><span class="mi" id="MathJax-Span-223" style="font-family: MathJax_Math-italic;">Q</span><span class="mo" id="MathJax-Span-224" style="font-family: MathJax_Main; padding-left: 0.278em;">∣</span><span class="mi" id="MathJax-Span-225" style="font-family: MathJax_Math-italic; padding-left: 0.278em;">R</span><span class="mo" id="MathJax-Span-226" style="font-family: MathJax_Main;">)</span></span></span></span></span></nobr></span><script type="math/tex" id="MathJax-Element-41">P(Q \mid R)</script> we zoom
in on the probability function within this set <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-177"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-178">R</span></span></span><span class="MathJax MathJax_Processed" id="MathJax-Element-42-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-227"><span style="display: inline-block; position: relative; width: 0em; height: 0px; font-size: 103%;"><span style="position: absolute;"><span class="mrow" id="MathJax-Span-228"><span class="mi" id="MathJax-Span-229" style="font-family: MathJax_Math-italic;">R</span></span></span></span></span></nobr></span><script type="math/tex" id="MathJax-Element-42">R</script>, i.e., we
consider the condition that the associated event occurs.</p>

<p>Now what does the probability function mean? The mathematical
notion of probability does not provide an answer.  The function <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-179"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-180">P</span></span></span><span class="MathJax MathJax_Processed" id="MathJax-Element-43-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-230"><span style="display: inline-block; position: relative; width: 0em; height: 0px; font-size: 103%;"><span style="position: absolute;"><span class="mrow" id="MathJax-Span-231"><span class="mi" id="MathJax-Span-232" style="font-family: MathJax_Math-italic;">P<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.109em;"></span></span></span></span></span></span></nobr></span><script type="math/tex" id="MathJax-Element-43">P</script>
may be interpreted as</p>

<ol>

<li><em>physical</em>, namely the frequency or propensity of the
occurrence of a state of affairs, often referred to as the chance, or
else as </li>

<li><em>epistemic</em>, namely the degree of belief in the
occurrence of the state of affairs, the willingness to act on its
assumption, a degree of support or confirmation, or
similar.</li>

</ol>

<p> This distinction should not be confused with that between
objective and subjective probability. Both physical and epistemic
probability can be given an objective and subjective character, in the
sense that both can be taken as dependent or independent of a
knowing subject and her conceptual apparatus. For more details on the
interpretation of probability, the reader is invited to consult
Galavotti (2005), Gillies (2000), Mellor (2005), von Plato (1994), the
anthology by Eagle (2010), the handbook of Hajek and Hitchcock
(forthcoming), or indeed the entry on 
 <a href="../probability-interpret/">interpretations of probability</a>.
In this context the key point is that the interpretations can all be
connected to foundational programmes for statistical
procedures. Although the match is not exact, the two major types
specified above can be associated with the two major theories of
statistics, classical and Bayesian statistics, respectively.</p>

<h3><a id="PhyProClaSta">2.1 Physical probability and classical statistics</a></h3>

<p>
In the sciences, the idea that probabilities express physical states
of affairs, often called chances or stochastic processes, is most
prominent. They are relative <em>frequencies</em> in series of events
or, alternatively, they are tendencies or <em>propensities</em> in the
systems that realize those events. More precisely, the probability
attached to the property of an event type can be understood as the
frequency or tendency with which that property manifests in a series
of events of that type. For instance, the probability of a coin
landing heads is a half exactly when in a series of similar coin
tosses, the coin lands heads half the time. Or alternatively, the
probability is half if there is an even tendency towards both possible
outcomes in the setup of the coin tossing. The mathematician Venn
(1888) and scientists like Quetelet and Maxwell (cf. von Plato 1994)
are early proponents of this way of viewing probability. Philosophical
theories of propensities were first coined by Peirce (1910), and
developed by Popper (1959), Mellor (1971), Bigelow (1977), and Giere
(1976); see Handfield (2012) for a recent overview. A rigourous theory
of probability as frequency was first devised by von Mises (1981),
also defended by Reichenbach  (1938) and beautifully expounded in
van Lambalgen (1987).</p>

<p>The notion of physical probability is connected to one of the major
theories of statistical method, which has come to be called
<em>classical statistics</em>.  It was developed roughly in the first
half of the 20th century, mostly by mathematicians and working
scientists like Fisher (1925, 1935, 1956), Wald (1939, 1950), Neyman
and Pearson (1928, 1933, 1967), and refined by very many classical
statisticians of the last few decades.  The key characteristic of this
theory of statistics aligns naturally with viewing probabilities as
physical chances, hence pertaining to observable and repeatable
events. Physical probability cannot meaningfully be attributed to
statistical hypotheses, since hypotheses do not have tendencies or
frequencies with which they come about: they are categorically true or
false, once and for all. Attributing probability to a hypothesis seems to entail that
the probability is read epistemically.</p>

<p>Classical statistics is often called <em>frequentist</em>, owing to
the centrality of frequencies of events in classical procedures and
the prominence of the frequentist interpretation of probability
developed by von Mises. In this interpretation, chances are
frequencies, or proportions in a class of similar events or
items. They are best thought of as analogous to other physical
quantities, like mass and energy. It deserves emphasis that
frequencies are thus conceptually prior to chances . In propensity
theory the probability of an individual event or item is viewed as a
tendency in nature, so that the frequencies, or the proportions in a
class of similar events or items, manifest as a consequence of the law
of large numbers. In the frequentist theory, by contrast, the
proportions lay down, indeed define what the chances are. This
leads to a central problem for frequentist probability, the
so-called <em>reference class problem</em>: it is not clear what
class to associate with an individual event or item (cf.  Reichenbach
1949, Hajek 2007). One may argue that the class needs to be as narrow
as it can be, but in the extreme case of a singleton class of events,
the chances of course trivialize to zero or one. Since classical
statistics employs non-trivial probabilities that attach to the single
case in its procedures, a fully frequentists understanding of
statistics is arguably in need of a response to the reference class
problem. </p>

<p>To illustrate physical probability, we briefly consider physical probability in the
example of the tea tasting lady.</p>

<blockquote>
<strong>Physical probability</strong><br /> We denote the null
hypothesis that the lady is merely guessing by <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-181"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-182">h</span></span></span><span class="MathJax MathJax_Processed" id="MathJax-Element-44-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-233"><span style="display: inline-block; position: relative; width: 0em; height: 0px; font-size: 103%;"><span style="position: absolute;"><span class="mrow" id="MathJax-Span-234"><span class="mi" id="MathJax-Span-235" style="font-family: MathJax_Math-italic;">h</span></span></span></span></span></nobr></span><script type="math/tex" id="MathJax-Element-44">h</script>. Say that we
follow the rule indicated in the example above: we reject this null
hypothesis, i.e., denying that the lady is merely guessing, whenever
the sampled data <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-183"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-184">s</span></span></span><span class="MathJax MathJax_Processed" id="MathJax-Element-45-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-236"><span style="display: inline-block; position: relative; width: 0em; height: 0px; font-size: 103%;"><span style="position: absolute;"><span class="mrow" id="MathJax-Span-237"><span class="mi" id="MathJax-Span-238" style="font-family: MathJax_Math-italic;">s</span></span></span></span></span></nobr></span><script type="math/tex" id="MathJax-Element-45">s</script> is included in a particular set <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-185"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-186">R</span></span></span><span class="MathJax MathJax_Processed" id="MathJax-Element-46-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-239"><span style="display: inline-block; position: relative; width: 0em; height: 0px; font-size: 103%;"><span style="position: absolute;"><span class="mrow" id="MathJax-Span-240"><span class="mi" id="MathJax-Span-241" style="font-family: MathJax_Math-italic;">R</span></span></span></span></span></nobr></span><script type="math/tex" id="MathJax-Element-46">R</script> of
possible samples, so <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-187"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-188">s</span><span class="MJXp-mo" id="MJXp-Span-189" style="margin-left: 0.333em; margin-right: 0.333em;">∈</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-190">R</span></span></span><span class="MathJax MathJax_Processed" id="MathJax-Element-47-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-242"><span style="display: inline-block; position: relative; width: 0em; height: 0px; font-size: 103%;"><span style="position: absolute;"><span class="mrow" id="MathJax-Span-243"><span class="mi" id="MathJax-Span-244" style="font-family: MathJax_Math-italic;">s</span><span class="mo" id="MathJax-Span-245" style="font-family: MathJax_Main; padding-left: 0.278em;">∈</span><span class="mi" id="MathJax-Span-246" style="font-family: MathJax_Math-italic; padding-left: 0.278em;">R</span></span></span></span></span></nobr></span><script type="math/tex" id="MathJax-Element-47">s \in R</script>, and that <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-191"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-192">R</span></span></span><span class="MathJax MathJax_Processed" id="MathJax-Element-48-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-247"><span style="display: inline-block; position: relative; width: 0em; height: 0px; font-size: 103%;"><span style="position: absolute;"><span class="mrow" id="MathJax-Span-248"><span class="mi" id="MathJax-Span-249" style="font-family: MathJax_Math-italic;">R</span></span></span></span></span></nobr></span><script type="math/tex" id="MathJax-Element-48">R</script> has a summed
probability of 5% according to the null hypothesis. Now imagine that
we are supposed to judge a whole population of tea tasting ladies,
scattered in tea rooms throughout the country. Then, by running the
experiment and adopting the rule just cited, we know that we will
falsely attribute special tea tasting talents to 5% of those ladies
for whom the null hypothesis is true, i.e., who are in fact merely
guessing. In other words, this percentage pertains to the physical
probability of a particular set of events, which by the rule is
connected to a particular error in our judgment.</blockquote>

<p>Now say that we have found a lady for whom we reject the null
hypothesis, i.e., a lady who passes the test. Does she have the tea
tasting ability or not? Unfortunately this is not the sort of question
that can be answered by the test at hand. A good answer would
presumably involve the proportion of ladies who indeed have the
special tea tasting ability among those whose scores exceeded a
certain threshold, i.e., those who answered correctly on all five
cups. But this latter proportion, namely of ladies for whom the null
hypothesis is false among all those ladies who passed the test,
differs from the proportion of ladies who passed the test among
those ladies for whom it is false. It will depend also on the
proportion of ladies who have the ability in the population under
scrutiny. The test, by contrast, only involves proportions within a
group of ladies for whom the null hypothesis is true: we can only
consider probabilities for particular events on the assumption that
the events are distributed in a given way.</p>

<h3><a id="EpiProStaThe">2.2 Epistemic probability and statistical theory</a></h3>

<p>
There is an alternative way of viewing the probabilities that appear
in statistical methods: they can be seen as expressions of epistemic
attitudes. We are again facing several interrelated options. Very
roughly speaking, epistemic probabilities can be doxastic,
decision-theoretic, or logical.</p>

<h4><a id="TypEpiPro">2.2.1 Types of epistemic probability</a></h4>

<p>Probabilities may be taken to represent <em>doxastic</em> attitudes
in the sense that they specify opinions about data and hypotheses of
an idealized rational agent. The probability then expresses the strength
or degree of belief, for instance regarding the correctness of the
next guess of the tea tasting lady. They may also be taken as
<em>decision-theoretic</em>, i.e., as part of a more elaborate
representation of the agent, which determines her dispositions towards
decisions and actions about the data and the hypotheses. Oftentimes a
decision-theoretic representation involves doxastic attitudes
alongside preferential and perhaps other ones. In that case, the
probability may for instance express a willingness to bet on the lady
being correct. Finally, the probabilities may be taken as
<em>logical</em>.  More precisely, a probabilistic model may be
taken as a logic, i.e., a formal representation that fixes a normative
ideal for uncertain reasoning. According to this latter option,
probability values over data and hypotheses have a role that is
comparable to the role of truth values in deductive logic: they serve
to secure a notion of valid inference, without carrying the suggestion
that the numerical values refer to anything psychologically
salient.</p>

<p>The epistemic view on probability came into development in the 19th
and the first half of the 20th century, first by the hand of De Morgan
(1847) and Boole (1854), later by Keynes (1921), Ramsey (1926) and de
Finetti (1937), and by decision theorists, philosophers and
inductive logicians such as Carnap (1950), Savage (1962), Levi (1980),
and Jeffrey (1992). Important proponents of these views in statistics
were Jeffreys (1961), Edwards (1972), Lindley (1965), Good (1983),
Jaynes (2003) as well as very many Bayesian philosophers and
statisticians of the last few decades (e.g., Goldstein 2006, Kadane
2011, Berger 2006, Dawid 2004). All of these have a view that places
probabilities somewhere in the realm of the epistemic rather than the
physical, i.e., not as part of a model of the world but rather as a
means to model a representing system like the human mind. </p>

<p>The above division is certainly not complete and it is blurry at
the edges. For one, the doxastic notion of probability has mostly been
spelled out in a behaviorist manner, with the help of decision theory.
Many have adopted so-called Dutch book arguments to make the
degree of belief precise, and to show that it is indeed captured by
the mathematical theory of probability (cf. Jeffrey 1992). According
to such arguments, the degree of belief in the occurrence of an event
is given by the price of a betting contract that pays out one monetary
unit if the event manifests. However, there are alternatives to this
behaviorist take on probability as doxastic attitude, using accuracy
or proximity to the truth. Most of these are versions or extensions of
the arguments proposed by de Finetti (1974). Others have
developed an axiomatic approach based on natural desiderata for
degrees of belief (e.g., Cox 1961).</p>

<p>Furthermore, and as alluded to above, within the doxastic
conception of probability we can make a further subdivision
into subjective and objective doxastic attitudes. The defining
characteristic of an objective doxastic probability is that it is
constrained by the demand that the beliefs are calibrated to some
objective fact or state of affairs, or else by further rationality
criteria. A subjective doxastic attitude, by contrast, is not
constrained in such a way: from a normative perspective, agents are
free to believe as they see fit, as long as they comply to the
probability axioms.</p>

<h4><a id="StaThe">2.2.2 Statistical theories</a></h4>

<p>
For present concerns the important point is that each of these
epistemic interpretations of the probability calculus comes with its
own set of foundational programs for statistics. On the whole,
epistemic probability is most naturally associated with <em>Bayesian
statistics</em>, the second major theory of statistical methods (Press
2002, Berger 2006, Gelman et al 2013). The key
characteristic of Bayesian statistics flows directly from the
epistemic interpretation: under this interpretation it becomes
possible to assign probability to a statistical hypothesis and to
relate this probability, understood as an expression of how strongly
we believe the hypothesis, to the probabilities of events. Bayesian
statistics allows us to express how our epistemic attitudes towards a
statistical hypothesis, be it logical, decision-theoretic, or
doxastic, changes under the impact of data.</p>

<p>To illustrate the epistemic conception of probability in Bayesian
statistics, we briefly return to the example of the tea tasting
lady. </p>

<blockquote><strong>Epistemic probability</strong><br /> As before we
denote the null hypothesis that the lady is guessing randomly with
<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-193"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-194">h</span></span></span><span class="MathJax MathJax_Processed" id="MathJax-Element-49-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-250"><span style="display: inline-block; position: relative; width: 0em; height: 0px; font-size: 103%;"><span style="position: absolute;"><span class="mrow" id="MathJax-Span-251"><span class="mi" id="MathJax-Span-252" style="font-family: MathJax_Math-italic;">h</span></span></span></span></span></nobr></span><script type="math/tex" id="MathJax-Element-49">h</script>, so that the distribution <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-195"><span class="MJXp-msubsup" id="MJXp-Span-196"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-197" style="margin-right: 0.05em;">P</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-198" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-199">h</span></span></span></span></span><span class="MathJax MathJax_Processed" id="MathJax-Element-50-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-253"><span style="display: inline-block; position: relative; width: 0em; height: 0px; font-size: 103%;"><span style="position: absolute;"><span class="mrow" id="MathJax-Span-254"><span class="msubsup" id="MathJax-Span-255"><span style="display: inline-block; position: relative; width: 1.124em; height: 0px;"><span style="position: absolute; clip: rect(3.142em, 1000.75em, 4.178em, -1000em); top: -4.001em; left: 0em;"><span class="mi" id="MathJax-Span-256" style="font-family: MathJax_Math-italic;">P<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.109em;"></span></span><span style="display: inline-block; width: 0px; height: 4.001em;"></span></span><span style="position: absolute; top: -3.851em; left: 0.642em;"><span class="texatom" id="MathJax-Span-257"><span class="mrow" id="MathJax-Span-258"><span class="mi" id="MathJax-Span-259" style="font-size: 70.7%; font-family: MathJax_Math-italic;">h</span></span></span><span style="display: inline-block; width: 0px; height: 4.001em;"></span></span></span></span></span></span></span></span></nobr></span><script type="math/tex" id="MathJax-Element-50">P_{h}</script> gives a probability of 1/2
to any guess made by the lady. The alternative <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-200"><span class="MJXp-msup" id="MJXp-Span-201"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-202" style="margin-right: 0.05em;">h</span><span class="MJXp-mo MJXp-script" id="MJXp-Span-203" style="vertical-align: 0.5em;">′</span></span></span></span><span class="MathJax MathJax_Processed" id="MathJax-Element-51-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-260"><span style="display: inline-block; position: relative; width: 0em; height: 0px; font-size: 103%;"><span style="position: absolute;"><span class="mrow" id="MathJax-Span-261"><span class="msup" id="MathJax-Span-262"><span style="display: inline-block; position: relative; width: 0.845em; height: 0px;"><span style="position: absolute; clip: rect(3.131em, 1000.55em, 4.189em, -1000em); top: -4.001em; left: 0em;"><span class="mi" id="MathJax-Span-263" style="font-family: MathJax_Math-italic;">h</span><span style="display: inline-block; width: 0px; height: 4.001em;"></span></span><span style="position: absolute; top: -4.364em; left: 0.576em;"><span class="mo" id="MathJax-Span-264" style="font-size: 70.7%; font-family: MathJax_Main;">′</span><span style="display: inline-block; width: 0px; height: 4.001em;"></span></span></span></span></span></span></span></span></nobr></span><script type="math/tex" id="MathJax-Element-51">h'</script> is that the lady
performs better than a fair coin. More precisely, we might stipulate
that the distribution <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-204"><span class="MJXp-msubsup" id="MJXp-Span-205"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-206" style="margin-right: 0.05em;">P</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-207" style="vertical-align: -0.4em;"><span class="MJXp-msup" id="MJXp-Span-208"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-209" style="margin-right: 0.05em;">h</span><span class="MJXp-mo MJXp-script" id="MJXp-Span-210" style="vertical-align: 0.5em;">′</span></span></span></span></span></span><span class="MathJax MathJax_Processed" id="MathJax-Element-52-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-265"><span style="display: inline-block; position: relative; width: 0em; height: 0px; font-size: 103%;"><span style="position: absolute;"><span class="mrow" id="MathJax-Span-266"><span class="msubsup" id="MathJax-Span-267"><span style="display: inline-block; position: relative; width: 1.315em; height: 0px;"><span style="position: absolute; clip: rect(3.142em, 1000.75em, 4.178em, -1000em); top: -4.001em; left: 0em;"><span class="mi" id="MathJax-Span-268" style="font-family: MathJax_Math-italic;">P<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.109em;"></span></span><span style="display: inline-block; width: 0px; height: 4.001em;"></span></span><span style="position: absolute; top: -3.768em; left: 0.642em;"><span class="texatom" id="MathJax-Span-269"><span class="mrow" id="MathJax-Span-270"><span class="msup" id="MathJax-Span-271"><span style="display: inline-block; position: relative; width: 0.598em; height: 0px;"><span style="position: absolute; clip: rect(3.334em, 1000.39em, 4.185em, -1000em); top: -4.001em; left: 0em;"><span class="mi" id="MathJax-Span-272" style="font-size: 70.7%; font-family: MathJax_Math-italic;">h</span><span style="display: inline-block; width: 0px; height: 4.001em;"></span></span><span style="position: absolute; top: -4.299em; left: 0.407em;"><span class="mo" id="MathJax-Span-273" style="font-size: 50%; font-family: MathJax_Main;">′</span><span style="display: inline-block; width: 0px; height: 4.001em;"></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.001em;"></span></span></span></span></span></span></span></span></nobr></span><script type="math/tex" id="MathJax-Element-52">P_{h'}</script> gives a probability of 3/4 to a
correct guess. At the outset we might find it rather improbable that
the tea tasting lady has special tea tasting abilities. To express
this we give the hypothesis of her having these abilities only half
the probability of her not having the abilities: <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-211"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-212">P</span><span class="MJXp-mo" id="MJXp-Span-213" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msup" id="MJXp-Span-214"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-215" style="margin-right: 0.05em;">h</span><span class="MJXp-mo MJXp-script" id="MJXp-Span-216" style="vertical-align: 0.5em;">′</span></span><span class="MJXp-mo" id="MJXp-Span-217" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-218" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mn" id="MJXp-Span-219">1</span><span class="MJXp-mrow" id="MJXp-Span-220"><span class="MJXp-mo" id="MJXp-Span-221" style="margin-left: 0.111em; margin-right: 0.111em;">/</span></span><span class="MJXp-mn" id="MJXp-Span-222">3</span></span></span><span class="MathJax MathJax_Processed" id="MathJax-Element-53-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-274"><span style="display: inline-block; position: relative; width: 0em; height: 0px; font-size: 103%;"><span style="position: absolute;"><span class="mrow" id="MathJax-Span-275"><span class="mi" id="MathJax-Span-276" style="font-family: MathJax_Math-italic;">P<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.109em;"></span></span><span class="mo" id="MathJax-Span-277" style="font-family: MathJax_Main;">(</span><span class="msup" id="MathJax-Span-278"><span style="display: inline-block; position: relative; width: 0.845em; height: 0px;"><span style="position: absolute; clip: rect(3.131em, 1000.55em, 4.189em, -1000em); top: -4.001em; left: 0em;"><span class="mi" id="MathJax-Span-279" style="font-family: MathJax_Math-italic;">h</span><span style="display: inline-block; width: 0px; height: 4.001em;"></span></span><span style="position: absolute; top: -4.364em; left: 0.576em;"><span class="mo" id="MathJax-Span-280" style="font-size: 70.7%; font-family: MathJax_Main;">′</span><span style="display: inline-block; width: 0px; height: 4.001em;"></span></span></span></span><span class="mo" id="MathJax-Span-281" style="font-family: MathJax_Main;">)</span><span class="mo" id="MathJax-Span-282" style="font-family: MathJax_Main; padding-left: 0.278em;">=</span><span class="mn" id="MathJax-Span-283" style="font-family: MathJax_Main; padding-left: 0.278em;">1</span><span class="texatom" id="MathJax-Span-284"><span class="mrow" id="MathJax-Span-285"><span class="mo" id="MathJax-Span-286" style="font-family: MathJax_Main;">/</span></span></span><span class="mn" id="MathJax-Span-287" style="font-family: MathJax_Main;">3</span></span></span></span></span></nobr></span><script type="math/tex" id="MathJax-Element-53">P(h') = 1/3</script> and
<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-223"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-224">P</span><span class="MJXp-mo" id="MJXp-Span-225" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-226">h</span><span class="MJXp-mo" id="MJXp-Span-227" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-228" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mn" id="MJXp-Span-229">2</span><span class="MJXp-mrow" id="MJXp-Span-230"><span class="MJXp-mo" id="MJXp-Span-231" style="margin-left: 0.111em; margin-right: 0.111em;">/</span></span><span class="MJXp-mn" id="MJXp-Span-232">3</span></span></span><span class="MathJax MathJax_Processed" id="MathJax-Element-54-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-288"><span style="display: inline-block; position: relative; width: 0em; height: 0px; font-size: 103%;"><span style="position: absolute;"><span class="mrow" id="MathJax-Span-289"><span class="mi" id="MathJax-Span-290" style="font-family: MathJax_Math-italic;">P<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.109em;"></span></span><span class="mo" id="MathJax-Span-291" style="font-family: MathJax_Main;">(</span><span class="mi" id="MathJax-Span-292" style="font-family: MathJax_Math-italic;">h</span><span class="mo" id="MathJax-Span-293" style="font-family: MathJax_Main;">)</span><span class="mo" id="MathJax-Span-294" style="font-family: MathJax_Main; padding-left: 0.278em;">=</span><span class="mn" id="MathJax-Span-295" style="font-family: MathJax_Main; padding-left: 0.278em;">2</span><span class="texatom" id="MathJax-Span-296"><span class="mrow" id="MathJax-Span-297"><span class="mo" id="MathJax-Span-298" style="font-family: MathJax_Main;">/</span></span></span><span class="mn" id="MathJax-Span-299" style="font-family: MathJax_Main;">3</span></span></span></span></span></nobr></span><script type="math/tex" id="MathJax-Element-54">P(h) = 2/3</script>. Now, leaving the mathematical details to
 <a href="#BasPatInf">Section 4.1</a>, after receiving the data that
she guessed all five cups correctly, our new belief in the lady's
special abilities has more than reversed. We now think it roughly four
times more probable that the lady has the special abilities than that
she is merely a random guesser: <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-233"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-234">P</span><span class="MJXp-mo" id="MJXp-Span-235" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msup" id="MJXp-Span-236"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-237" style="margin-right: 0.05em;">h</span><span class="MJXp-mo MJXp-script" id="MJXp-Span-238" style="vertical-align: 0.5em;">′</span></span><span class="MJXp-mo" id="MJXp-Span-239" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-240" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mn" id="MJXp-Span-241">243</span><span class="MJXp-mrow" id="MJXp-Span-242"><span class="MJXp-mo" id="MJXp-Span-243" style="margin-left: 0.111em; margin-right: 0.111em;">/</span></span><span class="MJXp-mn" id="MJXp-Span-244">307</span><span class="MJXp-mo" id="MJXp-Span-245" style="margin-left: 0.333em; margin-right: 0.333em;">≈</span><span class="MJXp-mn" id="MJXp-Span-246">4</span><span class="MJXp-mrow" id="MJXp-Span-247"><span class="MJXp-mo" id="MJXp-Span-248" style="margin-left: 0.111em; margin-right: 0.111em;">/</span></span><span class="MJXp-mn" id="MJXp-Span-249">5</span></span></span><span class="MathJax MathJax_Processed" id="MathJax-Element-55-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-300"><span style="display: inline-block; position: relative; width: 0em; height: 0px; font-size: 103%;"><span style="position: absolute;"><span class="mrow" id="MathJax-Span-301"><span class="mi" id="MathJax-Span-302" style="font-family: MathJax_Math-italic;">P<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.109em;"></span></span><span class="mo" id="MathJax-Span-303" style="font-family: MathJax_Main;">(</span><span class="msup" id="MathJax-Span-304"><span style="display: inline-block; position: relative; width: 0.845em; height: 0px;"><span style="position: absolute; clip: rect(3.131em, 1000.55em, 4.189em, -1000em); top: -4.001em; left: 0em;"><span class="mi" id="MathJax-Span-305" style="font-family: MathJax_Math-italic;">h</span><span style="display: inline-block; width: 0px; height: 4.001em;"></span></span><span style="position: absolute; top: -4.364em; left: 0.576em;"><span class="mo" id="MathJax-Span-306" style="font-size: 70.7%; font-family: MathJax_Main;">′</span><span style="display: inline-block; width: 0px; height: 4.001em;"></span></span></span></span><span class="mo" id="MathJax-Span-307" style="font-family: MathJax_Main;">)</span><span class="mo" id="MathJax-Span-308" style="font-family: MathJax_Main; padding-left: 0.278em;">=</span><span class="mn" id="MathJax-Span-309" style="font-family: MathJax_Main; padding-left: 0.278em;">243</span><span class="texatom" id="MathJax-Span-310"><span class="mrow" id="MathJax-Span-311"><span class="mo" id="MathJax-Span-312" style="font-family: MathJax_Main;">/</span></span></span><span class="mn" id="MathJax-Span-313" style="font-family: MathJax_Main;">307</span><span class="mo" id="MathJax-Span-314" style="font-family: MathJax_Main; padding-left: 0.278em;">≈</span><span class="mn" id="MathJax-Span-315" style="font-family: MathJax_Main; padding-left: 0.278em;">4</span><span class="texatom" id="MathJax-Span-316"><span class="mrow" id="MathJax-Span-317"><span class="mo" id="MathJax-Span-318" style="font-family: MathJax_Main;">/</span></span></span><span class="mn" id="MathJax-Span-319" style="font-family: MathJax_Main;">5</span></span></span></span></span></nobr></span><script type="math/tex" id="MathJax-Element-55">P(h') = 243/307 \approx 4/5</script> and
<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-250"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-251">P</span><span class="MJXp-mo" id="MJXp-Span-252" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msup" id="MJXp-Span-253"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-254" style="margin-right: 0.05em;">h</span><span class="MJXp-mo MJXp-script" id="MJXp-Span-255" style="vertical-align: 0.5em;">′</span></span><span class="MJXp-mo" id="MJXp-Span-256" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-257" style="margin-left: 0.333em; margin-right: 0.333em;">≈</span><span class="MJXp-mn" id="MJXp-Span-258">1</span><span class="MJXp-mrow" id="MJXp-Span-259"><span class="MJXp-mo" id="MJXp-Span-260" style="margin-left: 0.111em; margin-right: 0.111em;">/</span></span><span class="MJXp-mn" id="MJXp-Span-261">5</span></span></span><span class="MathJax MathJax_Processed" id="MathJax-Element-56-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-320"><span style="display: inline-block; position: relative; width: 0em; height: 0px; font-size: 103%;"><span style="position: absolute;"><span class="mrow" id="MathJax-Span-321"><span class="mi" id="MathJax-Span-322" style="font-family: MathJax_Math-italic;">P<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.109em;"></span></span><span class="mo" id="MathJax-Span-323" style="font-family: MathJax_Main;">(</span><span class="msup" id="MathJax-Span-324"><span style="display: inline-block; position: relative; width: 0.845em; height: 0px;"><span style="position: absolute; clip: rect(3.131em, 1000.55em, 4.189em, -1000em); top: -4.001em; left: 0em;"><span class="mi" id="MathJax-Span-325" style="font-family: MathJax_Math-italic;">h</span><span style="display: inline-block; width: 0px; height: 4.001em;"></span></span><span style="position: absolute; top: -4.364em; left: 0.576em;"><span class="mo" id="MathJax-Span-326" style="font-size: 70.7%; font-family: MathJax_Main;">′</span><span style="display: inline-block; width: 0px; height: 4.001em;"></span></span></span></span><span class="mo" id="MathJax-Span-327" style="font-family: MathJax_Main;">)</span><span class="mo" id="MathJax-Span-328" style="font-family: MathJax_Main; padding-left: 0.278em;">≈</span><span class="mn" id="MathJax-Span-329" style="font-family: MathJax_Main; padding-left: 0.278em;">1</span><span class="texatom" id="MathJax-Span-330"><span class="mrow" id="MathJax-Span-331"><span class="mo" id="MathJax-Span-332" style="font-family: MathJax_Main;">/</span></span></span><span class="mn" id="MathJax-Span-333" style="font-family: MathJax_Main;">5</span></span></span></span></span></nobr></span><script type="math/tex" id="MathJax-Element-56">P(h') \approx 1/5</script>. </blockquote>

<p>The take-home message is that the Bayesian method allows us to
express our epistemic attitudes to statistical hypotheses in terms of
a probability assignment, and that the data impact on this epistemic
attitude in a regulated fashion.</p>

<p>It should be emphasized that Bayesian statistics is not the sole
user of an epistemic notion of probability. Indeed, a frequentists
understanding of probabilities assigned to statistical hypotheses
seems nonsensical. But it is perfectly possible to read the
probabilities of events, or elements in sample space, as epistemic,
quite independently of the statistical method that is being used. As
further explained in the next section, several philosophical
developments of classical statistics employ epistemic probability,
most notably fiducial probability (Fisher 1955 and 1956; see also
Seidenfeld 1992 and Zabell 1992), likelihoodism (Hacking 1965, Edwards
1972, Royall 1997), and evidential probability (Kyburg 1961), or
connect the procedures of classical statistics to inference and
support in some other way. In all these developments, probabilities
and functions over sample space are read epistemically, i.e., as
expressions of the strength of evidence, the degree of support, or
similar.</p>

<h2><a id="ClaSta">3. Classical statistics</a></h2>

<p>
The collection of procedures that may be grouped under classical
statistics is vast and multi-faceted. By and large, classical
statistical procedures share the feature that they only rely on
probability assignments over sample spaces. As indicated, an important
motivation for this is that those probabilities can be interpreted as
frequencies, from which the term of <em>frequentist
statistics</em> originates.  Classical statistical procedures are
typically defined by some function over sample space, where this
function depends, often exclusively, on the distributions that the
hypotheses under consideration assign to the sample space. For the
range of samples that may be obtained, the function then points to one
of the hypotheses, or perhaps to a set of them, as being in some sense
the best fit with that sample. Or, conversely, it discards candidate
hypotheses that render the sample too improbable. </p>

<p>In sum, classical procedures employ the data to narrow down a set
of hypotheses. Put in such general terms, it becomes apparent that
classical procedures provide a response to the problem of
induction. The data are used to get from a weak general statement
about the target system to a stronger one, namely from a set of
candidate hypotheses to a subset of them. The central concern in the
philosophy of statistics is how we are to understand these procedures,
and how we might justify them. Notice that the pattern of classical
statistics resembles that of <em>eliminative induction</em>: in view
of the data we discard some of the candidate hypotheses. Indeed
classical statistics is often seen in loose association with Popper's
falsificationism, but this association is somewhat misleading. In
classical procedures statistical hypotheses are discarded when they
render the observed sample too improbable, which of course differs
from discarding hypotheses that deem the observed sample
impossible.</p>

<h3><a id="BasClaSta">3.1 Basics of classical statistics</a></h3>

<p>The foregoing already provided a short example and a rough sketch
of classical statistical procedures. These are now specified in more
detail, on the basis of Barnett (1999) as primary source. The
following focuses on two very central procedures, hypothesis testing
and estimation. The first has to do with the comparison of two
statistical hypotheses, and invokes theory developed by Neyman and
Pearson. The second concerns the choice of a hypothesis from a set,
and employs procedures devised by Fisher. While these figures are
rightly associated with classical statistics, their philosophical
views diverge. We return to this below.</p>

<h4><a id="HypTes">3.1.1 Hypothesis testing</a></h4>

<p>The procedure of Fisher's<em> null hypothesis test</em> was already
discussed briefly in the foregoing. Let <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-262"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-263">h</span></span></span><span class="MathJax MathJax_Processed" id="MathJax-Element-57-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-334"><span style="display: inline-block; position: relative; width: 0em; height: 0px; font-size: 103%;"><span style="position: absolute;"><span class="mrow" id="MathJax-Span-335"><span class="mi" id="MathJax-Span-336" style="font-family: MathJax_Math-italic;">h</span></span></span></span></span></nobr></span><script type="math/tex" id="MathJax-Element-57">h</script> be the hypothesis of
interest and, for the sake of simplicity, let <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-264"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-265">S</span></span></span><span class="MathJax MathJax_Processed" id="MathJax-Element-58-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-337"><span style="display: inline-block; position: relative; width: 0em; height: 0px; font-size: 103%;"><span style="position: absolute;"><span class="mrow" id="MathJax-Span-338"><span class="mi" id="MathJax-Span-339" style="font-family: MathJax_Math-italic;">S<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.032em;"></span></span></span></span></span></span></nobr></span><script type="math/tex" id="MathJax-Element-58">S</script> be a finite sample
space. The hypothesis <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-266"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-267">h</span></span></span><span class="MathJax MathJax_Processed" id="MathJax-Element-59-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-340"><span style="display: inline-block; position: relative; width: 0em; height: 0px; font-size: 103%;"><span style="position: absolute;"><span class="mrow" id="MathJax-Span-341"><span class="mi" id="MathJax-Span-342" style="font-family: MathJax_Math-italic;">h</span></span></span></span></span></nobr></span><script type="math/tex" id="MathJax-Element-59">h</script> imposes a distribution over the sample
space, denoted <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-268"><span class="MJXp-msubsup" id="MJXp-Span-269"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-270" style="margin-right: 0.05em;">P</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-271" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-272">h</span></span></span></span></span><span class="MathJax MathJax_Processed" id="MathJax-Element-60-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-343"><span style="display: inline-block; position: relative; width: 0em; height: 0px; font-size: 103%;"><span style="position: absolute;"><span class="mrow" id="MathJax-Span-344"><span class="msubsup" id="MathJax-Span-345"><span style="display: inline-block; position: relative; width: 1.124em; height: 0px;"><span style="position: absolute; clip: rect(3.142em, 1000.75em, 4.178em, -1000em); top: -4.001em; left: 0em;"><span class="mi" id="MathJax-Span-346" style="font-family: MathJax_Math-italic;">P<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.109em;"></span></span><span style="display: inline-block; width: 0px; height: 4.001em;"></span></span><span style="position: absolute; top: -3.851em; left: 0.642em;"><span class="texatom" id="MathJax-Span-347"><span class="mrow" id="MathJax-Span-348"><span class="mi" id="MathJax-Span-349" style="font-size: 70.7%; font-family: MathJax_Math-italic;">h</span></span></span><span style="display: inline-block; width: 0px; height: 4.001em;"></span></span></span></span></span></span></span></span></nobr></span><script type="math/tex" id="MathJax-Element-60">P_{h}</script>. Every point <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-273"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-274">s</span></span></span><span class="MathJax MathJax_Processed" id="MathJax-Element-61-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-350"><span style="display: inline-block; position: relative; width: 0em; height: 0px; font-size: 103%;"><span style="position: absolute;"><span class="mrow" id="MathJax-Span-351"><span class="mi" id="MathJax-Span-352" style="font-family: MathJax_Math-italic;">s</span></span></span></span></span></nobr></span><script type="math/tex" id="MathJax-Element-61">s</script> in the space represents a
possible sample of data. We now define a function <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-275"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-276">F</span></span></span><span class="MathJax MathJax_Processed" id="MathJax-Element-62-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-353"><span style="display: inline-block; position: relative; width: 0em; height: 0px; font-size: 103%;"><span style="position: absolute;"><span class="mrow" id="MathJax-Span-354"><span class="mi" id="MathJax-Span-355" style="font-family: MathJax_Math-italic;">F<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.106em;"></span></span></span></span></span></span></nobr></span><script type="math/tex" id="MathJax-Element-62">F</script> on the sample
space that identifies when we will reject the null hypothesis by
marking the samples <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-277"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-278">s</span></span></span><span class="MathJax MathJax_Processed" id="MathJax-Element-63-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-356"><span style="display: inline-block; position: relative; width: 0em; height: 0px; font-size: 103%;"><span style="position: absolute;"><span class="mrow" id="MathJax-Span-357"><span class="mi" id="MathJax-Span-358" style="font-family: MathJax_Math-italic;">s</span></span></span></span></span></nobr></span><script type="math/tex" id="MathJax-Element-63">s</script> that lead to rejection with <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-279"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-280">F</span><span class="MJXp-mo" id="MJXp-Span-281" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-282">s</span><span class="MJXp-mo" id="MJXp-Span-283" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-284" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mn" id="MJXp-Span-285">1</span></span></span><span class="MathJax MathJax_Processed" id="MathJax-Element-64-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-359"><span style="display: inline-block; position: relative; width: 0em; height: 0px; font-size: 103%;"><span style="position: absolute;"><span class="mrow" id="MathJax-Span-360"><span class="mi" id="MathJax-Span-361" style="font-family: MathJax_Math-italic;">F<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.106em;"></span></span><span class="mo" id="MathJax-Span-362" style="font-family: MathJax_Main;">(</span><span class="mi" id="MathJax-Span-363" style="font-family: MathJax_Math-italic;">s</span><span class="mo" id="MathJax-Span-364" style="font-family: MathJax_Main;">)</span><span class="mo" id="MathJax-Span-365" style="font-family: MathJax_Main; padding-left: 0.278em;">=</span><span class="mn" id="MathJax-Span-366" style="font-family: MathJax_Main; padding-left: 0.278em;">1</span></span></span></span></span></nobr></span><script type="math/tex" id="MathJax-Element-64">F(s) = 1</script>, as
follows:

 <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-286"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-287">F</span><span class="MJXp-mo" id="MJXp-Span-288" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-289">s</span><span class="MJXp-mo" id="MJXp-Span-290" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-291" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mrow" id="MJXp-Span-292"><span class="MJXp-mo" id="MJXp-Span-293" style="margin-left: 0em; margin-right: 0em; vertical-align: -0.567em;"><span class="MJXp-right MJXp-scale4" style="font-size: 3.267em; margin-left: -0.278em;">{</span></span><span class="MJXp-mtable" id="MJXp-Span-294"><span><span class="MJXp-mtr" id="MJXp-Span-295" style="vertical-align: baseline;"><span class="MJXp-mtd" id="MJXp-Span-296" style="text-align: left;"><span class="MJXp-mn" id="MJXp-Span-297">1</span><span class="MJXp-mspace" id="MJXp-Span-298" style="width: 1em; height: 0em;"></span><span class="MJXp-mtext" id="MJXp-Span-299">if </span><span class="MJXp-msubsup" id="MJXp-Span-300"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-301" style="margin-right: 0.05em;">P</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-302" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-303">h</span></span></span><span class="MJXp-mo" id="MJXp-Span-304" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-305">s</span><span class="MJXp-mo" id="MJXp-Span-306" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-307" style="margin-left: 0.333em; margin-right: 0.333em;">&lt;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-308">r</span><span class="MJXp-mo" id="MJXp-Span-309" style="margin-left: 0em; margin-right: 0.222em;">,</span></span></span><span class="MJXp-mtr" id="MJXp-Span-310" style="vertical-align: baseline;"><span class="MJXp-mtd" id="MJXp-Span-311" style="padding-top: 0.2em; text-align: left;"><span class="MJXp-mn" id="MJXp-Span-312">0</span><span class="MJXp-mspace" id="MJXp-Span-313" style="width: 1em; height: 0em;"></span><span class="MJXp-mtext" id="MJXp-Span-314">otherwise.</span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-315" style="margin-left: 0em; margin-right: 0em;"></span></span></span></span><div class="MathJax_Display MathJax_Processing"><span class="MathJax" id="MathJax-Element-65-Frame" tabindex="0" style=""></span></div><script type="math/tex; mode=display" id="MathJax-Element-65">   F(s) =   \begin{cases}  1 \quad \text{if } P_{h}(s) &lt; r,\\ 0 \quad
\text{otherwise.} \end{cases} </script>

Notice that the definition of the region of rejection, <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-316"><span class="MJXp-msubsup" id="MJXp-Span-317"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-318" style="margin-right: 0.05em;">R</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-319" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-320">r</span></span></span><span class="MJXp-mo" id="MJXp-Span-321" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mo" id="MJXp-Span-322" style="margin-left: 0em; margin-right: 0em;">{</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-323">s</span><span class="MJXp-mo" id="MJXp-Span-324" style="margin-left: 0.111em; margin-right: 0.167em;">:</span><span class="MJXp-mspace" id="MJXp-Span-325" style="width: 0.222em; height: 0em;"></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-326">F</span><span class="MJXp-mo" id="MJXp-Span-327" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-328">s</span><span class="MJXp-mo" id="MJXp-Span-329" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-330" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mn" id="MJXp-Span-331">1</span><span class="MJXp-mo" id="MJXp-Span-332" style="margin-left: 0em; margin-right: 0em;">}</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-66-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-66">R_{r} = \{
s:\: F(s) = 1 \}</script>, hinges on the probability of the data under the
assumption of the hypothesis, <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-333"><span class="MJXp-msubsup" id="MJXp-Span-334"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-335" style="margin-right: 0.05em;">P</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-336" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-337">h</span></span></span><span class="MJXp-mo" id="MJXp-Span-338" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-339">s</span><span class="MJXp-mo" id="MJXp-Span-340" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-67-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-67">P_{h}(s)</script>. This expression is often
called the
<em>likelihood</em> of the hypothesis on the sample <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-341"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-342">s</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-68-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-68">s</script>. We can set
the threshold <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-343"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-344">r</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-69-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-69">r</script> for the likelihood to a suitable value, such that
the total probability of the region of rejection <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-345"><span class="MJXp-msubsup" id="MJXp-Span-346"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-347" style="margin-right: 0.05em;">R</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-348" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-349">r</span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-70-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-70">R_{r}</script> is below a
given level of error, for example, <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-350"><span class="MJXp-msubsup" id="MJXp-Span-351"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-352" style="margin-right: 0.05em;">P</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-353" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-354">h</span></span></span><span class="MJXp-mo" id="MJXp-Span-355" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-356">R</span><span class="MJXp-mo" id="MJXp-Span-357" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-358" style="margin-left: 0.333em; margin-right: 0.333em;">&lt;</span><span class="MJXp-mn" id="MJXp-Span-359">0.05</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-71-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-71">P_{h}(R) &lt; 0.05</script>.</p>

<p>It soon appeared that comparisons between two rival hypotheses were
far more informative, in particular because little can be said about
error rates if the null hypothesis is in fact false. Neyman and
Pearson (1928, 1933, and 1967) devised the so-called <em>likelihood
ratio test</em>, a test that compares the likelihoods of two rivaling
hypotheses. Let <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-360"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-361">h</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-72-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-72">h</script> and <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-362"><span class="MJXp-msup" id="MJXp-Span-363"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-364" style="margin-right: 0.05em;">h</span><span class="MJXp-mo MJXp-script" id="MJXp-Span-365" style="vertical-align: 0.5em;">′</span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-73-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-73">h'</script> be the null and the alternative
hypothesis respectively. We can compare these hypotheses by the
following test function <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-366"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-367">F</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-74-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-74">F</script> over the sample space:

<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-368"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-369">F</span><span class="MJXp-mo" id="MJXp-Span-370" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-371">s</span><span class="MJXp-mo" id="MJXp-Span-372" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-373" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mrow" id="MJXp-Span-374"><span class="MJXp-mo" id="MJXp-Span-375" style="margin-left: 0em; margin-right: 0em; vertical-align: -1.078em;"><span class="MJXp-right MJXp-scale3" style="font-size: 5.311em; margin-left: -0.336em;">{</span></span><span class="MJXp-mtable" id="MJXp-Span-376"><span><span class="MJXp-mtr" id="MJXp-Span-377" style="vertical-align: baseline;"><span class="MJXp-mtd" id="MJXp-Span-378" style="text-align: left;"><span class="MJXp-mn" id="MJXp-Span-379">1</span><span class="MJXp-mspace" id="MJXp-Span-380" style="width: 1em; height: 0em;"></span><span class="MJXp-mtext" id="MJXp-Span-381">if </span><span class="MJXp-mfrac" id="MJXp-Span-382" style="vertical-align: 0.25em;"><span class="MJXp-box MJXp-script"><span class="MJXp-msubsup" id="MJXp-Span-383"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-384" style="margin-right: 0.05em;">P</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-385" style="vertical-align: -0.4em;"><span class="MJXp-msup" id="MJXp-Span-386"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-387" style="margin-right: 0.05em;">h</span><span class="MJXp-mo MJXp-script" id="MJXp-Span-388" style="vertical-align: 0.5em;">′</span></span></span></span><span class="MJXp-mo" id="MJXp-Span-389">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-390">s</span><span class="MJXp-mo" id="MJXp-Span-391">)</span></span><span class="MJXp-box" style="margin-top: -0.9em;"><span class="MJXp-denom"><span><span class="MJXp-rule" style="height: 1em; border-top: none; border-bottom: 1px solid; margin: 0.1em 0px;"></span></span><span><span class="MJXp-box MJXp-script"><span class="MJXp-msubsup" id="MJXp-Span-392"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-393" style="margin-right: 0.05em;">P</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-394" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-395">h</span></span></span><span class="MJXp-mo" id="MJXp-Span-396">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-397">s</span><span class="MJXp-mo" id="MJXp-Span-398">)</span></span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-399" style="margin-left: 0.333em; margin-right: 0.333em;">&gt;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-400">r</span><span class="MJXp-mo" id="MJXp-Span-401" style="margin-left: 0em; margin-right: 0.222em;">,</span></span></span><span class="MJXp-mtr" id="MJXp-Span-402" style="vertical-align: baseline;"><span class="MJXp-mtd" id="MJXp-Span-403" style="padding-top: 0.2em; text-align: left;"><span class="MJXp-mn" id="MJXp-Span-404">0</span><span class="MJXp-mspace" id="MJXp-Span-405" style="width: 1em; height: 0em;"></span><span class="MJXp-mtext" id="MJXp-Span-406">otherwise,</span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-407" style="margin-left: 0em; margin-right: 0em;"></span></span></span></span><div class="MathJax_Display MathJax_Processing"><span class="MathJax" id="MathJax-Element-75-Frame" tabindex="0"></span></div><script type="math/tex; mode=display" id="MathJax-Element-75"> F(s) = \begin{cases} 1 \quad \text{if } \frac{P_{h'}(s)}{P_{h}(s)}
&gt; r,\\ 0 \quad \text{otherwise,} \end{cases} </script>

where <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-408"><span class="MJXp-msubsup" id="MJXp-Span-409"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-410" style="margin-right: 0.05em;">P</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-411" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-412">h</span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-76-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-76">P_{h}</script> and <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-413"><span class="MJXp-msubsup" id="MJXp-Span-414"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-415" style="margin-right: 0.05em;">P</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-416" style="vertical-align: -0.4em;"><span class="MJXp-msup" id="MJXp-Span-417"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-418" style="margin-right: 0.05em;">h</span><span class="MJXp-mo MJXp-script" id="MJXp-Span-419" style="vertical-align: 0.5em;">′</span></span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-77-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-77">P_{h'}</script> are the probability distributions over
the sample space determined by the statistical hypotheses <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-420"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-421">h</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-78-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-78">h</script> and
<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-422"><span class="MJXp-msup" id="MJXp-Span-423"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-424" style="margin-right: 0.05em;">h</span><span class="MJXp-mo MJXp-script" id="MJXp-Span-425" style="vertical-align: 0.5em;">′</span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-79-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-79">h'</script> respectively. If <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-426"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-427">F</span><span class="MJXp-mo" id="MJXp-Span-428" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-429">s</span><span class="MJXp-mo" id="MJXp-Span-430" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-431" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mn" id="MJXp-Span-432">1</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-80-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-80">F(s) = 1</script> we decide to reject the null
hypothesis <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-433"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-434">h</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-81-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-81">h</script>, else we accept <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-435"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-436">h</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-82-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-82">h</script> for the time being and so
disregard <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-437"><span class="MJXp-msup" id="MJXp-Span-438"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-439" style="margin-right: 0.05em;">h</span><span class="MJXp-mo MJXp-script" id="MJXp-Span-440" style="vertical-align: 0.5em;">′</span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-83-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-83">h'</script>.</p>

<p>The decision to accept or reject a hypothesis is associated with
the so-called significance and power of the test. The
<em>significance</em> is the probability, according to the null
hypothesis <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-441"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-442">h</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-84-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-84">h</script>, of obtaining data that leads us to falsely reject
this hypothesis <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-443"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-444">h</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-85-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-85">h</script>:

<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-445"><span class="MJXp-msubsup" id="MJXp-Span-446"><span class="MJXp-mtext" id="MJXp-Span-447" style="margin-right: 0.05em;">Significance</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-448" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-449">F</span></span></span><span class="MJXp-mo" id="MJXp-Span-450" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-451">α</span><span class="MJXp-mo" id="MJXp-Span-452" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-msubsup" id="MJXp-Span-453"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-454" style="margin-right: 0.05em;">P</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-455" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-456">h</span></span></span><span class="MJXp-mo" id="MJXp-Span-457" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-458"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-459" style="margin-right: 0.05em;">R</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-460" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-461">r</span></span></span><span class="MJXp-mo" id="MJXp-Span-462" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-463" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-munderover" id="MJXp-Span-464"><span class=""><span class="MJXp-mo" id="MJXp-Span-465" style="margin-left: 0.111em; margin-right: 0.167em;"><span class="MJXp-largeop">∑</span></span></span><span class=" MJXp-script"><span class="MJXp-mrow" id="MJXp-Span-466" style="margin-left: 0px;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-467">s</span><span class="MJXp-mo" id="MJXp-Span-468">∈</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-469">S</span></span></span></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-470">F</span><span class="MJXp-mo" id="MJXp-Span-471" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-472">s</span><span class="MJXp-mo" id="MJXp-Span-473" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-msubsup" id="MJXp-Span-474"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-475" style="margin-right: 0.05em;">P</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-476" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-477">h</span></span></span><span class="MJXp-mo" id="MJXp-Span-478" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-479">s</span><span class="MJXp-mo" id="MJXp-Span-480" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-481">d</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-482">s</span><span class="MJXp-mo" id="MJXp-Span-483" style="margin-left: 0em; margin-right: 0.222em;">,</span></span></span><div class="MathJax_Display MathJax_Processing"><span class="MathJax" id="MathJax-Element-86-Frame" tabindex="0"></span></div><script type="math/tex; mode=display" id="MathJax-Element-86"> \text{Significance}_{F} = \alpha = P_{h}(R_{r}) = \sum_{s \in S}
F(s) P_{h}(s) d s , </script>

The probability <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-484"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-485">α</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-87-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-87">\alpha</script> is alternatively called the <em>type-I
error</em>, and it is often denoted as the
<em>significance</em> or the <em>p-value</em>. The <em>power</em> is
the probability, according to the alternative hypothesis <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-486"><span class="MJXp-msup" id="MJXp-Span-487"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-488" style="margin-right: 0.05em;">h</span><span class="MJXp-mo MJXp-script" id="MJXp-Span-489" style="vertical-align: 0.5em;">′</span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-88-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-88">h'</script>, of
obtaining data that leads us to correctly reject the null hypothesis
<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-490"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-491">h</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-89-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-89">h</script>:

<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-492"><span class="MJXp-msubsup" id="MJXp-Span-493"><span class="MJXp-mtext" id="MJXp-Span-494" style="margin-right: 0.05em;">Power</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-495" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-496">F</span></span></span><span class="MJXp-mo" id="MJXp-Span-497" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mn" id="MJXp-Span-498">1</span><span class="MJXp-mo" id="MJXp-Span-499" style="margin-left: 0.267em; margin-right: 0.267em;">−</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-500">β</span><span class="MJXp-mo" id="MJXp-Span-501" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-msubsup" id="MJXp-Span-502"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-503" style="margin-right: 0.05em;">P</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-504" style="vertical-align: -0.4em;"><span class="MJXp-msup" id="MJXp-Span-505"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-506" style="margin-right: 0.05em;">h</span><span class="MJXp-mo MJXp-script" id="MJXp-Span-507" style="vertical-align: 0.5em;">′</span></span></span></span><span class="MJXp-mo" id="MJXp-Span-508" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-509"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-510" style="margin-right: 0.05em;">F</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-511" style="vertical-align: -0.4em;"><span class="MJXp-mn" id="MJXp-Span-512">1</span></span></span><span class="MJXp-mo" id="MJXp-Span-513" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-514" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-munderover" id="MJXp-Span-515"><span class=""><span class="MJXp-mo" id="MJXp-Span-516" style="margin-left: 0.111em; margin-right: 0.167em;"><span class="MJXp-largeop">∑</span></span></span><span class=" MJXp-script"><span class="MJXp-mrow" id="MJXp-Span-517" style="margin-left: 0px;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-518">s</span><span class="MJXp-mo" id="MJXp-Span-519">∈</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-520">S</span></span></span></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-521">F</span><span class="MJXp-mo" id="MJXp-Span-522" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-523">s</span><span class="MJXp-mo" id="MJXp-Span-524" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-msubsup" id="MJXp-Span-525"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-526" style="margin-right: 0.05em;">P</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-527" style="vertical-align: -0.4em;"><span class="MJXp-msup" id="MJXp-Span-528"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-529" style="margin-right: 0.05em;">h</span><span class="MJXp-mo MJXp-script" id="MJXp-Span-530" style="vertical-align: 0.5em;">′</span></span></span></span><span class="MJXp-mo" id="MJXp-Span-531" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-532">s</span><span class="MJXp-mo" id="MJXp-Span-533" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-534">d</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-535">s</span><span class="MJXp-mo" id="MJXp-Span-536" style="margin-left: 0em; margin-right: 0.222em;">.</span></span></span><div class="MathJax_Display MathJax_Processing"><span class="MathJax" id="MathJax-Element-90-Frame" tabindex="0"></span></div><script type="math/tex; mode=display" id="MathJax-Element-90"> \text{Power}_{F} = 1 - \beta = P_{h'}(F_{1}) = \sum_{s \in S} F(s)
P_{h'}(s) d s.  </script>

The probability <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-537"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-538">β</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-91-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-91">\beta</script> is called the <em>type-II error</em> of
falsely accepting the null hypothesis. An optimal test is one that
minimizes both the errors <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-539"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-540">α</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-92-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-92">\alpha</script> and <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-541"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-542">β</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-93-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-93">\beta</script>. In their
fundamental lemma, Neyman and Pearson proved that the decision has
optimal significance and power for, and only for, likelihood-ratio
test functions <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-543"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-544">F</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-94-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-94">F</script>. That is, an optimal test depends only on a
threshold for the ratio <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-545"><span class="MJXp-msubsup" id="MJXp-Span-546"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-547" style="margin-right: 0.05em;">P</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-548" style="vertical-align: -0.4em;"><span class="MJXp-msup" id="MJXp-Span-549"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-550" style="margin-right: 0.05em;">h</span><span class="MJXp-mo MJXp-script" id="MJXp-Span-551" style="vertical-align: 0.5em;">′</span></span></span></span><span class="MJXp-mo" id="MJXp-Span-552" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-553">s</span><span class="MJXp-mo" id="MJXp-Span-554" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mrow" id="MJXp-Span-555"><span class="MJXp-mo" id="MJXp-Span-556" style="margin-left: 0.111em; margin-right: 0.111em;">/</span></span><span class="MJXp-msubsup" id="MJXp-Span-557"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-558" style="margin-right: 0.05em;">P</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-559" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-560">h</span></span></span><span class="MJXp-mo" id="MJXp-Span-561" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-562">s</span><span class="MJXp-mo" id="MJXp-Span-563" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-95-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-95">P_{h'}(s) / P_{h}(s)</script>.</p>

<p>The example of the tea tasting lady allows for an easy illustration
of the likelihood ratio test.</p>

<blockquote><strong>Neyman-Pearson test</strong><br /> Next to the
null hypothesis <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-564"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-565">h</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-96-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-96">h</script> that the lady is randomly guessing, we now
consider the alternative hypothesis <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-566"><span class="MJXp-msup" id="MJXp-Span-567"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-568" style="margin-right: 0.05em;">h</span><span class="MJXp-mo MJXp-script" id="MJXp-Span-569" style="vertical-align: 0.5em;">′</span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-97-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-97">h'</script> that she has a chance of
<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-570"><span class="MJXp-mn" id="MJXp-Span-571">3</span><span class="MJXp-mrow" id="MJXp-Span-572"><span class="MJXp-mo" id="MJXp-Span-573" style="margin-left: 0.111em; margin-right: 0.111em;">/</span></span><span class="MJXp-mn" id="MJXp-Span-574">4</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-98-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-98">3/4</script> to guess the order of tea and milk correctly. The samples
<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-575"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-576">s</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-99-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-99">s</script> are binary 5-tuples that record guesses as correct and
incorrect. To determine the likelihoods of the two hypotheses, and
thereby the value of the test function for each sample, we only need
to know the so-called <em>sufficient statistic</em>, in this case the
number of correct guesses <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-577"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-578">n</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-100-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-100">n</script> independently of the order. Denoting a
particular sequence of guesses in which the lady has <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-579"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-580">n</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-101-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-101">n</script> correct
guesses out of <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-581"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-582">t</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-102-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-102">t</script> with <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-583"><span class="MJXp-msubsup" id="MJXp-Span-584"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-585" style="margin-right: 0.05em;">s</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-586" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-587">n</span><span class="MJXp-mrow" id="MJXp-Span-588"><span class="MJXp-mo" id="MJXp-Span-589">/</span></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-590">t</span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-103-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-103">s_{n/t}</script>, we have <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-591"><span class="MJXp-msubsup" id="MJXp-Span-592"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-593" style="margin-right: 0.05em;">P</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-594" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-595">h</span></span></span><span class="MJXp-mo" id="MJXp-Span-596" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-597"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-598" style="margin-right: 0.05em;">s</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-599" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-600">n</span><span class="MJXp-mrow" id="MJXp-Span-601"><span class="MJXp-mo" id="MJXp-Span-602">/</span></span><span class="MJXp-mn" id="MJXp-Span-603">5</span></span></span><span class="MJXp-mo" id="MJXp-Span-604" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-605" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mn" id="MJXp-Span-606">1</span><span class="MJXp-mrow" id="MJXp-Span-607"><span class="MJXp-mo" id="MJXp-Span-608" style="margin-left: 0.111em; margin-right: 0.111em;">/</span></span><span class="MJXp-msubsup" id="MJXp-Span-609"><span class="MJXp-mn" id="MJXp-Span-610" style="margin-right: 0.05em;">2</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-611" style="vertical-align: 0.5em;"><span class="MJXp-mn" id="MJXp-Span-612">5</span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-104-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-104">P_{h}(s_{n/5}) =
1/2^{5}</script> and <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-613"><span class="MJXp-msubsup" id="MJXp-Span-614"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-615" style="margin-right: 0.05em;">P</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-616" style="vertical-align: -0.4em;"><span class="MJXp-msup" id="MJXp-Span-617"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-618" style="margin-right: 0.05em;">h</span><span class="MJXp-mo MJXp-script" id="MJXp-Span-619" style="vertical-align: 0.5em;">′</span></span></span></span><span class="MJXp-mo" id="MJXp-Span-620" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-621"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-622" style="margin-right: 0.05em;">s</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-623" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-624">n</span><span class="MJXp-mrow" id="MJXp-Span-625"><span class="MJXp-mo" id="MJXp-Span-626">/</span></span><span class="MJXp-mn" id="MJXp-Span-627">5</span></span></span><span class="MJXp-mo" id="MJXp-Span-628" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-629" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-msubsup" id="MJXp-Span-630"><span class="MJXp-mn" id="MJXp-Span-631" style="margin-right: 0.05em;">3</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-632" style="vertical-align: 0.5em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-633">n</span></span></span><span class="MJXp-mrow" id="MJXp-Span-634"><span class="MJXp-mo" id="MJXp-Span-635" style="margin-left: 0.111em; margin-right: 0.111em;">/</span></span><span class="MJXp-msubsup" id="MJXp-Span-636"><span class="MJXp-mn" id="MJXp-Span-637" style="margin-right: 0.05em;">4</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-638" style="vertical-align: 0.5em;"><span class="MJXp-mn" id="MJXp-Span-639">5</span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-105-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-105">P_{h'}(s_{n/5}) = 3^{n} / 4^{5}</script>, so that the
likelihood ratio becomes <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-640"><span class="MJXp-msubsup" id="MJXp-Span-641"><span class="MJXp-mn" id="MJXp-Span-642" style="margin-right: 0.05em;">3</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-643" style="vertical-align: 0.5em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-644">n</span></span></span><span class="MJXp-mrow" id="MJXp-Span-645"><span class="MJXp-mo" id="MJXp-Span-646" style="margin-left: 0.111em; margin-right: 0.111em;">/</span></span><span class="MJXp-msubsup" id="MJXp-Span-647"><span class="MJXp-mn" id="MJXp-Span-648" style="margin-right: 0.05em;">2</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-649" style="vertical-align: 0.5em;"><span class="MJXp-mn" id="MJXp-Span-650">5</span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-106-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-106">3^{n} / 2^{5}</script>. If we require that the
significance is lower than 5%, then it can be calculated that only the
samples with <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-651"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-652">n</span><span class="MJXp-mo" id="MJXp-Span-653" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mn" id="MJXp-Span-654">5</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-107-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-107">n = 5</script> may be included in the region of
rejection. Accordingly we may set the cut-off point <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-655"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-656">r</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-108-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-108">r</script> such that
<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-657"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-658">r</span><span class="MJXp-mo" id="MJXp-Span-659" style="margin-left: 0.333em; margin-right: 0.333em;">≥</span><span class="MJXp-msubsup" id="MJXp-Span-660"><span class="MJXp-mn" id="MJXp-Span-661" style="margin-right: 0.05em;">3</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-662" style="vertical-align: 0.5em;"><span class="MJXp-mn" id="MJXp-Span-663">4</span></span></span><span class="MJXp-mrow" id="MJXp-Span-664"><span class="MJXp-mo" id="MJXp-Span-665" style="margin-left: 0.111em; margin-right: 0.111em;">/</span></span><span class="MJXp-msubsup" id="MJXp-Span-666"><span class="MJXp-mn" id="MJXp-Span-667" style="margin-right: 0.05em;">2</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-668" style="vertical-align: 0.5em;"><span class="MJXp-mn" id="MJXp-Span-669">5</span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-109-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-109">r \geq 3^{4} / 2^{5}</script> and <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-670"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-671">r</span><span class="MJXp-mo" id="MJXp-Span-672" style="margin-left: 0.333em; margin-right: 0.333em;">&lt;</span><span class="MJXp-msubsup" id="MJXp-Span-673"><span class="MJXp-mn" id="MJXp-Span-674" style="margin-right: 0.05em;">3</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-675" style="vertical-align: 0.5em;"><span class="MJXp-mn" id="MJXp-Span-676">5</span></span></span><span class="MJXp-mrow" id="MJXp-Span-677"><span class="MJXp-mo" id="MJXp-Span-678" style="margin-left: 0.111em; margin-right: 0.111em;">/</span></span><span class="MJXp-msubsup" id="MJXp-Span-679"><span class="MJXp-mn" id="MJXp-Span-680" style="margin-right: 0.05em;">2</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-681" style="vertical-align: 0.5em;"><span class="MJXp-mn" id="MJXp-Span-682">5</span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-110-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-110">r \lt 3^{5} / 2^{5}</script>, e.g., <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-683"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-684">r</span><span class="MJXp-mo" id="MJXp-Span-685" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-msubsup" id="MJXp-Span-686"><span class="MJXp-mn" id="MJXp-Span-687" style="margin-right: 0.05em;">3</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-688" style="vertical-align: 0.5em;"><span class="MJXp-mn" id="MJXp-Span-689">4</span></span></span><span class="MJXp-mrow" id="MJXp-Span-690"><span class="MJXp-mo" id="MJXp-Span-691" style="margin-left: 0.111em; margin-right: 0.111em;">/</span></span><span class="MJXp-msubsup" id="MJXp-Span-692"><span class="MJXp-mn" id="MJXp-Span-693" style="margin-right: 0.05em;">2</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-694" style="vertical-align: 0.5em;"><span class="MJXp-mn" id="MJXp-Span-695">5</span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-111-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-111">r =
3^{4} / 2^{5}</script>.</blockquote>

<p>The threshold of 5% significance is part of statistical convention
and very often fixed before even considering the power. Notice that
the statistical procedure associates expected error rates with a
decision to reject or accept. Especially Neyman has become known for
interpreting this in a strictly behaviourist fashion. For further
discussion on this point, please see 
 <a href="#NatEvi">Section 3.2.2</a>.</p>

<h4><a id="Est">3.1.2 Estimation</a></h4>

<p>In this section we briefly consider parameter estimation by maximum
likelihood, as first devised by Fisher (1956). While in the foregoing
we used a finite sample space, we now employ a space with infinitely
many possible samples. Accordingly, a probability distribution over
sample space is written down in terms of a so-called <em>density
function</em>, denoted <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-696"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-697">P</span><span class="MJXp-mo" id="MJXp-Span-698" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-699">s</span><span class="MJXp-mo" id="MJXp-Span-700" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-701">d</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-702">s</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-112-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-112">P(s) ds</script>, which technically speaking
expresses the infinitely small probability assigned to an infinitely
small patch <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-703"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-704">d</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-705">s</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-113-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-113">ds</script> around the point <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-706"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-707">s</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-114-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-114">s</script>. This probability density
works much like an ordinary probability function.</p>

<p>Maximum likelihood estimation, or MLE for short, is a tool for
determining the best among a set of hypotheses, often called a
<em>statistical model</em>.  Let <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-708"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-709">M</span><span class="MJXp-mo" id="MJXp-Span-710" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mo" id="MJXp-Span-711" style="margin-left: 0em; margin-right: 0em;">{</span><span class="MJXp-msubsup" id="MJXp-Span-712"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-713" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-714" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-715">θ</span></span></span><span class="MJXp-mo" id="MJXp-Span-716" style="margin-left: 0.111em; margin-right: 0.167em;">:</span><span class="MJXp-mspace" id="MJXp-Span-717" style="width: 0.222em; height: 0em;"></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-718">θ</span><span class="MJXp-mo" id="MJXp-Span-719" style="margin-left: 0.333em; margin-right: 0.333em;">∈</span><span class="MJXp-mi" id="MJXp-Span-720">Θ</span><span class="MJXp-mo" id="MJXp-Span-721" style="margin-left: 0em; margin-right: 0em;">}</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-115-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-115">M = \{h_{\theta} :\: \theta \in
\Theta \}</script> be the model, labeled by the parameter <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-722"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-723">θ</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-116-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-116">\theta</script>, let
<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-724"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-725">S</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-117-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-117">S</script> be the sample space, and <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-726"><span class="MJXp-msubsup" id="MJXp-Span-727"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-728" style="margin-right: 0.05em;">P</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-729" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-730">θ</span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-118-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-118">P_{\theta}</script> the distribution
associated with <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-731"><span class="MJXp-msubsup" id="MJXp-Span-732"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-733" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-734" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-735">θ</span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-119-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-119">h_{\theta}</script>.  Then define the <em>maximum
likelihood estimator</em> <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-736"><span class="MJXp-mrow" id="MJXp-Span-737"><span class="MJXp-munderover" id="MJXp-Span-738"><span><span class="MJXp-over"><span class="" style="margin-bottom: -0.92em;"><span class="MJXp-mo" id="MJXp-Span-740" style="margin-left: 0px; margin-right: 0px;">ˆ</span></span><span class=""><span class="MJXp-mi MJXp-italic" id="MJXp-Span-739">θ</span></span></span></span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-120-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-120">\hat{\theta}</script> as a function over the
sample space:

<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-741"><span class="MJXp-mrow" id="MJXp-Span-742"><span class="MJXp-munderover" id="MJXp-Span-743"><span><span class="MJXp-over"><span class="" style="margin-bottom: -0.92em;"><span class="MJXp-mo" id="MJXp-Span-745" style="margin-left: 0px; margin-right: 0px;">ˆ</span></span><span class=""><span class="MJXp-mi MJXp-italic" id="MJXp-Span-744">θ</span></span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-746" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-747">s</span><span class="MJXp-mo" id="MJXp-Span-748" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-749" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mrow" id="MJXp-Span-750"><span class="MJXp-mo" id="MJXp-Span-751" style="margin-left: 0em; margin-right: 0em; vertical-align: -0.244em;"><span class="MJXp-right MJXp-scale7" style="font-size: 1.978em; margin-left: -0.104em;">{</span></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-752">θ</span><span class="MJXp-mo" id="MJXp-Span-753" style="margin-left: 0.111em; margin-right: 0.167em;">:</span><span class="MJXp-mspace" id="MJXp-Span-754" style="width: 0.222em; height: 0em;"></span><span class="MJXp-mi" id="MJXp-Span-755">∀</span><span class="MJXp-msubsup" id="MJXp-Span-756"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-757" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-758" style="vertical-align: -0.4em;"><span class="MJXp-msup" id="MJXp-Span-759"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-760" style="margin-right: 0.05em;">θ</span><span class="MJXp-mo MJXp-script" id="MJXp-Span-761" style="vertical-align: 0.5em;">′</span></span></span></span><span class="MJXp-mrow" id="MJXp-Span-762"><span class="MJXp-mo" id="MJXp-Span-763" style="margin-left: 0em; margin-right: 0em; vertical-align: -0.083em;"><span class="MJXp-right MJXp-scale10" style="font-size: 1.333em; margin-left: 0.07em;">(</span></span></span><span class="MJXp-msubsup" id="MJXp-Span-764"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-765" style="margin-right: 0.05em;">P</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-766" style="vertical-align: -0.4em;"><span class="MJXp-msup" id="MJXp-Span-767"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-768" style="margin-right: 0.05em;">θ</span><span class="MJXp-mo MJXp-script" id="MJXp-Span-769" style="vertical-align: 0.5em;">′</span></span></span></span><span class="MJXp-mo" id="MJXp-Span-770" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-771">s</span><span class="MJXp-mo" id="MJXp-Span-772" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-773">d</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-774">s</span><span class="MJXp-mo" id="MJXp-Span-775" style="margin-left: 0.333em; margin-right: 0.333em;">≤</span><span class="MJXp-msubsup" id="MJXp-Span-776"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-777" style="margin-right: 0.05em;">P</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-778" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-779">θ</span></span></span><span class="MJXp-mo" id="MJXp-Span-780" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-781">s</span><span class="MJXp-mo" id="MJXp-Span-782" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-783">d</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-784">s</span><span class="MJXp-mrow" id="MJXp-Span-785"><span class="MJXp-mo" id="MJXp-Span-786" style="margin-left: 0em; margin-right: 0em; vertical-align: -0.083em;"><span class="MJXp-right MJXp-scale10" style="font-size: 1.333em; margin-left: 0.07em;">)</span></span></span><span class="MJXp-mo" id="MJXp-Span-787" style="margin-left: 0em; margin-right: 0em; vertical-align: -0.244em;"><span class="MJXp-right MJXp-scale7" style="font-size: 1.978em; margin-left: -0.104em;">}</span></span></span><span class="MJXp-mo" id="MJXp-Span-788" style="margin-left: 0em; margin-right: 0.222em;">.</span></span></span><div class="MathJax_Display MathJax_Processing"><span class="MathJax" id="MathJax-Element-121-Frame" tabindex="0"></span></div><script type="math/tex; mode=display" id="MathJax-Element-121"> \hat{\theta}(s) = \left\{ \theta :\: \forall h_{\theta'}
\bigl(P_{\theta'}(s)ds \leq P_{\theta}(s)ds \bigr) \right\}. </script>

So the estimator is a set, typically a singleton, of values of
<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-789"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-790">θ</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-122-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-122">\theta</script> for which the likelihood of <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-791"><span class="MJXp-msubsup" id="MJXp-Span-792"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-793" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-794" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-795">θ</span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-123-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-123">h_{\theta}</script> on the data
<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-796"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-797">s</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-124-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-124">s</script> is maximal. The associated best hypothesis we denote with
<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-798"><span class="MJXp-msubsup" id="MJXp-Span-799"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-800" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-801" style="vertical-align: -0.4em;"><span class="MJXp-mrow" id="MJXp-Span-802"><span class="MJXp-munderover" id="MJXp-Span-803"><span><span class="MJXp-over"><span class=" MJXp-script" style="margin-bottom: -0.92em;"><span class="MJXp-mo" id="MJXp-Span-805" style="margin-right: 0px; margin-left: 0px;">ˆ</span></span><span class=""><span class="MJXp-mi MJXp-italic" id="MJXp-Span-804">θ</span></span></span></span></span></span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-125-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-125">h_{\hat{\theta}}</script>. This can again be illustrated for the tea
tasting lady.</p>

<blockquote>
<strong>Maximum likelihood estimation</strong><br /> A natural
statistical model for the case of the tea tasting lady consists of
hypotheses <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-806"><span class="MJXp-msubsup" id="MJXp-Span-807"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-808" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-809" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-810">θ</span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-126-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-126">h_{\theta}</script> for all possible levels of accuracy that the
lady may have, <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-811"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-812">θ</span><span class="MJXp-mo" id="MJXp-Span-813" style="margin-left: 0.333em; margin-right: 0.333em;">∈</span><span class="MJXp-mo" id="MJXp-Span-814" style="margin-left: 0em; margin-right: 0em;">[</span><span class="MJXp-mn" id="MJXp-Span-815">0</span><span class="MJXp-mo" id="MJXp-Span-816" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mn" id="MJXp-Span-817">1</span><span class="MJXp-mo" id="MJXp-Span-818" style="margin-left: 0em; margin-right: 0em;">]</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-127-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-127">\theta \in [0, 1]</script>. Now the number of correct
guesses <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-819"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-820">n</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-128-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-128">n</script> and the total number of guesses <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-821"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-822">t</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-129-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-129">t</script> are the sufficient
statistics: the probability of a sample only depends on those
numbers. For any particular sequence <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-823"><span class="MJXp-msubsup" id="MJXp-Span-824"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-825" style="margin-right: 0.05em;">s</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-826" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-827">n</span><span class="MJXp-mrow" id="MJXp-Span-828"><span class="MJXp-mo" id="MJXp-Span-829">/</span></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-830">t</span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-130-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-130">s_{n/t}</script> of <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-831"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-832">t</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-131-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-131">t</script> guesses with
<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-833"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-834">n</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-132-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-132">n</script> successes, the associated likelihoods of <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-835"><span class="MJXp-msubsup" id="MJXp-Span-836"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-837" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-838" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-839">θ</span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-133-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-133">h_{\theta}</script> are

<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-840"><span class="MJXp-msubsup" id="MJXp-Span-841"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-842" style="margin-right: 0.05em;">P</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-843" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-844">θ</span></span></span><span class="MJXp-mo" id="MJXp-Span-845" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-846"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-847" style="margin-right: 0.05em;">s</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-848" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-849">n</span><span class="MJXp-mrow" id="MJXp-Span-850"><span class="MJXp-mo" id="MJXp-Span-851">/</span></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-852">t</span></span></span><span class="MJXp-mo" id="MJXp-Span-853" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-854" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-msubsup" id="MJXp-Span-855"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-856" style="margin-right: 0.05em;">θ</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-857" style="vertical-align: 0.5em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-858">n</span></span></span><span class="MJXp-mo" id="MJXp-Span-859" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mn" id="MJXp-Span-860">1</span><span class="MJXp-mo" id="MJXp-Span-861" style="margin-left: 0.267em; margin-right: 0.267em;">−</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-862">θ</span><span class="MJXp-msubsup" id="MJXp-Span-863"><span class="MJXp-mo" id="MJXp-Span-864" style="margin-left: 0em; margin-right: 0.05em;">)</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-865" style="vertical-align: 0.5em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-866">t</span><span class="MJXp-mo" id="MJXp-Span-867">−</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-868">n</span></span></span><span class="MJXp-mo" id="MJXp-Span-869" style="margin-left: 0em; margin-right: 0.222em;">.</span></span></span><div class="MathJax_Display MathJax_Processing"><span class="MathJax" id="MathJax-Element-134-Frame" tabindex="0"></span></div><script type="math/tex; mode=display" id="MathJax-Element-134">  P_{\theta}(s_{n/t}) = \theta^{n} (1 - \theta)^{t - n} . </script>

For any number of trials <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-870"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-871">t</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-135-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-135">t</script> the maximum likelihood estimator then
becomes <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-872"><span class="MJXp-mrow" id="MJXp-Span-873"><span class="MJXp-munderover" id="MJXp-Span-874"><span><span class="MJXp-over"><span class="" style="margin-bottom: -0.92em;"><span class="MJXp-mo" id="MJXp-Span-876" style="margin-left: 0px; margin-right: 0px;">ˆ</span></span><span class=""><span class="MJXp-mi MJXp-italic" id="MJXp-Span-875">θ</span></span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-877" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-878">n</span><span class="MJXp-mrow" id="MJXp-Span-879"><span class="MJXp-mo" id="MJXp-Span-880" style="margin-left: 0.111em; margin-right: 0.111em;">/</span></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-881">t</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-136-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-136">\hat{\theta} = n / t</script>.</blockquote>

<p>We suppose that the number of cups served to the lady is fixed at
<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-882"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-883">t</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-137-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-137">t</script> so that sample space is finite again. Notice, finally, that
<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-884"><span class="MJXp-mrow" id="MJXp-Span-885"><span class="MJXp-munderover" id="MJXp-Span-886"><span><span class="MJXp-over"><span class="" style="margin-bottom: -0.92em;"><span class="MJXp-mo" id="MJXp-Span-888" style="margin-left: 0px; margin-right: 0px;">ˆ</span></span><span class=""><span class="MJXp-mi MJXp-italic" id="MJXp-Span-887">θ</span></span></span></span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-138-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-138">\hat{\theta}</script> is the hypothesis that makes the data most probable
and not the hypothesis that is most probable in the light of the
data. </p>

<p>There are several requirements that we might impose on an estimator
function. One is that the estimator must be consistent.  This means
that for larger samples the estimator function <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-889"><span class="MJXp-mrow" id="MJXp-Span-890"><span class="MJXp-munderover" id="MJXp-Span-891"><span><span class="MJXp-over"><span class="" style="margin-bottom: -0.92em;"><span class="MJXp-mo" id="MJXp-Span-893" style="margin-left: 0px; margin-right: 0px;">ˆ</span></span><span class=""><span class="MJXp-mi MJXp-italic" id="MJXp-Span-892">θ</span></span></span></span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-139-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-139">\hat{\theta}</script>
converges to the parameter values associated with the distribution
<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-894"><span class="MJXp-msubsup" id="MJXp-Span-895"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-896" style="margin-right: 0.05em;">θ</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-897" style="vertical-align: 0.5em;"><span class="MJXp-mo" id="MJXp-Span-898">⋆</span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-140-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-140">\theta^{\star}</script> of the data generating system, or the true
parameter values for short. Another requirement is that the estimator
must be unbiased, meaning that there is no discrepancy between the
expected value of the estimator and the true parameter values. The MLE
procedure is certainly not the only one used for estimating the value
of a parameter of interest on the basis of statistical data. A simpler
technique is the minimization of a particular target function, e.g.,
the minimizing the sum of the squares of the distances between the
prediction of the statistical hypothesis and the data points, also
known as the <em>method of least squares</em>.  A more general
perspective, first developed by Wald (1950), is provided by measuring
the discrepancy between the predictions of the hypothesis and the
actual data in terms of a loss function. The summed squares and the
likelihoods may be taken as expressions of this loss.</p>

<p>Often the estimation is coupled to a so-called <em>confidence
interval</em> (cf. Cumming 2012).  For ease of exposition, assume that
<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-899"><span class="MJXp-mi" id="MJXp-Span-900">Θ</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-141-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-141">\Theta</script> consists of the real numbers and that every sample <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-901"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-902">s</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-142-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-142">s</script> is
labelled with a unique <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-903"><span class="MJXp-mrow" id="MJXp-Span-904"><span class="MJXp-munderover" id="MJXp-Span-905"><span><span class="MJXp-over"><span class="" style="margin-bottom: -0.92em;"><span class="MJXp-mo" id="MJXp-Span-907" style="margin-left: 0px; margin-right: 0px;">ˆ</span></span><span class=""><span class="MJXp-mi MJXp-italic" id="MJXp-Span-906">θ</span></span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-908" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-909">s</span><span class="MJXp-mo" id="MJXp-Span-910" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-143-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-143">\hat{\theta}(s)</script>. We define the set
<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-911"><span class="MJXp-msubsup" id="MJXp-Span-912"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-913" style="margin-right: 0.05em;">R</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-914" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-915">τ</span></span></span><span class="MJXp-mo" id="MJXp-Span-916" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mo" id="MJXp-Span-917" style="margin-left: 0em; margin-right: 0em;">{</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-918">s</span><span class="MJXp-mo" id="MJXp-Span-919" style="margin-left: 0.111em; margin-right: 0.167em;">:</span><span class="MJXp-mspace" id="MJXp-Span-920" style="width: 0.222em; height: 0em;"></span><span class="MJXp-mrow" id="MJXp-Span-921"><span class="MJXp-munderover" id="MJXp-Span-922"><span><span class="MJXp-over"><span class="" style="margin-bottom: -0.92em;"><span class="MJXp-mo" id="MJXp-Span-924" style="margin-left: 0px; margin-right: 0px;">ˆ</span></span><span class=""><span class="MJXp-mi MJXp-italic" id="MJXp-Span-923">θ</span></span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-925" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-926">s</span><span class="MJXp-mo" id="MJXp-Span-927" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-928" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-929">τ</span><span class="MJXp-mo" id="MJXp-Span-930" style="margin-left: 0em; margin-right: 0em;">}</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-144-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-144">R_{\tau} = \{ s:\: \hat{\theta}(s) = \tau \}</script>, the set of samples
for which the estimator function has the value <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-931"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-932">τ</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-145-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-145">\tau</script>. We can now
collate a region in sample space within which the estimator function
<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-933"><span class="MJXp-mrow" id="MJXp-Span-934"><span class="MJXp-munderover" id="MJXp-Span-935"><span><span class="MJXp-over"><span class="" style="margin-bottom: -0.92em;"><span class="MJXp-mo" id="MJXp-Span-937" style="margin-left: 0px; margin-right: 0px;">ˆ</span></span><span class=""><span class="MJXp-mi MJXp-italic" id="MJXp-Span-936">θ</span></span></span></span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-146-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-146">\hat{\theta}</script> is not too far off the mark, i.e., not too far from
the true value <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-938"><span class="MJXp-msubsup" id="MJXp-Span-939"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-940" style="margin-right: 0.05em;">θ</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-941" style="vertical-align: 0.5em;"><span class="MJXp-mo" id="MJXp-Span-942">⋆</span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-147-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-147">\theta^{\star}</script> of the parameter. For example,

<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-943"><span class="MJXp-msubsup" id="MJXp-Span-944"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-945" style="margin-right: 0.05em;">C</span><span class="MJXp-script-box" style="height: 1.86em; vertical-align: -0.64em;"><span class=" MJXp-script"><span><span style="margin-bottom: -0.25em;"><span class="MJXp-mrow" id="MJXp-Span-948"><span class="MJXp-mo" id="MJXp-Span-949">⋆</span></span></span></span></span><span class=" MJXp-script"><span><span style="margin-top: -0.85em;"><span class="MJXp-mrow" id="MJXp-Span-946"><span class="MJXp-mi" id="MJXp-Span-947">Δ</span></span></span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-950" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mo" id="MJXp-Span-951" style="margin-left: 0em; margin-right: 0em;">{</span><span class="MJXp-msubsup" id="MJXp-Span-952"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-953" style="margin-right: 0.05em;">R</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-954" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-955">τ</span></span></span><span class="MJXp-mo" id="MJXp-Span-956" style="margin-left: 0.111em; margin-right: 0.167em;">:</span><span class="MJXp-mspace" id="MJXp-Span-957" style="width: 0.222em; height: 0em;"></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-958">τ</span><span class="MJXp-mo" id="MJXp-Span-959" style="margin-left: 0.333em; margin-right: 0.333em;">∈</span><span class="MJXp-mo" id="MJXp-Span-960" style="margin-left: 0em; margin-right: 0em;">[</span><span class="MJXp-msubsup" id="MJXp-Span-961"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-962" style="margin-right: 0.05em;">θ</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-963" style="vertical-align: 0.5em;"><span class="MJXp-mo" id="MJXp-Span-964">⋆</span></span></span><span class="MJXp-mo" id="MJXp-Span-965" style="margin-left: 0.267em; margin-right: 0.267em;">−</span><span class="MJXp-mi" id="MJXp-Span-966">Δ</span><span class="MJXp-mo" id="MJXp-Span-967" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-msubsup" id="MJXp-Span-968"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-969" style="margin-right: 0.05em;">θ</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-970" style="vertical-align: 0.5em;"><span class="MJXp-mo" id="MJXp-Span-971">⋆</span></span></span><span class="MJXp-mo" id="MJXp-Span-972" style="margin-left: 0.267em; margin-right: 0.267em;">+</span><span class="MJXp-mi" id="MJXp-Span-973">Δ</span><span class="MJXp-mo" id="MJXp-Span-974" style="margin-left: 0em; margin-right: 0em;">]</span><span class="MJXp-mo" id="MJXp-Span-975" style="margin-left: 0em; margin-right: 0em;">}</span><span class="MJXp-mo" id="MJXp-Span-976" style="margin-left: 0em; margin-right: 0.222em;">.</span></span></span><div class="MathJax_Display MathJax_Processing"><span class="MathJax" id="MathJax-Element-148-Frame" tabindex="0"></span></div><script type="math/tex; mode=display" id="MathJax-Element-148"> C^{\star}_{\Delta} = \{ R_{\tau} :\: \tau \in [ \theta^{\star} -
\Delta , \theta^{\star} + \Delta ] \} . </script>

So this set is the union of all <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-977"><span class="MJXp-msubsup" id="MJXp-Span-978"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-979" style="margin-right: 0.05em;">R</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-980" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-981">τ</span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-149-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-149">R_{\tau}</script> for which <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-982"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-983">τ</span><span class="MJXp-mo" id="MJXp-Span-984" style="margin-left: 0.333em; margin-right: 0.333em;">∈</span><span class="MJXp-mo" id="MJXp-Span-985" style="margin-left: 0em; margin-right: 0em;">[</span><span class="MJXp-msubsup" id="MJXp-Span-986"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-987" style="margin-right: 0.05em;">θ</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-988" style="vertical-align: 0.5em;"><span class="MJXp-mo" id="MJXp-Span-989">⋆</span></span></span><span class="MJXp-mo" id="MJXp-Span-990" style="margin-left: 0.267em; margin-right: 0.267em;">−</span><span class="MJXp-mi" id="MJXp-Span-991">Δ</span><span class="MJXp-mo" id="MJXp-Span-992" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-msubsup" id="MJXp-Span-993"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-994" style="margin-right: 0.05em;">θ</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-995" style="vertical-align: 0.5em;"><span class="MJXp-mo" id="MJXp-Span-996">⋆</span></span></span><span class="MJXp-mo" id="MJXp-Span-997" style="margin-left: 0.267em; margin-right: 0.267em;">+</span><span class="MJXp-mi" id="MJXp-Span-998">Δ</span><span class="MJXp-mo" id="MJXp-Span-999" style="margin-left: 0em; margin-right: 0em;">]</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-150-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-150">\tau \in [
\theta^{\star} - \Delta , \theta^{\star} + \Delta ]</script>. Now we might
set this region in such a way that it covers a large portion of the
sample space, say <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1000"><span class="MJXp-mn" id="MJXp-Span-1001">1</span><span class="MJXp-mo" id="MJXp-Span-1002" style="margin-left: 0.267em; margin-right: 0.267em;">−</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1003">α</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-151-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-151">1 - \alpha</script>, as measured by the true distribution
<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1004"><span class="MJXp-msubsup" id="MJXp-Span-1005"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1006" style="margin-right: 0.05em;">P</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1007" style="vertical-align: -0.4em;"><span class="MJXp-msubsup" id="MJXp-Span-1008"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1009" style="margin-right: 0.05em;">θ</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1010" style="vertical-align: 0.5em;"><span class="MJXp-mo" id="MJXp-Span-1011">⋆</span></span></span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-152-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-152">P_{\theta^{\star}}</script>. We choose <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1012"><span class="MJXp-mi" id="MJXp-Span-1013">Δ</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-153-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-153">\Delta</script> such that

<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-1014"><span class="MJXp-msubsup" id="MJXp-Span-1015"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1016" style="margin-right: 0.05em;">P</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1017" style="vertical-align: -0.4em;"><span class="MJXp-msubsup" id="MJXp-Span-1018"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1019" style="margin-right: 0.05em;">θ</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1020" style="vertical-align: 0.5em;"><span class="MJXp-mo" id="MJXp-Span-1021">⋆</span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-1022" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-1023"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1024" style="margin-right: 0.05em;">C</span><span class="MJXp-script-box" style="height: 1.86em; vertical-align: -0.64em;"><span class=" MJXp-script"><span><span style="margin-bottom: -0.25em;"><span class="MJXp-mrow" id="MJXp-Span-1027"><span class="MJXp-mo" id="MJXp-Span-1028">⋆</span></span></span></span></span><span class=" MJXp-script"><span><span style="margin-top: -0.85em;"><span class="MJXp-mrow" id="MJXp-Span-1025"><span class="MJXp-mi" id="MJXp-Span-1026">Δ</span></span></span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-1029" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-1030" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-msubsup" id="MJXp-Span-1031"><span class="MJXp-mo" id="MJXp-Span-1032" style="margin-left: 0em; margin-right: 0.05em;"><span class="MJXp-largeop MJXp-int">∫</span></span><span class="MJXp-script-box" style="height: 2.356em; vertical-align: -0.7em;"><span class=" MJXp-script"><span><span style="margin-bottom: -0.25em;"><span class="MJXp-mrow" id="MJXp-Span-1040"><span class="MJXp-msubsup" id="MJXp-Span-1041"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1042" style="margin-right: 0.05em;">θ</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1043" style="vertical-align: 0.5em;"><span class="MJXp-mo" id="MJXp-Span-1044">⋆</span></span></span><span class="MJXp-mo" id="MJXp-Span-1045">+</span><span class="MJXp-mi" id="MJXp-Span-1046">Δ</span></span></span></span></span><span class=" MJXp-script"><span><span style="margin-top: -1.17em;"><span class="MJXp-mrow" id="MJXp-Span-1033"><span class="MJXp-msubsup" id="MJXp-Span-1034"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1035" style="margin-right: 0.05em;">θ</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1036" style="vertical-align: 0.5em;"><span class="MJXp-mo" id="MJXp-Span-1037">⋆</span></span></span><span class="MJXp-mo" id="MJXp-Span-1038">−</span><span class="MJXp-mi" id="MJXp-Span-1039">Δ</span></span></span></span></span></span></span><span class="MJXp-msubsup" id="MJXp-Span-1047"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1048" style="margin-right: 0.05em;">P</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1049" style="vertical-align: -0.4em;"><span class="MJXp-msubsup" id="MJXp-Span-1050"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1051" style="margin-right: 0.05em;">θ</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1052" style="vertical-align: 0.5em;"><span class="MJXp-mo" id="MJXp-Span-1053">⋆</span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-1054" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-1055"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1056" style="margin-right: 0.05em;">R</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1057" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1058">τ</span></span></span><span class="MJXp-mo" id="MJXp-Span-1059" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1060">d</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1061">τ</span><span class="MJXp-mo" id="MJXp-Span-1062" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mn" id="MJXp-Span-1063">1</span><span class="MJXp-mo" id="MJXp-Span-1064" style="margin-left: 0.267em; margin-right: 0.267em;">−</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1065">α</span><span class="MJXp-mo" id="MJXp-Span-1066" style="margin-left: 0em; margin-right: 0.222em;">.</span></span></span><div class="MathJax_Display MathJax_Processing"><span class="MathJax" id="MathJax-Element-154-Frame" tabindex="0"></span></div><script type="math/tex; mode=display" id="MathJax-Element-154"> P_{\theta^{\star}}(C^{\star}_{\Delta}) = \int_{\theta^{\star} -
\Delta}^{\theta^{\star} + \Delta} P_{\theta^{\star}}(R_{\tau}) d\tau =
1 - \alpha .</script>

Statistical folk lore typically sets <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1067"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1068">α</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-155-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-155">\alpha</script> at a value
5%. Relative to this number, the size of <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1069"><span class="MJXp-mi" id="MJXp-Span-1070">Δ</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-156-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-156">\Delta</script> says something
about the quality of the estimate. If we were to repeat the collection
of the sample over and over, we would find the estimator
<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1071"><span class="MJXp-mrow" id="MJXp-Span-1072"><span class="MJXp-munderover" id="MJXp-Span-1073"><span><span class="MJXp-over"><span class="" style="margin-bottom: -0.92em;"><span class="MJXp-mo" id="MJXp-Span-1075" style="margin-left: 0px; margin-right: 0px;">ˆ</span></span><span class=""><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1074">θ</span></span></span></span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-157-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-157">\hat{\theta}</script> within a range <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1076"><span class="MJXp-mi" id="MJXp-Span-1077">Δ</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-158-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-158">\Delta</script> of the true value
<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1078"><span class="MJXp-msubsup" id="MJXp-Span-1079"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1080" style="margin-right: 0.05em;">θ</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1081" style="vertical-align: 0.5em;"><span class="MJXp-mo" id="MJXp-Span-1082">⋆</span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-159-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-159">\theta^{\star}</script> in 95% of all samples. This leads us to define the
symmetric 95% confidence interval:

<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-1083"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1084">C</span><span class="MJXp-msubsup" id="MJXp-Span-1085"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1086" style="margin-right: 0.05em;">I</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1087" style="vertical-align: -0.4em;"><span class="MJXp-mn" id="MJXp-Span-1088">95</span></span></span><span class="MJXp-mo" id="MJXp-Span-1089" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mo" id="MJXp-Span-1090" style="margin-left: 0em; margin-right: 0em;">[</span><span class="MJXp-mrow" id="MJXp-Span-1091"><span class="MJXp-munderover" id="MJXp-Span-1092"><span><span class="MJXp-over"><span class="" style="margin-bottom: -0.92em;"><span class="MJXp-mo" id="MJXp-Span-1094" style="margin-left: 0px; margin-right: 0px;">ˆ</span></span><span class=""><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1093">θ</span></span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-1095" style="margin-left: 0.267em; margin-right: 0.267em;">−</span><span class="MJXp-mi" id="MJXp-Span-1096">Δ</span><span class="MJXp-mo" id="MJXp-Span-1097" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mrow" id="MJXp-Span-1098"><span class="MJXp-munderover" id="MJXp-Span-1099"><span><span class="MJXp-over"><span class="" style="margin-bottom: -0.92em;"><span class="MJXp-mo" id="MJXp-Span-1101" style="margin-left: 0px; margin-right: 0px;">ˆ</span></span><span class=""><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1100">θ</span></span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-1102" style="margin-left: 0.267em; margin-right: 0.267em;">+</span><span class="MJXp-mi" id="MJXp-Span-1103">Δ</span><span class="MJXp-mo" id="MJXp-Span-1104" style="margin-left: 0em; margin-right: 0em;">]</span></span></span><div class="MathJax_Display MathJax_Processing"><span class="MathJax" id="MathJax-Element-160-Frame" tabindex="0"></span></div><script type="math/tex; mode=display" id="MathJax-Element-160"> CI_{95} = [ \hat{\theta} - \Delta , \hat{\theta} + \Delta ] </script>

The interpretation is the same as in the foregoing: with repeated
sampling we find the true value within <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1105"><span class="MJXp-mi" id="MJXp-Span-1106">Δ</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-161-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-161">\Delta</script> of the estimate in
95% of all samples. </p>

<p>It is crucial that we can provide an unproblematic frequentist
interpretation of the event that <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1107"><span class="MJXp-mrow" id="MJXp-Span-1108"><span class="MJXp-munderover" id="MJXp-Span-1109"><span><span class="MJXp-over"><span class="" style="margin-bottom: -0.92em;"><span class="MJXp-mo" id="MJXp-Span-1111" style="margin-left: 0px; margin-right: 0px;">ˆ</span></span><span class=""><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1110">θ</span></span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-1112" style="margin-left: 0.333em; margin-right: 0.333em;">∈</span><span class="MJXp-mo" id="MJXp-Span-1113" style="margin-left: 0em; margin-right: 0em;">[</span><span class="MJXp-msubsup" id="MJXp-Span-1114"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1115" style="margin-right: 0.05em;">θ</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1116" style="vertical-align: 0.5em;"><span class="MJXp-mo" id="MJXp-Span-1117">⋆</span></span></span><span class="MJXp-mo" id="MJXp-Span-1118" style="margin-left: 0.267em; margin-right: 0.267em;">−</span><span class="MJXp-mi" id="MJXp-Span-1119">Δ</span><span class="MJXp-mo" id="MJXp-Span-1120" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-msubsup" id="MJXp-Span-1121"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1122" style="margin-right: 0.05em;">θ</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1123" style="vertical-align: 0.5em;"><span class="MJXp-mo" id="MJXp-Span-1124">⋆</span></span></span><span class="MJXp-mo" id="MJXp-Span-1125" style="margin-left: 0.267em; margin-right: 0.267em;">+</span><span class="MJXp-mi" id="MJXp-Span-1126">Δ</span><span class="MJXp-mo" id="MJXp-Span-1127" style="margin-left: 0em; margin-right: 0em;">]</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-162-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-162">\hat{\theta} \in [\theta^{\star} -
\Delta, \theta^{\star} + \Delta]</script>, under the assumption of the true
distribution. In a series of estimations, the fraction of times in
which the estimator <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1128"><span class="MJXp-mrow" id="MJXp-Span-1129"><span class="MJXp-munderover" id="MJXp-Span-1130"><span><span class="MJXp-over"><span class="" style="margin-bottom: -0.92em;"><span class="MJXp-mo" id="MJXp-Span-1132" style="margin-left: 0px; margin-right: 0px;">ˆ</span></span><span class=""><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1131">θ</span></span></span></span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-163-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-163">\hat{\theta}</script> is further away from
<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1133"><span class="MJXp-msubsup" id="MJXp-Span-1134"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1135" style="margin-right: 0.05em;">θ</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1136" style="vertical-align: 0.5em;"><span class="MJXp-mo" id="MJXp-Span-1137">⋆</span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-164-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-164">\theta^{\star}</script> than <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1138"><span class="MJXp-mi" id="MJXp-Span-1139">Δ</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-165-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-165">\Delta</script>, and hence outside this interval,
will tend to 5%. The smaller this region, the more reliable the
estimate.  Note that this interval is defined in terms of the unknown
true value <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1140"><span class="MJXp-msubsup" id="MJXp-Span-1141"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1142" style="margin-right: 0.05em;">θ</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1143" style="vertical-align: 0.5em;"><span class="MJXp-mo" id="MJXp-Span-1144">⋆</span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-166-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-166">\theta^{\star}</script>. However, especially if the size of the
interval <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1145"><span class="MJXp-mn" id="MJXp-Span-1146">2</span><span class="MJXp-mi" id="MJXp-Span-1147">Δ</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-167-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-167">2 \Delta</script> is independent of the true parameter
<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1148"><span class="MJXp-msubsup" id="MJXp-Span-1149"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1150" style="margin-right: 0.05em;">θ</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1151" style="vertical-align: 0.5em;"><span class="MJXp-mo" id="MJXp-Span-1152">⋆</span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-168-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-168">\theta^{\star}</script>, it is tempting to associate the 95% confidence
interval with the frequency with which the true value lies within a
range of <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1153"><span class="MJXp-mi" id="MJXp-Span-1154">Δ</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-169-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-169">\Delta</script> around the estimate <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1155"><span class="MJXp-mrow" id="MJXp-Span-1156"><span class="MJXp-munderover" id="MJXp-Span-1157"><span><span class="MJXp-over"><span class="" style="margin-bottom: -0.92em;"><span class="MJXp-mo" id="MJXp-Span-1159" style="margin-left: 0px; margin-right: 0px;">ˆ</span></span><span class=""><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1158">θ</span></span></span></span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-170-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-170">\hat{\theta}</script>.  Below we
come back to this interpretation.</p>

<p>There are of course many more procedures for estimating a variety
of statistical targets, and there are many more expressions for the
quality of the estimation (e.g., bootstrapping, see Efron and
Tibshirani 1993). Theories of estimation often come equipped with a
rich catalogue of situation-specific criteria for estimators,
reflecting the epistemic and pragmatic goals that the estimator helps
achieving. However, in itself the estimator functions do
not present guidelines for belief and, importantly,
confidence intervals do not either. </p>

<h3><a id="ProForClaSta">3.2 Problems for classical statistics</a></h3>

<p>Classical statistics is widely discussed in the philosophy of
statistics. In what follows two problems with the classical approach
are outlined, to wit, its problematic interface with belief and the
fact that it violates the so-called likelihood principle. Many more
specific problems can be seen to derive from these general
ones.</p>

<h4><a id="IntBel">3.2.1 Interface with belief</a></h4>

<p>Consider the likelihood ratio test of Neyman and Pearson. As
indicated, the significance or p-value of a test is an error rate that
will manifest if data collection and testing is repeated, assuming
that the null hypothesis is in fact true.  Notably, the p-value does
not tell us anything about how probable the truth of the null
hypothesis is. However, many scientists do use hypothesis testing in
this manner, and there is much debate over what can and cannot be
derived from a p-value (cf. Berger and Sellke 1987, Casella and
Berger 1987, Cohen 1994, Harlow et al 1997, Wagenmakers 2007,
Ziliak and McCloskey 2008, Spanos 2007, Greco 2011, Sprenger
forthcoming-a). After all, the test leads to the advice to either
reject the hypothesis or accept it, and this seems conceptually very
close to giving a verdict of truth or falsity.</p>

<p>While the evidential value of <em>p</em>-values is much debated,
many admit that the probability of data according to a hypothesis
cannot be used straightforwardly as an indication of how believable
the hypothesis is (cf. Gillies 1971, Spielman 1974 and 1978).  Such
usage runs into the so-called <em>base-rate fallacy.</em> The example
of the tea tasting lady is again instructive. </p>

<blockquote>
<strong>Base-rate fallacy</strong><br /> Imagine that we travel the
country to perform the tea tasting test with a large number of ladies,
and that we find a particular lady who guesses all five cups
correctly.  Should we conclude that the lady has a special talent for
tasting tea?  The problem is that this depends on how many ladies
among those tested actually have the special talent. If the ability is
very rare, it is more attractive to put the five correct guesses down
to a chance occurrence.  By comparison, imagine that all the ladies
enter the lottery. In analogy to a lady guessing all cups correctly,
consider a lady who wins one of the lottery's prizes. Of course
winning a prize is very improbable, unless one is in cahoots with the
bookmaker, i.e., the analogon of having a special tea tasting
ability. But surely if a lady wins the lottery, this is not a good
reason to conclude that she must have committed fraud and call for her
arrest. Similarly, if a lady has guessed all cups correctly, we cannot
simply conclude that she has special abilities.</blockquote>

<p>Essentially the same problem occurs if we consider the estimations
of a parameter as direct advice on what to believe, as made clear by
an example of Good (1983, p. 57) that is presented here in the tea
tasting context. After observing five correct guesses, we have
<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1160"><span class="MJXp-mrow" id="MJXp-Span-1161"><span class="MJXp-munderover" id="MJXp-Span-1162"><span><span class="MJXp-over"><span class="" style="margin-bottom: -0.92em;"><span class="MJXp-mo" id="MJXp-Span-1164" style="margin-left: 0px; margin-right: 0px;">ˆ</span></span><span class=""><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1163">θ</span></span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-1165" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mn" id="MJXp-Span-1166">1</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-171-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-171">\hat{\theta} = 1</script> as maximum likelihood estimator. But it is hardly
believable that the lady will in the long run be 100% accurate. The
point that estimation and belief maintain complicated relations is
also put forward in discussions of <em>Lindley's paradox</em> (Lindley
1957, Spanos 2013, Sprenger forthcoming-b). In short, it seems
wrongheaded to turn the results of classical statistical procedures
into beliefs.</p>

<p>It is a matter of debate whether any of this can be blamed on
classical statistics.  Initially, Neyman was emphatic that their
procedures could not be taken as inferences, or as in some other way
pertaining to the epistemic status of the hypotheses. Their own
statistical philosophy was strictly behaviorist (cf. Neyman 1957), and
it may be argued that the problems disappear if only scientists
abandon their faulty epistemic use of classical statistics. As
explained in the foregoing, we can uncontroversially associate error
rates with classical procedures, and so with the decisions that flow
from these procedures. Hence, a behavioural and error-based
understanding of classical statistics seems just fine. However, both
statisticians and philosophers have argued that an epistemic reading
of classical statistics is possible, and in fact preferable (e.g.,
Fisher 1955, Royall 1997). Accordingly, many have attempted to
reinterpret or develop the theory, in order to align it with the
epistemically oriented statistical practice of scientists (see Mayo
1996, Mayo and Spanos 2011, Spanos 2013b).</p>

<h4><a id="NatEvi">3.2.2 The nature of evidence</a></h4>

<p>Hypothesis tests and estimations are sometimes criticised because
their results generally depend on the probability functions over the
entire sample space, and not exclusively on the probabilities of the
observed sample. That is, the decision to accept or reject the null
hypothesis depends not just on the probability of what has actually
been observed according to the various hypotheses, but also on the
probability assignments over events that could have been observed but
were not. A well-known illustration of this problem concerns so-called
<em>optional stopping</em> (Robbins 1952, Roberts 1967, Kadane et al
1996, Mayo 1996, Howson and Urbach 2006).</p>

<p>Optional stopping is here illustrated for the likelihood ratio test
of Neyman and Pearson but a similar story can be run for Fisher's null
hypothesis test and for the determination of estimators and confidence
intervals. </p>

<!--pdf include
<br/>
pdf include-->

<blockquote><strong>Optional stopping</strong><br /> Imagine two
researchers who are both testing the same lady on her ability to
determine the order in which milk and tea were poured in her cup. They
both entertain the null hypothesis that she is guessing at random,
with a probability of <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1167"><span class="MJXp-mn" id="MJXp-Span-1168">1</span><span class="MJXp-mrow" id="MJXp-Span-1169"><span class="MJXp-mo" id="MJXp-Span-1170" style="margin-left: 0.111em; margin-right: 0.111em;">/</span></span><span class="MJXp-mn" id="MJXp-Span-1171">2</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-172-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-172">1/2</script>, against the alternative of her guessing
correctly with a probability of <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1172"><span class="MJXp-mn" id="MJXp-Span-1173">3</span><span class="MJXp-mrow" id="MJXp-Span-1174"><span class="MJXp-mo" id="MJXp-Span-1175" style="margin-left: 0.111em; margin-right: 0.111em;">/</span></span><span class="MJXp-mn" id="MJXp-Span-1176">4</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-173-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-173">3/4</script>. The more diligent researcher
of the two decides to record six trials. The more impatient, on the
other hand researcher records at most six trials, but decides to stop
recording the first trial that the lady guesses incorrectly. Now
imagine that, in actual fact, the lady guesses all but the last of the
cups correctly. Both researchers then have the exact same data of five
successes and one failure, and the likelihoods for these data are the
same for the two researchers too.  However, while the diligent
researcher cannot reject the null hypothesis, the impatient researcher
can.</blockquote>

<p>This might strike us as peculiar: statistics should tell us the
objective impact that the data have on a hypothesis, but here the
impact seems to depend on the <em>sampling plan</em> of the researcher
and not just on the data themselves. As further explained in 
 <a href="#ExcOptSto">Section 3.2.3</a>, 
the results of the two researchers differ because of
differences in how samples that were not observed are factored into
the procedure. </p>

<p>Some will find this dependence unacceptable: the intentions and
plans of the researcher are irrelevant to the evidential value of the
data. But others argue that it is just right. They maintain that the
impact of data on the hypotheses should depend on the <em>stopping
rule</em> or protocol that is followed in obtaining it, and not only
on the likelihoods that the hypotheses have for those data
(e.g. Mayo 1996). The motivating intuition is that upholding the
irrelevance of the stopping rule makes it impossible to ban
opportunistic choices in data collection. In fact, defenders of
classical statistics turn the table on those who maintain that
optional stopping is irrelevant.  They submit that it opens up the
possibility of reasoning to a foregone conclusion by, for example,
<em>persistent experimentation</em>: we might decide to cease
experimentation only if the preferred result is reached. However, as
shown in Kadane <em>et al</em>. (1996) and further discussed in Steele
(2012), persistent experimentation is not guaranteed to be
effective, as long as we make sure to use the correct, in this case
Bayesian, procedures.</p>

<p>The debate over optional stopping is eventually concerned with the
appropriate evidential impact of data. A central concern in this wider
debate is the so-called <em>likelihood principle</em> (see Hacking
1965 and Edwards 1972). This principle has it that the likelihoods of
hypotheses for the observed data completely fix the evidential impact
of those data on the hypotheses. In the formulation of Berger and
Wolpert (1984), the likelihood principle states that two samples <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1177"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1178">s</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-174-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-174">s</script>
and <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1179"><span class="MJXp-msup" id="MJXp-Span-1180"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1181" style="margin-right: 0.05em;">s</span><span class="MJXp-mo MJXp-script" id="MJXp-Span-1182" style="vertical-align: 0.5em;">′</span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-175-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-175">s'</script> are evidentially equivalent exactly when <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1183"><span class="MJXp-msubsup" id="MJXp-Span-1184"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1185" style="margin-right: 0.05em;">P</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1186" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1187">i</span></span></span><span class="MJXp-mo" id="MJXp-Span-1188" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1189">s</span><span class="MJXp-mo" id="MJXp-Span-1190" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-1191" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1192">k</span><span class="MJXp-msubsup" id="MJXp-Span-1193"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1194" style="margin-right: 0.05em;">P</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1195" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1196">i</span></span></span><span class="MJXp-mo" id="MJXp-Span-1197" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msup" id="MJXp-Span-1198"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1199" style="margin-right: 0.05em;">s</span><span class="MJXp-mo MJXp-script" id="MJXp-Span-1200" style="vertical-align: 0.5em;">′</span></span><span class="MJXp-mo" id="MJXp-Span-1201" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-176-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-176">P_{i}(s) =
kP_{i}(s')</script> for all hypotheses <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1202"><span class="MJXp-msubsup" id="MJXp-Span-1203"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1204" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1205" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1206">i</span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-177-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-177">h_{i}</script> under consideration, given
some constant <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1207"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1208">k</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-178-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-178">k</script>. Famously, Birnbaum (1962) offers a proof of the
principle from more basic assumptions. This proof relies on the
assumption of <em>conditionality</em>.  Say that we first toss a coin,
find that it lands heads, then do the experiment associated with this
outcome, to record the sample <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1209"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1210">s</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-179-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-179">s</script>. Compare this to the case where we
do the experiment and find <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1211"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1212">s</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-180-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-180">s</script> directly, without randomly picking
it. The conditionality principle states that this second sample has
the same evidential impact as the first one: what we could have found,
but did not find, has no impact on the evidential value of the
sample. Recently, Mayo (2010) has taken issue with Birnbaum's
derivation of the likelihood principle.</p>

<p>The classical view sketched above entails a violation of this: the
impact of the observed data may be different depending on the
probability of other samples than the observed one, because those
other samples come into play when determining regions of acceptance
and rejection. The Bayesian procedures discussed in 
 <a href="#BaySta">Section 4</a>,
on the other hand, uphold the likelihood principle: in determining the
posterior distribution over hypotheses only the prior and the
likelihood of the observed data matter. In the debate over optional
stopping and in many of the other debates between classical and
Bayesian statistics, the likelihood principle is the focal point.</p>

<h4><a id="ExcOptSto">3.2.3 Excursion: optional stopping</a></h4>

<p>The view that the data reveal more, or something else,
than what is expressed by the likelihoods of the hypotheses at
issue merits detailed attention. Here we investigate this issue
further with reference to the controversy over optional stopping.</p>

<p>Let us consider the analyses of the two above researchers in some
numerical detail by constructing the regions of rejection for both of
them.</p>

<blockquote>
<p><strong>Determining regions of rejection</strong><br />
The <em>diligent</em> researcher considers all 6-tuples of success and
failure as the sample space, and takes their numbers as sufficient
statistic. The event of six successes, or six correct guesses, has a
probability of <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1213"><span class="MJXp-mn" id="MJXp-Span-1214">1</span><span class="MJXp-mrow" id="MJXp-Span-1215"><span class="MJXp-mo" id="MJXp-Span-1216" style="margin-left: 0.111em; margin-right: 0.111em;">/</span></span><span class="MJXp-msubsup" id="MJXp-Span-1217"><span class="MJXp-mn" id="MJXp-Span-1218" style="margin-right: 0.05em;">2</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1219" style="vertical-align: 0.5em;"><span class="MJXp-mn" id="MJXp-Span-1220">6</span></span></span><span class="MJXp-mo" id="MJXp-Span-1221" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mn" id="MJXp-Span-1222">1</span><span class="MJXp-mrow" id="MJXp-Span-1223"><span class="MJXp-mo" id="MJXp-Span-1224" style="margin-left: 0.111em; margin-right: 0.111em;">/</span></span><span class="MJXp-mn" id="MJXp-Span-1225">64</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-181-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-181">1 / 2^{6} = 1/64</script> under the null hypothesis that the
lady is merely guessing, against a probability of <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1226"><span class="MJXp-msubsup" id="MJXp-Span-1227"><span class="MJXp-mn" id="MJXp-Span-1228" style="margin-right: 0.05em;">3</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1229" style="vertical-align: 0.5em;"><span class="MJXp-mn" id="MJXp-Span-1230">6</span></span></span><span class="MJXp-mrow" id="MJXp-Span-1231"><span class="MJXp-mo" id="MJXp-Span-1232" style="margin-left: 0.111em; margin-right: 0.111em;">/</span></span><span class="MJXp-msubsup" id="MJXp-Span-1233"><span class="MJXp-mn" id="MJXp-Span-1234" style="margin-right: 0.05em;">4</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1235" style="vertical-align: 0.5em;"><span class="MJXp-mn" id="MJXp-Span-1236">6</span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-182-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-182">3^{6} / 4^{6}</script>
under the alternative hypothesis. If we set <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1237"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1238">r</span><span class="MJXp-mo" id="MJXp-Span-1239" style="margin-left: 0.333em; margin-right: 0.333em;">&lt;</span><span class="MJXp-msubsup" id="MJXp-Span-1240"><span class="MJXp-mn" id="MJXp-Span-1241" style="margin-right: 0.05em;">3</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1242" style="vertical-align: 0.5em;"><span class="MJXp-mn" id="MJXp-Span-1243">6</span></span></span><span class="MJXp-mrow" id="MJXp-Span-1244"><span class="MJXp-mo" id="MJXp-Span-1245" style="margin-left: 0.111em; margin-right: 0.111em;">/</span></span><span class="MJXp-msubsup" id="MJXp-Span-1246"><span class="MJXp-mn" id="MJXp-Span-1247" style="margin-right: 0.05em;">2</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1248" style="vertical-align: 0.5em;"><span class="MJXp-mn" id="MJXp-Span-1249">6</span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-183-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-183">r &lt; 3^{6} / 2^{6}</script>,
then this sample is included in the region of rejection of the null
hypothesis. Samples with five successes have a probability of <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1250"><span class="MJXp-mn" id="MJXp-Span-1251">1</span><span class="MJXp-mrow" id="MJXp-Span-1252"><span class="MJXp-mo" id="MJXp-Span-1253" style="margin-left: 0.111em; margin-right: 0.111em;">/</span></span><span class="MJXp-mn" id="MJXp-Span-1254">64</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-184-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-184">1/64</script>
under the null hypothesis too, against a probability of <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1255"><span class="MJXp-msubsup" id="MJXp-Span-1256"><span class="MJXp-mn" id="MJXp-Span-1257" style="margin-right: 0.05em;">3</span><span class="MJXp-mn MJXp-script" id="MJXp-Span-1258" style="vertical-align: 0.5em;">5</span></span><span class="MJXp-mrow" id="MJXp-Span-1259"><span class="MJXp-mo" id="MJXp-Span-1260" style="margin-left: 0.111em; margin-right: 0.111em;">/</span></span><span class="MJXp-msubsup" id="MJXp-Span-1261"><span class="MJXp-mn" id="MJXp-Span-1262" style="margin-right: 0.05em;">4</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1263" style="vertical-align: 0.5em;"><span class="MJXp-mn" id="MJXp-Span-1264">6</span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-185-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-185">3^5 /
4^{6}</script> under the alternative. By lowering the likelihood ratio by a
factor 3, we include all these samples in the region of rejection. But
this will lead to a total probability of false rejection of <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1265"><span class="MJXp-mn" id="MJXp-Span-1266">7</span><span class="MJXp-mrow" id="MJXp-Span-1267"><span class="MJXp-mo" id="MJXp-Span-1268" style="margin-left: 0.111em; margin-right: 0.111em;">/</span></span><span class="MJXp-mn" id="MJXp-Span-1269">64</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-186-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-186">7/64</script>,
which is larger than 5%. So these samples cannot be included in the
region of rejection, and hence the diligent researcher does not reject
the null hypothesis upon finding five successes and one failure.</p>

<p>
For the <em>impatient</em> researcher, on the other hand, the sample
space is much smaller. Apart from the sample consisting of six
successes, all samples consist of a series of successes ending with a
failure, differing only in the length of the series. Yet the
probabilities over the two samples of length six are the same as for
the diligent researcher. As before, the sample of six successes is
again included in the region of rejection. Similarly, the sequence of
five successes followed by one failure also has a probability of
<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1270"><span class="MJXp-mn" id="MJXp-Span-1271">1</span><span class="MJXp-mrow" id="MJXp-Span-1272"><span class="MJXp-mo" id="MJXp-Span-1273" style="margin-left: 0.111em; margin-right: 0.111em;">/</span></span><span class="MJXp-mn" id="MJXp-Span-1274">64</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-187-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-187">1/64</script> under the null hypothesis, against a probability of <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1275"><span class="MJXp-msubsup" id="MJXp-Span-1276"><span class="MJXp-mn" id="MJXp-Span-1277" style="margin-right: 0.05em;">3</span><span class="MJXp-mn MJXp-script" id="MJXp-Span-1278" style="vertical-align: 0.5em;">5</span></span><span class="MJXp-mrow" id="MJXp-Span-1279"><span class="MJXp-mo" id="MJXp-Span-1280" style="margin-left: 0.111em; margin-right: 0.111em;">/</span></span><span class="MJXp-msubsup" id="MJXp-Span-1281"><span class="MJXp-mn" id="MJXp-Span-1282" style="margin-right: 0.05em;">4</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1283" style="vertical-align: 0.5em;"><span class="MJXp-mn" id="MJXp-Span-1284">6</span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-188-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-188">3^5 /
4^{6}</script> according to the alternative. The difference is that lowering
the likelihood ratio to include this sample in the region of rejection
leads to the inclusion of this sample only. And if we include it in
the region of rejection, the probability of false rejection becomes
<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1285"><span class="MJXp-mn" id="MJXp-Span-1286">1</span><span class="MJXp-mrow" id="MJXp-Span-1287"><span class="MJXp-mo" id="MJXp-Span-1288" style="margin-left: 0.111em; margin-right: 0.111em;">/</span></span><span class="MJXp-mn" id="MJXp-Span-1289">32</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-189-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-189">1/32</script> and hence does not exceed 5%. Consequently, on the basis of
these data the laid-back researcher can reject the null hypothesis
that the lady is merely guessing.</p>

</blockquote>

<p>It is instructive to consider why exactly the impatient researcher
can reject the null hypothesis. In virtue of his sampling plan, the
other samples with five successes, namely the ones which kept the
diligent researcher from including the observed sample in the region
of rejection on pain of exceeding the error probability, could not
have been observed. This exemplifies that the results of a classical
statistical procedure do not only depend on the likelihoods for the
actual data, which are indeed the same for both researchers. They also
depend on the likelihoods for data that we did not obtain. </p>

<p>In the above example, it may be considered confusing that the
protocol used for optional stopping depends on the data that is being
recorded. But the controversy over optional stopping also emerges if
this dependence is absent. For example, imagine a third researcher who
samples until the diligent researcher is done, or before that if she
starts to feel peckish.  Furthermore we may suppose that with each new
cup offered to the lady, the probability of feeling peckish is
<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1290"><span class="MJXp-mfrac" id="MJXp-Span-1291" style="vertical-align: 0.25em;"><span class="MJXp-box MJXp-script"><span class="MJXp-mn" id="MJXp-Span-1292">1</span></span><span class="MJXp-box" style="margin-top: -0.9em;"><span class="MJXp-denom"><span><span class="MJXp-rule" style="height: 1em; border-top: none; border-bottom: 1px solid; margin: 0.1em 0px;"></span></span><span><span class="MJXp-box MJXp-script"><span class="MJXp-mn" id="MJXp-Span-1293">2</span></span></span></span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-190-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-190">\frac{1}{2}</script>. This peckish researcher will also be able to reject
the null hypothesis if she completes the series of six cups. And it
certainly seems at variance with the objectivity of the statistical
procedure that this rejection depends on the physiology and the state
of mind of the researcher: if she had not kept open the possibility of
a snack break, she would not have rejected the null hypothesis, even
though she did not actually take that break. As Jeffrey famously
quipped, this is indeed a “remarkable procedure”.</p>

<p>Yet the case is not as clear-cut as it may seem. For one, the
peckish researcher is arguably testing two hypotheses in tandem, one
about the ability of the tea tasting lady and another about her own
peckishness. Together the combined hypotheses have a different
likelihood for the actual sample than the simple hypothesis considered
by the diligent researcher. The likelihood principle given above
dictates that this difference does not affect the evidential impact of
the actual sample, but some retain the intuition that it
should. Moreover, in some cases this intuition is shared by those who
uphold the likelihood principle, namely when the stopping rule depends
on the process being recorded in a way not already expressed by the
hypotheses at issue (cf. Robbins 1952, Howson and Urbach 2006,
p. 365). In terms of our example, if the lady is merely guessing, then
it may be more probable that the researcher gets peckish out of sheer
boredom, than if the lady performs far below or above chance level. In
such a case the act of stopping itself reveals something about the
hypotheses at issue, and this should be reflected in the likelihoods
of the hypotheses. This would make the evidential impact that the data
have on the hypothesis dependent on the stopping rule after all.</p>

<h3><a id="ClaStaResCri">3.3 Responses to criticism</a></h3>

<p>There have been numerous responses to the above criticisms. Some of
those responses effectively reinterpret the classical statistical
procedures as pertaining only to the evidential impact of data. Other
responses develop the classical statistical theory to accommodate
the problems. Their common core is that they establish or at least
clarify the connection between two conceptual realms: the
statistical procedures refer to physical probabilities, while their
results pertain to evidence and support, and even to the rejection or
acceptance of hypotheses.</p>

<h4><a id="StrEvi">3.3.1 The strength of evidence</a></h4>

<p>Classical statistics is often presented as providing us with
advice for actions. The error probabilities do not tell us what
epistemic attitude to take on the basis of statistical procedures,
rather they indicate the long-run frequency of error if we live by
them. Specifically Neyman advocated this interpretation of classical
procedures. Against this, Fisher (1935a, 1955), Pearson, and
other classical statisticians have argued for more epistemic
interpretations, and many more recent authors have followed suit.</p>

<p>Central to the above discussion on classical statistics is the
concept of likelihood, which reflects how the data bears on the
hypotheses at issue. In the works of Hacking (1965), Edwards (1972),
and more recently Royall (1997), the likelihoods are taken as a
cornerstone for statistical procedures and given an epistemic
interpretation. They are said to express the strength of the evidence
presented by the data, or the comparative degree of support that the
data give to a hypothesis. Hacking formulates this idea in the
so-called <em>law of likelihood</em> (1965, p. 59): if the sample
<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1294"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1295">s</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-191-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-191">s</script> is more probable on the condition of <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1296"><span class="MJXp-msubsup" id="MJXp-Span-1297"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1298" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1299" style="vertical-align: -0.4em;"><span class="MJXp-mn" id="MJXp-Span-1300">0</span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-192-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-192">h_{0}</script> than on
<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1301"><span class="MJXp-msubsup" id="MJXp-Span-1302"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1303" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1304" style="vertical-align: -0.4em;"><span class="MJXp-mn" id="MJXp-Span-1305">1</span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-193-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-193">h_{1}</script>, then <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1306"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1307">s</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-194-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-194">s</script> supports <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1308"><span class="MJXp-msubsup" id="MJXp-Span-1309"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1310" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1311" style="vertical-align: -0.4em;"><span class="MJXp-mn" id="MJXp-Span-1312">0</span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-195-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-195">h_{0}</script> more than it supports
<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1313"><span class="MJXp-msubsup" id="MJXp-Span-1314"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1315" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1316" style="vertical-align: -0.4em;"><span class="MJXp-mn" id="MJXp-Span-1317">1</span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-196-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-196">h_{1}</script>.</p>

<p>The position of likelihoodism is based on a specific combination of
views on probability. On the one hand, it only employs probabilities
over sample space, and avoids putting probabilities over statistical
hypotheses. It thereby avoids the use of probability that cannot be
given a physical interpretation. On the other hand, it does interpret
the probabilities over sample space as components of a support
relation, and thereby as pertaining to the epistemic rather than the
physical realm. Notably, the likelihoodist approach fits well with a
long history in formal approaches to epistemology, in particular with
confirmation theory (see Fitelson 2007), in which the probability
theory is used to spell out confirmation relations between data
and hypotheses. Measures of confirmation invariably take the
likelihoods of hypotheses as input components. They provide a
quantitative expression of the support relations described by the law
of likelihood.</p>

<p>Another epistemic approach to classical statistics is presented by
Mayo (1996) and Mayo and Spanos (2011). Over the past decade or so,
they have done much to push the agenda of classical statistics in the
philosophy of science, which had become dominated by Bayesian
statistics. Countering the original behaviourist tendencies of Neyman,
the <em>error statistical approach</em> advances an epistemic reading
of classical test and estimation procedures. Mayo and Spanos argue
that classical procedures are best understood as inferential: they
license inductive inferences. But they readily admit that the
inferences are defeasible, i.e., they could lead us
astray. Classical procedures are always associated with particular
error probabilities, e.g., the probability of a false rejection or
acceptance, or the probability of an estimator falling within a
certain range. In the theory of Mayo and Spanos, these error
probabilities obtain an epistemic role, because they are taken to
indicate the reliability of the inferences licensed by the
procedures.</p>

<p>The error statistical approach of Mayo and others comprises a
general philosophy of science as well as a particular viewpoint on the
philosophy statistics. We briefly focus on the latter, through a
discussion of the notion of a severe test (cf. Mayo and Spanos 2006).
The claim is that we gain knowledge of experimental effects on the
basis of <em>severely testing</em> hypotheses, which can be
characterized by the significance and power. In Mayo's definition, a
hypothesis passes a severe test on two conditions: the data must agree
with the hypothesis, and the probability must be very low that
the data agree with the alternative hypothesis.  Ignoring potential
controversy over the precise interpretation of “agree” and “low
probability”, we can recognize the criteria of Neyman and Pearson in
these requirements. The test is severe if the significance is low,
since the data must agree with the hypothesis, and the power is high,
since those data must not agree, or else have a low probability of
agreeing, with the alternative. </p>

<h4><a id="TheDev">3.3.2 Theoretical developments </a></h4>

<p>Apart from re-interpretations of the classical statistical
procedures, numerous statisticians and philosophers have developed the
theory of classical statistics further in order to make good on the
epistemic role of its results. We focus on two developments in
particular, to wit, fiducial and evidential probability. </p>

<p>The theory of <em>evidential probability</em> originates in Kyburg
(1961), who developed a logical system to deal consistently with the
results of classical statistical analyses.  Evidential probability
thus falls within the attempts to establish the epistemic use of
classical statistics. Haenni et al (2010) and Kyburg and Teng (2001)
present an insightful introduction to evidential probability.  The
system is based on a version default reasoning: statistical hypotheses
come attached with a confidence level, and the logical system
organizes how such confidence levels are propagated in inference, and
thus advises which hypothesis to use for predictions and
decisions. Particular attention is devoted to the propagation of
confidence levels in inferences that involve multiple instances of the
same hypothesis tagged with different confidences, where those
confidences result from diverse data sets that are each associated
with a particular population. Evidential probability assists in
selecting the optimal confidence level, and thus in choosing
the appropriate population for the case under consideration. In
other words, evidential probability helps to resolve the reference
class problem alluded in the foregoing.</p>

<p>Fiducial probability presents another way in which classical
statistics can be given an epistemic status. Fisher (1930, 1933,
1935c, 1956/1973) developed the notion of <em>fiducial
probability</em> as a way of deriving a probability assignment over
hypotheses without assuming a prior probability over statistical
hypotheses at the outset. The fiducial argument is controversial, and
it is generally agreed that its applicability is limited to particular
statistical problems. Dempster (1964), Hacking (1965), Edwards (1972),
Seidenfeld (1996) and Zabell (1996) provide insightful
discussions. Seidenfeld (1979) presents a particularly detailed study
and a further discussion of the restricted applicability of the
argument in cases with multiple parameters. Dawid and Stone (1982)
argue that in order to run the fiducial argument, one has to assume
that the statistical problem can be captured in a functional model
that is smoothly invertible. Dempster (1966) provides generalizations
of this idea for cases in which the distribution over <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1318"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1319">θ</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-197-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-197">\theta</script> is
not fixed uniquely but only constrained within upper and lower bounds
(cf. Haenni et al 2011). Crucially, such constraints on the
probability distribution over values of <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1320"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1321">θ</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-198-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-198">\theta</script> are obtained
without assuming any distribution over <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1322"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1323">θ</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-199-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-199">\theta</script> at the outset.</p>

<h4><a id="ExcFidArg">3.3.3 Excursion: the fiducial argument</a></h4>

<p>To explain the <em>fiducial argument</em> we first set up a simple
example.  Say that we estimate the mean <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1324"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1325">θ</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-200-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-200">\theta</script> of a normal
distribution with unit variance over a variable <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1326"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1327">X</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-201-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-201">X</script>. We collect a
sample <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1328"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1329">s</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-202-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-202">s</script> consisting of measurements <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1330"><span class="MJXp-msubsup" id="MJXp-Span-1331"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1332" style="margin-right: 0.05em;">X</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1333" style="vertical-align: -0.4em;"><span class="MJXp-mn" id="MJXp-Span-1334">1</span></span></span><span class="MJXp-mo" id="MJXp-Span-1335" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-msubsup" id="MJXp-Span-1336"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1337" style="margin-right: 0.05em;">X</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1338" style="vertical-align: -0.4em;"><span class="MJXp-mn" id="MJXp-Span-1339">2</span></span></span><span class="MJXp-mo" id="MJXp-Span-1340" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mo" id="MJXp-Span-1341" style="margin-left: 0em; margin-right: 0em;">…</span><span class="MJXp-msubsup" id="MJXp-Span-1342"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1343" style="margin-right: 0.05em;">X</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1344" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1345">n</span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-203-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-203">X_{1}, X_{2}, \ldots
X_{n}</script>. The maximum likelihood estimator for <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1346"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1347">θ</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-204-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-204">\theta</script> is the
average value of the <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1348"><span class="MJXp-msubsup" id="MJXp-Span-1349"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1350" style="margin-right: 0.05em;">X</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1351" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1352">i</span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-205-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-205">X_{i}</script>, that is, <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1353"><span class="MJXp-mrow" id="MJXp-Span-1354"><span class="MJXp-munderover" id="MJXp-Span-1355"><span><span class="MJXp-over"><span class="" style="margin-bottom: -0.92em;"><span class="MJXp-mo" id="MJXp-Span-1357" style="margin-left: 0px; margin-right: 0px;">ˆ</span></span><span class=""><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1356">θ</span></span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-1358" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1359">s</span><span class="MJXp-mo" id="MJXp-Span-1360" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-1361" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-msubsup" id="MJXp-Span-1362"><span class="MJXp-mo" id="MJXp-Span-1363" style="margin-left: 0.111em; margin-right: 0.05em;">∑</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1364" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1365">i</span></span></span><span class="MJXp-msubsup" id="MJXp-Span-1366"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1367" style="margin-right: 0.05em;">X</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1368" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1369">i</span></span></span><span class="MJXp-mrow" id="MJXp-Span-1370"><span class="MJXp-mo" id="MJXp-Span-1371" style="margin-left: 0.111em; margin-right: 0.111em;">/</span></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1372">n</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-206-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-206">\hat{\theta}(s) = \sum_{i}
X_{i} / n</script>.  Under an assumed true value <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1373"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1374">θ</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-207-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-207">\theta</script> we then have a
normal distribution for the estimator <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1375"><span class="MJXp-mrow" id="MJXp-Span-1376"><span class="MJXp-munderover" id="MJXp-Span-1377"><span><span class="MJXp-over"><span class="" style="margin-bottom: -0.92em;"><span class="MJXp-mo" id="MJXp-Span-1379" style="margin-left: 0px; margin-right: 0px;">ˆ</span></span><span class=""><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1378">θ</span></span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-1380" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1381">s</span><span class="MJXp-mo" id="MJXp-Span-1382" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-208-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-208">\hat{\theta}(s)</script>, centred on
the true value and with a variance <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1383"><span class="MJXp-mn" id="MJXp-Span-1384">1</span><span class="MJXp-mrow" id="MJXp-Span-1385"><span class="MJXp-mo" id="MJXp-Span-1386" style="margin-left: 0.111em; margin-right: 0.111em;">/</span></span><span class="MJXp-msqrt" id="MJXp-Span-1387"><span class="MJXp-surd"><span style="font-size: 134%; margin-top: 0.104em;">√</span></span><span class="MJXp-root"><span class="MJXp-rule" style="border-top: 0.08em solid;"></span><span class="MJXp-box"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1388">n</span></span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-209-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-209">1 / \sqrt{n}</script>. Notably, this
distribution has the same shape for all values of <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1389"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1390">θ</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-210-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-210">\theta</script>. Because
of this, argued Fisher, we can use the distribution over the estimator
<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1391"><span class="MJXp-mrow" id="MJXp-Span-1392"><span class="MJXp-munderover" id="MJXp-Span-1393"><span><span class="MJXp-over"><span class="" style="margin-bottom: -0.92em;"><span class="MJXp-mo" id="MJXp-Span-1395" style="margin-left: 0px; margin-right: 0px;">ˆ</span></span><span class=""><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1394">θ</span></span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-1396" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1397">s</span><span class="MJXp-mo" id="MJXp-Span-1398" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-211-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-211">\hat{\theta}(s)</script> as a stand-in for the distribution over the true
value <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1399"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1400">θ</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-212-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-212">\theta</script>. We thus derive a probability distribution
<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1401"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1402">P</span><span class="MJXp-mo" id="MJXp-Span-1403" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1404">θ</span><span class="MJXp-mo" id="MJXp-Span-1405" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-213-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-213">P(\theta)</script> on the basis of a sample <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1406"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1407">s</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-214-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-214">s</script>, seemingly without
assuming a prior probability.</p>

<p>There are several ways to clarify this so-called fiducial argument.
One way employs a so-called <em>functional model</em>, i.e., the
specification of a statistical model by means of a particular
function. For the above model, the function is

<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-1408"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1409">f</span><span class="MJXp-mo" id="MJXp-Span-1410" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1411">θ</span><span class="MJXp-mo" id="MJXp-Span-1412" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1413">ϵ</span><span class="MJXp-mo" id="MJXp-Span-1414" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-1415" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1416">θ</span><span class="MJXp-mo" id="MJXp-Span-1417" style="margin-left: 0.267em; margin-right: 0.267em;">+</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1418">ϵ</span><span class="MJXp-mo" id="MJXp-Span-1419" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mrow" id="MJXp-Span-1420"><span class="MJXp-munderover" id="MJXp-Span-1421"><span><span class="MJXp-over"><span class="" style="margin-bottom: -0.92em;"><span class="MJXp-mo" id="MJXp-Span-1423" style="margin-left: 0px; margin-right: 0px;">ˆ</span></span><span class=""><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1422">θ</span></span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-1424" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1425">s</span><span class="MJXp-mo" id="MJXp-Span-1426" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-1427" style="margin-left: 0em; margin-right: 0.222em;">.</span></span></span><div class="MathJax_Display MathJax_Processing"><span class="MathJax" id="MathJax-Element-215-Frame" tabindex="0"></span></div><script type="math/tex; mode=display" id="MathJax-Element-215"> f(\theta, \epsilon) = \theta + \epsilon = \hat{\theta}(s) . </script>

It relates possible parameter values <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1428"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1429">θ</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-216-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-216">\theta</script> to a quantity based on
the sample, in this case the estimator of the observations
<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1430"><span class="MJXp-mrow" id="MJXp-Span-1431"><span class="MJXp-munderover" id="MJXp-Span-1432"><span><span class="MJXp-over"><span class="" style="margin-bottom: -0.92em;"><span class="MJXp-mo" id="MJXp-Span-1434" style="margin-left: 0px; margin-right: 0px;">ˆ</span></span><span class=""><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1433">θ</span></span></span></span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-217-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-217">\hat{\theta}</script>. The two are related through a stochastic component
<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1435"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1436">ϵ</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-218-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-218">\epsilon</script> whose distribution is known, and the same for all the
samples under consideration. In our case <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1437"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1438">ϵ</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-219-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-219">\epsilon</script> is distributed
normally with variance <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1439"><span class="MJXp-mn" id="MJXp-Span-1440">1</span><span class="MJXp-mrow" id="MJXp-Span-1441"><span class="MJXp-mo" id="MJXp-Span-1442" style="margin-left: 0.111em; margin-right: 0.111em;">/</span></span><span class="MJXp-msqrt" id="MJXp-Span-1443"><span class="MJXp-surd"><span style="font-size: 134%; margin-top: 0.104em;">√</span></span><span class="MJXp-root"><span class="MJXp-rule" style="border-top: 0.08em solid;"></span><span class="MJXp-box"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1444">n</span></span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-220-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-220">1 / \sqrt{n}</script>. Importantly, the distribution
of <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1445"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1446">ϵ</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-221-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-221">\epsilon</script> is the same for every value of <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1447"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1448">θ</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-222-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-222">\theta</script>. The
interpretation of the function <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1449"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1450">f</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-223-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-223">f</script> may now be apparent. Relative to
the choice of a value of <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1451"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1452">θ</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-224-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-224">\theta</script>, which then obtains the role of
the true value <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1453"><span class="MJXp-msubsup" id="MJXp-Span-1454"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1455" style="margin-right: 0.05em;">θ</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1456" style="vertical-align: 0.5em;"><span class="MJXp-mo" id="MJXp-Span-1457">⋆</span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-225-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-225">\theta^{\star}</script>, the distribution over <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1458"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1459">ϵ</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-226-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-226">\epsilon</script>
dictates the distribution over the estimator function
<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1460"><span class="MJXp-mrow" id="MJXp-Span-1461"><span class="MJXp-munderover" id="MJXp-Span-1462"><span><span class="MJXp-over"><span class="" style="margin-bottom: -0.92em;"><span class="MJXp-mo" id="MJXp-Span-1464" style="margin-left: 0px; margin-right: 0px;">ˆ</span></span><span class=""><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1463">θ</span></span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-1465" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1466">s</span><span class="MJXp-mo" id="MJXp-Span-1467" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-227-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-227">\hat{\theta}(s)</script>.</p>

<p>The idea of the fiducial argument can now be expressed succinctly.
It is to project the distribution over the stochastic component back
onto the possible parameter values. The key observation is that the
functional relation <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1468"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1469">f</span><span class="MJXp-mo" id="MJXp-Span-1470" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1471">θ</span><span class="MJXp-mo" id="MJXp-Span-1472" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1473">ϵ</span><span class="MJXp-mo" id="MJXp-Span-1474" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-228-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-228">f(\theta, \epsilon)</script> is smoothly invertible,
i.e., the function

<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-1475"><span class="MJXp-msubsup" id="MJXp-Span-1476"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1477" style="margin-right: 0.05em;">f</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1478" style="vertical-align: 0.5em;"><span class="MJXp-mo" id="MJXp-Span-1479">−</span><span class="MJXp-mn" id="MJXp-Span-1480">1</span></span></span><span class="MJXp-mo" id="MJXp-Span-1481" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mrow" id="MJXp-Span-1482"><span class="MJXp-munderover" id="MJXp-Span-1483"><span><span class="MJXp-over"><span class="" style="margin-bottom: -0.92em;"><span class="MJXp-mo" id="MJXp-Span-1485" style="margin-left: 0px; margin-right: 0px;">ˆ</span></span><span class=""><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1484">θ</span></span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-1486" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1487">s</span><span class="MJXp-mo" id="MJXp-Span-1488" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-1489" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1490">ϵ</span><span class="MJXp-mo" id="MJXp-Span-1491" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-1492" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mrow" id="MJXp-Span-1493"><span class="MJXp-munderover" id="MJXp-Span-1494"><span><span class="MJXp-over"><span class="" style="margin-bottom: -0.92em;"><span class="MJXp-mo" id="MJXp-Span-1496" style="margin-left: 0px; margin-right: 0px;">ˆ</span></span><span class=""><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1495">θ</span></span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-1497" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1498">s</span><span class="MJXp-mo" id="MJXp-Span-1499" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-1500" style="margin-left: 0.267em; margin-right: 0.267em;">−</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1501">ϵ</span><span class="MJXp-mo" id="MJXp-Span-1502" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1503">θ</span></span></span><div class="MathJax_Display MathJax_Processing"><span class="MathJax" id="MathJax-Element-229-Frame" tabindex="0"></span></div><script type="math/tex; mode=display" id="MathJax-Element-229"> f^{-1}(\hat{\theta}(s), \epsilon) = \hat{\theta}(s) - \epsilon =
\theta </script>

points each combination of <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1504"><span class="MJXp-mrow" id="MJXp-Span-1505"><span class="MJXp-munderover" id="MJXp-Span-1506"><span><span class="MJXp-over"><span class="" style="margin-bottom: -0.92em;"><span class="MJXp-mo" id="MJXp-Span-1508" style="margin-left: 0px; margin-right: 0px;">ˆ</span></span><span class=""><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1507">θ</span></span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-1509" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1510">s</span><span class="MJXp-mo" id="MJXp-Span-1511" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-230-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-230">\hat{\theta}(s)</script> and <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1512"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1513">ϵ</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-231-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-231">\epsilon</script> to a
unique parameter value <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1514"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1515">θ</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-232-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-232">\theta</script>. Hence, we can invert the claim of
the previous paragraph: relative to fixing a value for
<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1516"><span class="MJXp-mrow" id="MJXp-Span-1517"><span class="MJXp-munderover" id="MJXp-Span-1518"><span><span class="MJXp-over"><span class="" style="margin-bottom: -0.92em;"><span class="MJXp-mo" id="MJXp-Span-1520" style="margin-left: 0px; margin-right: 0px;">ˆ</span></span><span class=""><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1519">θ</span></span></span></span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-233-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-233">\hat{\theta}</script>, the distribution over <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1521"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1522">ϵ</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-234-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-234">\epsilon</script> fully determines
the distribution over <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1523"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1524">θ</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-235-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-235">\theta</script>. Hence, in virtue of the inverted
functional model, we can transfer the normal distribution over
<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1525"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1526">ϵ</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-236-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-236">\epsilon</script> to the values <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1527"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1528">θ</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-237-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-237">\theta</script> around <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1529"><span class="MJXp-mrow" id="MJXp-Span-1530"><span class="MJXp-munderover" id="MJXp-Span-1531"><span><span class="MJXp-over"><span class="" style="margin-bottom: -0.92em;"><span class="MJXp-mo" id="MJXp-Span-1533" style="margin-left: 0px; margin-right: 0px;">ˆ</span></span><span class=""><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1532">θ</span></span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-1534" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1535">s</span><span class="MJXp-mo" id="MJXp-Span-1536" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-238-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-238">\hat{\theta}(s)</script>. This
yields a so-called fiducial probability distribution over the
parameter <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1537"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1538">θ</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-239-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-239">\theta</script>. The distribution is obtained because,
conditional on the value of the estimator, the parameters and the
stochastic terms become perfectly correlated. A distribution over the
latter is then automatically applicable to the former (cf. Haenni et
al, 52-55 and 119–122). </p>

<p>Another way of explaining the same idea invokes the notion of a
<em>pivotal quantity</em>.  Because of how the above statistical model
is set up, we can construct the pivotal quantity <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1539"><span class="MJXp-mrow" id="MJXp-Span-1540"><span class="MJXp-munderover" id="MJXp-Span-1541"><span><span class="MJXp-over"><span class="" style="margin-bottom: -0.92em;"><span class="MJXp-mo" id="MJXp-Span-1543" style="margin-left: 0px; margin-right: 0px;">ˆ</span></span><span class=""><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1542">θ</span></span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-1544" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1545">s</span><span class="MJXp-mo" id="MJXp-Span-1546" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-1547" style="margin-left: 0.267em; margin-right: 0.267em;">−</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1548">θ</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-240-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-240">\hat{\theta}(s) -
\theta</script>. We know the distribution of this quantity, namely normal and
with the aforementioned variance. Moreover, this distribution is
independent of the sample, and it is such that fixing the sample to
<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1549"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1550">s</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-241-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-241">s</script>, and so fixing the value of <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1551"><span class="MJXp-mrow" id="MJXp-Span-1552"><span class="MJXp-munderover" id="MJXp-Span-1553"><span><span class="MJXp-over"><span class="" style="margin-bottom: -0.92em;"><span class="MJXp-mo" id="MJXp-Span-1555" style="margin-left: 0px; margin-right: 0px;">ˆ</span></span><span class=""><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1554">θ</span></span></span></span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-242-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-242">\hat{\theta}</script>, uniquely
determines a distribution over the parameter values <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1556"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1557">θ</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-243-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-243">\theta</script>. The
fiducial argument thus allows us to construct a probability
distribution over the parameter values on the basis of the observed
sample. The argument can be run whenever we can construct a pivotal
quantity like that or, equivalently, whenever we can express the
statistical model as a functional model.</p>

<p>A warning is in order here. As revealed in many of the above
references, the fiducial argument is highly controversial. The
mathematical results are there, but the proper interpretation of the
results is still up for discussion . In order to properly appreciate
the precise inferential move and its wobbly conceptual basis, it will
be instructive to consider the use of fiducial probability in
interpreting confidence intervals. A proper understanding of this
requires first reading the 
 <a href="#Est">Section 3.1.2</a>.</p>

<p>Recall that confidence intervals, which are standardly taken to
indicate the quality of an estimation, are often interpreted
epistemically. The 95% confidence interval is often misunderstood as
the range of parameter values that includes the true value with 95%
probability, a so-called <em>credal interval</em>:

<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-1558"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1559">P</span><span class="MJXp-mo" id="MJXp-Span-1560" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1561">θ</span><span class="MJXp-mo" id="MJXp-Span-1562" style="margin-left: 0.333em; margin-right: 0.333em;">∈</span><span class="MJXp-mo" id="MJXp-Span-1563" style="margin-left: 0em; margin-right: 0em;">[</span><span class="MJXp-mrow" id="MJXp-Span-1564"><span class="MJXp-munderover" id="MJXp-Span-1565"><span><span class="MJXp-over"><span class="" style="margin-bottom: -0.92em;"><span class="MJXp-mo" id="MJXp-Span-1567" style="margin-left: 0px; margin-right: 0px;">ˆ</span></span><span class=""><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1566">θ</span></span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-1568" style="margin-left: 0.267em; margin-right: 0.267em;">−</span><span class="MJXp-mi" id="MJXp-Span-1569">Δ</span><span class="MJXp-mo" id="MJXp-Span-1570" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mrow" id="MJXp-Span-1571"><span class="MJXp-munderover" id="MJXp-Span-1572"><span><span class="MJXp-over"><span class="" style="margin-bottom: -0.92em;"><span class="MJXp-mo" id="MJXp-Span-1574" style="margin-left: 0px; margin-right: 0px;">ˆ</span></span><span class=""><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1573">θ</span></span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-1575" style="margin-left: 0.267em; margin-right: 0.267em;">+</span><span class="MJXp-mi" id="MJXp-Span-1576">Δ</span><span class="MJXp-mo" id="MJXp-Span-1577" style="margin-left: 0em; margin-right: 0em;">]</span><span class="MJXp-mo" id="MJXp-Span-1578" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-1579" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mn" id="MJXp-Span-1580">0.95</span><span class="MJXp-mo" id="MJXp-Span-1581" style="margin-left: 0em; margin-right: 0.222em;">.</span></span></span><div class="MathJax_Display MathJax_Processing"><span class="MathJax" id="MathJax-Element-244-Frame" tabindex="0"></span></div><script type="math/tex; mode=display" id="MathJax-Element-244"> P(\theta \in [\hat{\theta} - \Delta, \hat{\theta} + \Delta]) = 0.95
. </script>

This interpretation is at odds with classical statistics but, as will
become apparent, it can be motivated by an application of the fiducial
argument. Say that we replace the integral determining the size
<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1582"><span class="MJXp-mi" id="MJXp-Span-1583">Δ</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-245-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-245">\Delta</script> of the confidence interval by the following:

<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-1584"><span class="MJXp-msubsup" id="MJXp-Span-1585"><span class="MJXp-mo" id="MJXp-Span-1586" style="margin-left: 0em; margin-right: 0.05em;"><span class="MJXp-largeop MJXp-int">∫</span></span><span class="MJXp-script-box" style="height: 2.279em; vertical-align: -0.7em;"><span class=" MJXp-script"><span><span style="margin-bottom: -0.25em;"><span class="MJXp-mrow" id="MJXp-Span-1597"><span class="MJXp-mrow" id="MJXp-Span-1598"><span class="MJXp-munderover" id="MJXp-Span-1599"><span><span class="MJXp-over"><span class=" MJXp-script" style="margin-bottom: -0.92em;"><span class="MJXp-mo" id="MJXp-Span-1601" style="margin-right: 0px; margin-left: 0px;">ˆ</span></span><span class=""><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1600">θ</span></span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-1602">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1603">s</span><span class="MJXp-mo" id="MJXp-Span-1604">)</span><span class="MJXp-mo" id="MJXp-Span-1605">+</span><span class="MJXp-mi" id="MJXp-Span-1606">Δ</span></span></span></span></span><span class=" MJXp-script"><span><span style="margin-top: -1.074em;"><span class="MJXp-mrow" id="MJXp-Span-1587"><span class="MJXp-mrow" id="MJXp-Span-1588"><span class="MJXp-munderover" id="MJXp-Span-1589"><span><span class="MJXp-over"><span class=" MJXp-script" style="margin-bottom: -0.92em;"><span class="MJXp-mo" id="MJXp-Span-1591" style="margin-right: 0px; margin-left: 0px;">ˆ</span></span><span class=""><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1590">θ</span></span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-1592">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1593">s</span><span class="MJXp-mo" id="MJXp-Span-1594">)</span><span class="MJXp-mo" id="MJXp-Span-1595">−</span><span class="MJXp-mi" id="MJXp-Span-1596">Δ</span></span></span></span></span></span></span><span class="MJXp-msubsup" id="MJXp-Span-1607"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1608" style="margin-right: 0.05em;">P</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1609" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1610">θ</span></span></span><span class="MJXp-mo" id="MJXp-Span-1611" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-1612"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1613" style="margin-right: 0.05em;">R</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1614" style="vertical-align: -0.4em;"><span class="MJXp-mrow" id="MJXp-Span-1615"><span class="MJXp-munderover" id="MJXp-Span-1616"><span><span class="MJXp-over"><span class=" MJXp-script" style="margin-bottom: -0.92em;"><span class="MJXp-mo" id="MJXp-Span-1618" style="margin-right: 0px; margin-left: 0px;">ˆ</span></span><span class=""><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1617">θ</span></span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-1619">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1620">s</span><span class="MJXp-mo" id="MJXp-Span-1621">)</span></span></span><span class="MJXp-mo" id="MJXp-Span-1622" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1623">d</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1624">θ</span><span class="MJXp-mo" id="MJXp-Span-1625" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mn" id="MJXp-Span-1626">0.95</span><span class="MJXp-mo" id="MJXp-Span-1627" style="margin-left: 0em; margin-right: 0.222em;">.</span></span></span><div class="MathJax_Display MathJax_Processing"><span class="MathJax" id="MathJax-Element-246-Frame" tabindex="0"></span></div><script type="math/tex; mode=display" id="MathJax-Element-246"> \int_{\hat{\theta}(s) - \Delta}^{\hat{\theta}(s) + \Delta}
P_{\theta}(R_{\hat{\theta}(s)}) d\theta = 0.95 .</script>

In words, we fix the estimator <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1628"><span class="MJXp-mrow" id="MJXp-Span-1629"><span class="MJXp-munderover" id="MJXp-Span-1630"><span><span class="MJXp-over"><span class="" style="margin-bottom: -0.92em;"><span class="MJXp-mo" id="MJXp-Span-1632" style="margin-left: 0px; margin-right: 0px;">ˆ</span></span><span class=""><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1631">θ</span></span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-1633" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1634">s</span><span class="MJXp-mo" id="MJXp-Span-1635" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-247-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-247">\hat{\theta}(s)</script> and then integrate
over the parameters <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1636"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1637">θ</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-248-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-248">\theta</script> in <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1638"><span class="MJXp-msubsup" id="MJXp-Span-1639"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1640" style="margin-right: 0.05em;">P</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1641" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1642">θ</span></span></span><span class="MJXp-mo" id="MJXp-Span-1643" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-1644"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1645" style="margin-right: 0.05em;">R</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1646" style="vertical-align: -0.4em;"><span class="MJXp-mrow" id="MJXp-Span-1647"><span class="MJXp-munderover" id="MJXp-Span-1648"><span><span class="MJXp-over"><span class=" MJXp-script" style="margin-bottom: -0.92em;"><span class="MJXp-mo" id="MJXp-Span-1650" style="margin-right: 0px; margin-left: 0px;">ˆ</span></span><span class=""><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1649">θ</span></span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-1651">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1652">s</span><span class="MJXp-mo" id="MJXp-Span-1653">)</span></span></span><span class="MJXp-mo" id="MJXp-Span-1654" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-249-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-249">P_{\theta}(R_{\hat{\theta}(s)})</script>,
rather than assuming <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1655"><span class="MJXp-msubsup" id="MJXp-Span-1656"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1657" style="margin-right: 0.05em;">θ</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1658" style="vertical-align: 0.5em;"><span class="MJXp-mo" id="MJXp-Span-1659">⋆</span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-250-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-250">\theta^{\star}</script> and then integrating over the
parameters <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1660"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1661">τ</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-251-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-251">\tau</script> in <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1662"><span class="MJXp-msubsup" id="MJXp-Span-1663"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1664" style="margin-right: 0.05em;">R</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1665" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1666">τ</span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-252-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-252">R_{\tau}</script>. Sure enough we can calculate this
integral. But what ensures that we can treat the integral as a
probability? Notice that it runs over a continuum of probability
distributions and that, as it stands, there is no reason to think that
the terms <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1667"><span class="MJXp-msubsup" id="MJXp-Span-1668"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1669" style="margin-right: 0.05em;">P</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1670" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1671">θ</span></span></span><span class="MJXp-mo" id="MJXp-Span-1672" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-1673"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1674" style="margin-right: 0.05em;">R</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1675" style="vertical-align: -0.4em;"><span class="MJXp-mrow" id="MJXp-Span-1676"><span class="MJXp-munderover" id="MJXp-Span-1677"><span><span class="MJXp-over"><span class=" MJXp-script" style="margin-bottom: -0.92em;"><span class="MJXp-mo" id="MJXp-Span-1679" style="margin-right: 0px; margin-left: 0px;">ˆ</span></span><span class=""><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1678">θ</span></span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-1680">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1681">s</span><span class="MJXp-mo" id="MJXp-Span-1682">)</span></span></span><span class="MJXp-mo" id="MJXp-Span-1683" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-253-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-253">P_{\theta}(R_{\hat{\theta}(s)})</script> add up to a proper
distribution in <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1684"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1685">θ</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-254-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-254">\theta</script>.</p>

<p>The assumptions of the fiducial argument, here explained in terms
of the invertibility of the functional model, ensure that the terms
indeed add up, and that a well-behaved distribution will surface. We
can choose the statistical model in such a way that the sample
statistic <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1686"><span class="MJXp-mrow" id="MJXp-Span-1687"><span class="MJXp-munderover" id="MJXp-Span-1688"><span><span class="MJXp-over"><span class="" style="margin-bottom: -0.92em;"><span class="MJXp-mo" id="MJXp-Span-1690" style="margin-left: 0px; margin-right: 0px;">ˆ</span></span><span class=""><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1689">θ</span></span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-1691" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1692">s</span><span class="MJXp-mo" id="MJXp-Span-1693" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-255-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-255">\hat{\theta}(s)</script> and the parameter <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1694"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1695">θ</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-256-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-256">\theta</script> are related
in the right way: relative to the parameter <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1696"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1697">θ</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-257-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-257">\theta</script>, we have a
distribution over the statistic <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1698"><span class="MJXp-mrow" id="MJXp-Span-1699"><span class="MJXp-munderover" id="MJXp-Span-1700"><span><span class="MJXp-over"><span class="" style="margin-bottom: -0.92em;"><span class="MJXp-mo" id="MJXp-Span-1702" style="margin-left: 0px; margin-right: 0px;">ˆ</span></span><span class=""><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1701">θ</span></span></span></span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-258-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-258">\hat{\theta}</script>, but by the same
token we have a distribution over parameters relative to this
statistic. As a result, the probability function
<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1703"><span class="MJXp-msubsup" id="MJXp-Span-1704"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1705" style="margin-right: 0.05em;">P</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1706" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1707">θ</span></span></span><span class="MJXp-mo" id="MJXp-Span-1708" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-1709"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1710" style="margin-right: 0.05em;">R</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1711" style="vertical-align: -0.4em;"><span class="MJXp-mrow" id="MJXp-Span-1712"><span class="MJXp-munderover" id="MJXp-Span-1713"><span><span class="MJXp-over"><span class=" MJXp-script" style="margin-bottom: -0.92em;"><span class="MJXp-mo" id="MJXp-Span-1715" style="margin-right: 0px; margin-left: 0px;">ˆ</span></span><span class=""><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1714">θ</span></span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-1716">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1717">s</span><span class="MJXp-mo" id="MJXp-Span-1718">)</span><span class="MJXp-mo" id="MJXp-Span-1719">+</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1720">ϵ</span></span></span><span class="MJXp-mo" id="MJXp-Span-1721" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-259-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-259">P_{\theta}(R_{\hat{\theta}(s) + \epsilon})</script> over <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1722"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1723">ϵ</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-260-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-260">\epsilon</script>,
where <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1724"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1725">θ</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-261-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-261">\theta</script> is fixed, can be transferred to a fiducial
probability function <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1726"><span class="MJXp-msubsup" id="MJXp-Span-1727"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1728" style="margin-right: 0.05em;">P</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1729" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1730">θ</span><span class="MJXp-mo" id="MJXp-Span-1731">+</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1732">ϵ</span></span></span><span class="MJXp-mo" id="MJXp-Span-1733" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-1734"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1735" style="margin-right: 0.05em;">R</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1736" style="vertical-align: -0.4em;"><span class="MJXp-mrow" id="MJXp-Span-1737"><span class="MJXp-munderover" id="MJXp-Span-1738"><span><span class="MJXp-over"><span class=" MJXp-script" style="margin-bottom: -0.92em;"><span class="MJXp-mo" id="MJXp-Span-1740" style="margin-right: 0px; margin-left: 0px;">ˆ</span></span><span class=""><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1739">θ</span></span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-1741">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1742">s</span><span class="MJXp-mo" id="MJXp-Span-1743">)</span></span></span><span class="MJXp-mo" id="MJXp-Span-1744" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-262-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-262">P_{\theta + \epsilon}(R_{\hat{\theta}(s)})</script>
over <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1745"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1746">ϵ</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-263-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-263">\epsilon</script>, where <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1747"><span class="MJXp-mrow" id="MJXp-Span-1748"><span class="MJXp-munderover" id="MJXp-Span-1749"><span><span class="MJXp-over"><span class="" style="margin-bottom: -0.92em;"><span class="MJXp-mo" id="MJXp-Span-1751" style="margin-left: 0px; margin-right: 0px;">ˆ</span></span><span class=""><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1750">θ</span></span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-1752" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1753">s</span><span class="MJXp-mo" id="MJXp-Span-1754" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-264-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-264">\hat{\theta}(s)</script> is fixed. The function
<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1755"><span class="MJXp-msubsup" id="MJXp-Span-1756"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1757" style="margin-right: 0.05em;">P</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1758" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1759">θ</span></span></span><span class="MJXp-mo" id="MJXp-Span-1760" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-1761"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1762" style="margin-right: 0.05em;">R</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1763" style="vertical-align: -0.4em;"><span class="MJXp-mrow" id="MJXp-Span-1764"><span class="MJXp-munderover" id="MJXp-Span-1765"><span><span class="MJXp-over"><span class=" MJXp-script" style="margin-bottom: -0.92em;"><span class="MJXp-mo" id="MJXp-Span-1767" style="margin-right: 0px; margin-left: 0px;">ˆ</span></span><span class=""><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1766">θ</span></span></span></span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-1768" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-265-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-265">P_{\theta}(R_{\hat{\theta}})</script> of the parameter <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1769"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1770">θ</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-266-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-266">\theta</script> is thus a
proper probability function, from which a credal interval can be
constructed.</p>

<p>Even then, it is not clear why we should take this distribution as
an appropriate expression of our belief, so that we may support the
epistemic interpretation of confidence intervals with it. And so the
debate continues. In the end fiducial probability is perhaps best
understood as a half-way house between the classical and the Bayesian
view on statistics. Classical statistics grew out of a frequentist
interpretation of probability, and accordingly the probabilities
appearing in the classical statistical methods are all interpreted as
frequencies of events. Clearly, the probability distribution over
hypotheses that is generated by a fiducial argument cannot be
interpreted in this way, so that an epistemic interpretation of this
distribution seems the only option.  Several authors (e.g., Dempster
1964) have noted that fiducial probability indeed makes most sense in
a Bayesian perspective. It is to this perspective that we now turn.
</p>

<h2><a id="BaySta">4. Bayesian statistics</a></h2>

<p>Bayesian statistical methods are often presented in the form of an
inference. The inference runs from a so-called <em>prior</em>
probability distribution over statistical hypotheses, which expresses
the degree of belief in the hypotheses before data has been collected,
to a <em>posterior</em> probability distribution over the
hypotheses, which expresses the beliefs after the data have been
incorporated. The posterior distribution follows, via the axioms of
probability theory, from the prior distribution and the
<em>likelihoods</em> of the hypotheses for the data obtained, i.e.,
the probability that the hypotheses assign to the data. Bayesian
methods thus employ data to modulate our attitude towards
a designated set of statistical hypotheses, and in this respect
they achieve the same as classical statistical procedures. Both types
of statistics present a response to the problem of induction. But
whereas classical procedures select or eliminate elements from the set
of hypotheses, Bayesian methods express the impact of data in a
posterior probability assignment over the set. This posterior is fully
determined by the prior and the likelihoods of the hypotheses, via the
formalism of probability theory.</p>

<p>The defining characteristic of Bayesian statistics is that it
considers probability distributions over statistical hypotheses as
well as over data. It embraces the epistemic interpretation of
probability whole-heartedly: probabilities over hypotheses are
interpreted as degrees of belief, i.e., as expressions of epistemic
uncertainty. The philosophy of Bayesian statistics is concerned
with determining the appropriate interpretation of these input
components, and of the mathematical formalism of probability itself,
ultimately with the aim to justify the output. Notice that the general
pattern of a Bayesian statistical method is that of
<em>inductivism</em> in the cumulative sense: under the impact of
data we move to more and more informed probabilistic opinions about
the hypotheses. However, in the following it will appear that Bayesian
methods may also be understood as deductivist in nature.</p>

<h3><a id="BasPatInf">4.1 Basic pattern of inference</a></h3>

<p>Bayesian inference always starts from a <em>statistical
model</em>, i.e., a set of statistical hypotheses. While the general
pattern of inference is the same, we treat models with a finite number
and a continuum of hypotheses separately and draw parallels with
hypothesis testing and estimation, respectively. The exposition is
mostly based on Press 2002, Howson and Urbach 2006, Gelman et al
2013, and Earman 1992.</p>

<h4><a id="FinMod">4.1.1 Finite model</a></h4>

<p>Central to Bayesian methods is a theorem from probability theory
known as <em>Bayes' theorem</em>.  Relative to a prior probability
distribution over hypotheses, and the probability distributions over
sample space for each hypothesis, it tells us what the adequate
posterior probability over hypotheses is. More precisely, let <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1771"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1772">s</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-267-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-267">s</script> be
the sample and <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1773"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1774">S</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-268-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-268">S</script> be the sample space as before, and let <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1775"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1776">M</span><span class="MJXp-mo" id="MJXp-Span-1777" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mo" id="MJXp-Span-1778" style="margin-left: 0em; margin-right: 0em;">{</span><span class="MJXp-msubsup" id="MJXp-Span-1779"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1780" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1781" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1782">θ</span></span></span><span class="MJXp-mo" id="MJXp-Span-1783" style="margin-left: 0.111em; margin-right: 0.167em;">:</span><span class="MJXp-mspace" id="MJXp-Span-1784" style="width: 0.222em; height: 0em;"></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1785">θ</span><span class="MJXp-mo" id="MJXp-Span-1786" style="margin-left: 0.333em; margin-right: 0.333em;">∈</span><span class="MJXp-mi" id="MJXp-Span-1787">Θ</span><span class="MJXp-mo" id="MJXp-Span-1788" style="margin-left: 0em; margin-right: 0em;">}</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-269-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-269">M = \{
h_{\theta} :\: \theta \in \Theta \}</script> be the space of statistical
hypotheses, with <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1789"><span class="MJXp-mi" id="MJXp-Span-1790">Θ</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-270-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-270">\Theta</script> the space of parameter values. The
function <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1791"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1792">P</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-271-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-271">P</script> is a probability distribution over the entire space <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1793"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1794">M</span><span class="MJXp-mo" id="MJXp-Span-1795" style="margin-left: 0.267em; margin-right: 0.267em;">×</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1796">S</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-272-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-272">M
\times S</script>, meaning that every element <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1797"><span class="MJXp-msubsup" id="MJXp-Span-1798"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1799" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1800" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1801">θ</span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-273-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-273">h_{\theta}</script> is associated
with its own sample space <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1802"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1803">S</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-274-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-274">S</script>, and its own probability distribution
over that space. For the latter, which is fully determined by the
likelihoods of the hypotheses, we write the probability of the sample
conditional on the hypothesis, <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1804"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1805">P</span><span class="MJXp-mo" id="MJXp-Span-1806" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1807">s</span><span class="MJXp-mo" id="MJXp-Span-1808" style="margin-left: 0.333em; margin-right: 0.333em;">∣</span><span class="MJXp-msubsup" id="MJXp-Span-1809"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1810" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1811" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1812">θ</span></span></span><span class="MJXp-mo" id="MJXp-Span-1813" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-275-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-275">P(s \mid h_{\theta})</script>. This differs
from the expression <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1814"><span class="MJXp-msubsup" id="MJXp-Span-1815"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1816" style="margin-right: 0.05em;">P</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1817" style="vertical-align: -0.4em;"><span class="MJXp-msubsup" id="MJXp-Span-1818"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1819" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1820" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1821">θ</span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-1822" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1823">s</span><span class="MJXp-mo" id="MJXp-Span-1824" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-276-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-276">P_{h_{\theta}}(s)</script>, written in the context of
classical statistics, because in contrast to classical statisticians,
Bayesians accept <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1825"><span class="MJXp-msubsup" id="MJXp-Span-1826"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1827" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1828" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1829">θ</span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-277-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-277">h_{\theta}</script> as an argument for the probability
distribution. </p>

<p>Bayesian statistics is first introduced in the context of a finite
set of hypotheses, after which a generalization to the infinite case
is provided. Assume the prior probability <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1830"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1831">P</span><span class="MJXp-mo" id="MJXp-Span-1832" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-1833"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1834" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1835" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1836">θ</span></span></span><span class="MJXp-mo" id="MJXp-Span-1837" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-278-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-278">P(h_{\theta})</script> over the
hypotheses <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1838"><span class="MJXp-msubsup" id="MJXp-Span-1839"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1840" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1841" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1842">θ</span></span></span><span class="MJXp-mo" id="MJXp-Span-1843" style="margin-left: 0.333em; margin-right: 0.333em;">∈</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1844">M</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-279-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-279">h_{\theta} \in M</script>. Further assume the likelihoods <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1845"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1846">P</span><span class="MJXp-mo" id="MJXp-Span-1847" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1848">s</span><span class="MJXp-mo" id="MJXp-Span-1849" style="margin-left: 0.333em; margin-right: 0.333em;">∣</span><span class="MJXp-msubsup" id="MJXp-Span-1850"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1851" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1852" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1853">θ</span></span></span><span class="MJXp-mo" id="MJXp-Span-1854" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-280-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-280">P(s
\mid h_{\theta})</script>, i.e., the probability assigned to the data <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1855"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1856">s</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-281-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-281">s</script>
conditional on the hypotheses <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1857"><span class="MJXp-msubsup" id="MJXp-Span-1858"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1859" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1860" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1861">θ</span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-282-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-282">h_{\theta}</script>. Then Bayes' theorem
determines that

<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-1862"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1863">P</span><span class="MJXp-mo" id="MJXp-Span-1864" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-1865"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1866" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1867" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1868">θ</span></span></span><span class="MJXp-mo" id="MJXp-Span-1869" style="margin-left: 0.333em; margin-right: 0.333em;">∣</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1870">s</span><span class="MJXp-mo" id="MJXp-Span-1871" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mspace" id="MJXp-Span-1872" style="width: 0.278em; height: 0em;"></span><span class="MJXp-mo" id="MJXp-Span-1873" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mspace" id="MJXp-Span-1874" style="width: 0.278em; height: 0em;"></span><span class="MJXp-mfrac" id="MJXp-Span-1875" style="vertical-align: 0.25em;"><span class="MJXp-box"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1876">P</span><span class="MJXp-mo" id="MJXp-Span-1877" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1878">s</span><span class="MJXp-mo" id="MJXp-Span-1879" style="margin-left: 0.333em; margin-right: 0.333em;">∣</span><span class="MJXp-msubsup" id="MJXp-Span-1880"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1881" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1882" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1883">θ</span></span></span><span class="MJXp-mo" id="MJXp-Span-1884" style="margin-left: 0em; margin-right: 0em;">)</span></span><span class="MJXp-box" style="margin-top: -0.9em;"><span class="MJXp-denom"><span><span class="MJXp-rule" style="height: 1em; border-top: none; border-bottom: 1px solid; margin: 0.1em 0px;"></span></span><span><span class="MJXp-box"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1885">P</span><span class="MJXp-mo" id="MJXp-Span-1886" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1887">s</span><span class="MJXp-mo" id="MJXp-Span-1888" style="margin-left: 0em; margin-right: 0em;">)</span></span></span></span></span></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1889">P</span><span class="MJXp-mo" id="MJXp-Span-1890" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-1891"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1892" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1893" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1894">θ</span></span></span><span class="MJXp-mo" id="MJXp-Span-1895" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-1896" style="margin-left: 0em; margin-right: 0.222em;">.</span></span></span><div class="MathJax_Display MathJax_Processing"><span class="MathJax" id="MathJax-Element-283-Frame" tabindex="0"></span></div><script type="math/tex; mode=display" id="MathJax-Element-283"> P(h_{\theta} \mid s) \; = \; \frac{P(s \mid h_{\theta})}{P(s)}
P(h_{\theta}) . </script>

Bayesian statistics outputs the posterior probability assignment,
<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1897"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1898">P</span><span class="MJXp-mo" id="MJXp-Span-1899" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-1900"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1901" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1902" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1903">θ</span></span></span><span class="MJXp-mo" id="MJXp-Span-1904" style="margin-left: 0.333em; margin-right: 0.333em;">∣</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1905">s</span><span class="MJXp-mo" id="MJXp-Span-1906" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-284-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-284">P(h_{\theta} \mid s)</script>. This expression gets the interpretation of
an opinion concerning <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1907"><span class="MJXp-msubsup" id="MJXp-Span-1908"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1909" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1910" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1911">θ</span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-285-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-285">h_{\theta}</script> after the sample <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1912"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1913">s</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-286-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-286">s</script> has been
recorded accommodated, i.e., it is a revised opinion. Further results
from a Bayesian inference can all be derived from the posterior
distribution over the statistical hypotheses. For instance, we can use
the posterior to determine the most probable value for the parameter,
i.e., picking the hypothesis <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1914"><span class="MJXp-msubsup" id="MJXp-Span-1915"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1916" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1917" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1918">θ</span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-287-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-287">h_{\theta}</script> for which <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1919"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1920">P</span><span class="MJXp-mo" id="MJXp-Span-1921" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-1922"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1923" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1924" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1925">θ</span></span></span><span class="MJXp-mo" id="MJXp-Span-1926" style="margin-left: 0.333em; margin-right: 0.333em;">∣</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1927">s</span><span class="MJXp-mo" id="MJXp-Span-1928" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-288-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-288">P(h_{\theta}
\mid s)</script> is maximal.</p>

<p>In this characterization of Bayesian statistical inference the
probability of the data <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1929"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1930">P</span><span class="MJXp-mo" id="MJXp-Span-1931" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1932">s</span><span class="MJXp-mo" id="MJXp-Span-1933" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-289-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-289">P(s)</script> is not presupposed, because it can be
computed from the prior and the likelihoods by the law of total
probability,

<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-1934"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1935">P</span><span class="MJXp-mo" id="MJXp-Span-1936" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1937">s</span><span class="MJXp-mo" id="MJXp-Span-1938" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mspace" id="MJXp-Span-1939" style="width: 0.278em; height: 0em;"></span><span class="MJXp-mo" id="MJXp-Span-1940" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mspace" id="MJXp-Span-1941" style="width: 0.278em; height: 0em;"></span><span class="MJXp-munderover" id="MJXp-Span-1942"><span class=""><span class="MJXp-mo" id="MJXp-Span-1943" style="margin-left: 0.111em; margin-right: 0.167em;"><span class="MJXp-largeop">∑</span></span></span><span class=" MJXp-script"><span class="MJXp-mrow" id="MJXp-Span-1944" style="margin-left: 0px;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1945">θ</span><span class="MJXp-mo" id="MJXp-Span-1946">∈</span><span class="MJXp-mi" id="MJXp-Span-1947">Θ</span></span></span></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1948">P</span><span class="MJXp-mo" id="MJXp-Span-1949" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-1950"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1951" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1952" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1953">θ</span></span></span><span class="MJXp-mo" id="MJXp-Span-1954" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1955">P</span><span class="MJXp-mo" id="MJXp-Span-1956" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1957">s</span><span class="MJXp-mo" id="MJXp-Span-1958" style="margin-left: 0.333em; margin-right: 0.333em;">∣</span><span class="MJXp-msubsup" id="MJXp-Span-1959"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1960" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1961" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1962">θ</span></span></span><span class="MJXp-mo" id="MJXp-Span-1963" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-1964" style="margin-left: 0em; margin-right: 0.222em;">.</span></span></span><div class="MathJax_Display MathJax_Processing"><span class="MathJax" id="MathJax-Element-290-Frame" tabindex="0"></span></div><script type="math/tex; mode=display" id="MathJax-Element-290"> P(s) \; = \; \sum_{\theta \in \Theta} P(h_{\theta}) P(s \mid
h_{\theta}) . </script>

The result of a Bayesian statistical inference is not always reported
as a posterior probability. Often the interest is only in comparing
the ratio of the posteriors of two hypotheses. By Bayes' theorem we
have

<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-1965"><span class="MJXp-mfrac" id="MJXp-Span-1966" style="vertical-align: 0.25em;"><span class="MJXp-box"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1967">P</span><span class="MJXp-mo" id="MJXp-Span-1968" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-1969"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1970" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1971" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1972">θ</span></span></span><span class="MJXp-mo" id="MJXp-Span-1973" style="margin-left: 0.333em; margin-right: 0.333em;">∣</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1974">s</span><span class="MJXp-mo" id="MJXp-Span-1975" style="margin-left: 0em; margin-right: 0em;">)</span></span><span class="MJXp-box" style="margin-top: -0.9em;"><span class="MJXp-denom"><span><span class="MJXp-rule" style="height: 1em; border-top: none; border-bottom: 1px solid; margin: 0.1em 0px;"></span></span><span><span class="MJXp-box"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1976">P</span><span class="MJXp-mo" id="MJXp-Span-1977" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-1978"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1979" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1980" style="vertical-align: -0.4em;"><span class="MJXp-msup" id="MJXp-Span-1981"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1982" style="margin-right: 0.05em;">θ</span><span class="MJXp-mo MJXp-script" id="MJXp-Span-1983" style="vertical-align: 0.5em;">′</span></span></span></span><span class="MJXp-mo" id="MJXp-Span-1984" style="margin-left: 0.333em; margin-right: 0.333em;">∣</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1985">s</span><span class="MJXp-mo" id="MJXp-Span-1986" style="margin-left: 0em; margin-right: 0em;">)</span></span></span></span></span></span><span class="MJXp-mspace" id="MJXp-Span-1987" style="width: 0.278em; height: 0em;"></span><span class="MJXp-mo" id="MJXp-Span-1988" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mspace" id="MJXp-Span-1989" style="width: 0.278em; height: 0em;"></span><span class="MJXp-mfrac" id="MJXp-Span-1990" style="vertical-align: 0.25em;"><span class="MJXp-box"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1991">P</span><span class="MJXp-mo" id="MJXp-Span-1992" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-1993"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1994" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-1995" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1996">θ</span></span></span><span class="MJXp-mo" id="MJXp-Span-1997" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-1998">P</span><span class="MJXp-mo" id="MJXp-Span-1999" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2000">s</span><span class="MJXp-mo" id="MJXp-Span-2001" style="margin-left: 0.333em; margin-right: 0.333em;">∣</span><span class="MJXp-msubsup" id="MJXp-Span-2002"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2003" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2004" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2005">θ</span></span></span><span class="MJXp-mo" id="MJXp-Span-2006" style="margin-left: 0em; margin-right: 0em;">)</span></span><span class="MJXp-box" style="margin-top: -0.9em;"><span class="MJXp-denom"><span><span class="MJXp-rule" style="height: 1em; border-top: none; border-bottom: 1px solid; margin: 0.1em 0px;"></span></span><span><span class="MJXp-box"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2007">P</span><span class="MJXp-mo" id="MJXp-Span-2008" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-2009"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2010" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2011" style="vertical-align: -0.4em;"><span class="MJXp-msup" id="MJXp-Span-2012"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2013" style="margin-right: 0.05em;">θ</span><span class="MJXp-mo MJXp-script" id="MJXp-Span-2014" style="vertical-align: 0.5em;">′</span></span></span></span><span class="MJXp-mo" id="MJXp-Span-2015" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2016">P</span><span class="MJXp-mo" id="MJXp-Span-2017" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2018">s</span><span class="MJXp-mo" id="MJXp-Span-2019" style="margin-left: 0.333em; margin-right: 0.333em;">∣</span><span class="MJXp-msubsup" id="MJXp-Span-2020"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2021" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2022" style="vertical-align: -0.4em;"><span class="MJXp-msup" id="MJXp-Span-2023"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2024" style="margin-right: 0.05em;">θ</span><span class="MJXp-mo MJXp-script" id="MJXp-Span-2025" style="vertical-align: 0.5em;">′</span></span></span></span><span class="MJXp-mo" id="MJXp-Span-2026" style="margin-left: 0em; margin-right: 0em;">)</span></span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-2027" style="margin-left: 0em; margin-right: 0.222em;">,</span></span></span><div class="MathJax_Display MathJax_Processing"><span class="MathJax" id="MathJax-Element-291-Frame" tabindex="0"></span></div><script type="math/tex; mode=display" id="MathJax-Element-291"> \frac{P(h_{\theta} \mid s)}{P(h_{\theta'} \mid s)} \; = \;
\frac{P(h_{\theta}) P(s \mid h_{\theta})}{P(h_{\theta'}) P(s \mid
h_{\theta'})} , </script>

and if we assume equal priors <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2028"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2029">P</span><span class="MJXp-mo" id="MJXp-Span-2030" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-2031"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2032" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2033" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2034">θ</span></span></span><span class="MJXp-mo" id="MJXp-Span-2035" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-2036" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2037">P</span><span class="MJXp-mo" id="MJXp-Span-2038" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-2039"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2040" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2041" style="vertical-align: -0.4em;"><span class="MJXp-msup" id="MJXp-Span-2042"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2043" style="margin-right: 0.05em;">θ</span><span class="MJXp-mo MJXp-script" id="MJXp-Span-2044" style="vertical-align: 0.5em;">′</span></span></span></span><span class="MJXp-mo" id="MJXp-Span-2045" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-292-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-292">P(h_{\theta}) = P(h_{\theta'})</script>, we
can use the ratio of the likelihoods of the hypotheses, the so-called
Bayes factor, to compare the hypotheses.</p>

<p>Here is a Bayesian procedure for the example of the tea tasting
lady. </p>

<blockquote>
<strong>Bayesian statistical analysis</strong><br /> Consider the
hypotheses <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2046"><span class="MJXp-msubsup" id="MJXp-Span-2047"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2048" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2049" style="vertical-align: -0.4em;"><span class="MJXp-mn" id="MJXp-Span-2050">1</span><span class="MJXp-mrow" id="MJXp-Span-2051"><span class="MJXp-mo" id="MJXp-Span-2052">/</span></span><span class="MJXp-mn" id="MJXp-Span-2053">2</span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-293-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-293">h_{1/2}</script> and <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2054"><span class="MJXp-msubsup" id="MJXp-Span-2055"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2056" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2057" style="vertical-align: -0.4em;"><span class="MJXp-mn" id="MJXp-Span-2058">3</span><span class="MJXp-mrow" id="MJXp-Span-2059"><span class="MJXp-mo" id="MJXp-Span-2060">/</span></span><span class="MJXp-mn" id="MJXp-Span-2061">4</span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-294-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-294">h_{3/4}</script>, which in the foregoing were
used as null and alternative, <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2062"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2063">h</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-295-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-295">h</script> and <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2064"><span class="MJXp-msup" id="MJXp-Span-2065"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2066" style="margin-right: 0.05em;">h</span><span class="MJXp-mo MJXp-script" id="MJXp-Span-2067" style="vertical-align: 0.5em;">′</span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-296-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-296">h'</script>, respectively. Instead
of choosing among them on the basis of the data, we assign a prior
distribution over them so that the null is twice as probable as the
alternative: <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2068"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2069">P</span><span class="MJXp-mo" id="MJXp-Span-2070" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-2071"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2072" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2073" style="vertical-align: -0.4em;"><span class="MJXp-mn" id="MJXp-Span-2074">1</span><span class="MJXp-mrow" id="MJXp-Span-2075"><span class="MJXp-mo" id="MJXp-Span-2076">/</span></span><span class="MJXp-mn" id="MJXp-Span-2077">2</span></span></span><span class="MJXp-mo" id="MJXp-Span-2078" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-2079" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mn" id="MJXp-Span-2080">2</span><span class="MJXp-mrow" id="MJXp-Span-2081"><span class="MJXp-mo" id="MJXp-Span-2082" style="margin-left: 0.111em; margin-right: 0.111em;">/</span></span><span class="MJXp-mn" id="MJXp-Span-2083">3</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-297-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-297">P(h_{1/2}) = 2/3</script> and <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2084"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2085">P</span><span class="MJXp-mo" id="MJXp-Span-2086" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-2087"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2088" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2089" style="vertical-align: -0.4em;"><span class="MJXp-mn" id="MJXp-Span-2090">3</span><span class="MJXp-mrow" id="MJXp-Span-2091"><span class="MJXp-mo" id="MJXp-Span-2092">/</span></span><span class="MJXp-mn" id="MJXp-Span-2093">4</span></span></span><span class="MJXp-mo" id="MJXp-Span-2094" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-2095" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mn" id="MJXp-Span-2096">1</span><span class="MJXp-mrow" id="MJXp-Span-2097"><span class="MJXp-mo" id="MJXp-Span-2098" style="margin-left: 0.111em; margin-right: 0.111em;">/</span></span><span class="MJXp-mn" id="MJXp-Span-2099">3</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-298-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-298">P(h_{3/4}) = 1/3</script>. Denoting
the a particular sequence of guessing <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2100"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2101">n</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-299-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-299">n</script> out of 5 cups correctly
with <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2102"><span class="MJXp-msubsup" id="MJXp-Span-2103"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2104" style="margin-right: 0.05em;">s</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2105" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2106">n</span><span class="MJXp-mrow" id="MJXp-Span-2107"><span class="MJXp-mo" id="MJXp-Span-2108">/</span></span><span class="MJXp-mn" id="MJXp-Span-2109">5</span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-300-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-300">s_{n/5}</script>, we have that <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2110"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2111">P</span><span class="MJXp-mo" id="MJXp-Span-2112" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-2113"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2114" style="margin-right: 0.05em;">s</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2115" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2116">n</span><span class="MJXp-mrow" id="MJXp-Span-2117"><span class="MJXp-mo" id="MJXp-Span-2118">/</span></span><span class="MJXp-mn" id="MJXp-Span-2119">5</span></span></span><span class="MJXp-mo" id="MJXp-Span-2120" style="margin-left: 0.333em; margin-right: 0.333em;">∣</span><span class="MJXp-msubsup" id="MJXp-Span-2121"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2122" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2123" style="vertical-align: -0.4em;"><span class="MJXp-mn" id="MJXp-Span-2124">1</span><span class="MJXp-mrow" id="MJXp-Span-2125"><span class="MJXp-mo" id="MJXp-Span-2126">/</span></span><span class="MJXp-mn" id="MJXp-Span-2127">2</span></span></span><span class="MJXp-mo" id="MJXp-Span-2128" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-2129" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mn" id="MJXp-Span-2130">1</span><span class="MJXp-mrow" id="MJXp-Span-2131"><span class="MJXp-mo" id="MJXp-Span-2132" style="margin-left: 0.111em; margin-right: 0.111em;">/</span></span><span class="MJXp-msubsup" id="MJXp-Span-2133"><span class="MJXp-mn" id="MJXp-Span-2134" style="margin-right: 0.05em;">2</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2135" style="vertical-align: 0.5em;"><span class="MJXp-mn" id="MJXp-Span-2136">5</span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-301-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-301">P(s_{n/5} \mid h_{1/2}) = 1 / 2^{5}</script>
while <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2137"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2138">P</span><span class="MJXp-mo" id="MJXp-Span-2139" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-2140"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2141" style="margin-right: 0.05em;">s</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2142" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2143">n</span><span class="MJXp-mrow" id="MJXp-Span-2144"><span class="MJXp-mo" id="MJXp-Span-2145">/</span></span><span class="MJXp-mn" id="MJXp-Span-2146">5</span></span></span><span class="MJXp-mo" id="MJXp-Span-2147" style="margin-left: 0.333em; margin-right: 0.333em;">∣</span><span class="MJXp-msubsup" id="MJXp-Span-2148"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2149" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2150" style="vertical-align: -0.4em;"><span class="MJXp-mn" id="MJXp-Span-2151">3</span><span class="MJXp-mrow" id="MJXp-Span-2152"><span class="MJXp-mo" id="MJXp-Span-2153">/</span></span><span class="MJXp-mn" id="MJXp-Span-2154">4</span></span></span><span class="MJXp-mo" id="MJXp-Span-2155" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-2156" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-msubsup" id="MJXp-Span-2157"><span class="MJXp-mn" id="MJXp-Span-2158" style="margin-right: 0.05em;">3</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2159" style="vertical-align: 0.5em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2160">n</span></span></span><span class="MJXp-mrow" id="MJXp-Span-2161"><span class="MJXp-mo" id="MJXp-Span-2162" style="margin-left: 0.111em; margin-right: 0.111em;">/</span></span><span class="MJXp-msubsup" id="MJXp-Span-2163"><span class="MJXp-mn" id="MJXp-Span-2164" style="margin-right: 0.05em;">4</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2165" style="vertical-align: 0.5em;"><span class="MJXp-mn" id="MJXp-Span-2166">5</span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-302-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-302">P(s_{n/5} \mid h_{3/4}) = 3^{n} / 4^{5}</script>.  As before, the
likelihood ratio of five guesses thus becomes

<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-2167"><span class="MJXp-mfrac" id="MJXp-Span-2168" style="vertical-align: 0.25em;"><span class="MJXp-box"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2169">P</span><span class="MJXp-mo" id="MJXp-Span-2170" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-2171"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2172" style="margin-right: 0.05em;">s</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2173" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2174">n</span><span class="MJXp-mrow" id="MJXp-Span-2175"><span class="MJXp-mo" id="MJXp-Span-2176">/</span></span><span class="MJXp-mn" id="MJXp-Span-2177">5</span></span></span><span class="MJXp-mo" id="MJXp-Span-2178" style="margin-left: 0.333em; margin-right: 0.333em;">∣</span><span class="MJXp-msubsup" id="MJXp-Span-2179"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2180" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2181" style="vertical-align: -0.4em;"><span class="MJXp-mn" id="MJXp-Span-2182">3</span><span class="MJXp-mrow" id="MJXp-Span-2183"><span class="MJXp-mo" id="MJXp-Span-2184">/</span></span><span class="MJXp-mn" id="MJXp-Span-2185">4</span></span></span><span class="MJXp-mo" id="MJXp-Span-2186" style="margin-left: 0em; margin-right: 0em;">)</span></span><span class="MJXp-box" style="margin-top: -0.9em;"><span class="MJXp-denom"><span><span class="MJXp-rule" style="height: 1em; border-top: none; border-bottom: 1px solid; margin: 0.1em 0px;"></span></span><span><span class="MJXp-box"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2187">P</span><span class="MJXp-mo" id="MJXp-Span-2188" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-2189"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2190" style="margin-right: 0.05em;">s</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2191" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2192">n</span><span class="MJXp-mrow" id="MJXp-Span-2193"><span class="MJXp-mo" id="MJXp-Span-2194">/</span></span><span class="MJXp-mn" id="MJXp-Span-2195">5</span></span></span><span class="MJXp-mo" id="MJXp-Span-2196" style="margin-left: 0.333em; margin-right: 0.333em;">∣</span><span class="MJXp-msubsup" id="MJXp-Span-2197"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2198" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2199" style="vertical-align: -0.4em;"><span class="MJXp-mn" id="MJXp-Span-2200">1</span><span class="MJXp-mrow" id="MJXp-Span-2201"><span class="MJXp-mo" id="MJXp-Span-2202">/</span></span><span class="MJXp-mn" id="MJXp-Span-2203">2</span></span></span><span class="MJXp-mo" id="MJXp-Span-2204" style="margin-left: 0em; margin-right: 0em;">)</span></span></span></span></span></span><span class="MJXp-mspace" id="MJXp-Span-2205" style="width: 0.278em; height: 0em;"></span><span class="MJXp-mo" id="MJXp-Span-2206" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mspace" id="MJXp-Span-2207" style="width: 0.278em; height: 0em;"></span><span class="MJXp-mfrac" id="MJXp-Span-2208" style="vertical-align: 0.25em;"><span class="MJXp-box"><span class="MJXp-msubsup" id="MJXp-Span-2209"><span class="MJXp-mn" id="MJXp-Span-2210" style="margin-right: 0.05em;">3</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2211" style="vertical-align: 0.5em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2212">n</span></span></span></span><span class="MJXp-box" style="margin-top: -0.9em;"><span class="MJXp-denom"><span><span class="MJXp-rule" style="height: 1em; border-top: none; border-bottom: 1px solid; margin: 0.1em 0px;"></span></span><span><span class="MJXp-box"><span class="MJXp-msubsup" id="MJXp-Span-2213"><span class="MJXp-mn" id="MJXp-Span-2214" style="margin-right: 0.05em;">2</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2215" style="vertical-align: 0.5em;"><span class="MJXp-mn" id="MJXp-Span-2216">5</span></span></span></span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-2217" style="margin-left: 0em; margin-right: 0.222em;">.</span></span></span><div class="MathJax_Display MathJax_Processing"><span class="MathJax" id="MathJax-Element-303-Frame" tabindex="0"></span></div><script type="math/tex; mode=display" id="MathJax-Element-303"> \frac{P(s_{n/5} \mid h_{3/4})}{P(s_{n/5} \mid h_{1/2})} \; = \;
\frac{3^{n}}{2^{5}} . </script>

The posterior ratio after 5 correct guesses is thus

<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-2218"><span class="MJXp-mfrac" id="MJXp-Span-2219" style="vertical-align: 0.25em;"><span class="MJXp-box"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2220">P</span><span class="MJXp-mo" id="MJXp-Span-2221" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-2222"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2223" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2224" style="vertical-align: -0.4em;"><span class="MJXp-mn" id="MJXp-Span-2225">3</span><span class="MJXp-mrow" id="MJXp-Span-2226"><span class="MJXp-mo" id="MJXp-Span-2227">/</span></span><span class="MJXp-mn" id="MJXp-Span-2228">4</span></span></span><span class="MJXp-mo" id="MJXp-Span-2229" style="margin-left: 0.333em; margin-right: 0.333em;">∣</span><span class="MJXp-msubsup" id="MJXp-Span-2230"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2231" style="margin-right: 0.05em;">s</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2232" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2233">n</span><span class="MJXp-mrow" id="MJXp-Span-2234"><span class="MJXp-mo" id="MJXp-Span-2235">/</span></span><span class="MJXp-mn" id="MJXp-Span-2236">5</span></span></span><span class="MJXp-mo" id="MJXp-Span-2237" style="margin-left: 0em; margin-right: 0em;">)</span></span><span class="MJXp-box" style="margin-top: -0.9em;"><span class="MJXp-denom"><span><span class="MJXp-rule" style="height: 1em; border-top: none; border-bottom: 1px solid; margin: 0.1em 0px;"></span></span><span><span class="MJXp-box"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2238">P</span><span class="MJXp-mo" id="MJXp-Span-2239" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-2240"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2241" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2242" style="vertical-align: -0.4em;"><span class="MJXp-mn" id="MJXp-Span-2243">1</span><span class="MJXp-mrow" id="MJXp-Span-2244"><span class="MJXp-mo" id="MJXp-Span-2245">/</span></span><span class="MJXp-mn" id="MJXp-Span-2246">2</span></span></span><span class="MJXp-mo" id="MJXp-Span-2247" style="margin-left: 0.333em; margin-right: 0.333em;">∣</span><span class="MJXp-msubsup" id="MJXp-Span-2248"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2249" style="margin-right: 0.05em;">s</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2250" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2251">n</span><span class="MJXp-mrow" id="MJXp-Span-2252"><span class="MJXp-mo" id="MJXp-Span-2253">/</span></span><span class="MJXp-mn" id="MJXp-Span-2254">5</span></span></span><span class="MJXp-mo" id="MJXp-Span-2255" style="margin-left: 0em; margin-right: 0em;">)</span></span></span></span></span></span><span class="MJXp-mspace" id="MJXp-Span-2256" style="width: 0.278em; height: 0em;"></span><span class="MJXp-mo" id="MJXp-Span-2257" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mspace" id="MJXp-Span-2258" style="width: 0.278em; height: 0em;"></span><span class="MJXp-mfrac" id="MJXp-Span-2259" style="vertical-align: 0.25em;"><span class="MJXp-box"><span class="MJXp-msubsup" id="MJXp-Span-2260"><span class="MJXp-mn" id="MJXp-Span-2261" style="margin-right: 0.05em;">3</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2262" style="vertical-align: 0.5em;"><span class="MJXp-mn" id="MJXp-Span-2263">5</span></span></span></span><span class="MJXp-box" style="margin-top: -0.9em;"><span class="MJXp-denom"><span><span class="MJXp-rule" style="height: 1em; border-top: none; border-bottom: 1px solid; margin: 0.1em 0px;"></span></span><span><span class="MJXp-box"><span class="MJXp-msubsup" id="MJXp-Span-2264"><span class="MJXp-mn" id="MJXp-Span-2265" style="margin-right: 0.05em;">2</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2266" style="vertical-align: 0.5em;"><span class="MJXp-mn" id="MJXp-Span-2267">5</span></span></span></span></span></span></span></span><span class="MJXp-mspace" id="MJXp-Span-2268" style="width: 0.167em; height: 0em;"></span><span class="MJXp-mfrac" id="MJXp-Span-2269" style="vertical-align: 0.25em;"><span class="MJXp-box"><span class="MJXp-mn" id="MJXp-Span-2270">1</span></span><span class="MJXp-box" style="margin-top: -0.9em;"><span class="MJXp-denom"><span><span class="MJXp-rule" style="height: 1em; border-top: none; border-bottom: 1px solid; margin: 0.1em 0px;"></span></span><span><span class="MJXp-box"><span class="MJXp-mn" id="MJXp-Span-2271">2</span></span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-2272" style="margin-left: 0.333em; margin-right: 0.333em;">≈</span><span class="MJXp-mn" id="MJXp-Span-2273">4</span><span class="MJXp-mo" id="MJXp-Span-2274" style="margin-left: 0em; margin-right: 0.222em;">.</span></span></span><div class="MathJax_Display MathJax_Processing"><span class="MathJax" id="MathJax-Element-304-Frame" tabindex="0"></span></div><script type="math/tex; mode=display" id="MathJax-Element-304"> \frac{P(h_{3/4} \mid s_{n/5})}{P(h_{1/2} \mid s_{n/5})} \; = \;
\frac{3^{5}}{2^{5}}\, \frac{1}{2} \approx 4 . </script>

This posterior is derived by the axioms of probability theory alone,
in particular by Bayes' theorem. It tells us how believable each of
the hypotheses is after incorporating the sample data into our
beliefs.</blockquote>

<p>Notice that in the above exposition, the posterior probability is
written as <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2275"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2276">P</span><span class="MJXp-mo" id="MJXp-Span-2277" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-2278"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2279" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2280" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2281">θ</span></span></span><span class="MJXp-mo" id="MJXp-Span-2282" style="margin-left: 0.333em; margin-right: 0.333em;">∣</span><span class="MJXp-msubsup" id="MJXp-Span-2283"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2284" style="margin-right: 0.05em;">s</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2285" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2286">n</span><span class="MJXp-mrow" id="MJXp-Span-2287"><span class="MJXp-mo" id="MJXp-Span-2288">/</span></span><span class="MJXp-mn" id="MJXp-Span-2289">5</span></span></span><span class="MJXp-mo" id="MJXp-Span-2290" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-305-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-305">P(h_{\theta} \mid s_{n/5})</script>. Some expositions of
Bayesian inference prefer to express the revised opinion as a new
probability function <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2291"><span class="MJXp-msup" id="MJXp-Span-2292"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2293" style="margin-right: 0.05em;">P</span><span class="MJXp-mo MJXp-script" id="MJXp-Span-2294" style="vertical-align: 0.5em;">′</span></span><span class="MJXp-mo" id="MJXp-Span-2295" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mo" id="MJXp-Span-2296" style="margin-left: 0.267em; margin-right: 0.267em;">⋅</span><span class="MJXp-mo" id="MJXp-Span-2297" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-306-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-306">P'( \cdot )</script>, which is then equated to the old
<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2298"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2299">P</span><span class="MJXp-mo" id="MJXp-Span-2300" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mo" id="MJXp-Span-2301" style="margin-left: 0.267em; margin-right: 0.267em;">⋅</span><span class="MJXp-mo" id="MJXp-Span-2302" style="margin-left: 0.333em; margin-right: 0.333em;">∣</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2303">s</span><span class="MJXp-mo" id="MJXp-Span-2304" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-307-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-307">P( \cdot \mid s)</script>.  For the basic formal workings of Bayesian
inference, tis distinction is inessential. But we will return to it in
 <a href="#BayStaLog">Section 4.3.3</a>.
</p>

<h4><a id="ConMod">4.1.2 Continuous model</a></h4>

<p>In many applications the model is not a finite set of hypotheses,
but rather a continuum labelled by a real-valued parameter. This leads
to some subtle changes in the definition of the distribution over
hypotheses and the likelihoods. The prior and posterior must be
written down as a so-called <em>probability density function</em>,
<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2305"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2306">P</span><span class="MJXp-mo" id="MJXp-Span-2307" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-2308"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2309" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2310" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2311">θ</span></span></span><span class="MJXp-mo" id="MJXp-Span-2312" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2313">d</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2314">θ</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-308-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-308">P(h_{\theta}) d\theta</script>. The likelihoods need to be defined by a
limit process: the probability <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2315"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2316">P</span><span class="MJXp-mo" id="MJXp-Span-2317" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-2318"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2319" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2320" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2321">θ</span></span></span><span class="MJXp-mo" id="MJXp-Span-2322" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-309-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-309">P(h_{\theta})</script> is infinitely small
so that we cannot define <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2323"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2324">P</span><span class="MJXp-mo" id="MJXp-Span-2325" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2326">s</span><span class="MJXp-mo" id="MJXp-Span-2327" style="margin-left: 0.333em; margin-right: 0.333em;">∣</span><span class="MJXp-msubsup" id="MJXp-Span-2328"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2329" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2330" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2331">θ</span></span></span><span class="MJXp-mo" id="MJXp-Span-2332" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-310-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-310">P(s \mid h_{\theta})</script> in the normal
manner. But other than that the Bayesian machinery works exactly the
same:

<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-2333"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2334">P</span><span class="MJXp-mo" id="MJXp-Span-2335" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-2336"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2337" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2338" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2339">θ</span></span></span><span class="MJXp-mo" id="MJXp-Span-2340" style="margin-left: 0.333em; margin-right: 0.333em;">∣</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2341">s</span><span class="MJXp-mo" id="MJXp-Span-2342" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2343">d</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2344">θ</span><span class="MJXp-mspace" id="MJXp-Span-2345" style="width: 0.278em; height: 0em;"></span><span class="MJXp-mspace" id="MJXp-Span-2346" style="width: 0.278em; height: 0em;"></span><span class="MJXp-mo" id="MJXp-Span-2347" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mspace" id="MJXp-Span-2348" style="width: 0.278em; height: 0em;"></span><span class="MJXp-mspace" id="MJXp-Span-2349" style="width: 0.278em; height: 0em;"></span><span class="MJXp-mfrac" id="MJXp-Span-2350" style="vertical-align: 0.25em;"><span class="MJXp-box"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2351">P</span><span class="MJXp-mo" id="MJXp-Span-2352" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2353">s</span><span class="MJXp-mo" id="MJXp-Span-2354" style="margin-left: 0.333em; margin-right: 0.333em;">∣</span><span class="MJXp-msubsup" id="MJXp-Span-2355"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2356" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2357" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2358">θ</span></span></span><span class="MJXp-mo" id="MJXp-Span-2359" style="margin-left: 0em; margin-right: 0em;">)</span></span><span class="MJXp-box" style="margin-top: -0.9em;"><span class="MJXp-denom"><span><span class="MJXp-rule" style="height: 1em; border-top: none; border-bottom: 1px solid; margin: 0.1em 0px;"></span></span><span><span class="MJXp-box"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2360">P</span><span class="MJXp-mo" id="MJXp-Span-2361" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2362">s</span><span class="MJXp-mo" id="MJXp-Span-2363" style="margin-left: 0em; margin-right: 0em;">)</span></span></span></span></span></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2364">P</span><span class="MJXp-mo" id="MJXp-Span-2365" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-2366"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2367" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2368" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2369">θ</span></span></span><span class="MJXp-mo" id="MJXp-Span-2370" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2371">d</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2372">θ</span><span class="MJXp-mo" id="MJXp-Span-2373" style="margin-left: 0em; margin-right: 0.222em;">.</span></span></span><div class="MathJax_Display MathJax_Processing"><span class="MathJax" id="MathJax-Element-311-Frame" tabindex="0"></span></div><script type="math/tex; mode=display" id="MathJax-Element-311"> P(h_{\theta} \mid s) d\theta \;\; = \;\; \frac{P(s \mid
h_{\theta})}{P(s)} P(h_{\theta}) d\theta. </script>

Finally, summations need to be replaced by integrations:

<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-2374"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2375">P</span><span class="MJXp-mo" id="MJXp-Span-2376" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2377">s</span><span class="MJXp-mo" id="MJXp-Span-2378" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mspace" id="MJXp-Span-2379" style="width: 0.278em; height: 0em;"></span><span class="MJXp-mo" id="MJXp-Span-2380" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mspace" id="MJXp-Span-2381" style="width: 0.278em; height: 0em;"></span><span class="MJXp-msubsup" id="MJXp-Span-2382"><span class="MJXp-mo" id="MJXp-Span-2383" style="margin-left: 0em; margin-right: 0.05em;"><span class="MJXp-largeop MJXp-int">∫</span></span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2384" style="vertical-align: -0.46em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2385">θ</span><span class="MJXp-mo" id="MJXp-Span-2386">∈</span><span class="MJXp-mi" id="MJXp-Span-2387">Θ</span></span></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2388">P</span><span class="MJXp-mo" id="MJXp-Span-2389" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-2390"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2391" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2392" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2393">θ</span></span></span><span class="MJXp-mo" id="MJXp-Span-2394" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2395">P</span><span class="MJXp-mo" id="MJXp-Span-2396" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2397">s</span><span class="MJXp-mo" id="MJXp-Span-2398" style="margin-left: 0.333em; margin-right: 0.333em;">∣</span><span class="MJXp-msubsup" id="MJXp-Span-2399"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2400" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2401" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2402">θ</span></span></span><span class="MJXp-mo" id="MJXp-Span-2403" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2404">d</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2405">θ</span><span class="MJXp-mo" id="MJXp-Span-2406" style="margin-left: 0em; margin-right: 0.222em;">.</span></span></span><div class="MathJax_Display MathJax_Processing"><span class="MathJax" id="MathJax-Element-312-Frame" tabindex="0"></span></div><script type="math/tex; mode=display" id="MathJax-Element-312"> P(s) \; = \; \int_{\theta \in \Theta} P(h_{\theta}) P(s \mid
h_{\theta}) d\theta . </script>

This expression is often called the <em>marginal likelihood</em> of
the model: it expresses how probable the data is in the light of the
model as a whole.</p>

<p>The posterior probability density provides a basis for conclusions
that one might draw from the sample <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2407"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2408">s</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-313-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-313">s</script>, and which are similar to
estimations and measures for the accuracy of the estimations. For one,
we can derive an expectation for the parameter <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2409"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2410">θ</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-314-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-314">\theta</script>, where we
assume that <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2411"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2412">θ</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-315-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-315">\theta</script> varies continuously:

<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-2413"><span class="MJXp-mrow" id="MJXp-Span-2414"><span class="MJXp-munderover" id="MJXp-Span-2415"><span><span class="MJXp-over"><span class="" style="margin-bottom: -0.92em;"><span class="MJXp-mo" id="MJXp-Span-2417" style="margin-left: 0px; margin-right: 0px;">ˉ</span></span><span class=""><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2416">θ</span></span></span></span></span></span><span class="MJXp-mspace" id="MJXp-Span-2418" style="width: 0.278em; height: 0em;"></span><span class="MJXp-mspace" id="MJXp-Span-2419" style="width: 0.278em; height: 0em;"></span><span class="MJXp-mo" id="MJXp-Span-2420" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mspace" id="MJXp-Span-2421" style="width: 0.278em; height: 0em;"></span><span class="MJXp-mspace" id="MJXp-Span-2422" style="width: 0.278em; height: 0em;"></span><span class="MJXp-msubsup" id="MJXp-Span-2423"><span class="MJXp-mo" id="MJXp-Span-2424" style="margin-left: 0em; margin-right: 0.05em;"><span class="MJXp-largeop MJXp-int">∫</span></span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2425" style="vertical-align: -0.46em;"><span class="MJXp-mi" id="MJXp-Span-2426">Θ</span></span></span><span class="MJXp-mspace" id="MJXp-Span-2427" style="width: 0.167em; height: 0em;"></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2428">θ</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2429">P</span><span class="MJXp-mo" id="MJXp-Span-2430" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-2431"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2432" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2433" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2434">θ</span></span></span><span class="MJXp-mo" id="MJXp-Span-2435" style="margin-left: 0.333em; margin-right: 0.333em;">∣</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2436">s</span><span class="MJXp-mo" id="MJXp-Span-2437" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2438">d</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2439">θ</span><span class="MJXp-mo" id="MJXp-Span-2440" style="margin-left: 0em; margin-right: 0.222em;">.</span></span></span><div class="MathJax_Display MathJax_Processing"><span class="MathJax" id="MathJax-Element-316-Frame" tabindex="0"></span></div><script type="math/tex; mode=display" id="MathJax-Element-316"> \bar{\theta} \;\; = \;\; \int_{\Theta}\, \theta P(h_{\theta} \mid s)
d\theta. </script>

If the model is parameterized by a convex set, which it typically is,
then there will be a hypothesis <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2441"><span class="MJXp-msubsup" id="MJXp-Span-2442"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2443" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2444" style="vertical-align: -0.4em;"><span class="MJXp-mrow" id="MJXp-Span-2445"><span class="MJXp-munderover" id="MJXp-Span-2446"><span><span class="MJXp-over"><span class=" MJXp-script" style="margin-bottom: -0.92em;"><span class="MJXp-mo" id="MJXp-Span-2448" style="margin-right: 0px; margin-left: 0px;">ˉ</span></span><span class=""><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2447">θ</span></span></span></span></span></span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-317-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-317">h_{\bar{\theta}}</script> in the
model. This hypothesis can serve as a Bayesian estimation. In analogy
to the confidence interval, we can also define a so-called
<em>credal</em> <em>interval</em> or <em>credibility interval</em>
from the posterior probability distribution: an interval of size
<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2449"><span class="MJXp-mn" id="MJXp-Span-2450">2</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2451">d</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-318-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-318">2d</script> around the expectation value <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2452"><span class="MJXp-mrow" id="MJXp-Span-2453"><span class="MJXp-munderover" id="MJXp-Span-2454"><span><span class="MJXp-over"><span class="" style="margin-bottom: -0.92em;"><span class="MJXp-mo" id="MJXp-Span-2456" style="margin-left: 0px; margin-right: 0px;">ˉ</span></span><span class=""><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2455">θ</span></span></span></span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-319-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-319">\bar{\theta}</script>, written
<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2457"><span class="MJXp-mo" id="MJXp-Span-2458" style="margin-left: 0em; margin-right: 0em;">[</span><span class="MJXp-mrow" id="MJXp-Span-2459"><span class="MJXp-munderover" id="MJXp-Span-2460"><span><span class="MJXp-over"><span class="" style="margin-bottom: -0.92em;"><span class="MJXp-mo" id="MJXp-Span-2462" style="margin-left: 0px; margin-right: 0px;">ˉ</span></span><span class=""><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2461">θ</span></span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-2463" style="margin-left: 0.267em; margin-right: 0.267em;">−</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2464">d</span><span class="MJXp-mo" id="MJXp-Span-2465" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mrow" id="MJXp-Span-2466"><span class="MJXp-munderover" id="MJXp-Span-2467"><span><span class="MJXp-over"><span class="" style="margin-bottom: -0.92em;"><span class="MJXp-mo" id="MJXp-Span-2469" style="margin-left: 0px; margin-right: 0px;">ˉ</span></span><span class=""><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2468">θ</span></span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-2470" style="margin-left: 0.267em; margin-right: 0.267em;">+</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2471">d</span><span class="MJXp-mo" id="MJXp-Span-2472" style="margin-left: 0em; margin-right: 0em;">]</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-320-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-320">[\bar{\theta} - d, \bar{\theta} + d]</script>, such that

<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-2473"><span class="MJXp-msubsup" id="MJXp-Span-2474"><span class="MJXp-mo" id="MJXp-Span-2475" style="margin-left: 0em; margin-right: 0.05em;"><span class="MJXp-largeop MJXp-int">∫</span></span><span class="MJXp-script-box" style="height: 2.279em; vertical-align: -0.7em;"><span class=" MJXp-script"><span><span style="margin-bottom: -0.25em;"><span class="MJXp-mrow" id="MJXp-Span-2483"><span class="MJXp-mrow" id="MJXp-Span-2484"><span class="MJXp-munderover" id="MJXp-Span-2485"><span><span class="MJXp-over"><span class=" MJXp-script" style="margin-bottom: -0.92em;"><span class="MJXp-mo" id="MJXp-Span-2487" style="margin-right: 0px; margin-left: 0px;">ˉ</span></span><span class=""><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2486">θ</span></span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-2488">+</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2489">d</span></span></span></span></span><span class=" MJXp-script"><span><span style="margin-top: -1.074em;"><span class="MJXp-mrow" id="MJXp-Span-2476"><span class="MJXp-mrow" id="MJXp-Span-2477"><span class="MJXp-munderover" id="MJXp-Span-2478"><span><span class="MJXp-over"><span class=" MJXp-script" style="margin-bottom: -0.92em;"><span class="MJXp-mo" id="MJXp-Span-2480" style="margin-right: 0px; margin-left: 0px;">ˉ</span></span><span class=""><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2479">θ</span></span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-2481">−</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2482">d</span></span></span></span></span></span></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2490">P</span><span class="MJXp-mo" id="MJXp-Span-2491" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-2492"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2493" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2494" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2495">θ</span></span></span><span class="MJXp-mo" id="MJXp-Span-2496" style="margin-left: 0.333em; margin-right: 0.333em;">∣</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2497">s</span><span class="MJXp-mo" id="MJXp-Span-2498" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2499">d</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2500">θ</span><span class="MJXp-mo" id="MJXp-Span-2501" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mn" id="MJXp-Span-2502">1</span><span class="MJXp-mo" id="MJXp-Span-2503" style="margin-left: 0.267em; margin-right: 0.267em;">−</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2504">ϵ</span><span class="MJXp-mo" id="MJXp-Span-2505" style="margin-left: 0em; margin-right: 0.222em;">.</span></span></span><div class="MathJax_Display MathJax_Processing"><span class="MathJax" id="MathJax-Element-321-Frame" tabindex="0"></span></div><script type="math/tex; mode=display" id="MathJax-Element-321"> \int_{\bar{\theta} - d}^{\bar{\theta} + d} P(h_{\theta} \mid s)
d\theta = 1-\epsilon .  </script>

This range of values for <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2506"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2507">θ</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-322-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-322">\theta</script> is such that the posterior
probability of the corresponding <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2508"><span class="MJXp-msubsup" id="MJXp-Span-2509"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2510" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2511" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2512">θ</span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-323-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-323">h_{\theta}</script> adds up to
<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2513"><span class="MJXp-mn" id="MJXp-Span-2514">1</span><span class="MJXp-mo" id="MJXp-Span-2515" style="margin-left: 0.267em; margin-right: 0.267em;">−</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2516">ϵ</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-324-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-324">1-\epsilon</script> of the total posterior probability.</p>

<p>There are many other ways of defining Bayesian estimations and
credal intervals for <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2517"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2518">θ</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-325-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-325">\theta</script> on the basis of the posterior
density. The specific type of estimation that the Bayesian analysis
offers can be determined by the demands of the scientist. Any Bayesian
estimation will to some extent resemble the maximum likelihood
estimator due to the central role of the likelihoods in the Bayesian
formalism. However, the output will also depend on the prior
probability over the hypotheses, and generally speaking it will only
tend to the maximum likelihood estimator when the sample size tends to
infinity. See
 <a href="#DetPri">Section 4.2.2</a> 
for more on this so-called “washing out” of the
priors. </p>

<h3><a id="ProBayApp">4.2 Problems with the Bayesian approach</a></h3>

<p>Most of the controversy over the Bayesian method concerns the
probability assignment over hypotheses. One important set of problems
surrounds the interpretation of those probabilities as beliefs, as to
do with a willingness to act, or the like. Another set of
problems pertains to the determination of the prior probability
assignment, and the criteria that might govern it.</p>

<h4><a id="IntProOveHyp">4.2.1 Interpretations of the probability over hypotheses</a></h4>

<p>The overall question here is how we should understand the
probability assigned to a statistical hypothesis. Naturally the
interpretation will be epistemic: the probability expresses the
strength of belief in the hypothesis. It makes little sense to attempt
a physical interpretation since the hypothesis cannot be seen as a
repeatable event, or as an event that might have some tendency of
occurring.</p>

<p>This leaves open several interpretations of the probability
assignment as a strength of belief.  One very influential
interpretation of probability as degree of belief relates probability
to a willingness to bet against certain odds (cf.  Ramsey 1926, De
Finetti 1937/1964, Earman 1992, Jeffrey 1992, Howson 2000).  According
to this interpretation, assigning a probability of <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2519"><span class="MJXp-mn" id="MJXp-Span-2520">3</span><span class="MJXp-mrow" id="MJXp-Span-2521"><span class="MJXp-mo" id="MJXp-Span-2522" style="margin-left: 0.111em; margin-right: 0.111em;">/</span></span><span class="MJXp-mn" id="MJXp-Span-2523">4</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-326-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-326">3/4</script> to a
proposition, for example, means that we are prepared to pay at most
$0.75 for a betting contract that pays out $1 if the
proposition is true, and that turns worthless if the proposition is
false. The claim that degrees of belief are correctly expressed in a
probability assignment is then supported by a so-called <em>Dutch book
argument</em>: if an agent does not comply to the axioms of
probability theory, a malign bookmaker can propose a set of bets that
seems fair to the agent but that lead to a certain monetary loss, and
that is therefore called Dutch, presumably owing to the Dutch's
mercantile reputation. This interpretation associates beliefs directly
with their behavioral consequences: believing something is the same as
having the willingness to engage in a particular activity, e.g., in a
bet. </p>

<p>There are several problems with this interpretation of the
probability assignment over hypotheses. For one, it seems to make
little sense to bet on the truth of a statistical hypothesis, because
such hypotheses cannot be falsified or verified.  Consequently, a
betting contract on them will never be cashed. More generally, it is
not clear that beliefs about statistical hypotheses are properly
framed by connecting them to behavior in this way. It has been argued
(e.g., Armendt 1993) that this way of framing probability assignments
introduces pragmatic considerations on beliefs, to do with navigating
the world successfully, into a setting that is by itself more
concerned with belief as a truthful representation of the world.</p>

<p>A somewhat different problem is that the Bayesian formalism, in
particular its use of probability assignments over statistical
hypotheses, suggests a remarkable closed-mindedness on the part of the
Bayesian statistician. Recall the example of the foregoing, with the
model <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2524"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2525">M</span><span class="MJXp-mo" id="MJXp-Span-2526" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mo" id="MJXp-Span-2527" style="margin-left: 0em; margin-right: 0em;">{</span><span class="MJXp-msubsup" id="MJXp-Span-2528"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2529" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2530" style="vertical-align: -0.4em;"><span class="MJXp-mn" id="MJXp-Span-2531">1</span><span class="MJXp-mrow" id="MJXp-Span-2532"><span class="MJXp-mo" id="MJXp-Span-2533">/</span></span><span class="MJXp-mn" id="MJXp-Span-2534">2</span></span></span><span class="MJXp-mo" id="MJXp-Span-2535" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-msubsup" id="MJXp-Span-2536"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2537" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2538" style="vertical-align: -0.4em;"><span class="MJXp-mn" id="MJXp-Span-2539">3</span><span class="MJXp-mrow" id="MJXp-Span-2540"><span class="MJXp-mo" id="MJXp-Span-2541">/</span></span><span class="MJXp-mn" id="MJXp-Span-2542">4</span></span></span><span class="MJXp-mo" id="MJXp-Span-2543" style="margin-left: 0em; margin-right: 0em;">}</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-327-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-327">M = \{ h_{1/2}, h_{3/4} \}</script>.  The Bayesian formalism requires
that we assign a probability distribution over these two hypotheses,
and further that the probability of the model is <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2544"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2545">P</span><span class="MJXp-mo" id="MJXp-Span-2546" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2547">M</span><span class="MJXp-mo" id="MJXp-Span-2548" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-2549" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mn" id="MJXp-Span-2550">1</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-328-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-328">P(M) = 1</script>. It is
quite a strong assumption, even of an ideally rational agent, that she
is indeed equipped with a real-valued function that expresses her
opinion over the hypotheses. Moreover, the probability assignment over
hypotheses seems to entail that the Bayesian statistician is certain
that the true hypothesis is included in the model. This is an unduly
strong claim to which a Bayesian statistician will have to commit at
the start of her analysis. It sits badly with broadly shared
methodological insights (e.g., Popper 1934/1956), according to which
scientific theory must be open to revision at all times (cf. Mayo
1996). In this regard Bayesian statistics does not do justice to the
nature of scientific inquiry, or so it seems.</p>

<p>The problem just outlined obtains a mathematically more
sophisticated form in the problem that Bayesians expect to be
<em>well-calibrated</em>.  This problem, as formulated in Dawid
(1982), concerns a Bayesian forecaster, e.g., a weatherman who
determines a daily probability for precipitation in the next day.  It
is then shown that such a weatherman believes of himself that in
the long run he will converge onto the correct probability with
probability 1. Yet it seems reasonable to suppose that the weatherman
realizes something could potentially be wrong with his meteorological
model, and so sets his probability for correct prediction below 1. The
weatherman is thus led to incoherent beliefs. It seems that Bayesian
statistical analysis places unrealistic demands, even on an ideal
agent.</p>

<h4><a id="DetPri">4.2.2 Determination of the prior</a></h4>

<p>For the moment, assume that we can interpret the probability over
hypotheses as an expression of epistemic uncertainty. Then how do we
determine a prior probability? Perhaps we already have an intuitive
judgment on the hypotheses in the model, so that we can pin down the
prior probability on that basis. Or else we might have additional
criteria for choosing our prior. However, several serious problems
attach to procedures for determining the prior.</p>

<p>First consider the idea that the scientist who runs the Bayesian
analysis provides the prior probability herself. One obvious problem
with this idea is that the opinion of the scientist might not be
precise enough for a determination of a full prior distribution. It
does not seem realistic to suppose that the scientist can transform
her opinion into a single real-valued function over the model,
especially not if the model itself consists of a continuum of
hypotheses. But the more pressing problem is that different scientists
will provide different prior distributions, and that these different
priors will lead to different statistical results. In other words,
Bayesian statistical inference introduces an inevitable subjective
component into scientific method.</p>

<p>It is one thing that the statistical results depend on the initial
opinion of the scientist. But it may so happen that the scientist has
no opinion whatsoever about the hypotheses. How is she supposed to
assign a prior probability to the hypotheses then? The prior will have
to express her ignorance concerning the hypotheses. The leading idea
in expressing such ignorance is usually the <em>principle of
indifference</em>: ignorance means that we are indifferent between any
pair of hypotheses.  For a finite number of hypotheses, indifference
means that every hypothesis gets equal probability. For a continuum of
hypotheses, indifference means that the probability density
function must be uniform. </p>

<p>Nevertheless, there are different ways of applying the
principle of indifference and so there are different probability
distributions over the hypotheses that can count as expression of
ignorance. This insight is nicely illustrated in Bertrand's paradox
.</p>

<blockquote>
<strong>Bertrand's paradox</strong><br /> Consider a circle drawn
around an equilateral triangle, and now imagine that a knitting needle
whose length exceeds the circle's diameter is thrown onto the
circle. What is the probability that the section of the needle lying
within the circle is longer than the side of the equilateral triangle?
To determine the answer, we need to parameterize the ways in which the
needle may be thrown, determine the subset of parameter values for
which the included section is indeed longer than the triangle's side,
and express our ignorance over the exact throw of the needle in a
probability distribution over the parameter, so that the probability
of the said event can be derived. The problem is that we may provide
any number of ways to parameterize how the needle lands in the
circle. If we use the angle that the needle makes with the tangent of
the circle at the intersection, then the included section of the
needle is only going to be longer if the angle is between
<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2551"><span class="MJXp-msubsup" id="MJXp-Span-2552"><span class="MJXp-mn" id="MJXp-Span-2553" style="margin-right: 0.05em;">60</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2554" style="vertical-align: 0.5em;"><span class="MJXp-mo" id="MJXp-Span-2555">∘</span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-329-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-329">60^{\circ}</script> and <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2556"><span class="MJXp-msubsup" id="MJXp-Span-2557"><span class="MJXp-mn" id="MJXp-Span-2558" style="margin-right: 0.05em;">120</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2559" style="vertical-align: 0.5em;"><span class="MJXp-mo" id="MJXp-Span-2560">∘</span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-330-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-330">120^{\circ}</script>. If we assume that our ignorance is
expressed by a uniform distribution over these angles, which ranges
from <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2561"><span class="MJXp-msubsup" id="MJXp-Span-2562"><span class="MJXp-mn" id="MJXp-Span-2563" style="margin-right: 0.05em;">0</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2564" style="vertical-align: 0.5em;"><span class="MJXp-mo" id="MJXp-Span-2565">∘</span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-331-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-331">0^{\circ}</script> to <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2566"><span class="MJXp-msubsup" id="MJXp-Span-2567"><span class="MJXp-mn" id="MJXp-Span-2568" style="margin-right: 0.05em;">180</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2569" style="vertical-align: 0.5em;"><span class="MJXp-mo" id="MJXp-Span-2570">∘</span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-332-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-332">180^{\circ}</script>, then the probability of the
event is going to be <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2571"><span class="MJXp-mn" id="MJXp-Span-2572">1</span><span class="MJXp-mrow" id="MJXp-Span-2573"><span class="MJXp-mo" id="MJXp-Span-2574" style="margin-left: 0.111em; margin-right: 0.111em;">/</span></span><span class="MJXp-mn" id="MJXp-Span-2575">3</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-333-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-333">1/3</script>. However, we can also parameterize the
ways in which the needle lands differently, namely by the shortest
distance of the needle to the centre of the circle. A uniform
probability over the distances will lead to a probability of
<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2576"><span class="MJXp-mn" id="MJXp-Span-2577">1</span><span class="MJXp-mrow" id="MJXp-Span-2578"><span class="MJXp-mo" id="MJXp-Span-2579" style="margin-left: 0.111em; margin-right: 0.111em;">/</span></span><span class="MJXp-mn" id="MJXp-Span-2580">2</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-334-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-334">1/2</script>.</blockquote>

<p>Jaynes (1973 and 2003) provides a very insightful discussion of
this riddle and also argues that it may be resolved by relying on
invariances of the problem under certain transformations. But the
general message for now is that the principle of indifference does not
lead to a unique choice of priors.  The point is not that ignorance
concerning a parameter is hard to express in a probability
distribution over those values. It is rather that in some cases, we do
not even know what parameters to use to express our ignorance
over.</p>

<p>In part the problem of the subjectivity of Bayesian analysis may be
resolved by taking a different attitude to scientific theory, and by
giving up the ideal of absolute objectivity. Indeed, some will argue
that it is just right that the statistical methods accommodate
differences of opinion among scientists. However, this response misses
the mark if the prior distribution expresses ignorance rather than
opinion: it seems harder to defend the rationality of differences of
opinion that stem from different ways of spelling out ignorance. Now
there is also a more positive answer to worries over objectivity,
based on so-called <em>convergence results </em>(e.g., Blackwell and
Dubins 1962 and Gaifman and Snir 1982). It turns out that the impact
of prior choice diminishes with the accumulation of data, and that in
the limit the posterior distribution will converge to a set, possibly
a singleton, of best hypotheses, determined by the sampled data and
hence completely independent of the prior distribution.  However, in
the short and medium run the influence of subjective prior choice
remains.</p>

<p>Summing up, it remains problematic that Bayesian statistics is
sensitive to subjective input. The undeniable advantage of the
classical statistical procedures is that they do not need any such
input, although arguably the classical procedures are in turn
sensitive to choices concerning the sample space (Lindley 2000).
Against this, Bayesian statisticians point to the advantage of being
able to incorporate initial opinions into the statistical
analysis.</p>

<h3><a id="BayStaResCri">4.3 Responses to criticism</a></h3>

<p>The philosophy of Bayesian statistics offers a wide range of
responses to the problems outlined above. Some Bayesians bite the
bullet and defend the essentially subjective character of Bayesian
methods. Others attempt to remedy or compensate for the subjectivity,
by providing objectively motivated means of determining the prior
probability or by emphasizing the objective character of the Bayesian
formalism itself.</p>

<h4><a id="StrButEmpInfSub">4.3.1 Strict but empirically informed subjectivism </a></h4>

<p>One very influential view on Bayesian statistics buys into the
subjectivity of the analysis (e.g., Goldstein 2006, Kadane 2011).
So-called <em>personalist</em>s or <em>strict subjectivists </em>argue
that it is just right that the statistical methods do not provide any
objective guidelines, pointing to radically subjective sources of any
form of knowledge. The problems on the interpretation and choice of
the prior distribution are thus dissolved, at least in part: the
Bayesian statistician may choose her prior at will, and they are an
expression of her beliefs. However, it deserves emphasis that a
subjectivist view on Bayesian statistics does not mean that all
constraints deriving from empirical fact can be disregarded. Nobody
denies that if you have further knowledge that imposes constraints on
the model or the prior, then those constraints must be
accommodated. For example, today's posterior probability may be used
as tomorrow's prior, in the next statistical inference. The point is
that such constraints concern the rationality of belief and not the
consistency of the statistical inference per se.</p>

<p>Subjectivist views are most prominent among those who interpret
probability assignments in a pragmatic fashion, and motivate the
representation of belief with probability assignments by the
afore-mentioned Dutch book arguments. Central to this approach is the
work of Savage and De Finetti. Savage (1962) proposed to axiomatize
statistics in tandem with <em>decision theory</em>, a mathematical
theory about practical rationality. He argued that by themselves the
probability assignments do not mean anything at all, and that they can
only be interpreted in the context where an agent faces a choice
between actions, i.e., a choice among a set of bets. In similar vein,
De Finetti (e.g., 1974) advocated a view on statistics in which only
the empirical consequences of the probabilistic beliefs, expressed in
a willingness to bet, mattered but he did not make statistical
inference fully dependent on decision theory. Remarkably, it thus
appears that the subjectivist view on Bayesian statistics is based on
the same behaviorism and empiricism that motivated Neyman and Pearson
to develop classical statistics.</p>

<p>Notice that all this makes one aspect of the interpretation problem
of 
 <a href="#IntProOveHyp">Section 4.2.1</a>
reappear: how will the prior distribution over hypotheses make itself
apparent in behavior, so that it can rightfully be interpreted in
terms of belief, here understood as a willingness to act? One response
to this question is to turn to different motivations for representing
degrees of beliefs by means of probability assignments.  Following
work by De Finetti, several authors have proposed vindications of
probabilistic expressions of belief that are not based on behavioral
goals, but rather on the epistemic goal of holding beliefs that
accurately represent the world, e.g., Rosenkrantz (1981), Joyce
(2001), Leitgeb and Pettigrew (2010), Easwaran (2013). A strong
generalization of this idea is achieved in Schervish, Seidenfeld and
Kadane (2009), which builds on a longer tradition of using scoring
rules for achieving statistical aims. An alternative approach is that
any formal representation of belief must respect certain logical
constraints, e.g., Cox provides an argument for the expression of
belief in terms of probability assignments on the basis of the nature
of partial belief per se. </p>

<p>However, the original subjectivist response to the issue that a
prior over hypotheses is hard to interpret came from De Finetti's
so-called <em>representation theorem</em>, which shows that every
prior distribution can be associated with its own set of predictions,
and hence with its own behavioral consequences.  In other words, De
Finetti showed how priors are indeed associated with beliefs that can
carry a betting interpretation.
</p>

<h4><a id="ExcRepThe">4.3.2 Excursion: the representation theorem</a></h4>

<p>De Finetti's representation theorem relates rules for
prediction, as functions of the given sample data, to Bayesian
statistical analyses of those data, against the background of a
statistical model. See Festa (1996) and Suppes (2001) for useful
introductions. De Finetti considers a process that generates a series
of time-indexed observations, and he then studies prediction rules
that take these finite segments as input and return a probability over
future events, using a statistical model that can analyze such samples
and provide the predictions. The key result of De Finetti is that a
particular statistical model, namely the set of all distributions in
which the observations are independently and identically
distributed, can be equated with the class of <em>exchangeable
prediction rules</em>, namely the rules whose predictions do not
depend on the order in which the observations come in.</p>

<p>Let us consider the representation theorem in some more formal
detail. For simplicity, say that the process generates time-indexed
binary observations, i.e., 0's and 1's. The prediction rules take such
bit strings of length <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2581"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2582">t</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-335-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-335">t</script>, denoted <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2583"><span class="MJXp-msubsup" id="MJXp-Span-2584"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2585" style="margin-right: 0.05em;">S</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2586" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2587">t</span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-336-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-336">S_{t}</script>, as input, and return a
probability for the event that the next bit in the string is a 1,
denoted <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2588"><span class="MJXp-msubsup" id="MJXp-Span-2589"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2590" style="margin-right: 0.05em;">Q</span><span class="MJXp-script-box" style="height: 1.86em; vertical-align: -0.64em;"><span class=" MJXp-script"><span><span style="margin-bottom: -0.25em;"><span class="MJXp-mrow" id="MJXp-Span-2595"><span class="MJXp-mn" id="MJXp-Span-2596">1</span></span></span></span></span><span class=" MJXp-script"><span><span style="margin-top: -0.85em;"><span class="MJXp-mrow" id="MJXp-Span-2591"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2592">t</span><span class="MJXp-mo" id="MJXp-Span-2593">+</span><span class="MJXp-mn" id="MJXp-Span-2594">1</span></span></span></span></span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-337-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-337">Q^{1}_{t+1}</script>. So we write the prediction rules as partial
probability assignments <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2597"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2598">P</span><span class="MJXp-mo" id="MJXp-Span-2599" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-2600"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2601" style="margin-right: 0.05em;">Q</span><span class="MJXp-script-box" style="height: 1.86em; vertical-align: -0.64em;"><span class=" MJXp-script"><span><span style="margin-bottom: -0.25em;"><span class="MJXp-mrow" id="MJXp-Span-2606"><span class="MJXp-mn" id="MJXp-Span-2607">1</span></span></span></span></span><span class=" MJXp-script"><span><span style="margin-top: -0.85em;"><span class="MJXp-mrow" id="MJXp-Span-2602"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2603">t</span><span class="MJXp-mo" id="MJXp-Span-2604">+</span><span class="MJXp-mn" id="MJXp-Span-2605">1</span></span></span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-2608" style="margin-left: 0.333em; margin-right: 0.333em;">∣</span><span class="MJXp-msubsup" id="MJXp-Span-2609"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2610" style="margin-right: 0.05em;">S</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2611" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2612">t</span></span></span><span class="MJXp-mo" id="MJXp-Span-2613" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-338-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-338">P(Q^{1}_{t+1} \mid S_{t})</script>. Exchangeable
prediction rules are rules that deliver the same prediction
independently of the order of the bits in the string <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2614"><span class="MJXp-msubsup" id="MJXp-Span-2615"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2616" style="margin-right: 0.05em;">S</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2617" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2618">t</span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-339-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-339">S_{t}</script>. If we
write the event that the string <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2619"><span class="MJXp-msubsup" id="MJXp-Span-2620"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2621" style="margin-right: 0.05em;">S</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2622" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2623">t</span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-340-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-340">S_{t}</script> has a total of <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2624"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2625">n</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-341-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-341">n</script>
observations of 1's as <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2626"><span class="MJXp-msubsup" id="MJXp-Span-2627"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2628" style="margin-right: 0.05em;">S</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2629" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2630">n</span><span class="MJXp-mrow" id="MJXp-Span-2631"><span class="MJXp-mo" id="MJXp-Span-2632">/</span></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2633">t</span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-342-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-342">S_{n/t}</script>, then exchangeable prediction rules
are written as <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2634"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2635">P</span><span class="MJXp-mo" id="MJXp-Span-2636" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-2637"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2638" style="margin-right: 0.05em;">Q</span><span class="MJXp-script-box" style="height: 1.86em; vertical-align: -0.64em;"><span class=" MJXp-script"><span><span style="margin-bottom: -0.25em;"><span class="MJXp-mrow" id="MJXp-Span-2643"><span class="MJXp-mn" id="MJXp-Span-2644">1</span></span></span></span></span><span class=" MJXp-script"><span><span style="margin-top: -0.85em;"><span class="MJXp-mrow" id="MJXp-Span-2639"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2640">t</span><span class="MJXp-mo" id="MJXp-Span-2641">+</span><span class="MJXp-mn" id="MJXp-Span-2642">1</span></span></span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-2645" style="margin-left: 0.333em; margin-right: 0.333em;">∣</span><span class="MJXp-msubsup" id="MJXp-Span-2646"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2647" style="margin-right: 0.05em;">S</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2648" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2649">n</span><span class="MJXp-mrow" id="MJXp-Span-2650"><span class="MJXp-mo" id="MJXp-Span-2651">/</span></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2652">t</span></span></span><span class="MJXp-mo" id="MJXp-Span-2653" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-343-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-343">P(Q^{1}_{t+1} \mid S_{n/t})</script>. The crucial property
is that the value of the prediction is not affected by the order in
which the 0's and 1's show up in the string <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2654"><span class="MJXp-msubsup" id="MJXp-Span-2655"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2656" style="margin-right: 0.05em;">S</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2657" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2658">t</span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-344-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-344">S_{t}</script>.</p>

<p>De Finetti relates this particular set of exchangeable prediction
rules to a Bayesian inference over a specific type of statistical
model. The model that De Finetti considers comprises the so-called
<em>Bernoulli hypotheses</em> <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2659"><span class="MJXp-msubsup" id="MJXp-Span-2660"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2661" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2662" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2663">θ</span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-345-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-345">h_{\theta}</script>, i.e., hypotheses for
which

<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-2664"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2665">P</span><span class="MJXp-mo" id="MJXp-Span-2666" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-2667"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2668" style="margin-right: 0.05em;">Q</span><span class="MJXp-script-box" style="height: 1.86em; vertical-align: -0.64em;"><span class=" MJXp-script"><span><span style="margin-bottom: -0.25em;"><span class="MJXp-mrow" id="MJXp-Span-2673"><span class="MJXp-mn" id="MJXp-Span-2674">1</span></span></span></span></span><span class=" MJXp-script"><span><span style="margin-top: -0.85em;"><span class="MJXp-mrow" id="MJXp-Span-2669"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2670">t</span><span class="MJXp-mo" id="MJXp-Span-2671">+</span><span class="MJXp-mn" id="MJXp-Span-2672">1</span></span></span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-2675" style="margin-left: 0.333em; margin-right: 0.333em;">∣</span><span class="MJXp-msubsup" id="MJXp-Span-2676"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2677" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2678" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2679">θ</span></span></span><span class="MJXp-mo" id="MJXp-Span-2680" style="margin-left: 0.267em; margin-right: 0.267em;">∩</span><span class="MJXp-msubsup" id="MJXp-Span-2681"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2682" style="margin-right: 0.05em;">S</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2683" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2684">t</span></span></span><span class="MJXp-mo" id="MJXp-Span-2685" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-2686" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2687">θ</span><span class="MJXp-mo" id="MJXp-Span-2688" style="margin-left: 0em; margin-right: 0.222em;">.</span></span></span><div class="MathJax_Display MathJax_Processing"><span class="MathJax" id="MathJax-Element-346-Frame" tabindex="0"></span></div><script type="math/tex; mode=display" id="MathJax-Element-346"> P(Q^{1}_{t+1} \mid h_{\theta} \cap S_{t}) = \theta . </script>

This likelihood does not depend on the string <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2689"><span class="MJXp-msubsup" id="MJXp-Span-2690"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2691" style="margin-right: 0.05em;">S</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2692" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2693">t</span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-347-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-347">S_{t}</script> that has gone
before. The hypotheses are best thought of as determining a fixed bias
<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2694"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2695">θ</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-348-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-348">\theta</script> for the binary process, where <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2696"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2697">θ</span><span class="MJXp-mo" id="MJXp-Span-2698" style="margin-left: 0.333em; margin-right: 0.333em;">∈</span><span class="MJXp-mi" id="MJXp-Span-2699">Θ</span><span class="MJXp-mo" id="MJXp-Span-2700" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mo" id="MJXp-Span-2701" style="margin-left: 0em; margin-right: 0em;">[</span><span class="MJXp-mn" id="MJXp-Span-2702">0</span><span class="MJXp-mo" id="MJXp-Span-2703" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mn" id="MJXp-Span-2704">1</span><span class="MJXp-mo" id="MJXp-Span-2705" style="margin-left: 0em; margin-right: 0em;">]</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-349-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-349">\theta \in \Theta = [0,
1]</script>.  The <em>representation theorem</em>states that there is a
one-to-one mapping of priors over Bernoulli hypotheses and
exchangeable prediction rules. That is, every prior distribution
<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2706"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2707">P</span><span class="MJXp-mo" id="MJXp-Span-2708" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-2709"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2710" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2711" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2712">θ</span></span></span><span class="MJXp-mo" id="MJXp-Span-2713" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-350-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-350">P(h_{\theta})</script> can be associated with exactly one exchangeable
prediction rule <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2714"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2715">P</span><span class="MJXp-mo" id="MJXp-Span-2716" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-2717"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2718" style="margin-right: 0.05em;">Q</span><span class="MJXp-script-box" style="height: 1.86em; vertical-align: -0.64em;"><span class=" MJXp-script"><span><span style="margin-bottom: -0.25em;"><span class="MJXp-mrow" id="MJXp-Span-2723"><span class="MJXp-mn" id="MJXp-Span-2724">1</span></span></span></span></span><span class=" MJXp-script"><span><span style="margin-top: -0.85em;"><span class="MJXp-mrow" id="MJXp-Span-2719"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2720">t</span><span class="MJXp-mo" id="MJXp-Span-2721">+</span><span class="MJXp-mn" id="MJXp-Span-2722">1</span></span></span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-2725" style="margin-left: 0.333em; margin-right: 0.333em;">∣</span><span class="MJXp-msubsup" id="MJXp-Span-2726"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2727" style="margin-right: 0.05em;">S</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2728" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2729">n</span><span class="MJXp-mrow" id="MJXp-Span-2730"><span class="MJXp-mo" id="MJXp-Span-2731">/</span></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2732">t</span></span></span><span class="MJXp-mo" id="MJXp-Span-2733" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-351-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-351">P(Q^{1}_{t+1} \mid S_{n/t})</script>, and conversely. Next
to the original representation theorem derived by De Finetti, several
other and more general representation theorems were proved, e.g., for
partially exchangeable sequences and hypotheses on Markov processes
(Diaconis and Freedman 1980, Skyrms 1991), for clustering predictions
and partitioning processes (Kingman 1975 and 1978), and even for
sequences of graphs and their generating process (Aldous 1981).</p>

<p>Representation theorems equate a prior distribution over
statistical hypotheses to a prediction rule, and thus to a probability
assignment that can be given a subjective and behavioral
interpretation. This removes the worry expressed above, that the prior
distribution over hypotheses cannot be interpreted subjectively
because it cannot be related to belief as a willingness to act: priors
relate uniquely to particular predictions. However, for De Finetti the
representation theorem provided a reason for doing away with
statistical hypotheses altogether, and hence for the removal of a
notion of probability as anything other than subjective opinion (cf.
Hintikka 1970): hypotheses whose probabilistic claims could be taken
to refer to intangible chancy processes are superfluous metaphysical
baggage.</p>

<p>Not all subjectivists are equally dismissive of the use of
statistical hypotheses. Jeffrey (1992) has proposed so-called
<em>mixed Bayesianism</em> in which subjectively interpreted
distributions over the hypotheses are combined with a physical
interpretation of the distributions that hypotheses define over sample
space. Romeijn (2003, 2005, 2006) argues that priors over hypotheses
are an efficient and more intuitive way of determining inductive
predictions than specifying properties of predictive systems directly. This advantage of using hypotheses seems in agreement with the practice of science,
in which hypotheses are routinely used, and often motivated by mechanistic knowledge on the data generating process. The fact that statistical hypotheses can
strictly speaking be eliminated does not take away from their utility in making predictions.</p>

<h4><a id="BayStaLog">4.3.3 Bayesian statistics as logic</a></h4>

<p>Despite its—seemingly inevitable—subjective character,
there is a sense in which Bayesian statistics might lay claim to
objectivity. It can be shown that the Bayesian formalism meets certain
objective criteria of rationality, coherence, and
calibration. Bayesian statistics thus answers to the requirement of
objectivity at a meta-level: while the opinions that it deals with
retain a subjective aspect, the way in which it deals with these
opinions, in particular the way in which data impacts on them, is
objectively correct, or so it is argued. Arguments supporting the
Bayesian way of accommodating data, namely by
<em>conditionalization</em>, have been provided in a pragmatic context
by <em>dynamic Dutch book arguments</em>, whereby probability is
interpreted as a willingness to bet (cf. Maher 1993, van Fraassen
1989). Similar arguments have been advanced on the grounds that our
beliefs must accurately represent the world along the lines of De
Finetti (1974), e.g., Greaves and Wallace (2006) and Leitgeb and
Pettigrew (2010).</p>

<p>An important distinction must be made in arguments that support the
Bayesian way of accommodating evidence: the distinction between Bayes'
theorem, as a mathematical given, and <em>Bayes' rule</em>, as a
principle of coherence over time. The theorem is simply a mathematical
relation among probability assignments,

<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-2734"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2735">P</span><span class="MJXp-mo" id="MJXp-Span-2736" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2737">h</span><span class="MJXp-mo" id="MJXp-Span-2738" style="margin-left: 0.333em; margin-right: 0.333em;">∣</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2739">s</span><span class="MJXp-mo" id="MJXp-Span-2740" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mspace" id="MJXp-Span-2741" style="width: 0.278em; height: 0em;"></span><span class="MJXp-mo" id="MJXp-Span-2742" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mspace" id="MJXp-Span-2743" style="width: 0.278em; height: 0em;"></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2744">P</span><span class="MJXp-mo" id="MJXp-Span-2745" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2746">h</span><span class="MJXp-mo" id="MJXp-Span-2747" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mfrac" id="MJXp-Span-2748" style="vertical-align: 0.25em;"><span class="MJXp-box"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2749">P</span><span class="MJXp-mo" id="MJXp-Span-2750" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2751">s</span><span class="MJXp-mo" id="MJXp-Span-2752" style="margin-left: 0.333em; margin-right: 0.333em;">∣</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2753">h</span><span class="MJXp-mo" id="MJXp-Span-2754" style="margin-left: 0em; margin-right: 0em;">)</span></span><span class="MJXp-box" style="margin-top: -0.9em;"><span class="MJXp-denom"><span><span class="MJXp-rule" style="height: 1em; border-top: none; border-bottom: 1px solid; margin: 0.1em 0px;"></span></span><span><span class="MJXp-box"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2755">P</span><span class="MJXp-mo" id="MJXp-Span-2756" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2757">s</span><span class="MJXp-mo" id="MJXp-Span-2758" style="margin-left: 0em; margin-right: 0em;">)</span></span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-2759" style="margin-left: 0em; margin-right: 0.222em;">,</span></span></span><div class="MathJax_Display MathJax_Processing"><span class="MathJax" id="MathJax-Element-352-Frame" tabindex="0"></span></div><script type="math/tex; mode=display" id="MathJax-Element-352"> P(h \mid s) \; = \; P(h) \frac{P(s \mid h)}{P(s)} , </script>

and as such not subject to debate. Arguments that support the
representation of the epistemic state of an agent by means of
probability assignments also provide support for Bayes' theorem as a
constraint on degrees of belief. The conditional probability <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2760"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2761">P</span><span class="MJXp-mo" id="MJXp-Span-2762" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2763">h</span><span class="MJXp-mo" id="MJXp-Span-2764" style="margin-left: 0.333em; margin-right: 0.333em;">∣</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2765">s</span><span class="MJXp-mo" id="MJXp-Span-2766" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-353-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-353">P(h
\mid s)</script> can be interpreted as the degree of belief attached to the
hypothesis <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2767"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2768">h</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-354-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-354">h</script> on the condition that the sample <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2769"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2770">s</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-355-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-355">s</script> is obtained,
as integral part of the epistemic state captured by the probability
assignment. Bayes' rule, by contrast, presents a constraint on
probability assignments that represent epistemic states of an agent at
different points in time. It is written as

<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-2771"><span class="MJXp-msubsup" id="MJXp-Span-2772"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2773" style="margin-right: 0.05em;">P</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2774" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2775">s</span></span></span><span class="MJXp-mo" id="MJXp-Span-2776" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2777">h</span><span class="MJXp-mo" id="MJXp-Span-2778" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mspace" id="MJXp-Span-2779" style="width: 0.278em; height: 0em;"></span><span class="MJXp-mo" id="MJXp-Span-2780" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2781">P</span><span class="MJXp-mo" id="MJXp-Span-2782" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2783">h</span><span class="MJXp-mo" id="MJXp-Span-2784" style="margin-left: 0.333em; margin-right: 0.333em;">∣</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2785">s</span><span class="MJXp-mo" id="MJXp-Span-2786" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-2787" style="margin-left: 0em; margin-right: 0.222em;">,</span></span></span><div class="MathJax_Display MathJax_Processing"><span class="MathJax" id="MathJax-Element-356-Frame" tabindex="0"></span></div><script type="math/tex; mode=display" id="MathJax-Element-356"> P_{s}(h) \; = P(h \mid s) , </script>

and it determines that the new probability assignment, expressing the
epistemic state of the agent after the sample has been obtained, is
systematically related to the old assignment, representing the
epistemic state before the sample came in. In the philosophy of
statistics many Bayesians adopt Bayes' rule implicitly, but in what
follows I will only assume that Bayesian statistical inferences rely
on Bayes' theorem.</p>

<p>Whether the focus lies on Bayes' rule or on Bayes' theorem, the
common theme in the above-mentioned arguments is that they approach
Bayesian statistical inference from a logical angle, and focus on its
internal coherence or consistency (cf. Howson 2003). While its use in
statistics is undeniably inductive, Bayesian inference thereby obtains
a deductive, or at least non-ampliative character: everything that is
concluded in the inference is somehow already present in the
premises. In Bayesian statistical inference, those premises are given
by the prior over the hypotheses, <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2788"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2789">P</span><span class="MJXp-mo" id="MJXp-Span-2790" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-2791"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2792" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2793" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2794">θ</span></span></span><span class="MJXp-mo" id="MJXp-Span-2795" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-357-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-357">P(h_{\theta})</script> for <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2796"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2797">θ</span><span class="MJXp-mo" id="MJXp-Span-2798" style="margin-left: 0.333em; margin-right: 0.333em;">∈</span><span class="MJXp-mi" id="MJXp-Span-2799">Θ</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-358-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-358">\theta \in
\Theta</script>, and the likelihood functions, <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2800"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2801">P</span><span class="MJXp-mo" id="MJXp-Span-2802" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2803">s</span><span class="MJXp-mo" id="MJXp-Span-2804" style="margin-left: 0.333em; margin-right: 0.333em;">∣</span><span class="MJXp-msubsup" id="MJXp-Span-2805"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2806" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2807" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2808">θ</span></span></span><span class="MJXp-mo" id="MJXp-Span-2809" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-359-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-359">P(s \mid h_{\theta})</script>, as
determined for each hypothesis <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2810"><span class="MJXp-msubsup" id="MJXp-Span-2811"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2812" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2813" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2814">θ</span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-360-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-360">h_{\theta}</script> separately.  These
premises fix a single probability assignment over the space <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2815"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2816">M</span><span class="MJXp-mo" id="MJXp-Span-2817" style="margin-left: 0.267em; margin-right: 0.267em;">×</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2818">S</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-361-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-361">M \times
S</script> at the outset of the inference. The conclusions, in turn, are
straightforward consequences of this probability assignment. They can
be derived by applying theorems of probability theory, most notably
Bayes' theorem. Bayesian statistical inference thus becomes an
instance of <em>probabilistic logic</em> (cf. Hailperin 1986, Halpern
2003, Haenni <em>et al</em> 2011).</p>

<p>Summing up, there are several arguments showing that statistical
inference by Bayes' theorem, or by Bayes' rule, is objectively
correct. These arguments invite us to consider Bayesian statistics as
an instance of probabilistic logic.  Such appeals to the logicality of
Bayesian statistical inference may provide a partial remedy for its
subjective character. Moreover, a logical approach to the statistical
inferences avoids the problem that the formalism places
unrealistic demands on the agents, and that it presumes the agent to
have certain knowledge. Much like in deductive logic, we need not
assume that the inferences are psychologically realistic, nor that the
agents actually believe the premises of the arguments. Rather the
arguments present the agents with a normative ideal and take the
conditional form of consistency constraints: if you accept the
premises, then these are the conclusions.</p>

<h4><a id="ExcIndLogSta">4.3.4 Excursion: inductive logic and statistics</a></h4>

<p>An important instance of probabilistic logic is presented in
<em>inductive logic</em>, as devised by Carnap, Hintikka and others
(Carnap 1950 and 1952, Hintikka and Suppes 1966, Carnap and Jeffrey
1970, Hintikka and Niiniluoto 1980, Kuipers 1978, and Paris 1994, Nix
and Paris 2006, Paris and Waterhouse 2009). Historically, Carnapian
inductive logic developed prior to the probabilistic logics referenced
above, and more or less separately from the debates in the philosophy
of statistics. But the logical systems of Carnap can quite easily be
placed in the context of a logical approach to Bayesian inference, and
doing this is in fact quite insightful.</p>

<p>For simplicity, we choose a setting that is similar to the one used
in the exposition of the representation theorem, namely a binary data
generating process, i.e., strings of 0's and 1's. A prediction rule
determines a probability for the event, denoted <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2819"><span class="MJXp-msubsup" id="MJXp-Span-2820"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2821" style="margin-right: 0.05em;">Q</span><span class="MJXp-script-box" style="height: 1.86em; vertical-align: -0.64em;"><span class=" MJXp-script"><span><span style="margin-bottom: -0.25em;"><span class="MJXp-mrow" id="MJXp-Span-2826"><span class="MJXp-mn" id="MJXp-Span-2827">1</span></span></span></span></span><span class=" MJXp-script"><span><span style="margin-top: -0.85em;"><span class="MJXp-mrow" id="MJXp-Span-2822"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2823">t</span><span class="MJXp-mo" id="MJXp-Span-2824">+</span><span class="MJXp-mn" id="MJXp-Span-2825">1</span></span></span></span></span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-362-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-362">Q^{1}_{t+1}</script>, that
the next bit in the string is a 1, on the basis of a given string of
bits with length <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2828"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2829">t</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-363-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-363">t</script>, denoted by <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2830"><span class="MJXp-msubsup" id="MJXp-Span-2831"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2832" style="margin-right: 0.05em;">S</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2833" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2834">t</span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-364-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-364">S_{t}</script>. Carnap and followers
designed specific exchangeable prediction rules, mostly variants of
the <em>straight rule</em> (Reichenbach 1938),

<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-2835"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2836">P</span><span class="MJXp-mo" id="MJXp-Span-2837" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-2838"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2839" style="margin-right: 0.05em;">Q</span><span class="MJXp-script-box" style="height: 1.86em; vertical-align: -0.64em;"><span class=" MJXp-script"><span><span style="margin-bottom: -0.25em;"><span class="MJXp-mrow" id="MJXp-Span-2844"><span class="MJXp-mn" id="MJXp-Span-2845">1</span></span></span></span></span><span class=" MJXp-script"><span><span style="margin-top: -0.85em;"><span class="MJXp-mrow" id="MJXp-Span-2840"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2841">t</span><span class="MJXp-mo" id="MJXp-Span-2842">+</span><span class="MJXp-mn" id="MJXp-Span-2843">1</span></span></span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-2846" style="margin-left: 0.333em; margin-right: 0.333em;">∣</span><span class="MJXp-msubsup" id="MJXp-Span-2847"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2848" style="margin-right: 0.05em;">S</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2849" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2850">n</span><span class="MJXp-mrow" id="MJXp-Span-2851"><span class="MJXp-mo" id="MJXp-Span-2852">/</span></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2853">t</span></span></span><span class="MJXp-mo" id="MJXp-Span-2854" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-2855" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mfrac" id="MJXp-Span-2856" style="vertical-align: 0.25em;"><span class="MJXp-box"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2857">n</span><span class="MJXp-mo" id="MJXp-Span-2858" style="margin-left: 0.267em; margin-right: 0.267em;">+</span><span class="MJXp-mn" id="MJXp-Span-2859">1</span></span><span class="MJXp-box" style="margin-top: -0.9em;"><span class="MJXp-denom"><span><span class="MJXp-rule" style="height: 1em; border-top: none; border-bottom: 1px solid; margin: 0.1em 0px;"></span></span><span><span class="MJXp-box"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2860">t</span><span class="MJXp-mo" id="MJXp-Span-2861" style="margin-left: 0.267em; margin-right: 0.267em;">+</span><span class="MJXp-mn" id="MJXp-Span-2862">2</span></span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-2863" style="margin-left: 0em; margin-right: 0.222em;">,</span></span></span><div class="MathJax_Display MathJax_Processing"><span class="MathJax" id="MathJax-Element-365-Frame" tabindex="0"></span></div><script type="math/tex; mode=display" id="MathJax-Element-365"> P(Q^{1}_{t+1} \mid S_{n/t}) = \frac{n + 1}{t + 2} , </script>

where <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2864"><span class="MJXp-msubsup" id="MJXp-Span-2865"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2866" style="margin-right: 0.05em;">S</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2867" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2868">n</span><span class="MJXp-mrow" id="MJXp-Span-2869"><span class="MJXp-mo" id="MJXp-Span-2870">/</span></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2871">t</span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-366-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-366">S_{n/t}</script> denotes a string of length <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2872"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2873">t</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-367-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-367">t</script> of which <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2874"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2875">n</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-368-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-368">n</script>
entries are 1's. Carnap derived such rules from constraints on the
probability assignments over the samples. Some of these constraints
boil down to the axioms of probability. Other constraints,
exchangeability among them, are independently motivated, by an appeal
to so-called <em>logical interpretation of probability</em>.  Under
this logical interpretation, the probability assignment must respect
certain invariances under transformations of the sample space, in
analogy to logical principles that constrain truth valuations over a
language in a particular way.</p>

<p>Carnapian inductive logic is an instance of probabilistic logic,
because its sequential predictions are all based on a single
probability assignment at the outset, and because it relies on Bayes'
theorem to adapt the predictions to sample data (cf. Romeijn 2011).
One important difference with Bayesian statistical inference is that,
for Carnap, the probability assignment specified at the outset only
ranges over samples and not over hypotheses. However, by De Finetti's
representation theorem Carnap's exchangeable rules can be equated to
particular Bayesian statistical inferences. A further difference is
that Carnapian inductive logic gives preferred status to particular
exchangeable rules. In view of De Finetti's representation theorem,
this comes down to the choice for a particular set of preferred
priors. As further developed below, Carnapian inductive logic is thus
related to objective Bayesian statistics. It is a moot point whether
further constraints on the probability assignments can be considered
as logical, as Carnap and followers have it, or whether the title of
logic is best reserved for the probability formalism in isolation, as
De Finetti and followers argue. </p>

<h4><a id="ObjPri">4.3.5 Objective priors</a></h4>

<p>A further set of responses to the subjectivity of Bayesian
statistical inference targets the prior distribution directly: we
might provide further rationality principles, with which the choice of
priors can be chosen objectively. The literature proposes several
objective criteria for filling in the prior over the model. Each of
these lays claim to being the correct expression of complete ignorance
concerning the value of the model parameters, or of minimal
information regarding the parameters. Three such criteria are
discussed here.</p>

<p>In the context of Bertrand's paradox we already discussed
the principle of indifference, according to which probability
should be distributed evenly over the available possibilities. A
further development of this idea is presented by the requirement that
a distribution should have maximum entropy. Notably, the use of
entropy maximization for determining degrees of beliefs finds much
broader application than only in statistics: similar ideas are taken
up in diverse fields like epistemology (e.g., Shore and Johnson 1980,
Williams 1980, Uffink 1996, and also Williamson 2010), inductive logic
(Paris and Vencovska 1989), statistical mechanics (Jaynes 2003)
and decision theory (Seidenfeld 1986, Grunwald and Halpern 2004). In
<em>objective Bayesian statistics</em>, the idea is applied to the
prior distribution over the model (cf. Berger 2006).  For a finite
number of hypotheses the entropy of the distribution <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2876"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2877">P</span><span class="MJXp-mo" id="MJXp-Span-2878" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-2879"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2880" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2881" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2882">θ</span></span></span><span class="MJXp-mo" id="MJXp-Span-2883" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-369-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-369">P(h_{\theta})</script>
is defined as

<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-2884"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2885">E</span><span class="MJXp-mo" id="MJXp-Span-2886" style="margin-left: 0em; margin-right: 0em;">[</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2887">P</span><span class="MJXp-mo" id="MJXp-Span-2888" style="margin-left: 0em; margin-right: 0em;">]</span><span class="MJXp-mspace" id="MJXp-Span-2889" style="width: 0.278em; height: 0em;"></span><span class="MJXp-mo" id="MJXp-Span-2890" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mspace" id="MJXp-Span-2891" style="width: 0.278em; height: 0em;"></span><span class="MJXp-munderover" id="MJXp-Span-2892"><span class=""><span class="MJXp-mo" id="MJXp-Span-2893" style="margin-left: 0.111em; margin-right: 0.167em;"><span class="MJXp-largeop">∑</span></span></span><span class=" MJXp-script"><span class="MJXp-mrow" id="MJXp-Span-2894" style="margin-left: 0px;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2895">θ</span><span class="MJXp-mo" id="MJXp-Span-2896">∈</span><span class="MJXp-mi" id="MJXp-Span-2897">Θ</span></span></span></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2898">P</span><span class="MJXp-mo" id="MJXp-Span-2899" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-2900"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2901" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2902" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2903">θ</span></span></span><span class="MJXp-mo" id="MJXp-Span-2904" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mi" id="MJXp-Span-2905">log</span><span class="MJXp-mo" id="MJXp-Span-2906" style="margin-left: 0em; margin-right: 0em;"></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2907">P</span><span class="MJXp-mo" id="MJXp-Span-2908" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-2909"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2910" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2911" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2912">θ</span></span></span><span class="MJXp-mo" id="MJXp-Span-2913" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-2914" style="margin-left: 0em; margin-right: 0.222em;">.</span></span></span><div class="MathJax_Display MathJax_Processing"><span class="MathJax" id="MathJax-Element-370-Frame" tabindex="0"></span></div><script type="math/tex; mode=display" id="MathJax-Element-370"> E[P] \; = \; \sum_{\theta \in \Theta} P(h_{\theta}) \log
P(h_{\theta}) . </script>

This requirement unequivocally leads to equiprobable
hypotheses. However, for continuous models the maximum entropy
distribution depends crucially on the metric over the parameters in
the model. The burden of subjectivity is thereby moved to the
parameterization, but of course it may well be that we have strong
reasons for preferring a particular parameterization over others (cf.
Jaynes 1973).</p>

<p>There are other approaches to the objective determination of
priors. In view of the above problems, a particularly attractive
method for choosing a prior over a continuous model is proposed by
Jeffreys (1961). The general idea of so-called <em>Jeffreys
priors</em> is that the prior probability assigned to a small patch in
the parameter space is proportional to, what may be called, the
density of the distributions within that patch. Intuitively, if a lot
of distributions, i.e., distributions that differ quite a lot among
themselves, are packed together on a small patch in the parameter
space, this patch should be given a larger prior probability than a
similar patch within which there is little variation among the
distributions (cf. Balasubramanian 2005). More technically, such a
density is expressed by a prior distribution that is proportional to
the <em>Fisher information</em>.  A key advantage of these priors is
that they are invariant under reparameterizations of the parameter
space: a new parameterization naturally leads to an adjusted density
of distributions.</p>

<p>A final method of defining priors goes under the name of
<em>reference priors</em> (Berger et al 2009). The proposal
starts from the observation that we should minimize the subjectivity
of the results of our statistical analysis, and hence that we should
minimize the impact of the prior probability on the posterior. The
idea of reference priors is exactly that it will allow the sample data
a maximal say in the posterior distribution. But since at the outset
we do not know what sample we will obtain, the prior is chosen so as
to maximize the expected impact of the data. The expectation must
itself be taken with respect to some distribution over sample space,
but again, it may well be that we have strong reasons for this latter
distribution.</p>

<h4><a id="CirPri">4.3.6 Circumventing priors</a></h4>

<p>A different response to the subjectivity of priors is to
extend the Bayesian formalism, in order to leave the choice of prior
to some extent open. The subjective choice of a prior is in that case
circumvented. Two such responses will be considered in some
detail.</p>

<p>Recall that a prior probability distribution over statistical
hypotheses expresses our uncertain opinion on which of the hypotheses
is right. The central idea behind <em>hierarchical Bayesian
models</em> (Gelman et al 2013) is that the same pattern of putting a
prior over statistical hypotheses can be repeated on the level of
priors itself. More precisely, we may be uncertain over which prior
probability distribution over the hypotheses is right. If we
characterize possible priors by means of a set of parameters, we can
express this uncertainty about prior choice in a probability
distribution over the parameters that characterize the shape of the
prior. In other words, we move our uncertainty one level up in a
hierarchy: we consider multiple priors over the statistical
hypotheses, and compare the performance of these priors on the sample
data as if the priors were themselves hypotheses.</p>

<p>The idea of hierarchical Bayesian modeling (Gelman et al 2013)
relates naturally to the Bayesian comparison of Carnapian prediction
rules (e.g., Skyrms 1993 and 1996, Festa 1996), and also to the
estimation of optimum inductive methods (Kuipers 1986, Festa 1993).
Hierarchical Bayesian modeling can also be related to another
tool for choosing a particular prior distribution over hypotheses,
namely the method of <em>empirical Bayes</em>, which estimates the
prior that leads to the maximal marginal likelihood of the model. In
the philosophy of science, hierarchical Bayesian modeling has made a
first appearance due to Henderson <em>et al </em>(2010).</p> 

<p>There is also a response that avoids the choice of a prior
altogether. This response starts with the same idea as hierarchical
models: rather than considering a single prior over the hypotheses in
the model, we consider a parameterized set of them. But instead of
defining a distribution over this set, proponents of
<em>interval-valued</em> or <em>imprecise probability</em> claim that
our epistemic state regarding the priors is better expressed by this
set of distributions, and that sharp probability assignments must
therefore be replaced by lower and upper bounds to the
assignments. Now the idea that uncertain opinion is best captured by a
set of probability assignments, or a <em>credal set</em> for short,
has a long history and is backed by an extensive literature (e.g., De
Finetti 1974, Levi 1980, Dempster 1967 and 1968, Shafer 1976, Walley
1991). In light of the main debate in the philosophy of statistics,
the use of interval-valued priors indeed forms an attractive extension
of Bayesian statistics: it allows us to refrain from choosing a
specific prior, and thereby presents a rapprochement to the classical
view on statistics.</p>

<p>These theoretical developments may look attractive, but the fact is
that they mostly enjoy a cult status among philosophers of statistics
and that they have not moved the statistician in the street. On the
other hand, standard Bayesian statistics has seen a steep rise in
popularity over the past decade or so, owing to the availability of
good software and numerical approximation methods. And most of the
practical use of Bayesian statistics is more or less insensitive to
the potentially subjective aspects of the statistical results,
employing uniform priors as a neutral starting point for the analysis
and relying on the afore-mentioned convergence results to wash out the
remaining subjectivity (cf. Gelman and Shalizi 2013). However, this
practical attitude of scientists towards modelling should not be
mistaken for a principled answer to the questions raised in the
philosophy of statistics (see Morey <em>et al</em> 2013).</p>

<h2><a id="StaMod">5. Statistical models</a></h2>

<p>In the foregoing we have seen how classical and Bayesian statistics
differ. But the two major approaches to statistics also have a lot in
common. Most importantly, all statistical procedures rely on the
assumption of a <em>statistical model</em>, here referring to any
restricted set of statistical hypotheses.  Moreover, they are both
aimed at delivering a verdict over these hypotheses.  For example, a
classical likelihood ratio test considers two hypotheses, <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2915"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2916">h</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-371-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-371">h</script> and
<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2917"><span class="MJXp-msup" id="MJXp-Span-2918"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2919" style="margin-right: 0.05em;">h</span><span class="MJXp-mo MJXp-script" id="MJXp-Span-2920" style="vertical-align: 0.5em;">′</span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-372-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-372">h'</script>, and then offers a verdict of rejection and acceptance, while a
Bayesian comparison delivers a posterior probability over these two
hypotheses. Whereas in Bayesian statistics the model presents a very
strong assumption, classical statistics does not endow the model with
a special epistemic status: they are simply the hypotheses currently
entertained by the scientist. But across the board, the adoption of a
model is absolutely central to any statistical procedure.</p>

<p>A natural question is whether anything can be said about the
quality of the statistical model, and whether any verdict on this
starting point for statistical procedures can be given. Surely some
models will lead to better predictions, or be a better guide to the
truth, than others. The evaluation of models touches on deep issues in
the philosophy of science, because the statistical model often
determines how the data-generating system under investigation is
conceptualized and approached (Kieseppa 2001). Model choice thus
resembles the choice of a theory, a conceptual scheme, or even of a
whole paradigm, and thereby might seem to transcend the formal
frameworks for studying theoretical rationality (cf. Carnap 1950,
Jeffrey 1980). Despite the fact that some considerations on model
choice will seem extra-statistical, in the sense that they fall
outside the scope of statistical treatment, statistics offers several
methods for approaching the choice of statistical models.</p>

<h3><a id="ModCom">5.1 Model comparisons</a></h3>

<p>There are in fact very many methods for evaluating statistical
models (Claeskens and Hjort 2008, Wagenmakers and Waldorp 2006). In
first instance, the methods occasion the comparison of statistical
models, but very often they are used for selecting one model over the
others. In what follows we only review prominent techniques that have
led to philosophical debate: Akaike's information criterion, the
Bayesian information criterion, and furthermore the computation of
marginal likelihoods and posterior model probabilities, both
associated with Bayesian model selection. We leave aside methods that
use cross-validation as they have, unduly, not received as much
attention in the philosophical literature.</p>

<h4><a id="AkaInfCri">5.1.1 Akaike's information criterion</a></h4>

<p><em>Akaike's information criterion</em>, modestly termed An
Information Criterion or AIC for short, is based on the classical
statistical procedure of estimation (see Burnham and Anderson 2002,
Kieseppa 1997). It starts from the idea that a model <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2921"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2922">M</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-373-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-373">M</script> can be
judged by the estimate <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2923"><span class="MJXp-mrow" id="MJXp-Span-2924"><span class="MJXp-munderover" id="MJXp-Span-2925"><span><span class="MJXp-over"><span class="" style="margin-bottom: -0.92em;"><span class="MJXp-mo" id="MJXp-Span-2927" style="margin-left: 0px; margin-right: 0px;">ˆ</span></span><span class=""><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2926">θ</span></span></span></span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-374-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-374">\hat{\theta}</script> that it delivers, and more
specifically by the proximity of this estimate to the distribution
with which the data are actually generated, i.e., the true
distribution. This proximity is often equated with the expected
predictive accuracy of the estimate, because if the estimate and the
true distribution are closer to each other, their predictions will be
better aligned to one another as well. In the derivation of the AIC,
the so-called relative entropy or <em>Kullback-Leibler divergence</em>
of the two distributions is used as a measure of their proximity, and
hence as a measure of the expected predictive accuracy of the
estimate.</p>

<p>Naturally, the true distribution is not known to the statistician
who is evaluating the model. If it were, then the whole statistical
analysis would be useless. However, it turns out that we can give an
unbiased estimation of the divergence between the true distribution
and the distribution estimated from a particular model,

 <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-2928"><span class="MJXp-mtext" id="MJXp-Span-2929">AIC</span><span class="MJXp-mo" id="MJXp-Span-2930" style="margin-left: 0em; margin-right: 0em;">[</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2931">M</span><span class="MJXp-mo" id="MJXp-Span-2932" style="margin-left: 0em; margin-right: 0em;">]</span><span class="MJXp-mo" id="MJXp-Span-2933" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mo" id="MJXp-Span-2934" style="margin-left: 0.267em; margin-right: 0.267em;">−</span><span class="MJXp-mn" id="MJXp-Span-2935">2</span><span class="MJXp-mi" id="MJXp-Span-2936">log</span><span class="MJXp-mo" id="MJXp-Span-2937" style="margin-left: 0em; margin-right: 0em;"></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2938">P</span><span class="MJXp-mo" id="MJXp-Span-2939" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2940">s</span><span class="MJXp-mo" id="MJXp-Span-2941" style="margin-left: 0.333em; margin-right: 0.333em;">∣</span><span class="MJXp-msubsup" id="MJXp-Span-2942"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2943" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-2944" style="vertical-align: -0.4em;"><span class="MJXp-mrow" id="MJXp-Span-2945"><span class="MJXp-munderover" id="MJXp-Span-2946"><span><span class="MJXp-over"><span class=" MJXp-script" style="margin-bottom: -0.92em;"><span class="MJXp-mo" id="MJXp-Span-2948" style="margin-right: 0px; margin-left: 0px;">ˆ</span></span><span class=""><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2947">θ</span></span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-2949">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2950">s</span><span class="MJXp-mo" id="MJXp-Span-2951">)</span></span></span><span class="MJXp-mo" id="MJXp-Span-2952" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-2953" style="margin-left: 0.267em; margin-right: 0.267em;">+</span><span class="MJXp-mn" id="MJXp-Span-2954">2</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2955">d</span><span class="MJXp-mo" id="MJXp-Span-2956" style="margin-left: 0em; margin-right: 0.222em;">,</span></span></span><div class="MathJax_Display MathJax_Processing"><span class="MathJax" id="MathJax-Element-375-Frame" tabindex="0"></span></div><script type="math/tex; mode=display" id="MathJax-Element-375"> \text{AIC}[M] = - 2 \log P( s \mid h_{\hat{\theta}(s)} ) + 2 d , </script>

in which <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2957"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2958">s</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-376-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-376">s</script> is the sample data, <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2959"><span class="MJXp-mrow" id="MJXp-Span-2960"><span class="MJXp-munderover" id="MJXp-Span-2961"><span><span class="MJXp-over"><span class="" style="margin-bottom: -0.92em;"><span class="MJXp-mo" id="MJXp-Span-2963" style="margin-left: 0px; margin-right: 0px;">ˆ</span></span><span class=""><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2962">θ</span></span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-2964" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2965">s</span><span class="MJXp-mo" id="MJXp-Span-2966" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-377-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-377">\hat{\theta}(s)</script> is the maximum
likelihood estimate (MLE) of the model <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2967"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2968">M</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-378-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-378">M</script>, and <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2969"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2970">d</span><span class="MJXp-mo" id="MJXp-Span-2971" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2972">d</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2973">i</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2974">m</span><span class="MJXp-mo" id="MJXp-Span-2975" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi" id="MJXp-Span-2976">Θ</span><span class="MJXp-mo" id="MJXp-Span-2977" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-379-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-379">d = dim(\Theta)</script>
is the number of dimensions of the parameter space of the model. The
MLE of the model thereby features in an expression of the model
quality, i.e., in a role that is conceptually distinct from the
estimator function.</p>

<p>As can be seen from the expression above, a model with a smaller
AIC is preferable: we want the fit to be optimal at little cost in
complexity. Notice that the number of dimensions, or independent
parameters, in the model increases the AIC and thereby lowers the
eligibility of the model: if two models achieve the same maximum
likelihood for the sample, then the model with fewer parameters will
be preferred. For this reason, statistical model selection by the AIC
can be seen as an independent motivation for preferring simple models
over more complex ones (Sober and Forster 1994). But this result also
invites some critical remarks. For one, we might impose other criteria
than merely the unbiasedness on the estimation of the proximity to the
truth, and this will lead to different expressions for the
approximation. Moreover, it is not always clearcut what the
dimensions of the model under scrutiny really are. For curve fitting
this may seem simple, but for more complicated models or different
conceptualizations of the space of models, things do not look so easy
(cf. Myung et al 2001, Kieseppa 2001). </p>

<p>A prime example of model selection is presented in <em>curve
fitting</em>.  Given a sample <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2978"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2979">s</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-380-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-380">s</script> consisting of a set of points in
the plane <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2980"><span class="MJXp-mo" id="MJXp-Span-2981" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2982">x</span><span class="MJXp-mo" id="MJXp-Span-2983" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2984">y</span><span class="MJXp-mo" id="MJXp-Span-2985" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-381-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-381">(x, y)</script>, we are asked to choose the curve that fits these
data best. We assume that the models under consideration are of the
form <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2986"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2987">y</span><span class="MJXp-mo" id="MJXp-Span-2988" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2989">f</span><span class="MJXp-mo" id="MJXp-Span-2990" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2991">x</span><span class="MJXp-mo" id="MJXp-Span-2992" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-2993" style="margin-left: 0.267em; margin-right: 0.267em;">+</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2994">ϵ</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-382-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-382">y = f(x) + \epsilon</script>, where <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2995"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2996">ϵ</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-383-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-383">\epsilon</script> is a normal
distribution with mean 0 and a fixed standard deviation, and where
<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2997"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2998">f</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-384-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-384">f</script> is a polynomial function. Different models are characterized by
polynomials of different degrees that have different numbers of
parameters. Estimations fix the parameters of these polynomials. For
example, for the 0-degree polynomial <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-2999"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3000">f</span><span class="MJXp-mo" id="MJXp-Span-3001" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3002">x</span><span class="MJXp-mo" id="MJXp-Span-3003" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-3004" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-msubsup" id="MJXp-Span-3005"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3006" style="margin-right: 0.05em;">c</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-3007" style="vertical-align: -0.4em;"><span class="MJXp-mn" id="MJXp-Span-3008">0</span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-385-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-385">f(x) = c_{0}</script> we estimate the
constant <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-3009"><span class="MJXp-mrow" id="MJXp-Span-3010"><span class="MJXp-munderover" id="MJXp-Span-3011"><span><span class="MJXp-over"><span class=""><span class="MJXp-mo" id="MJXp-Span-3016" style="margin-left: 0px; margin-right: 0px;">^</span></span><span class=""><span class="MJXp-msubsup" id="MJXp-Span-3012"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3013" style="margin-right: 0.05em;">c</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-3014" style="vertical-align: -0.4em;"><span class="MJXp-mn" id="MJXp-Span-3015">0</span></span></span></span></span></span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-386-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-386">\hat{c_{0}}</script> for which the probability of the data is
maximal, and for the 1-degree polynomial <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-3017"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3018">f</span><span class="MJXp-mo" id="MJXp-Span-3019" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3020">x</span><span class="MJXp-mo" id="MJXp-Span-3021" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-3022" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-msubsup" id="MJXp-Span-3023"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3024" style="margin-right: 0.05em;">c</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-3025" style="vertical-align: -0.4em;"><span class="MJXp-mn" id="MJXp-Span-3026">0</span></span></span><span class="MJXp-mo" id="MJXp-Span-3027" style="margin-left: 0.267em; margin-right: 0.267em;">+</span><span class="MJXp-msubsup" id="MJXp-Span-3028"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3029" style="margin-right: 0.05em;">c</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-3030" style="vertical-align: -0.4em;"><span class="MJXp-mn" id="MJXp-Span-3031">1</span></span></span><span class="MJXp-mspace" id="MJXp-Span-3032" style="width: 0.167em; height: 0em;"></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3033">x</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-387-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-387">f(x) = c_{0} + c_{1}\, x</script>
we estimate the slope <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-3034"><span class="MJXp-mrow" id="MJXp-Span-3035"><span class="MJXp-munderover" id="MJXp-Span-3036"><span><span class="MJXp-over"><span class=""><span class="MJXp-mo" id="MJXp-Span-3041" style="margin-left: 0px; margin-right: 0px;">^</span></span><span class=""><span class="MJXp-msubsup" id="MJXp-Span-3037"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3038" style="margin-right: 0.05em;">c</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-3039" style="vertical-align: -0.4em;"><span class="MJXp-mn" id="MJXp-Span-3040">1</span></span></span></span></span></span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-388-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-388">\hat{c_{1}}</script> and the offset
<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-3042"><span class="MJXp-mrow" id="MJXp-Span-3043"><span class="MJXp-munderover" id="MJXp-Span-3044"><span><span class="MJXp-over"><span class=""><span class="MJXp-mo" id="MJXp-Span-3049" style="margin-left: 0px; margin-right: 0px;">^</span></span><span class=""><span class="MJXp-msubsup" id="MJXp-Span-3045"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3046" style="margin-right: 0.05em;">c</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-3047" style="vertical-align: -0.4em;"><span class="MJXp-mn" id="MJXp-Span-3048">0</span></span></span></span></span></span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-389-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-389">\hat{c_{0}}</script>. Now notice that for a total of <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-3050"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3051">n</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-390-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-390">n</script> points, we can
always find a polynomial of degree <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-3052"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3053">n</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-391-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-391">n</script> that intersects with all
points exactly, resulting in a comparatively high maximum likelihood
<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-3054"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3055">P</span><span class="MJXp-mo" id="MJXp-Span-3056" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3057">s</span><span class="MJXp-mo" id="MJXp-Span-3058" style="margin-left: 0.333em; margin-right: 0.333em;">∣</span><span class="MJXp-mo" id="MJXp-Span-3059" style="margin-left: 0em; margin-right: 0em;">{</span><span class="MJXp-mrow" id="MJXp-Span-3060"><span class="MJXp-munderover" id="MJXp-Span-3061"><span><span class="MJXp-over"><span class=""><span class="MJXp-mo" id="MJXp-Span-3066" style="margin-left: 0px; margin-right: 0px;">^</span></span><span class=""><span class="MJXp-msubsup" id="MJXp-Span-3062"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3063" style="margin-right: 0.05em;">c</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-3064" style="vertical-align: -0.4em;"><span class="MJXp-mn" id="MJXp-Span-3065">0</span></span></span></span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-3067" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mo" id="MJXp-Span-3068" style="margin-left: 0em; margin-right: 0em;">…</span><span class="MJXp-mrow" id="MJXp-Span-3069"><span class="MJXp-munderover" id="MJXp-Span-3070"><span><span class="MJXp-over"><span class=""><span class="MJXp-mo" id="MJXp-Span-3075" style="margin-left: 0px; margin-right: 0px;">^</span></span><span class=""><span class="MJXp-msubsup" id="MJXp-Span-3071"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3072" style="margin-right: 0.05em;">c</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-3073" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3074">n</span></span></span></span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-3076" style="margin-left: 0em; margin-right: 0em;">}</span><span class="MJXp-mo" id="MJXp-Span-3077" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-392-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-392">P(s \mid \{\hat{c_{0}}, \ldots \hat{c_{n}} \})</script>. Applying the AIC,
however, we will typically find that some model with a polynomial of
degree <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-3078"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3079">k</span><span class="MJXp-mo" id="MJXp-Span-3080" style="margin-left: 0.333em; margin-right: 0.333em;">&lt;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3081">n</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-393-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-393">k &lt; n</script> is preferable. Although <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-3082"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3083">P</span><span class="MJXp-mo" id="MJXp-Span-3084" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3085">s</span><span class="MJXp-mo" id="MJXp-Span-3086" style="margin-left: 0.333em; margin-right: 0.333em;">∣</span><span class="MJXp-mo" id="MJXp-Span-3087" style="margin-left: 0em; margin-right: 0em;">{</span><span class="MJXp-mrow" id="MJXp-Span-3088"><span class="MJXp-munderover" id="MJXp-Span-3089"><span><span class="MJXp-over"><span class=""><span class="MJXp-mo" id="MJXp-Span-3094" style="margin-left: 0px; margin-right: 0px;">^</span></span><span class=""><span class="MJXp-msubsup" id="MJXp-Span-3090"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3091" style="margin-right: 0.05em;">c</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-3092" style="vertical-align: -0.4em;"><span class="MJXp-mn" id="MJXp-Span-3093">0</span></span></span></span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-3095" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mo" id="MJXp-Span-3096" style="margin-left: 0em; margin-right: 0em;">…</span><span class="MJXp-mrow" id="MJXp-Span-3097"><span class="MJXp-munderover" id="MJXp-Span-3098"><span><span class="MJXp-over"><span class=""><span class="MJXp-mo" id="MJXp-Span-3103" style="margin-left: 0px; margin-right: 0px;">^</span></span><span class=""><span class="MJXp-msubsup" id="MJXp-Span-3099"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3100" style="margin-right: 0.05em;">c</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-3101" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3102">k</span></span></span></span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-3104" style="margin-left: 0em; margin-right: 0em;">}</span><span class="MJXp-mo" id="MJXp-Span-3105" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-394-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-394">P(s \mid \{\hat{c_{0}},
\ldots \hat{c_{k}} \})</script> will be somewhat lower, this is compensated
for in the AIC by the smaller number of parameters.</p>

<h4><a id="BayEvaMod">5.1.2 Bayesian evaluation of models</a></h4>

<p>Various other prominent model selection tools are based on methods
from Bayesian statistics. They all start from the idea that the
quality of a model is expressed in the performance of the model on the
sample data: the model that, on the whole, makes the sampled data most
probable is to be preferred.  Because of this, there is a close
connection with the hierarchical Bayesian modelling referred to
earlier (Gelman 2013). The central notion in the Bayesian model
selection tools is thus the marginal likelihood of the model, i.e.,
the weighted average of the likelihoods over the model, using the
prior distribution as a weighing function:

<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-3106"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3107">P</span><span class="MJXp-mo" id="MJXp-Span-3108" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3109">s</span><span class="MJXp-mo" id="MJXp-Span-3110" style="margin-left: 0.333em; margin-right: 0.333em;">∣</span><span class="MJXp-msubsup" id="MJXp-Span-3111"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3112" style="margin-right: 0.05em;">M</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-3113" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3114">i</span></span></span><span class="MJXp-mo" id="MJXp-Span-3115" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mspace" id="MJXp-Span-3116" style="width: 0.278em; height: 0em;"></span><span class="MJXp-mo" id="MJXp-Span-3117" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mspace" id="MJXp-Span-3118" style="width: 0.278em; height: 0em;"></span><span class="MJXp-msubsup" id="MJXp-Span-3119"><span class="MJXp-mo" id="MJXp-Span-3120" style="margin-left: 0em; margin-right: 0.05em;"><span class="MJXp-largeop MJXp-int">∫</span></span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-3121" style="vertical-align: -0.46em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3122">θ</span><span class="MJXp-mo" id="MJXp-Span-3123">∈</span><span class="MJXp-msubsup" id="MJXp-Span-3124"><span class="MJXp-mi" id="MJXp-Span-3125" style="margin-right: 0.05em;">Θ</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-3126" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3127">i</span></span></span></span></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3128">P</span><span class="MJXp-mo" id="MJXp-Span-3129" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-3130"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3131" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-3132" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3133">θ</span></span></span><span class="MJXp-mo" id="MJXp-Span-3134" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3135">P</span><span class="MJXp-mo" id="MJXp-Span-3136" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3137">s</span><span class="MJXp-mo" id="MJXp-Span-3138" style="margin-left: 0.333em; margin-right: 0.333em;">∣</span><span class="MJXp-msubsup" id="MJXp-Span-3139"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3140" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-3141" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3142">θ</span></span></span><span class="MJXp-mo" id="MJXp-Span-3143" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3144">d</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3145">θ</span><span class="MJXp-mo" id="MJXp-Span-3146" style="margin-left: 0em; margin-right: 0.222em;">.</span></span></span><div class="MathJax_Display MathJax_Processing"><span class="MathJax" id="MathJax-Element-395-Frame" tabindex="0"></span></div><script type="math/tex; mode=display" id="MathJax-Element-395"> P(s \mid M_{i}) \; = \; \int_{\theta \in \Theta_{i}} P(h_{\theta}) P(s
\mid h_{\theta}) d\theta . </script>

Here <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-3147"><span class="MJXp-msubsup" id="MJXp-Span-3148"><span class="MJXp-mi" id="MJXp-Span-3149" style="margin-right: 0.05em;">Θ</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-3150" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3151">i</span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-396-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-396">\Theta_{i}</script> is the parameter space belonging to model
<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-3152"><span class="MJXp-msubsup" id="MJXp-Span-3153"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3154" style="margin-right: 0.05em;">M</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-3155" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3156">i</span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-397-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-397">M_{i}</script>.  The marginal likelihoods can be combined with a prior
probability over models, <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-3157"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3158">P</span><span class="MJXp-mo" id="MJXp-Span-3159" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-3160"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3161" style="margin-right: 0.05em;">M</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-3162" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3163">i</span></span></span><span class="MJXp-mo" id="MJXp-Span-3164" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-398-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-398">P(M_{i})</script>, to derive the
so-called <em>posterior model probability</em>, using Bayes'
theorem. One way of evaluating models, known as <em>Bayesian model
selection</em>, is by comparing the models on their marginal
likelihood, or else on their posteriors (cf. Kass and Raftery
1995).</p>

<p>Usually the marginal likelihood cannot be computed analytically.
Numerical approximations can often be obtained, but for practical
purposes it has proved very useful, and quite sufficient, to employ an
approximation of the marginal likelihood. This approximation has
become known as the <em>Bayesian information criterion</em>, or BIC
for short (Schwarz 1978, Raftery 1995). It turns out that this
approximation shows remarkable similarities to the AIC:

<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-3165"><span class="MJXp-mtext" id="MJXp-Span-3166">BIC</span><span class="MJXp-mo" id="MJXp-Span-3167" style="margin-left: 0em; margin-right: 0em;">[</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3168">M</span><span class="MJXp-mo" id="MJXp-Span-3169" style="margin-left: 0em; margin-right: 0em;">]</span><span class="MJXp-mspace" id="MJXp-Span-3170" style="width: 0.278em; height: 0em;"></span><span class="MJXp-mo" id="MJXp-Span-3171" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mspace" id="MJXp-Span-3172" style="width: 0.278em; height: 0em;"></span><span class="MJXp-mo" id="MJXp-Span-3173" style="margin-left: 0.267em; margin-right: 0.267em;">−</span><span class="MJXp-mn" id="MJXp-Span-3174">2</span><span class="MJXp-mi" id="MJXp-Span-3175">log</span><span class="MJXp-mo" id="MJXp-Span-3176" style="margin-left: 0em; margin-right: 0em;"></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3177">P</span><span class="MJXp-mo" id="MJXp-Span-3178" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3179">s</span><span class="MJXp-mo" id="MJXp-Span-3180" style="margin-left: 0.333em; margin-right: 0.333em;">∣</span><span class="MJXp-msubsup" id="MJXp-Span-3181"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3182" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-3183" style="vertical-align: -0.4em;"><span class="MJXp-mrow" id="MJXp-Span-3184"><span class="MJXp-munderover" id="MJXp-Span-3185"><span><span class="MJXp-over"><span class=" MJXp-script" style="margin-bottom: -0.92em;"><span class="MJXp-mo" id="MJXp-Span-3187" style="margin-right: 0px; margin-left: 0px;">ˆ</span></span><span class=""><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3186">θ</span></span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-3188">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3189">s</span><span class="MJXp-mo" id="MJXp-Span-3190">)</span></span></span><span class="MJXp-mo" id="MJXp-Span-3191" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-3192" style="margin-left: 0.267em; margin-right: 0.267em;">+</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3193">d</span><span class="MJXp-mi" id="MJXp-Span-3194">log</span><span class="MJXp-mo" id="MJXp-Span-3195" style="margin-left: 0em; margin-right: 0em;"></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3196">n</span><span class="MJXp-mo" id="MJXp-Span-3197" style="margin-left: 0em; margin-right: 0.222em;">.</span></span></span><div class="MathJax_Display MathJax_Processing"><span class="MathJax" id="MathJax-Element-399-Frame" tabindex="0"></span></div><script type="math/tex; mode=display" id="MathJax-Element-399"> \text{BIC}[M] \; = \; - 2 \log P(s \mid h_{\hat{\theta}(s)}) + d \log
n . </script>

Here <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-3198"><span class="MJXp-mrow" id="MJXp-Span-3199"><span class="MJXp-munderover" id="MJXp-Span-3200"><span><span class="MJXp-over"><span class="" style="margin-bottom: -0.92em;"><span class="MJXp-mo" id="MJXp-Span-3202" style="margin-left: 0px; margin-right: 0px;">ˆ</span></span><span class=""><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3201">θ</span></span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-3203" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3204">s</span><span class="MJXp-mo" id="MJXp-Span-3205" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-400-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-400">\hat{\theta}(s)</script> is again the maximum likelihood estimate of
the model, <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-3206"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3207">d</span><span class="MJXp-mo" id="MJXp-Span-3208" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3209">d</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3210">i</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3211">m</span><span class="MJXp-mo" id="MJXp-Span-3212" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3213">M</span><span class="MJXp-mo" id="MJXp-Span-3214" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-401-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-401">d = dim(M)</script> the number of independent parameters, and
<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-3215"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3216">n</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-402-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-402">n</script> is the number of data points in the sample. The latter
dependence is the only difference with the AIC, but a major difference
in how the model evaluation may turn out.</p>

<p>The concurrence of the AIC and the BIC seems to give a further
motivation for our intuitive preference for simple models over more
complex ones. Indeed, other model selection tools, like the
<em>deviance information criterion</em> (Spiegelhalter et al 2002) and
the approach based on <em>minimum description length</em> (Grunwald
2007), also result in expressions that feature a term that penalizes
complex models. However, this is not to say that the dimension term
that we know from the information criteria exhausts the notion of
model complexity. There is ongoing debate in the philosophy of science
concerning the merits of model selection in explications of the notion
of simplicity, informativeness, and the like (see, for example, Sober
2004, Romeijn and van de Schoot 2008, Romeijn et al 2012, Sprenger
2013).</p>

<h3><a id="StaWitMod">5.2 Statistics without models</a></h3>

<p>There are also statistical methods that refrain from the use of a
particular model, by focusing exclusively on the data or by
generalizing over all possible models.  Some of these techniques are
properly localized in descriptive statistics: they do not concern an
inference from data but merely serve to describe the data in a
particular way. Statistical methods that do not rely on an explicit
model choice have unfortunately not attracted much attention in the
philosophy of statistics, but for completeness sake they will be
briefly discussed here.</p>

<h4><a id="DatRedTec">5.2.1 Data reduction techniques</a></h4>

<p>One set of methods, and a quite important one for many practicing
statisticians, is aimed at <em>data reduction</em>. Often the sample
data are very rich, e.g., consisting of a set of points in a space of
very many dimensions. The first step in a statistical analysis may
then be to pick out the salient variability in the data, in order to
scale down the computational burden of the analysis itself.</p>

<p>The technique of <em>principal component analysis</em> (PCA) is
designed for this purpose (Jolliffe 2002). Given a set of points in a
space, it seeks out the set of vectors along which the variation in
the points is large. As an example, consider two points in a plane
parameterized as <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-3217"><span class="MJXp-mo" id="MJXp-Span-3218" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3219">x</span><span class="MJXp-mo" id="MJXp-Span-3220" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3221">y</span><span class="MJXp-mo" id="MJXp-Span-3222" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-403-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-403">(x, y)</script>: the points <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-3223"><span class="MJXp-mo" id="MJXp-Span-3224" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mn" id="MJXp-Span-3225">0</span><span class="MJXp-mo" id="MJXp-Span-3226" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mn" id="MJXp-Span-3227">0</span><span class="MJXp-mo" id="MJXp-Span-3228" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-404-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-404">(0, 0)</script> and <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-3229"><span class="MJXp-mo" id="MJXp-Span-3230" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mn" id="MJXp-Span-3231">1</span><span class="MJXp-mo" id="MJXp-Span-3232" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mn" id="MJXp-Span-3233">1</span><span class="MJXp-mo" id="MJXp-Span-3234" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-405-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-405">(1, 1)</script>. In
the <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-3235"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3236">x</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-406-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-406">x</script>-direction and in the <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-3237"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3238">y</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-407-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-407">y</script>-direction the variation is <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-3239"><span class="MJXp-mn" id="MJXp-Span-3240">1</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-408-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-408">1</script>,
but over the diagonal the variation is maximal, namely
<span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-3241"><span class="MJXp-msqrt" id="MJXp-Span-3242"><span class="MJXp-surd"><span style="font-size: 134%; margin-top: 0.104em;">√</span></span><span class="MJXp-root"><span class="MJXp-rule" style="border-top: 0.08em solid;"></span><span class="MJXp-box"><span class="MJXp-mn" id="MJXp-Span-3243">2</span></span></span></span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-409-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-409">\sqrt{2}</script>. The vector on the diagonal is called the principal
component of the data. In richer data structures, and using a more
general measure of variation among points, we can find the first
component in a similar way. Moreover, we can repeat the procedure
after subtracting the variation along the last found component, by
projecting the data onto the plane perpendicular to that
component. This allows us to build up a set of principal components of
diminishing importance.</p>

<p>PCA is only one item from a large collection of techniques that are
aimed at keeping the data manageable and finding patterns in it, a
collection that also includes <em>kernel methods</em> and <em>support
vector machines</em> (e.g., Vapnik and Kotz 2006). For present
purposes, it is important to stress that such tools should not be
confused with statistical analysis: they do not involve the testing or
evaluation of distributions over sample space, even though they build
up and evaluate models of the data. This sets them apart from, e.g.,
confirmatory and exploratory factor analysis (Bartholomew 2008), which
is sometimes taken to be a close relative of PCA because both
sets of techniques allows us to identify salient dimensions within
sample space, along which the data show large variation. </p>

<p>Practicing statisticians often employ data reduction tools to
arrive at conclusions on the distributions from which the data were
sampled. There is already a wide use for machine learning and data
mining techniques in the sciences, and we may expect even mode usage
of these techniques in the future, because so much data is now coming
available for scientific analysis. However, in the philosophy of
statistics there is as yet little debate over the epistemic status of
conclusions reached by means of these techniques. Philosophers of
statistics would do well to direct some attention here.</p>

<h4><a id="ForLeaThe">5.2.2 Formal learning theory</a></h4>

<p>An entirely different approach to statistics is presented by
 <a href="../learning-formal/"><em>formal learning theory</em></a>.
This is again a vast area of research, primarily located in
computer science and artificial intelligence. The discipline is here
mentioned briefly, as another example of an approach to statistics
that avoids the choice of a statistical model altogether and merely
identifies patterns in the data. We leave aside the theory of
<em>neural networks</em>, which also concerns predictive systems that
do not rely on a statistical model, and focus on the theory of
learning algorithms because of all these approaches they have seen
most philosophical attention.</p>

<p>Pioneering work on formal learning was done by Solomonoff
(1964). As before, the setting is one in which the data consist of
strings of 0's and 1's, and in which an agent is attempting to
identify the pattern in these data. So, for example, the data may be a
string of the form <span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-3244"><span class="MJXp-mn" id="MJXp-Span-3245">0101010101</span><span class="MJXp-mo" id="MJXp-Span-3246" style="margin-left: 0em; margin-right: 0em;">…</span></span></span><span class="MathJax MathJax_Processing" id="MathJax-Element-410-Frame" tabindex="0"></span><script type="math/tex" id="MathJax-Element-410">0101010101\ldots</script>, and the challenge is to
identify this strings as an alternating sequence. The central idea of
Solomonoff is that all possible computable patterns must be considered
by the agent, and therefore that no restrictive choice on statistical
hypotheses is warranted. Solomonoff then defined a formal system in
which indeed all patterns can be taken into consideration, effectively
using a Bayesian analysis with a cleverly constructed prior over all
computable hypotheses.</p>

<p>This general idea can also be identified in a rather new field on
the intersection of Bayesian statistics and machine learning,
<em>Bayesian </em><em>nonparametrics</em> (e.g., Orbanz and Teh
2010, Hjort et al 2010). Rather than specifying, at the outset, a
confined set of distributions from which a statistical analysis is
supposed to choose on the basis of the data, the idea is that the data
are confronted with a potentially infinite-dimensional space of
possible distributions. The set of distributions taken into
consideration is then made relative to the data obtained: the
complexity of the model grows with the sample. The result is a
predictive system that performs an online model selection alongside a
Bayesian accommodation of the posterior over the model.</p>

<p>Current formal learning theory is a lively field, to which
philosophers of statistics also contribute (e.g., Kelly 1996, Kelly et
al 1997). Particularly salient for the present concerns is that the
systems of formal learning are set up to achieve some notion of
adequate <em>universal prediction</em>, without confining themselves
to a specific set of hypotheses, and hence by imposing minimal
constraints on the set of possible patterns in the data. It is a
matter of debate whether this is at all possible, and to what extent
the predictions of formal learning theory thereby rely on, e.g.,
implicit assumptions on structure of the sample space. Philosophical
reflection on this is only in its infancy.</p>

<h2><a id="RelTop">6. Related topics</a></h2>

<p>
There are numerous topics in the philosophy of science that bear
direct relevance to the themes covered in this lemma. A few central
topics are mentioned here to direct the reader to related lemmas in
the encyclopedia. </p>

<p>One very important topic that is immediately adjacent to the
philosophy of statistics is 
 <a href="../confirmation/">confirmation theory</a>, 
the philosophical theory that describes and justifies
relations between scientific theory and empirical
evidence. Arguably, the theory of statistics is a proper part of
confirmation theory, as it describes and justifies the relation that
obtains between statistical theory and evidence in the form of
samples. It can be insightful to place statistical procedures in this
wider framework of relations between evidence and theory. Zooming out
even further, the philosophy of statistics is part of the
philosophical topic of methodology, i.e., the general theory on
whether and how science acquires knowledge. Thus conceived, statistics
is one component in a large collection of scientific methods
comprising concept formation, experimental design, manipulation and
observation, confirmation, revision, and theorizing.</p>

<p>There are also a fair number of specific topics from the philosophy
of science that are spelled out in terms of statistics or that are
located in close proximity to it. One of these topics is the process
of measurement, in particular the measurement of latent variables on
the basis of statistical facts about manifest variables.  The
so-called <em>representational theory of measurement</em> (Kranz et al
1971) relies on statistics, in particular on factor analysis, to
provide a conceptual clarification of how mathematical structures
represent empirical phenomena. Another important topic form the
philosophy of science is causation (see the entries on
 <a href="../causation-probabilistic/">probabilistic causation</a>
and
 <a href="../physics-Rpcc/">Reichenbach's common cause principle</a>). 
Philosophers have employed probability theory to capture causal
relations ever since Reichenbach (1956), but more recent work in
causality and statistics (e.g., Spirtes et al 2001) has given the
theory of <em>probabilistic causality</em> an enormous impulse. Here
again, statistics provides a basis for the conceptual analysis of
causal relations.</p>

<p>And there is so much more.  Several specific statistical
techniques, like factor analysis and the theory of Bayesian networks,
invite conceptual discussion of their own accord. Numerous topics
within the philosophy of science lend themselves to statistical
elucidation, e.g., the coherence, informativeness, and surprise of
evidence. And in turn there is a wide range of discussions in the
philosophy of science that inform a proper understanding of
statistics. Among them are debates over experimentation and
intervention, concepts of chance, the nature of scientific models, and
theoretical terms. The reader is invited to consult the entries on
these topics to find further indications of how they relate to the
philosophy of statistics.</p>

</div>

<div id="bibliography">

<h2><a id="Bib">Bibliography</a></h2>

<ul class="hanging">

<li>Aldous, D.J., 1981, “Representations for Partially Exchangeable
Arrays of Random Variables”, <em>Journal of Multivariate
Analysis</em>, 11: 581–598.</li>

<li>Armendt, B., 1993, “Dutch books, Additivity, and Utility
Theory”, <em>Philosophical Topics</em>, 21:1–20.</li>

<li>Auxier, R.E., and L.E. Hahn (eds.), 2006, <em>The Philosophy of
Jaako Hintikka</em>, Chicago: Open Court.</li>

<li>Balasubramanian, V., 2005, “MDL, Bayesian inference, and the
geometry of the space of probability distributions”, in: Advances in
Minimum Description Length: Theory and Applications, P.J. Grunwald et
al (eds.), Boston: MIT Press, 81–99.</li>

<li>Bandyopadhyay, P., and Forster, M. (eds.), 2011, Handbook for the
Philosophy of Science: Philosophy of Statistics, Elsevier.</li>

<li>Barnett, V., 1999, <em>Comparative Statistical Inference</em>,
Wiley Series in Probability and Statistics, New York: Wiley.</li>

<li>Bartholomew, D.J., F. Steele, J. Galbraith, I. Moustaki,
2008, <em>Analysis of Multivariate Social Science Data</em>,
Statistics in the Social and Behavioral Sciences Series, London:
Taylor and Francis, 2nd edition.</li>

<li>Berger, J. 2006, “The Case for Objective Bayesian
Analysis”, <em>Bayesian Analysis</em>, 1(3): 385–402.</li>

<li>Berger, J.O., J.M. Bernardo, and D. Sun, 2009, “The formal
definition of reference priors”, <em>Annals of Statistics</em>, 37(2):
905–938. </li>

<li>Berger, J.O., and R.L. Wolpert, 1984, <em>The Likelihood
Principle</em>.  Hayward (CA): Institute of Mathematical
Statistics.</li>

<li>Berger, J.O. and T. Sellke, 1987, “Testing a point null
hypothesis: The irreconciliability of P-values and
evidence”, <em>Journal of the American Statistical Association</em>,
82: 112–139.</li>

<li>Bernardo, J.M. and A.F.M. Smith, 1994, <em>Bayesian Theory</em>,
New York: John Wiley.</li>

<li>Bigelow, J. C., 1977, “Semantics of
probability”, <em>Synthese</em>, 36(4): 459–72. </li>

<li>Billingsley, P., 1995, <em>Probability and Measure</em>, Wiley
Series in Probability and Statistics, New York: Wiley, 3rd
edition.</li>

<li>Birnbaum, A., 1962, “On the Foundations of Statistical
Inference”, <em>Journal of the American Statistical Association</em>,
57: 269–306.</li>

<li>Blackwell, D. and L. Dubins, 1962, “Merging of Opinions with
Increasing Information”, <em>Annals of Mathematical Statistics</em>,
33(3): 882–886.</li>

<li>Boole, G., 1854, <em>An Investigation of The Laws of Thought on
Which are Founded the Mathematical Theories of Logic and
Probabilities</em>, London: Macmillan, reprinted 1958, London:
Dover.</li>

<li>Burnham, K.P. and D.R. Anderson, 2002, <em>Model Selection
and Multimodel Inference: A Practical Information-Theoretic
Approach</em>, New York: Springer, 2nd edition.</li>

<li>Carnap, R., 1950, <em>Logical Foundations of Probability</em>,
Chicago: The University of Chicago Press.</li>

<li>–––, 1952, <em>The Continuum of Inductive Methods</em>,
Chicago: University of Chicago Press.</li>

<li>Carnap, R. and Jeffrey, R.C. (eds.), 1970, <em>Studies in
Inductive Logic and Probability</em>, Volume I, Berkeley: University
of California Press.</li>

<li>Casella, G., and R. L. Berger, 1987, “Reconciling Bayesian and
Frequentist Evidence in the One-Sided Testing Problem”, <em>Journal of
the American Statistical Association</em>, 82: 106–111.</li>

<li>Claeskens, G. and N. L. Hjort, 2008, <em>Model selection and model
averaging</em>, Cambridge: Cambridge University Press.</li>

<li>Cohen, J., 1994, “The Earth is Round (p &lt; .05)”, <em>American
Psychologist</em>, 49: 997–1001.</li>

<li>Cox, R.T., 1961, <em>The Algebra of Probable Inference</em>,
Baltimore: John Hopkins University Press.</li>

<li>Cumming, G., 2012, <em>Understanding The New Statistics: Effect
Sizes, Confidence Intervals, and Meta-Analysis</em>, New York:
Routledge.</li>

<li>Dawid, A.P., 1982, “The Well-Calibrated Bayesian”, <em>Journal of
the American Statistical Association</em>, 77(379): 605–610.</li>

<li>–––, 2004, “Probability, causality and the empirical world:
A Bayes-de Finetti-Popper-Borel synthesis”, <em>Statistical
Science</em>, 19: 44–57.</li>

<li>Dawid, A.P. and P. Grunwald, 2004, “Game theory, maximum entropy,
minimum discrepancy, and robust Bayesian decision theory”, <em>Annals
of Statistics</em>, 32: 1367–1433.</li>

<li>Dawid, A.P. and M. Stone, 1982, “The functional-model basis of
fiducial inference”, <em>Annals of Statistics</em>, 10:
1054–1067.</li>

<li>De Finetti, B., 1937, “La Prévision: ses lois logiques, ses
sources subjectives”, <em>Annales de l'Institut Henri
Poincaré</em>, reprinted as “Foresight: its Logical Laws, Its
Subjective Sources”, in: Kyburg, H. E. and H. E. Smokler
(eds.), <em>Studies in Subjective Probability</em>, 1964, New York:
Wiley.</li>

<li>–––, 1974, <em>Theory of Probability</em>, Volumes I
and II, New York: Wiley, translation by A. Machi and
A.F.M. Smith.</li>

<li>De Morgan, A., 1847, <em>Formal Logic or The Calculus of
Inference</em>, London: Taylor &amp; Walton, reprinted by London: Open
Court, 1926.</li>

<li>Dempster, A.P., 1964, “On the Difficulties Inherent in Fisher's
Fiducial Argument”, <em>Journal of the American Statistical
Association</em>, 59: 56–66.</li>

<li>–––, 1966, “New Methods for Reasoning Towards Posterior
Distributions Based on Sample Data”, <em>Annals of Mathematics and
Statistics</em>, 37(2): 355–374. </li>

<li>–––, 1967, “Upper and lower probabilities induced by a
multivalued mapping”, <em>The Annals of Mathematical Statistics</em>,
38(2): 325–339.</li>

<li>–––, 1968, “A generalization of Bayesian
inference”, <em>Journal of the Royal Statistical Society</em>, Series
B, Vol. 30: 205–247.</li>

<li>Diaconis, P., and D. Freedman, 1980, “De Finetti’s theorem
for Markov chains”, <em>Annals of Probability</em>, 8:
115–130.</li>

<li>Eagle, A. (ed.), 2010, <em>Philosophy of Probability: Contemporary
Readings</em>, London: Routledge.</li>

<li>Earman, J., 1992, <em>Bayes or Bust? A Critical Examination of
Bayesian Confirmation Theory</em>, Cambridge (MA): MIT Press.</li>

<li>Easwaran, K., 2013, “Expected Accuracy Supports Conditionalization
- and Conglomerability and Reflection”, <em>Philosophy of
Science</em>, 80(1): 119–142.</li>

<li>Edwards, A.W.F., 1972, <em>Likelihood</em>, Cambridge: Cambridge
University Press.</li>

<li>Efron, B. and R. Tibshirani, R., 1993, <em>An Introduction to
the Bootstrap</em>, Boca Raton (FL): Chapman &amp; Hall/CRC.</li>

<li>Festa, R., 1993, <em>Optimum Inductive Methods</em>, Dordrecht:
Kluwer.</li>

<li>–––, 1996, “Analogy and exchangeability in predictive
inferences”, <em>Erkenntnis</em>, 45: 89–112.</li>

<li>Fisher, R.A., 1925, <em>Statistical Methods for Research
Workers</em>, Edinburgh: Oliver and Boyd.</li>

<li>–––, 1930, “Inverse probability”, <em>Proceedings of the
Cambridge Philosophical Society</em>, 26: 528–535.</li>

<li>–––, 1933, “The concepts of inverse probability and
fiducial probability referring to unknown parameters”, <em>Proceedings
of the Royal Society</em>, Series A, 139: 343–348.</li>

<li>–––, 1935a, “The logic of inductive
inference”, <em>Journal of the Royal Statistical Society</em>, 98:
39–82.</li>

<li>–––, 1935b, <em>The Design of Experiments</em>,
Edinburgh: Oliver and Boyd.</li>

<li>–––, 1935c, “The fiducial argument in statistical
inference”, <em>Annals of Eugenics</em>, 6: 317–324.</li>

<li>–––, 1955, “Statistical Methods and Scientific
Induction”, <em>Journal of the Royal Statistical Society</em>, B 17:
69–78.</li>

<li>–––, 1956, <em>Statistical Methods and Scientific
Inference</em>, New York: Hafner, 3rd edition 1973.</li>

<li>Fitelson, B., 2007, “Likelihoodism, Bayesianism, and relational
confirmation”, <em>Synthese</em>, 156(3): 473–489.</li>

<li>Forster, M. and E. Sober, 1994, “How to Tell when Simpler, More
Unified, or Less Ad Hoc Theories will Provide More Accurate
Predictions”, <em>British Journal for the Philosophy of Science</em>,
45: 1–35.</li>

<li>Fraassen, B. van, 1989, <em>Laws and Symmetry</em>, Oxford: Clarendon Press.</li>

<li>Gaifman, H. and M. Snir, 1982, “Probabilities over Rich
Languages”, <em>Journal of Symbolic Logic</em>, 47:
495–548.</li>

<li>Galavotti, M. C., 2005, <em>Philosophical Introduction to
Probability</em>, Stanford: CSLI Publications.</li>

<li>Gelman, A., J. Carlin, H. Stern, D. Dunson, A. Vehtari, and
D. Rubin, 2013, <em>Bayesian Data Analysis</em>, revised edition, New
York: Chapman &amp; Hall/CRC.</li>

<li>Gelman, A., and C. Shalizi, 2013, “Philosophy and the practice of
Bayesian statistics (with discussion)”, <em>British Journal of
Mathematical and Statistical Psychology</em>, 66: 8–18. </li>

<li>Giere, R. N., 1976, “A Laplacean Formal Semantics for Single-Case
Propensities”, <em>Journal of Philosophical Logic</em>, 5(3):
321–353.</li>

<li>Gillies, D., 1971, “A Falsifying Rule for Probability
Statements”, <em>British Journal for the Philosophy of Science</em>,
22: 231–261.</li>

<li>–––, 2000, <em>Philosophical Theories of Probability</em>,
London: Routledge.</li>

<li>Goldstein, M., 2006, “Subjective Bayesian analysis: principles and
practice”, <em>Bayesian Analysis</em>, 1(3): 403–420.</li>

<li>Good, I.J., 1983, <em>Good Thinking: The Foundations of
Probability and Its Applications</em>, University of Minnesota Press,
reprinted London: Dover, 2009.</li>

<li>–––, 1988, “The Interface Between Statistics and Philosophy
of Science”, <em>Statistical Science</em>, 3(4): 386–397.</li>

<li>Goodman, N., 1965, <em>Fact, Fiction and Forecast</em>,
Indianapolis: Bobbs-Merrill.</li>

<li>Greaves, H. and D. Wallace, 2006, “Justifying Conditionalization:
Conditionalization Maximizes Expected Epistemic
Utility”, <em>Mind</em>, 115(459): 607–632.</li>

<li>Greco, D., 2011, “Significance Testing in Theory and
Practice”, <em>British Journal for the Philosophy of Science</em>, 62:
607–37.</li>

<li>Grünwald, P.D., 2007, <em>The Minimum Description Length
Principle</em>, Boston: MIT Press.</li>

<li>Hacking, I.,1965, The Logic of Statistical Inference, Cambridge:
Cambridge University Press.</li>

<li>Haenni, R., Romeijn, J.-W., Wheeler, G., Andrews, J.,
2011, <em>Probabilistic Logics and Probabilistic Networks</em>,
Berlin: Springer.</li>

<li>Hailperin, T., 1996, <em>Sentential Probability Logic</em>, Lehigh
University Press.</li>

<li>Hájek, A., 2007, “The reference class problem is your
problem too”, <em>Synthese</em>, 156: 563–585.</li>

<li>Hajek, A. and C. Hitchcock (eds.), 2013, <em>Oxford Handbook of
Probability and Philosophy</em>, Oxford: Oxford University Press.</li>

<li>Halpern, J.Y., 2003, <em>Reasoning about Uncertainty</em>, MIT
press.</li>

<li>Handfield, T., 2012, <em>A Philosophical Guide to Chance: Physical
Probability</em>, Cambridge: Cambridge University Press.</li>

<li>Harlow, L.L., S.A. Mulaik, and J.H. Steiger, (eds.),
1997, <em>What if there were no significance tests?</em>, Mahwah (NJ):
Erlbaum.</li>

<li>Henderson, L., N.D. Goodman, J.B. Tenenbaum, and J.F.
Woodward, 2010, “The Structure and Dynamics of Scientific Theories: A
Hierarchical Bayesian Perspective”, <em>Philosophy of Science</em>,
77(2): 172–200.</li>

<li>Hjort, N., C. Holmes, P. Mueller, and S. Walker (eds.),
2010, <em>Bayesian Nonparametrics</em>, Cambridge Series in
Statistical and Probabilistic Mathematics, nr. 28, Cambridge:
Cambridge University Press.</li>

<li>Howson, C., 2000, <em>Hume's problem: induction and the
justification of belief</em>, Oxford: Oxford University Press.</li>

<li>–––, 2003, “Probability and logic”, <em>Journal of Applied
Logic</em>, 1(3–4): 151–165.</li>

<li>–––, 2011, “Bayesianism as a pure logic of Inference”, in:
Bandyopadhyay, P and Foster, M, (eds.), <em>Philosophy of statistics,
Handbook of the Philosophy of Science</em>, Oxford: North Holland,
441–472.</li>

<li>Howson, C. and P. Urbach, 2006, <em>Scientific Reasoning: The
Bayesian Approach</em>, La Salle: Open Court, 3rd edition. </li>

<li>Hintikka, J., 1970, “Unknown Probabilities, Bayesianism, and de
Finetti's Representation Theorem”, in <em>Proceedings of the Biennial
Meeting of the Philosophy of Science Association</em>, Vol.  1970,
Boston: Springer, 325–341.</li>

<li>Hintikka, J. and I. Niiniluoto, 1980, “An axiomatic foundation for
the logic of inductive generalization”, in R.C. Jeffrey
(ed.), <em>Studies in Inductive Logic and Probability</em>, volume II,
Berkeley: University of California Press, 157–181.</li>

<li>Hintikka J. and P. Suppes (eds.), 1966, <em>Aspects of Inductive
Logic</em>, Amsterdam: North-Holland.</li>

<li>Hume, D., 1739, <em>A Treatise of Human Nature</em>, 
 <a href="http://www.earlymoderntexts.com/authors/hume.html" target="other">available online</a>.</li>

<li>Jaynes, E.T., 1973, “The Well-Posed Problem”, <em>Foundations of
Physics</em>, 3: 477–493.</li>

<li>–––, 2003, <em>Probability Theory: The Logic of
Science</em>, Cambridge: Cambridge University Press.
 <a href="http://bayes.wustl.edu/etj/prob/book.pdf" target="other">first 3 chapters available online</a>.</li>

<li>Jeffrey, R., 1992, <em>Probability and the Art of
Judgment</em>, Cambridge: Cambridge University Press.</li>

<li>Jeffreys, H., 1961, <em>Theory of Probability</em>, Oxford:
Clarendon Press, 3rd edition.</li>

<li>Jolliffe, I.T., 2002, <em>Principal Component Analysis</em>, New
York: Springer, 2nd edition.</li>

<li>Kadane, J.B., 2011, <em>Principles of Uncertainty</em>, London:
Chapman and Hall.</li>

<li>Kadane, J.B., M.J. Schervish, and T. Seidenfeld, 1996, “When
Several Bayesians Agree That There Will Be No Reasoning to a Foregone
Conclusion”, <em>Philosophy of Science</em>, 63: S281-S289.</li>

<li>–––, 1996, “Reasoning to a
Foregone Conclusion”, <em>Journal of the American Statistical
Association</em>, 91(435): 1228–1235.</li>

<li>Kass, R. and A. Raftery, 1995, “Bayes
Factors”, <em>Journal of the American Statistical
Association</em>, 90: 773–790.</li>

<li>Kelly, K., 1996, <em>The Logic of Reliable Inquiry</em>, Oxford:
Oxford University Press.</li>

<li>Kelly, K., O. Schulte, and C. Juhl, 1997, “Learning Theory and the
Philosophy of Science”, <em>Philosophy of Science</em>, 64:
245–67.</li>

<li>Keynes, J.M., 1921, <em>A Treatise on Probability</em>, London:
Macmillan.</li>

<li>Kieseppä, I. A., 1997, “Akaike Information Criterion,
Curve-Fitting, and the Philosophical Problem of
Simplicity”, <em>British Journal for the Philosophy of Science</em>,
48(1): 21–48.</li>

<li>–––, 2001, “Statistical Model Selection Criteria and
the Philosophical Problem of Underdetermination”, <em>British Journal
for the Philosophy of Science</em>, 52(4): 761–794.</li>

<li>Kingman, J.F.C., 1975, “Random discrete
distributions”, <em>Journal of the Royal Statistical
Society</em>, 37: 1–22.</li>

<li>–––, 1978, “Uses of exchangeability”, <em>Annals of

Probability</em>, 6(2): 183–197.</li>

<li>Kolmogorov, A.N., 1933, <em>Grundbegriffe der
Wahrscheinlichkeitsrechnung</em>, Berlin: Julius Springer.</li>

<li>Krantz, D. H., R. D. Luce, A. Tversky and P. Suppes, 1971,
<em>Foundations of Measurement</em>, Volumes I and II. Mineola: Dover
Publications.</li>

<li>Kuipers, T.A.F., 1978, <em>Studies in Inductive Probability and
Rational Expectation</em>, Dordrecht: Reidel.</li>

<li>–––, 1986, “Some estimates of the optimum inductive
method”, <em>Erkenntnis</em>, 24: 37–46.</li>

<li>Kyburg, Jr., H.E., 1961, <em>Probability and the Logic of Rational
Belief</em>, Middletown (CT): Wesleyan University Press.</li>

<li>Kyburg, H.E. Jr. and C.M. Teng, 2001, <em>Uncertain Inference</em>,
Cambridge: Cambridge University Press.</li>

<li>van Lambalgen, M., 1987, <em>Random sequences</em>, Ph.D.
dissertation, Department of Mathematics and Computer Science,
University of Amsterdam,
 <a href="https://www.illc.uva.nl/Research/Publications/Dissertations/HDS-08-Michiel-van-Lambalgen.text.pdf" target="other">available online</a>.</li>

<li>Leitgeb, H. and Pettigrew, R., 2010a, “An Objective Justification
of Bayesianism I: Measuring  Inaccuracy”, <em>Philosophy of
Science</em>, 77(2): 201–235.</li>

<li>–––, 2010b, “An Objective Justiﬁcation
of Bayesianism II: The Consequences of Minimizing
Inaccuracy”, <em>Philosophy of Science</em>, 77(2):
236–272.</li>

<li>Levi, I., 1980, <em>The enterprise of knowledge: an essay on
knowledge, credal probability, and chance</em>, Cambridge MA: MIT
Press.</li>

<li>Lindley, D.V., 1957, “A statistical paradox”, <em>Biometrika</em>,
44: 187–192. </li>

<li>–––, 1965, <em>Introduction to Probability and
Statistics from a Bayesian Viewpoint</em>, Vols. I and II, Cambridge:
Cambridge University Press.</li>

<li>–––, 2000, “The Philosophy of Statistics”, <em>Journal
of the Royal Statistical Society</em>, D (The Statistician),
Vol. 49(3): 293–337.</li>

<li>Mackay, D.J.C., 2003, <em>Information Theory, Inference, and
Learning Algorithms</em>, Cambridge: Cambridge University Press.</li>

<li>Maher, P., 1993, <em>Betting on Theories</em>, Cambridge Studies
in Probability, Induction and Decision Theory, Cambridge: Cambridge
University Press. </li>

<li>Mayo, D.G., 1996, <em>Error and the Growth of Experimental
Knowledge</em>, Chicago: The University of Chicago Press.</li>

<li>–––, 2010, An error in the argument from conditionality and
sufficiency  to the likelihood principle, in: D. Mayo, A.  Spanos
(eds.), Error and Inference: Recent exchanges on experimental
reasoning, reliability, and the objectivity and rationality of
science, pp. 305–314, Cambridge: Cambridge University Press.</li>

<li>Mayo, D.G., and A. Spanos, 2006, “Severe Testing as a Basic
Concept in a Neyman-Pearson Philosophy of Induction”, <em>The British
Journal for the Philosophy of Science</em>, 57: 323–357.</li>

<li>–––, 2011, “Error Statistics”, in P.S.
Bandyopadhyay and M.R. Forster, <em>Philosophy of Statistics, Handbook
of the Philosophy of Science</em>, Vol. 7, Elsevier.</li>

<li>Mellor, D. H., 2005, <em>The Matter of Chance</em>, Cambridge:
Cambridge University Press.</li>

<li>–––, 2005, <em>Probability: A Philosophical
Introduction</em>, London: Routledge.</li>

<li>von Mises, R., 1981, <em>Probability, Statistics and Truth</em>,
2nd revised English edition, New York: Dover.</li>

<li>Mood, A. M., F. A. Graybill, and D. C. Boes,
1974, <em>Introduction to the Theory of Statistics</em>, Boston:
McGraw-Hill.</li>

<li>Morey, R., J.W. Romeijn and J. Rouder, 2013, “The Humble
Bayesian”,
<em>British Journal of Mathematical and Statistical Psychology</em>, 66(1): 68–75.</li>

<li>Myung, J., V. Balasubramanian, and M.A. Pitt, 2000, “Counting
probability distributions: Differential geometry and model selection”,
<em>Proceedings of the National Academy of Sciences</em>, 97(21):
11170–11175.</li>

<li>Nagel, T., 1939, <em>Principles of the Theory of Probability</em>,
Chicago: University of Chicago Press.</li>

<li>Neyman, J., 1957, “Inductive Behavior as a Basic Concept of
Philosophy of Science”, <em>Revue Institute Internationale De
Statistique</em>, 25: 7–22.</li>

<li>–––, 1971, Foundations of Behavioristic Statistics, in: V.
Godambe and D. Sprott (eds.), Foundations of Statistical Inference,
Toronto: Holt, Rinehart and Winston of Canada, pp. 1–19.</li>

<li>Neyman, J. and K. Pearson, 1928, “On the use and interpretation of
certain test criteria for purposes of statistical inference”,
<em>Biometrika</em>, A20:175–240 and 264–294.</li>

<li>Neyman, J. and E. Pearson, 1933, “On the problem of the most
efficient tests of statistical hypotheses”, <em>Philosophical
Transactions of the Royal Society</em>, A 231: 289–337</li>

<li>–––, 1967, <em>Joint Statistical
Papers</em>, Cambridge: Cambridge University Press. </li>

<li>Nix, C. J. and J. B. Paris, 2006, “A continuum of inductive
methods arising from a generalised principle of instantial
relevance”, <em>Journal of Philosophical Logic</em>, 35:
83–115.</li>

<li>Orbanz, P. and Y.W. Teh, 2010, “Bayesian Nonparametric Models”,
<em>Encyclopedia of Machine Learning</em>, New York: Springer.</li>

<li>Paris, J.B., 1994, <em>The uncertain reasoner’s
companion</em>, Cambridge: Cambridge University Press.</li>

<li>Paris, J.B. and A. Vencovska, 1989, “On the applicability of
maximum entropy to inexact reasoning”, <em>International Journal of
Approximate Reasoning</em>, 4(3): 183–224.</li>

<li>Paris, J., and P. Waterhouse, 2009, “Atom exchangeability and
instantial relevance, atom exchangeability and instantial relevance”,
<em>Journal of Philosophical Logic</em>, 38(3): 313–332.</li>

<li>Peirce, C. S., 1910, “Notes on the Doctrine of Chances”, in C.
Hartshorne and P. Weiss (eds.), <em>Collected Papers of Charles
Sanders Peirce</em>, Vol. 2, Cambridge MA: Harvard University Press,
405–14, reprinted 1931.</li>

<li>Plato, J. von, 1994, <em>Creating Modern Probability</em>,
Cambridge: Cambridge University Press.</li>

<li>Popper, K.R., 1934/1959, <em>The Logic of Scientific
Discovery</em>, New York: Basic Books.</li>

<li>–––, 1959, “The Propensity Interpretation of
Probability”,
<em>British Journal of the Philosophy of Science</em>, 10: 25–42.</li>

<li>Predd, J.B., R. Seiringer, E.H. Lieb, D.N. Osherson, H.V. Poor,
and S.R. Kulkarni, 2009, “Probabilistic Coherence and Proper
Scoring Rules”, <em>IEEE Transactions on Information
Theory</em>, 55(10): 4786–4792.</li>

<li>Press, S. J., 2002, <em>Bayesian Statistics: Principles, Models,
and Applications</em> (Wiley Series in Probability and Statistics), New
York: Wiley.</li>

<li>Raftery, A.E., 1995, “Bayesian model selection in social
research”,
<em>Sociological Methodology</em>, 25: 111–163.</li>

<li>Ramsey, F.P., 1926, “Truth and Probability”, in R.B. Braithwaite
(ed.),
<em>The Foundations of Mathematics and other Logical Essays</em>, Ch. VII,
p.156–198, printed in London: Kegan Paul, 1931.</li>

<li>Reichenbach, H., 1938, <em>Experience and prediction: an analysis
of the foundations and the structure of knowledge</em>, Chicago:
University of Chicago Press.</li>

<li>–––, 1949, <em>The theory of probability</em>,
Berkeley: University of California Press.</li>

<li>–––, 1956, <em>The Direction of Time</em>, Berkeley:
University of Los Angeles Press.</li>

<li>Renyi, A., 1970, <em>Probability Theory</em>, Amsterdam: North
Holland.</li>

<li>Robbins, H., 1952, “Some Aspects of the Sequential Design of
Experiments”, <em>Bulletin of the American Mathematical Society</em>,
58: 527–535.</li>

<li>Roberts, H.V., 1967, “Informative stopping rules and inferences
about population size”, <em>Journal of the American Statistical
Association</em>, 62(319): 763–775.</li>

<li>Romeijn, J.W., 2004, “Hypotheses and Inductive
Predictions”, <em>Synthese</em>, 141(3): 333–364.</li>

<li>–––, 2005, <em>Bayesian Inductive Logic</em>, PhD
dissertation, University of Groningen.</li>

<li>–––, 2006, “Analogical Predictions for Explicit
Similarity”,
<em>Erkenntnis</em>, 64: 253–280.</li>

<li>–––, 2011, “Statistics as Inductive Logic”,
in Bandyopadhyay, P. and M. Forster (eds.), <em>Handbook for the
Philosophy of Science</em>, Vol. 7: Philosophy of Statistics,
751–774.</li>

<li>Romeijn, J.W. and van de Schoot, R., 2008, “A Philosophical
Analysis of Bayesian model selection”, in Hoijtink, H.,
I. Klugkist and P. Boelen (eds.), <em>Null, Alternative and
Informative Hypotheses</em>, 329–357.</li>

<li>Romeijn, J.W., van de Schoot, R., and Hoijtink, H., 2012, “One
size does not fit all: derivation of a prior-adapted BIC”, in Dieks,
D., W. Gonzales, S. Hartmann, F.  Stadler, T. Uebel, and M. Weber
(eds.), <em>Probabilities, Laws, and Structures</em>, Berlin:
Springer.</li>

<li>Rosenkrantz, R.D., 1977, <em>Inference, method and decision:
towards a Bayesian philosophy of science</em>, Dordrecht:
Reidel. </li>

<li>–––, 1981, <em>Foundations and Applications of
Inductive Probability</em>, Ridgeview Press.</li>

<li>Royall, R., 1997, <em>Scientific Evidence: A Likelihood
Paradigm</em>, London: Chapman and Hall.</li>

<li>Savage, L.J., 1962, <em>The foundations of statistical
inference</em>, London: Methuen.</li>

<li>Schervish, M.J., T. Seidenfeld, and J.B. Kadane, 2009, “Proper
Scoring Rules, Dominated Forecasts, and Coherence”, <em>Decision
Analysis</em>, 6(4): 202–221.</li>

<li>Schwarz, G., 1978, “Estimating the Dimension of a
Model”, <em>Annals of Statistics</em>, 6: 461–464.</li>

<li>Seidenfeld, T., 1979, <em>Philosophical Problems of Statistical
Inference: Learning from R.A. Fisher</em>, Dordrecht: Reidel.</li>

<li>–––, 1986, “Entropy and uncertainty”, <em>Philosophy of
Science</em>, 53(4): 467–491.</li>

<li>–––, 1992, “R.A. Fisher's Fiducial Argument and
Bayes Theorem”, <em>Statistical Science</em>, 7(3):
358–368.</li>

<li>Shafer, G., 1976, <em>A Mathematical Theory of Evidence</em>, Princeton:
Princeton University Press.</li>

<li>–––, 1982, “On Lindley’s paradox (with discussion)”,
<em>Journal of the American Statistical Association</em>, 378: 325–351.</li>

<li>Shore, J. and Johnson, R., 1980, “Axiomatic derivation of the
principle of maximum entropy and the principle of minimum
cross-entropy”, <em>IEEE Transactions on Information Theory</em>,
26(1): 26–37. </li>

<li>Skyrms, B., 1991, “Carnapian inductive logic for Markov chains”,
<em>Erkenntnis</em>, 35: 439–460.</li>

<li>–––, 1993, “Analogy by similarity in hypercarnapian
inductive logic”, in Massey, G.J., J. Earman, A.I. Janis and
N. Rescher (eds.),
<em>Philosophical Problems of the Internal and External Worlds: Essays
Concerning the Philosophy of Adolf Gruenbaum</em>, Pittsburgh: Pittsburgh
University Press, 273–282.</li>

<li>–––, 1996, “Carnapian inductive logic and Bayesian
statistics”, in: Ferguson, T.S.,  L.S. Shapley, and
J.B. MacQueen (eds.), <em>Statistics, Probability, and Game Theory:
papers in honour of David Blackwell</em>, Hayward: IMS lecture notes,
321–336.</li>

<li>–––, 1999, <em>Choice and Chance: An Introduction to
Inductive Logic</em>, Wadsworth, 4th edition.</li>

<li>Sober, E., 2004, “Likelihood, model selection, and the Duhem-Quine
problem”, <em>Journal of Philosophy</em>, 101(5): 221–241.</li>

<li>Spanos, A., 2010, “Is Frequentist Testing Vulnerable to the
Base-Rate Fallacy?”, <em>Philosophy of Science</em>, 77: 565-583.</li>

<li>–––, 2013a, “Who should be afraid of the
Jeffreys–Lindley paradox?”, <em>Philosophy of Science</em>, 80:
73–93.</li>

<li>–––, 2013b, “A frequentist interpretation of probability
for model-based inductive inference”, <em>Synthese</em>, 190:
1555–1585.</li>

<li>Spiegelhalter, D.J., N.G. Best, B.P. Carlin, and A. van der Linde,
2002, “Bayesian measures of model complexity and fit”, <em>Journal of
Royal Statistical Society</em>, B 64: 583–639.</li>

<li>Spielman, S., 1974, “The Logic of Significance
Testing”, <em>Philosophy of Science</em>, 41: 211–225.</li>

<li>–––, 1978, “Statistical Dogma and the Logic of
Significance Testing”, <em>Philosophy of Science</em>, 45:
120–135.</li>

<li>Sprenger, J., 2013, “The role of Bayesian philosophy within
Bayesian model selection”, <em>European Journal for Philosophy
of Science</em>, 3(1): 101–114.</li>

<li>–––, forthcoming-a, “Bayesianism vs. Frequentism in Statistical
Inference”, in Hajek, A. and C. Hitchcock (eds.), <em>Oxford Handbook of
Probability and Philosophy</em>, Oxford: Oxford University Press.</li>

<li>–––, forthcoming-b, “Testing a precise null hypothesis:
The case of Lindley’s paradox”, <em>Philosophy of
Science</em>.</li>

<li>Spirtes, P., Glymour, C. and Scheines, R., 2001, <em>Causation,
Prediction, and Search</em>, Boston: MIT press, 2nd edition.</li>

<li>Solomonoff, R.J., 1964, “A formal theory of inductive inference”,
parts I and II, <em>Information and Control</em>, 7: 1–22 and
224–254.</li>

<li>Steele, K., 2013, “Persistent experimenters, stopping rules, and
statistical inference”, <em>Erkenntnis</em>, 78(4): 937–961.</li>

<li>Suppes, P., 2001, <em>Representation and Invariance of
Scientific Structures</em>, Chicago: University of Chicago Press.</li>

<li>Uffink, J., 1996, “The constraint rule of the maximum entropy
principle”,
<em>Studies in History and Philosophy of Modern Physics</em>, 27: 47–79.</li>

<li>Vapnik, V.N. and S. Kotz, 2006, <em>Estimation of Dependences
Based on Empirical Data</em>, New York: Springer.</li>

<li>Venn, J., 1888, <em>The Logic of Chance</em>, London: MacMillan,
3rd edition.</li>

<li>Wagenmakers, E.J., 2007, “A practical solution to the pervasive
problems of p values”, Psychonomic Bulletin and Review 14(5),
779–804.</li>

<li>Wagenmakers, E.J., and L.J. Waldorp, (eds.), 2006, <em>Journal of
Mathematical Psychology</em>, 50(2). Special issue on model selection,
99–214.</li>

<li>Wald, A., 1939, “Contributions to the Theory of Statistical Estimation
and Testing Hypotheses”, <em>Annals of Mathematical Statistics</em>, 10(4):
299–326.</li>

<li>–––, 1950, <em>Statistical Decision Functions</em>, New York:
John Wiley and Sons.</li>

<li>Walley, P., 1991, <em>Statistical Reasoning with Imprecise
Probabilities</em>, New York: Chapman &amp; Hall.</li>

<li>Williams, P.M., 1980, “Bayesian conditionalisation and the
principle of minimum information”, <em>British Journal for the
Philosophy of Science</em>, 31: 131–144.</li>

<li>Williamson, J., 2010, <em>In Defence of Objective
Bayesianism</em>, Oxford: Oxford University Press.</li>

<li>Ziliak, S.T. and D.N. McCloskey, 2008, <em>The Cult of Statistical
Significance</em>, Ann Arbor: University of Michigan Press.</li>

<li>Zabell, S.L., 1992, “R. A. Fisher and Fiducial
Argument”, <em>Statistical Science</em>, 7(3): 358–368.</li>

<li>–––, 1982, “W. E. Johnson's ‘Sufficientness’
Postulate”, <em>Annals of Statistics</em>, 10(4): 1090–1099.</li>

</ul>

</div>

<div id="academic-tools">

<h2><a id="Aca">Academic Tools</a></h2>

<blockquote>
<table>
<tbody><tr>
<td valign="top"><img src="../../symbols/sepman-icon.jpg" alt="sep man icon" /></td>
<td><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=statistics&amp;archive=win2019" target="other">How to cite this entry</a>.</td>
</tr>

<tr>
<td valign="top"><img src="../../symbols/sepman-icon.jpg" alt="sep man icon" /></td>
<td><a href="https://leibniz.stanford.edu/friends/preview/statistics/" target="other">Preview the PDF version of this entry</a> at the
 <a href="https://leibniz.stanford.edu/friends/" target="other">Friends of the SEP Society</a>.</td>
</tr>

<tr>
<td valign="top"><img src="../../symbols/inpho.png" alt="inpho icon" /></td>
<td><a href="https://www.inphoproject.org/entity?sep=statistics&amp;redirect=True" target="other">Look up this entry topic</a>
 at the <a href="https://www.inphoproject.org/" target="other">Indiana Philosophy Ontology Project</a>
 (InPhO).</td>
</tr>

<tr>
<td valign="top"><img src="../../symbols/pp.gif" alt="phil papers icon" /></td>
<td><a href="http://philpapers.org/sep/statistics/" target="other">Enhanced bibliography for this entry</a>
at <a href="http://philpapers.org/" target="other">PhilPapers</a>, with links to its database.</td>
</tr>

</tbody></table>
</blockquote>

</div>

<div id="other-internet-resources">

<h2><a id="Oth">Other Internet Resources</a></h2>

<p>
[Please contact the author with suggestions.]
</p>

</div>

<div id="related-entries">

<h2><a id="Rel">Related Entries</a></h2>

<p>

 <a href="../formal-belief/">belief, formal representations of</a> |
 <a href="../causation-probabilistic/">causation: probabilistic</a> |
 <a href="../confirmation/">confirmation</a> |
 <a href="../defaults-semantics-pragmatics/">defaults in semantics and pragmatics</a> |
 <a href="../evidence/">evidence</a> |
 <a href="../induction-problem/">induction: problem of</a> |
 <a href="../learning-formal/">learning theory, formal</a> |
 <a href="../logic-probability/">logic: and probability</a> |
 <a href="../logic-inductive/">logic: inductive</a> |
 <a href="../physics-Rpcc/">physics: Reichenbach’s common cause principle</a> |
 <a href="../probability-interpret/">probability, interpretations of</a> |
 <a href="../reasoning-defeasible/">reasoning: defeasible</a> |
 <a href="../scientific-method/">scientific method</a> |
 <a href="../simplicity/">simplicity</a> |
 <a href="../skepticism-ancient/">skepticism: ancient</a>

</p>

</div>

<script type="text/javascript" src="local.js"></script>
<script type="text/javascript" src="../../MathJax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

</div><!-- #aueditable --><!--DO NOT MODIFY THIS LINE AND BELOW-->

<!-- END ARTICLE HTML -->

</div> <!-- End article-content -->

  <div id="article-copyright">
    <p>
 <a href="../../info.html#c">Copyright © 2014</a> by

<br />
<a href="http://www.philos.rug.nl/~romeyn/index.html" target="other">Jan-Willem Romeijn</a>
&lt;<a href="mailto:j%2ew%2eromeijn%40rug%2enl"><em>j<abbr title=" dot ">.</abbr>w<abbr title=" dot ">.</abbr>romeijn<abbr title=" at ">@</abbr>rug<abbr title=" dot ">.</abbr>nl</em></a>&gt;
    </p>
  </div>

</div> <!-- End article -->

<!-- NOTE: article banner is outside of the id="article" div. -->
<div id="article-banner" class="scroll-block">
     <div id="article-banner-content">
  <a href="../../fundraising/">
  Open access to the SEP is made possible by a world-wide funding initiative.<br />
  Please Read How You Can Help Keep the Encyclopedia Free</a>
 </div>


</div> <!-- End article-banner -->

    </div> <!-- End content -->

    <div id="footer">

      <div id="footer-menu">
        <div class="menu-block">
          <h4><i class="icon-book"></i> Browse</h4>
          <ul role="menu">
            <li><a href="../../contents.html">Table of Contents</a></li>
            <li><a href="../../new.html">New in this Archive</a></li>
            
            <li><a href="../../published.html">Chronological</a></li>
            <li><a href="../../../../archives/">Archives <i class="icon-external-link"></i></a></li>
          </ul>
        </div>
        <div class="menu-block">
          <h4><i class="icon-info-sign"></i> About</h4>
          <ul role="menu">
            <li><a href="../../info.html">Editorial Information</a></li>
            <li><a href="../../about.html">About the SEP</a></li>
            <li><a href="../../board.html">Editorial Board</a></li>
            <li><a href="../../cite.html">How to Cite the SEP</a></li>
            <li><a href="../../special-characters.html">Special Characters</a></li>
            
            <li><a href="../../../../contact.html">Contact <i class="icon-external-link"></i></a></li>
          </ul>
        </div>
        <div class="menu-block">
          <h4><i class="icon-leaf"></i> Support SEP</h4>
          <ul role="menu">
            <li><a href="../../../../support/">Support the SEP</a></li>
            <li><a href="../../../../support/friends.html">PDFs for SEP Friends</a></li>
            <li><a href="../../../../support/donate.html">Make a Donation</a></li>
            <li><a href="../../../../support/sepia.html">SEPIA for Libraries</a></li>
          </ul>
        </div>
      </div> <!-- End footer menu -->

      <div id="mirrors">
        <div id="mirror-info">
          <h4><i class="icon-globe"></i> Mirror Sites</h4>
          <p>View this site from another server:</p>
        </div>
                <div class="btn-group">
<a class="btn dropdown-toggle" data-toggle="dropdown" href="https://plato.stanford.edu/"><span class="flag flag-usa"></span> USA (Main Site) <span class="caret"></span><span class="mirror-source">CSLI, Stanford University</span></a>          <ul class="dropdown-menu">
            <li><a href="https://stanford.library.sydney.edu.au/archives/win2019/entries/statistics/"><span class="flag flag-australia"></span> Australia <span class="mirror-source">Library, University of Sydney</span></a>           </li>
            <li><a href="https://seop.illc.uva.nl/archives/win2019/entries/statistics/"><span class="flag flag-netherlands"></span> Netherlands <span class="mirror-source">ILLC, University of Amsterdam</span></a>           </li>
          </ul>
        </div>
      </div> <!-- End mirrors -->
      
      <div id="site-credits">
        <p class="csli-logo"><a href="https://www-csli.stanford.edu/"><img src="../../symbols/SU_csli.png" width="355" alt="Stanford Center for the Study of Language and Information" /></a></p>
        <p>The Stanford Encyclopedia of Philosophy is <a href="../../info.html#c">copyright © 2016</a> by <a href="http://mally.stanford.edu/">The Metaphysics Research Lab</a>, Center for the Study of Language and Information (CSLI), Stanford University</p>
        <p>Library of Congress Catalog Data: ISSN 1095-5054</p>
      </div> <!-- End site credits -->

    </div> <!-- End footer -->

  </div> <!-- End container -->

   <!-- NOTE: Script required for drop-down button to work (mirrors). -->
  <script>
    $('.dropdown-toggle').dropdown();
  </script>





<div style="position: absolute; width: 0px; height: 0px; overflow: hidden; padding: 0px; border: 0px; margin: 0px;"><div id="MathJax_Font_Test" style="position: absolute; visibility: hidden; top: 0px; left: 0px; width: auto; padding: 0px; border: 0px; margin: 0px; white-space: nowrap; text-align: left; text-indent: 0px; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; font-size: 40px; font-weight: normal; font-style: normal; font-family: MathJax_AMS, monospace;"></div></div></body></html>