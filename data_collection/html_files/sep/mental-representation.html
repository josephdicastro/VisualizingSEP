<!DOCTYPE html><!--[if lt IE 7]> <html class="ie6 ie"> <![endif]--><!--[if IE 7]>    <html class="ie7 ie"> <![endif]--><!--[if IE 8]>    <html class="ie8 ie"> <![endif]--><!--[if IE 9]>    <html class="ie9 ie"> <![endif]--><!--[if !IE]> --><html xmlns="http://www.w3.org/1999/xhtml"><!-- <![endif]--><head>
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>
Mental Representation (Stanford Encyclopedia of Philosophy/Winter 2019 Edition)
</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="robots" content="noarchive, noodp" />
<meta property="citation_title" content="Mental Representation" />
<meta property="citation_author" content="Pitt, David" />
<meta property="citation_publication_date" content="2000/03/30" />
<meta name="DC.title" content="Mental Representation" />
<meta name="DC.creator" content="Pitt, David" />
<meta name="DCTERMS.issued" content="2000-03-30" />
<meta name="DCTERMS.modified" content="2012-12-11" />

<!-- NOTE: Import webfonts using this link: -->
<link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,300,600,200&amp;subset=latin,latin-ext" rel="stylesheet" type="text/css" />

<link rel="stylesheet" type="text/css" media="screen,handheld" href="../../css/bootstrap.min.css" />
<link rel="stylesheet" type="text/css" media="screen,handheld" href="../../css/bootstrap-responsive.min.css" />
<link rel="stylesheet" type="text/css" href="../../css/font-awesome.min.css" />
<!--[if IE 7]> <link rel="stylesheet" type="text/css" href="../../css/font-awesome-ie7.min.css"> <![endif]-->
<link rel="stylesheet" type="text/css" media="screen,handheld" href="../../css/style.css" />
<link rel="stylesheet" type="text/css" media="print" href="../../css/print.css" />
<link rel="stylesheet" type="text/css" href="../../css/entry.css" />
<!--[if IE]> <link rel="stylesheet" type="text/css" href="../../css/ie.css" /> <![endif]-->
<script type="text/javascript" src="../../js/jquery-1.9.1.min.js"></script>
<script type="text/javascript" src="../../js/bootstrap.min.js"></script>

<!-- NOTE: Javascript for sticky behavior needed on article and ToC pages -->
<script type="text/javascript" src="../../js/jquery-scrolltofixed-min.js"></script>
<script type="text/javascript" src="../../js/entry.js"></script>

<!-- SEP custom script -->
<script type="text/javascript" src="../../js/sep.js"></script>
</head>

<!-- NOTE: The nojs class is removed from the page if javascript is enabled. Otherwise, it drives the display when there is no javascript. -->
<body class="archive article" id="pagetopright">
<div id="container">
<div id="header-wrapper">
  <div id="header">
    <div id="branding">
      <div id="site-logo"><a href="../../index.html"><img src="../../symbols/sep-man-red.png" alt="SEP logo" /></a></div>
      <div id="site-title"><a href="../../index.html">Stanford Encyclopedia of Philosophy Archive<div id="site-subtitle">Winter 2019 Edition</div></a></div>
    </div>
    <div id="navigation">
      <div class="navbar">
        <div class="navbar-inner">
          <div class="container">
            <button class="btn btn-navbar collapsed" data-target=".collapse-main-menu" data-toggle="collapse" type="button"> <i class="icon-reorder"></i> Menu </button>
            <div class="nav-collapse collapse-main-menu collapse">
              <ul class="nav">
                <li class="dropdown"><a id="drop1" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-book"></i> Browse</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop1">
                    <li><a href="../../contents.html">Table of Contents</a></li>
                    <li><a href="../../new.html">New in this Archive</a></li>
                    
                    <li><a href="../../published.html">Chronological</a></li>
                    <li><a href="../../../../archives/">Archives <i class="icon-external-link"></i></a></li>
                  </ul>
                </li>
                <li class="dropdown"><a id="drop2" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-info-sign"></i> About</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop2">
                    <li><a href="../../info.html">Editorial Information</a></li>
                    <li><a href="../../about.html">About the SEP</a></li>
                    <li><a href="../../board.html">Editorial Board</a></li>
                    <li><a href="../../cite.html">How to Cite the SEP</a></li>
                    <li><a href="../../special-characters.html">Special Characters</a></li>
                    
                    <li><a href="../../../../contact.html">Contact <i class="icon-external-link"></i></a></li>
                  </ul>
                </li>
                <li class="dropdown"><a id="drop3" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-leaf"></i> Support SEP</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop3">
                    <li><a href="../../../../support/">Support the SEP</a></li>
                    <li><a href="../../../../support/friends.html">PDFs for SEP Friends</a></li>
                    <li><a href="../../../../support/donate.html">Make a Donation</a></li>
                    <li><a href="../../../../support/sepia.html">SEPIA for Libraries</a></li>
                  </ul>
                </li>
              </ul>
            </div>
          </div>
        </div>
      </div>
    </div>
    <!-- End navigation -->
    
    <div id="search">
      <form id="search-form" method="get" action="../../../../search/searcher.py">
        <input type="search" name="query" placeholder="Search this archive" />
<input type="hidden" name="archive" value="win2019" />

        <div class="search-btn-wrapper"><button class="btn search-btn" type="submit"><i class="icon-search"></i></button></div>
      </form>
    </div>
    <!-- End search --> 
    
  </div>
  <!-- End header --> 
</div>
<!-- End header wrapper -->

<div id="content">

<!-- Begin article sidebar -->
<div id="article-sidebar" class="sticky" style="z-index: 999;">
  <div class="navbar">
    <div class="navbar-inner">
      <div class="container">
        <button class="btn btn-navbar collapsed" data-target=".collapse-sidebar" data-toggle="collapse" type="button"> <i class="icon-reorder"></i> Entry Navigation </button>
        <div id="article-nav" class="nav-collapse collapse-sidebar collapse">
          <ul class="nav">
            <li><a href="#toc">Entry Contents</a></li>
            <li><a href="#Bib">Bibliography</a></li>
            <li><a href="#Aca">Academic Tools</a></li>
            <li><a href="https://leibniz.stanford.edu/friends/preview/mental-representation/">Friends PDF Preview <i class="icon-external-link"></i></a></li>
            <li><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=mental-representation&amp;archive=win2019">Author and Citation Info <i class="icon-external-link"></i></a> </li>
            <li><a href="#pagetopright" class="back-to-top">Back to Top <i class="icon-angle-up icon2x"></i></a></li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</div><div></div>
<!-- End article sidebar --> 

<!-- NOTE: Article content must have two wrapper divs: id="article" and id="article-content" -->
<div id="article">
<div id="article-content">

<!-- BEGIN ARTICLE HTML -->


<div id="aueditable"><!--DO NOT MODIFY THIS LINE AND ABOVE-->

<h1>Mental Representation</h1><div id="pubinfo"><em>First published Thu Mar 30, 2000; substantive revision Tue Dec 11, 2012</em></div>

<div id="preamble">

<p>

The notion of a “mental representation” is, arguably, in the first
instance a theoretical construct of cognitive science. As such, it is a
basic concept of the Computational Theory of Mind, according to which
cognitive states and processes are constituted by the occurrence,
transformation and storage (in the mind/brain) of information-bearing
structures (representations) of one kind or another.</p>

<p>

However, on the assumption that a representation is an object with
semantic properties (content, reference, truth-conditions,
truth-value, etc.), a mental representation may be more broadly
construed as a mental object with semantic properties. As such, mental
representations (and the states and processes that involve them) need
not be understood only in computational terms. On this broader
construal, mental representation is a philosophical topic with roots
in antiquity and a rich history and literature predating the recent
“cognitive revolution,” and which continues to be of interest in pure
philosophy. Though most contemporary philosophers of mind acknowledge
the relevance and importance of cognitive science, they vary in their
degree of engagement with its literature, methods and results; and
there remain, for many, issues concerning the representational
properties of the mind that can be addressed independently of the
computational hypothesis.</p>

<p>

Though the term ‘Representational Theory of Mind’ is
sometimes used almost interchangeably with ‘Computational Theory
of Mind’, I will use it here to refer to any theory that
postulates the existence of semantically evaluable mental objects,
including philosophy's stock in trade mentalia — thoughts,
concepts, percepts, ideas, impressions, notions, rules, schemas,
images, phantasms, etc. — as well as the various sorts of
“subpersonal” representations postulated by cognitive
science. Representational theories may thus be contrasted with
theories, such as those of Baker (1995), Collins (1987), Dennett
(1987), Gibson (1966, 1979), Reid (1764/1997), Stich (1983) and Thau
(2002), which deny the existence of such things.</p>

</div>

<div id="toc">
<!--Entry Contents-->
<ul>
<li><a href="#Representational">1. The Representational Theory of Mind</a></li>

<li><a href="#Propositional">2. Propositional Attitudes</a></li>

<li><a href="#Conceptual">3. Conceptual and Nonconceptual Representation</a></li>

<li><a href="#Representationalism">4. Representationalism and Phenomenalism</a></li>

<li><a href="#Imagery">5. Imagery</a></li>

<li><a href="#Content">6. Content Determination</a></li>

<li><a href="#Internalism">7. Internalism and Externalism</a></li>

<li><a href="#Computation">8. The Computational Theory of Mind</a></li>

<li><a href="#Thought">9. Thought and Language</a></li>

<li><a href="#Bib">Bibliography</a></li>

<li><a href="#Aca">Academic Tools</a></li>

<li><a href="#Oth">Other Internet Resources</a></li>

<li><a href="#Rel">Related Entries</a></li>
</ul>
<!--Entry Contents-->

<hr />

</div>

<div id="main-text">

<h2><a name="Representational">1. The Representational Theory of Mind</a></h2>

<p>

The Representational Theory of Mind (RTM) (which goes back at least
to Aristotle) takes as its starting point commonsense mental states,
such as thoughts, beliefs, desires, perceptions and imagings. Such states
are said to have “intentionality” — they are <em>about</em> or
<em>refer to</em> things, and may be evaluated with respect to
properties like consistency, truth, appropriateness and accuracy. (For
example, the thought that cousins are not related is inconsistent, the
belief that Elvis is dead is true, the desire to eat the moon is
inappropriate, a visual experience of a ripe strawberry as red is
accurate, an imaging of George W. Bush with dreadlocks is
inaccurate.)</p>

<p>

RTM defines such intentional mental states as relations to mental
representations, and explains the intentionality of the former in terms
of the semantic properties of the latter. For example, to believe that
Elvis is dead is to be appropriately related to a mental representation
whose propositional content is <em>that Elvis is dead</em>. (The
<em>desire</em> that Elvis be dead, the <em>fear</em> that he is dead,
the <em>regret</em> that he is dead, etc., involve different relations
to the same mental representation.) To perceive a strawberry is, on
the representational view, to have a sensory experience of some kind
which is appropriately related to (e.g., caused by) the
strawberry.</p>

<p>

RTM also understands mental processes such as thinking, reasoning and
imagining as sequences of intentional mental states. For example, to
imagine the moon rising over a mountain is, <em>inter alia</em>, to
entertain a series of mental images of the moon (and a mountain). To
infer a proposition
<em>q</em> from the propositions <em>p</em> and <em>if p then q</em> is
(<em>inter alia</em>) to have a sequence of thoughts of the form
<em>p</em>, <em>if p then q</em>, <em>q</em>.</p>

<p>

Contemporary philosophers of mind have typically supposed (or at
least <em>hoped</em>) that the mind can be <em>naturalized</em> —
i.e., that all mental facts have explanations in the terms of natural
science. This assumption is shared within cognitive science, which
attempts to provide accounts of mental states and processes in terms
(ultimately) of features of the brain and central nervous system. In
the course of doing so, the various sub-disciplines of cognitive
science (including cognitive and computational psychology and cognitive
and computational neuroscience) postulate a number of different kinds
of structures and processes, many of which are not directly implicated
by mental states and processes as commonsensically conceived. There
remains, however, a shared commitment to the idea that mental states
and processes are to be explained in terms of mental
representations.</p>

<p>

In philosophy, recent debates about mental representation have
centered around the existence of propositional attitudes (beliefs,
desires, etc.) and the determination of their contents (how they come
to be about what they are about), and the existence of phenomenal
properties and their relation to the content of thought and perceptual
experience. Within cognitive science itself, the philosophically
relevant debates have been focused on the computational architecture of
the brain and central nervous system, and the compatibility of
scientific and commonsense accounts of mentality.</p>

<h2><a name="Propositional">2. Propositional Attitudes</a></h2>

<p>

<em>Intentional Realists</em> such as Dretske (e.g., 1988) and Fodor
(e.g., 1987) note that the generalizations we apply in everyday life in
predicting and explaining each other's behavior (often collectively
referred to as “folk psychology”) are both remarkably successful and
indispensable. What a person believes, doubts, desires, fears, etc. is
a highly reliable indicator of what that person will do; and we have no
other way of making sense of each other's behavior than by ascribing
such states and applying the relevant generalizations. We are thus
committed to the basic truth of commonsense psychology and, hence, to
the existence of the states its generalizations refer to. (Some
realists, such as Fodor, also hold that commonsense psychology will be
vindicated by cognitive science, given that propositional attitudes can
be construed as computational relations to mental representations.)</p>

<p>

<em>Intentional Eliminativists</em>, such as Churchland, (perhaps)
Dennett and (at one time) Stich argue that no such things as
propositional attitudes (and their constituent representational states)
are implicated by the successful explanation and prediction of our
mental lives and behavior. Churchland denies that the generalizations
of commonsense propositional-attitude psychology are true. He (1981)
argues that folk psychology is a theory of the mind with a long history
of failure and decline, and that it resists incorporation into the
framework of modern scientific theories (including cognitive
psychology). As such, it is comparable to alchemy and phlogiston
theory, and ought to suffer a comparable fate. Commonsense psychology
is <em>false</em>, and the states (and representations) it postulates
simply don't exist. (It should be noted that Churchland is not an
eliminativist about mental representation <em>tout court</em>. See,
e.g., Churchland 1989.)</p>

<p>

Dennett (1987a) grants that the generalizations of commonsense
psychology are true and indispensable, but denies that this is
sufficient reason to believe in the entities they appear to refer to.
He argues that to give an intentional explanation of a system's
behavior is merely to adopt the “intentional stance”
toward it. If the strategy of assigning contentful states to a system
and predicting and explaining its behavior (on the assumption that it
is <em>rational</em> — i.e., that it behaves as it should, given
the propositional attitudes it should have, given its environment) is
successful, then the system is intentional, and the
propositional-attitude generalizations we apply to it are true. But
there is nothing more to having a propositional attitude than
this. (See Dennett 1987a: 29.)</p>

<p>

Though he has been taken to be thus claiming that intentional
explanations should be construed instrumentally, Dennett (1991)
insists that he is a “moderate” realist about
propositional attitudes, since he believes that the patterns in the
behavior and behavioral dispositions of a system on the basis of which
we (truly) attribute intentional states to it are objectively real. In
the event that there are two or more explanatorily adequate but
substantially different systems of intentional ascriptions to an
individual, however, Dennett claims there is no fact of the matter
about what the individual believes (1987b, 1991).  This does suggest
an irrealism at least with respect to the sorts of things Fodor and
Dretske take beliefs to be; though it is not the view that there is
simply <em>nothing</em> in the world that makes intentional
explanations true.</p>

<p>

(Davidson 1973, 1974 and Lewis 1974 also defend the view that what
it is to have a propositional attitude is just to be interpretable in a
particular way. It is, however, not entirely clear whether they intend
their views to imply irrealism about propositional attitudes.)</p>

<p>

Stich (1983) argues that cognitive psychology does not (or, in any
case, <em>should</em> not) taxonomize mental states by their semantic
properties at all, since attribution of psychological states by
content is sensitive to factors that render it problematic in the
context of a scientific psychology. Cognitive psychology seeks causal
explanations of behavior and cognition, and the causal powers of a
mental state are determined by its intrinsic “structural”
or “syntactic” properties. The semantic properties of a
mental state, however, are determined by its extrinsic properties
— e.g., its history, environmental or intramental
relations. Hence, such properties cannot figure in causal-scientific
explanations of behavior. (Fodor 1994 and Dretske 1988 are realist
attempts to come to grips with some of these problems.) Stich proposes
a <em>syntactic</em> theory of the mind, on which the semantic
properties of mental states play <em>no</em> explanatory role. (Stich
has since changed his views on a number of these issues. See Stich
1996.)</p>

<h2><a name="Conceptual">3. Conceptual and Non-Conceptual Representation</a></h2>

<p>

It is a traditional assumption among realists about mental
representations that representational states come in two basic
varieties (cf. Boghossian 1995). There are those, such as thoughts,
which are composed of concepts and have no phenomenal
(“what-it's-like”) features (“qualia”), and
those, such as sensations, which have phenomenal features but no
conceptual constituents. (Nonconceptual content is usually defined as
a kind of content that states of a creature lacking concepts might
nonetheless
 enjoy.<sup>[<a href="notes.html#1" name="note-1">1</a>]</sup>) 
On this taxonomy, mental states can
represent either in a way analogous to expressions of natural
languages or in a way analogous to drawings, paintings, maps,
photographs or movies.  Perceptual states such as <em>seeing that</em>
something is blue, are sometimes thought of as hybrid states,
consisting of, for example, a non-conceptual sensory experience and a
belief, or some more integrated compound of conceptual and
nonconceptual elements. (There is an extensive literature on the
representational content of perceptual experience. See the entry on
the
  <a href="../perception-contents/">contents of perception</a>.)</p>

<p>

Disagreement over nonconceptual representation concerns the existence
and nature of phenomenal properties and the role they play in
determining the content of sensory experience. Dennett (1988), for
example, denies that there are such things as qualia at all (as they
are standardly construed); while Brandom (2002), McDowell (1994), Rey
(1991) and Sellars (1956) deny that they are needed to explain the
content of sensory experience.  Among those who accept that
experiences have phenomenal content, some (Dretske, Lycan, Tye) argue
that it is reducible to a kind of intentional content, while others
(Block, Loar, Peacocke) argue that it is irreducible. (See the
discussion in the next section.)</p>

<p>

Some historical discussions of the representational properties of mind
(e.g., Aristotle <em>De Anima</em>, Locke 1689/1975, Hume 1739/1978)
seem to assume that nonconceptual representations — percepts
(“impressions”), images (“ideas”) and the like
— are the
<em>only</em> kinds of mental representations, and that the mind
represents the world in virtue of being in states that
<em>resemble</em> things in it. On such a view, all representational
states have their content in virtue of their phenomenal features.
Powerful arguments, however, focusing on the lack of generality
(Berkeley <em>Principles of Human Knowledge</em>), ambiguity
(Wittgenstein 1953) and non-compositionality (Fodor 1981c) of sensory
and imagistic representations, as well as their unsuitability to
function as logical (Frege 1918/1997, Geach 1957) or mathematical
(Frege 1884/1953) concepts, and the symmetry of resemblance (Goodman
1976), convinced philosophers that no theory of mind can get by with
only nonconceptual representations construed in this way.</p>

<p>

There has also been dissent from the traditional claim that conceptual
representations (thoughts, beliefs) lack phenomenology.  Chalmers
(1996), Flanagan (1992), Goldman (1993), Horgan and Tienson (2002),
Jackendoff (1987), Levine (1993, 1995, 2001), McGinn (1991a), Pitt
(2004, 2009, 2011, Forthcoming), Searle (1992), Siewert (1998) and
Strawson (1994), claim that purely conceptual (conscious)
representational states themselves have a (perhaps proprietary)
phenomenology. (This view — bread and butter, it should be said,
among historical and contemporary Phenomenologists — has been
gaining momentum of late among analytic philosophers of mind.  See,
e.g., the essays in Bayne and Montague 2011 and in Kriegel
Forthcoming, Farkas 2008 and Kriegel 2011.)  If this claim is correct,
the question of what role phenomenology plays in the determination of
content rearises for conceptual representation; and the eliminativist
ambitions of Sellars, Brandom, Rey, et al. would meet a new obstacle.
(It would also raise prima facie problems for reductivist
representationalism (see the next section), as well as for reductive
naturalistic theories of intentional content.)</p>

<h2><a name="Representationalism">4. Representationalism and Phenomenalism</a></h2>

<p>

Among realists about phenomenal properties, the central division is
between <em>representationalists</em> (also called
“representationists” and “intentionalists”)
— e.g., Dretske (1995), Harman (1990), Leeds (1993), Lycan
(1987, 1996), Rey (1991), Thau (2002), Tye (1995, 2000, 2009) —
and <em>phenomenalists</em> (also called “phenomenists”)
— e.g., Block (1996, 2003), Chalmers (1996,2004), Evans (1982),
Loar (2003a, 2003b), Peacocke (1983, 1989, 1992, 2001), Raffman
(1995), Shoemaker (1990). Representationalists claim that the
phenomenal character of a mental state is reducible to a kind of
intentional content, naturalistically construed (a la
Dretske). Phenomenalists claim that the phenomenal character of a
mental state is not so reducible.</p>

<p>

The representationalist thesis is often formulated as the claim that
phenomenal properties are representational or intentional. However,
this formulation is ambiguous between a reductive and a non-reductive
claim (though the term ‘representationalism’ is most often
used for the reductive claim). (See Chalmers 2004a.) On one hand, it
could mean that the phenomenal content of an experience is a kind of
intentional content (i.e., the objective qualitative properties it
represents). On the other, it could mean that the intrinsic,
subjective phenomenal properties of an experience determine an
intentional content. Representationalists such as Dretske, Lycan and
Tye would assent to the former claim, whereas phenomenalists such as
Block, Chalmers, Loar and Peacocke would assent to the latter. (Among
phenomenalists, there is further disagreement about whether qualia
are <em>intrinsically</em> representational (Loar) or not (Block,
Peacocke).  (So-called “Ganzfeld” experiences, in which,
for example, the visual field is completely taken up with a uniform
experience of a single color, are a standard test case: Do Ganzfeld
experiences <i>represent</i> anything?  It may be that doubts about
the representationality of such experiences is simply a consequence of
the fact that (outside the laboratory) we never encounter things that
would produce them.  Supposing we routinely did (and especially if we
had names for them), it seems unlikely such skepticism would
arise.)</p>

<p>

Most (reductive) representationalists are motivated by the
conviction that one or another naturalistic explanation of
intentionality (see the next section) is, in broad outline, correct,
and by the desire to complete the naturalization of the mental by
applying such theories to the problem of phenomenality. (Needless to
say, most phenomenalists (Chalmers is the major exception) are just as
eager to naturalize the phenomenal — though not in the same
way.)</p>

<p>

The main argument for representationalism appeals to the
<em>transparency</em> of experience (cf. Tye 2000: 45–51). The
properties that characterize what it's like to have a perceptual
experience are presented in experience as properties of objects
perceived: in attending to an experience, one seems to “see
through it” to the objects and properties it is experiences
 <em>of</em>.<sup>[<a href="notes.html#2" name="note-2">2</a>]</sup>
 They are not
presented as properties of the experience itself. If nonetheless they
<em>were</em> properties of the experience, perception would be
massively deceptive. But perception is not massively deceptive.
According to the representationalist, the phenomenal character of an
experience is due to its <em>representing</em> objective,
non-experiential properties. (In veridical perception, these properties
are locally instantiated; in illusion and hallucination, they are not.)
On this view, introspection is indirect perception: one comes to know
what phenomenal features one's experience has by coming to know what
objective features it represents.  (Cf. also Dretske 1996, 1999.)</p>

<p>

In order to account for the intuitive differences between conceptual
and sensory representations, representationalists appeal to 
structural or functional properties. Dretske (1995), for example,
distinguishes experiences and thoughts on the basis of the origin and
nature of their functions: an experience of a property <em>P</em> is a
state of a system whose <em>evolved</em> function is to indicate the
presence of <em>P</em> in the environment; a thought representing the
property <em>P</em>, on the other hand, is a state of a system whose
<em>assigned</em> (learned) function is to calibrate the output of the
experiential system. Rey (1991) takes both thoughts and experiences to
be relations to sentences in the language of thought, and distinguishes
them on the basis of (the functional roles of) such sentences'
constituent predicates. Lycan (1987, 1996) distinguishes them in terms
of their functional-computational profiles. Tye (2000) distinguishes
them in terms of their functional roles and the intrinsic structure of
their vehicles: thoughts are representations in a language-like medium,
whereas experiences are image-like representations consisting of
“symbol-filled arrays.” (Cf. the account of mental images in Tye
1991.)</p>

<p>

Phenomenalists tend to make use of the same sorts of features
(function, intrinsic structure) in explaining some of the intuitive
differences between thoughts and experiences; but they do not suppose
that such features exhaust the differences between phenomenal and
non-phenomenal representations. For the phenomenalist, it is the
phenomenal properties of experiences — qualia themselves —
that constitute the fundamental difference between experience and
thought. Peacocke (1992), for example, develops the notion of a
perceptual “scenario” (an assignment of phenomenal
properties to coordinates of a three-dimensional egocentric space),
whose content is “correct” (a semantic property) if in the
corresponding “scene” (the portion of the external world
represented by the scenario) properties are distributed as their
phenomenal analogues are in the scenario.</p>

<p>

Another sort of representation appealed to by some phenomenalists
(e.g., Chalmers (2003), Block (2003)) is what Chalmers calls a “pure
phenomenal concept.” A phenomenal concept in general is a concept
whose denotation is a phenomenal property, and it may be discurive
(‘the color of ripe bananas‘), demonstrative
(‘<em>this</em> color’; Loar 1996)), or even more
direct. On Chalmers's view, a <em>pure</em> phenomenal concept is
(something like) a conceptual/phenomenal hybrid consisting of a
phenomenological “sample” (an image or an occurrent sensation)
integrated with (or functioning as) a conceptual component. Phenomenal
concepts are postulated to account for the apparent fact (among
others) that, as McGinn (1991b) puts it, “you cannot form
[introspective] concepts of conscious properties unless you yourself
instantiate those properties.” One cannot have a phenomenal concept of
a phenomenal property <em>P</em>, and, hence,
phenomenal <em>beliefs</em> about <em>P</em>, without having
experience of <em>P</em>, because <em>P</em> itself is (in some
way) <em>constitutive</em> of the concept of <em>P</em>. (Cf. Jackson
1982, 1986 and Nagel 1974.) (Chalmers (2004b) puts pure phenomenal
concepts to use in defending the Knowledge Argument against
physicalism.  Alter and Walter 2007 is an excellent collection of
essays on phenomenal concepts.)</p>

<h2><a name="Imagery">5. Imagery</a></h2>

<p>

Though imagery has played an important role in the history of
philosophy of mind, the important contemporary literature on it is
primarily psychological. (McGinn 2004 is a notable recent exception.)
In a series of psychological experiments done in the 1970s (summarized
in Kosslyn 1980 and Shepard and Cooper 1982), subjects' response time
in tasks involving mental manipulation and examination of presented
figures was found to vary in proportion to the spatial properties
(size, orientation, etc.) of the figures presented.  The question of
how these experimental results are to be explained kindled a lively
debate on the nature of imagery and imagination.</p>

<p>

Kosslyn (1980) claims that the results suggest that the tasks were
accomplished via the examination and manipulation of mental
representations that themselves have spatial properties — i.e.,
<em>pictorial</em> representations, or <em>images</em>. Others,
principally Pylyshyn (1979, 1981a, 1981b, 2003), argue that the
empirical facts can be explained in terms exclusively of
<em>discursive</em>, or <em>propositional</em> representations and
cognitive processes defined over them. (Pylyshyn takes such
representations to be sentences in a language of thought.)</p>

<p>

The idea that pictorial representations are literally
<em>pictures</em> in the head is not taken seriously by proponents of
the pictorial view of imagery (see, e.g., Kosslyn and Pomerantz 1977).
The claim is, rather, that mental images represent in a way that is
relevantly <em>like</em> the way pictures represent. (Attention has
been focused on <em>visual</em> imagery — hence the designation
‘pictorial’; though of course there may be imagery in
other modalities — auditory, olfactory, etc. — as
well.  See O'Callaghan 2007 for discussion of auditory imagery.)</p>

<p>

The distinction between pictorial and discursive representation can
be characterized in terms of the distinction between <em>analog</em>
and <em>digital</em> representation (Goodman 1976). This distinction
has itself been variously understood (Fodor &amp; Pylyshyn 1981,
Goodman 1976, Haugeland 1981, Lewis 1971, McGinn 1989), though a widely
accepted construal is that analog representation is continuous (i.e.,
in virtue of continuously variable properties of the representation),
while digital representation is discrete (i.e., in virtue of properties
a representation either has or doesn't have) (Dretske 1981). (An
analog/digital distinction may also be made with respect to cognitive
<em>processes</em>. (Block 1983.)) On this understanding of the
analog/digital distinction, imagistic representations, which represent
in virtue of properties that may vary continuously (such as being more
or less bright, loud, vivid, etc.), would be analog, while conceptual
representations, whose properties do not vary continuously (a thought
cannot be more or less about Elvis: either it is or it is not) would be
digital.</p>

<p>

It might be supposed that the pictorial/discursive distinction is
best made in terms of the phenomenal/nonphenomenal distinction, but it
is not obvious that this is the case. For one thing, there may be
nonphenomenal properties of representations that vary continuously.
Moreover, there are ways of understanding pictorial representation that
presuppose neither phenomenality nor analogicity. According to Kosslyn
(1980, 1982, 1983), a mental representation is “quasi-pictorial” when
every part of the representation corresponds to a part of the object
represented, and relative distances between parts of the object
represented are preserved among the parts of the representation. But
distances between parts of a representation can be defined functionally
rather than spatially — for example, in terms of the number of
discrete computational steps required to combine stored information
about them. (Cf. Rey 1981.)</p>

<p>

Tye (1991) proposes a view of images on which they are hybrid
representations, consisting both of pictorial and discursive elements.
On Tye's account, images are “(labeled) interpreted symbol-filled
arrays.” The symbols represent discursively, while their arrangement in
arrays has representational significance (the location of each “cell”
in the array represents a specific viewer-centered 2-D location on the
surface of the imagined object).</p>

<h2><a name="Content">6. Content Determination</a></h2>

<p>

The contents of mental representations are typically taken to be
abstract objects (properties, relations, propositions, sets, etc.). A
pressing question, especially for the naturalist, is how mental
representations come to have their contents. Here the issue is not how
to naturalize <em>content</em> (abstract objects can't be
naturalized), but, rather, how to specify naturalistic
content-determining <em>relations</em> between mental representations
and the abstract objects they express. There are two basic types of
contemporary naturalistic theories of content-determination,
<em>causal-informational</em> and
 <em>functional</em>.<sup>[<a href="notes.html#3" name="note-3">3</a>]</sup></p>

<p>

Causal-informational theories (Dretske 1981, 1988, 1995) hold that
the content of a mental representation is grounded in the information
it carries about what <em>does</em> (Devitt 1996) or <em>would</em>
(Fodor 1987, 1990a) cause it to
 occur.<sup>[<a href="notes.html#4" name="note-4">4</a>]</sup>
 There is, however,
widespread agreement that causal-informational relations are not
sufficient to determine the content of mental representations. Such
relations are common, but representation is not. Tree trunks, smoke,
thermostats and ringing telephones carry information about what they
are causally related to, but they do not represent (in the relevant
sense) what they carry information about. Further, a representation can
be caused by something it does not represent, and can represent
something that has not caused it.</p>

<p>

The main attempts to specify what makes a causal-informational state
a mental representation are <em>Asymmetric Dependency Theories</em>
(e.g., Fodor 1987, 1990a, 1994) and <em>Teleological Theories</em>
(Fodor 1990b, Millikan 1984, Papineau 1987, Dretske 1988, 1995). The
Asymmetric Dependency Theory distinguishes merely informational
relations from representational relations on the basis of their
higher-order relations to each other: informational relations depend
upon representational relations, but not vice versa. For example, if
tokens of a mental state type are reliably caused by horses,
cows-on-dark-nights, zebras-in-the-mist and Great Danes, then they
carry information about horses, etc. If, however, such tokens are
caused by cows-on-dark-nights, etc. <em>because</em> they were caused
by horses, but not vice versa, then they represent horses (or the
property <em>horse</em>).</p>

<p>

According to Teleological Theories, representational relations are
those a representation-producing mechanism has the <em>selected</em>
(by evolution or learning) <em>function</em> of establishing. For
example, zebra-caused horse-representations do not mean <em>zebra</em>,
because the mechanism by which such tokens are produced has the
selected function of indicating horses, not zebras. The
horse-representation-producing mechanism that responds to zebras is
<em>malfunctioning</em>.</p>

<p>

Functional theories (Block 1986, Harman 1973), hold that the content
of a mental representation is determined, at least in part, by its
(causal, computational, inferential) relations to other mental
representations. They differ on whether relata should include all
other mental representations or only some of them, and on whether to
include external states of affairs. The view that the content of a
mental representation is determined by its inferential/computational
relations with <em>all</em> other representations is <em>holism</em>;
the view it is determined by relations to only <em>some</em> other
mental states is
<em>localism</em> (or <em>molecularism</em>). (The non-functional view that the
content of a mental state depends on <em>none</em> of its relations to
other mental states is <em>atomism</em>.) Functional theories that
recognize no content-determining external relata have been called
<em>solipsistic</em> (Harman 1987). Some theorists posit distinct roles
for internal and external connections, the former determining semantic
properties analogous to sense, the latter determining semantic
properties analogous to reference (McGinn 1982, Sterelny 1989).</p>

<p>

(Reductive) representationalists (Dretske, Lycan, Tye) usually take
one or another of these theories to provide an explanation of the
(non-conceptual) content of experiential states. They thus tend to be
externalists (see the next section) about phenomenological as well as
conceptual content. Phenomenalists and non-reductive
representationalists (Block, Chalmers, Loar, Peacocke, Siewert), on the
other hand, take it that the representational content of such states is
(at least in part) determined by their intrinsic phenomenal properties.
Further, those who advocate a phenomenally-based approach to
<em>conceptual</em> content (Horgan and Tienson, Kriegel, Loar, Pitt, Searle,
Siewert) also seem to be committed to internalist individuation of the
content (if not the reference) of such states.</p>

<h2><a name="Internalism">7. Internalism and Externalism</a></h2>

<p>

Generally, those who, like informational theorists, think relations to
one's (natural or social) environment are (at least partially)
determinative of the content of mental representations are
<em>externalists</em>, or <em>anti-individualists</em> (e.g., Burge
1979, 1986b, 2010, McGinn 1977), whereas those who, like some proponents of
functional theories, think representational content is determined by
an individual's intrinsic properties alone, are <em>internalists</em>
(or
<em>individualists</em>; cf. Putnam 1975, Fodor
 1981b).<sup>[<a href="notes.html#5" name="note-5">5</a>]</sup></p>

<p>

This issue is widely taken to be of central importance, since
psychological explanation, whether commonsense or scientific, is
supposed to be both causal and content-based. (Beliefs and desires
cause the behaviors they do because they have the contents they do. For
example, the desire <em>that one have a beer</em> and the beliefs
<em>that there is beer in the refrigerator</em> and <em>that the
refrigerator is in the kitchen</em> may explain one's getting up and
going to the kitchen.) If, however, a mental representation's having a
particular content is due to factors <em>extrinsic</em> to it, it is
unclear how its having that content could determine its causal powers,
which, arguably, must be intrinsic (see Stich 1983, Fodor 1982, 1987,
1994). Some who accept the standard arguments for externalism have
argued that internal factors determine a <em>component</em> of the
content of a mental representation. They say that mental
representations have both “narrow” content (determined by intrinsic
factors) and “wide” or “broad” content (determined by narrow content
plus extrinsic factors). (This distinction may be applied to the
sub-personal representations of cognitive science as well as to those
of commonsense psychology. See von Eckardt 1993: 189.)</p>

<p>

Narrow content has been variously construed. Putnam (1975), Fodor
(1982: 114; 1994: 39ff), and Block (1986: 627ff), for example, seem to
understand it as something like <em>de dicto</em> content (i.e.,
Fregean <em>sense</em>, or perhaps <em>character</em>, à la
Kaplan 1989). On this construal, narrow content is context-independent
and directly expressible. Fodor (1987) and Block (1986), however, have
also characterized narrow content as radically <em>inexpressible</em>.
On this construal, narrow content is a kind of proto-content, or
content-determinant, and can be specified only indirectly, via
specifications of context/wide-content pairings. On both construals,
narrow contents are characterized as functions from context to (wide)
content. The narrow content of a representation is determined by
properties intrinsic to it or its possessor, such as its syntactic
structure or its intramental computational or inferential role.</p>

<p>

Burge (1986b) has argued that causation-based worries about
externalist individuation of psychological content, and the
introduction of the narrow notion, are misguided. Fodor (1994, 1998)
has more recently urged that a scientific psychology might not need
narrow content in order to supply naturalistic (causal) explanations of
human cognition and action, since the sorts of cases they were
introduced to handle, viz., Twin-Earth cases and Frege cases, are
either nomologically impossible or dismissible as exceptions to
non-strict psychological laws.</p>

<p>

On the most common versions of externalism, though intentional
contents are externally determined, mental representations themselves,
and the states they partly constitute, remain “in the head.”  More
radical versions are possible.  One might maintain that since thoughts
are individuated by their contents, and some thought contents are
partially constituted by objects external to the mind, then some
thoughts are partly constituted by objects external to the mind. On
such a view, a <em>singular thought</em> — i.e., a thought about
a particular object — literally <em>contains</em> the object it
is about.  It is “object-involving.” Such a thought (and the mind that
thinks it) thus extend beyond the boundaries of the skull. (This
appears to be the view articulated in McDowell 1986, on which there is
“interpenetration” between the mind and the world.)</p>

<p>   

Clark and Chalmers (1998) and Clark (2001, 2005, 2008) have argued that
mental representations may exist <em>entirely</em> “outside the head.”
On their view, which they call “active externalism,” cognitive
processes (e.g., calculation) may be realized in external media (e.g.,
a calculator or pen and paper), and the “coupled system” of the
individual mind and the external workspace ought to count as a
cognitive system — a mind —in its own right. Symbolic
representations on external media would thus count as mental
representations.</p>

<p>Clark and Chalmers's paper has inspired a burgeoning literature on
extended, embodied and interactive cognition.  (Menary 2010 is a
recent collection of essays.  See also the entry on
 <a href="../embodied-cognition/">embodied cognition</a>.)</p>

<h2><a name="Computation">8. The Computational Theory of Mind</a></h2>

<p>

The leading contemporary version of the Representational Theory of
Mind, the Computational Theory of Mind (CTM), claims that the brain is
a kind of computer and that mental processes are computations.
According to CTM, cognitive states are constituted by computational
relations to mental representations of various kinds, and cognitive
processes are sequences of such states.</p>

<p>

CTM develops RTM by attempting to explain <em>all</em> psychological
states and processes in terms of mental representation. In the course
of constructing detailed empirical theories of human and other animal
cognition, and developing models of cognitive processes implementable in
artificial information processing systems, cognitive scientists have
proposed a variety of types of mental representations. While some of
these may be suited to be mental relata of commonsense psychological
states, some — so-called “subpersonal” or “sub-doxastic”
representations — are not. Though many philosophers believe that
CTM can provide the best scientific explanations of cognition and
behavior, there is disagreement over whether such explanations will
vindicate the commonsense psychological explanations of prescientific
RTM.</p>

<p>

According to Stich's (1983) Syntactic Theory of Mind, for example,
computational theories of psychological states should concern
themselves only with the <em>formal</em> properties of the objects
those states are relations to. Commitment to the explanatory relevance
of <em>content</em>, however, is for most cognitive scientists
fundamental (Fodor 1981a, Pylyshyn 1984, Von Eckardt 1993). That mental
processes are computations, that computations are rule-governed
sequences <em>of semantically evaluable objects</em>, and that the
rules apply to the symbols in virtue of their content, are central
tenets of mainstream cognitive science.</p>

<p>

Explanations in cognitive science appeal to a many different kinds of
mental representation, including, for example, the “mental
models” of Johnson-Laird 1983, the “retinal arrays,”
“primal sketches” and “2½-D sketches”
of Marr 1982, the “frames” of Minsky 1974, the
“sub-symbolic” structures of Smolensky 1989, the
“quasi-pictures” of Kosslyn 1980, and the
“interpreted symbol-filled arrays” of Tye 1991 — in
addition to representations that may be appropriate to the explanation
of commonsense psychological states. Computational explanations have
been offered of, among other mental phenomena, belief (Fodor 1975,
2008 Field 1978), visual perception (Marr 1982, Osherson, et
al. 1990), rationality (Newell and Simon 1972, Fodor 1975,
Johnson-Laird and Wason 1977), language learning and use (Chomsky
1965, Pinker 1989), and musical comprehension (Lerdahl and Jackendoff
1983).</p>

<p>

A fundamental disagreement among proponents of CTM concerns the
realization of personal-level representations (e.g., thoughts) and
processes (e.g., inferences) in the brain. The central debate here is
between proponents of <em>Classical Architectures</em> and proponents
of <em>Connectionist Architectures</em>.</p>

<p>

The classicists (e.g., Turing 1950, Fodor 1975, 2000, 2003, 2008,
Fodor and Pylyshyn 1988, Marr 1982, Newell and Simon 1976) hold that
mental representations are <em>symbolic</em> structures, which
typically have semantically evaluable constituents, and that mental
processes are rule-governed manipulations of them that are sensitive
to their constituent structure. The connectionists (e.g., McCulloch
&amp; Pitts 1943, Rumelhart 1989, Rumelhart and McClelland 1986,
Smolensky 1988) hold that mental representations are realized by
patterns of activation in a network of simple processors
(“nodes”) and that mental processes consist of the
spreading activation of such patterns. The nodes themselves are,
typically, not taken to be semantically evaluable; nor do the patterns
have semantically evaluable constituents. (Though there are versions
of Connectionism — “localist” versions — on
which individual nodes are taken to have semantic properties (e.g.,
Ballard 1986, Ballard &amp; Hayes 1984).) It is arguable, however,
that localist theories are neither definitive nor representative of
the connectionist program (Smolensky 1988, 1991, Chalmers 1993).)</p>

<p>

Classicists are motivated (in part) by properties thought seems to
share with language. Fodor's Language of Thought Hypothesis (LOTH)
(Fodor 1975, 1987, 2008), according to which the system of mental symbols
constituting the neural basis of thought is structured like a language,
provides a well-worked-out version of the classical approach as applied
to commonsense psychology. (Cf. also Marr 1982 for an application of
classical approach in scientific psychology.) According to the LOTH,
the potential infinity of complex representational mental states is
generated from a finite stock of primitive representational states, in
accordance with recursive formation rules. This combinatorial structure
accounts for the properties of <em>productivity</em> and
<em>systematicity</em> of the system of mental representations. As in
the case of symbolic languages, including natural languages (though
Fodor does not suppose either that the LOTH explains only linguistic
capacities or that only verbal creatures have this sort of cognitive
architecture), these properties of thought are explained by appeal to
the content of the representational units and their combinability into
contentful complexes. That is, the semantics of both language and
thought is <em>compositional</em>: the content of a complex
representation is determined by the contents of its constituents and
their structural configuration.  (See, e.g.,Fodor and Lepore 2002.) </p>

<p>

Connectionists are motivated mainly by a consideration of the
architecture of the brain, which apparently consists of layered
networks of interconnected neurons. They argue that this sort of
architecture is unsuited to carrying out classical serial computations.
For one thing, processing in the brain is typically massively parallel.
In addition, the elements whose manipulation drives computation in
connectionist networks (principally, the connections between nodes) are
neither semantically compositional nor semantically evaluable, as they
are on the classical approach. This contrast with classical
computationalism is often characterized by saying that representation
is, with respect to computation, <em>distributed</em> as opposed to
<em>local</em>: representation is local if it is computationally basic;
and distributed if it is not. (Another way of putting this is to say
that for classicists mental representations are computationally
<em>atomic</em>, whereas for connectionists they are not.)</p>

<p>

Moreover, connectionists argue that information processing as it
occurs in connectionist networks more closely resembles some features
of actual human cognitive functioning. For example, whereas on the
classical view learning involves something like hypothesis formation
and testing (Fodor 1981c), on the connectionist model it is a matter of
evolving distribution of “weights” (strengths) on the connections between
nodes, and typically does not involve the formulation of hypotheses
regarding the identity conditions for the objects of knowledge. The
connectionist network is “trained up” by repeated exposure to the
objects it is to learn to distinguish; and, though networks typically
require <em>many</em> more exposures to the objects than do humans,
this seems to model at least one feature of this type of human learning
quite well. (Cf. the sonar example in Churchland 1989.)</p>

<p>

Further, degradation in the performance of such networks in response
to damage is gradual, not sudden as in the case of a classical
information processor, and hence more accurately models the loss of
human cognitive function as it typically occurs in response to brain
damage. It is also sometimes claimed that connectionist systems show
the kind of flexibility in response to novel situations typical of
human cognition — situations in which classical systems are
relatively “brittle” or “fragile.”</p>

<p>

Some philosophers have maintained that connectionism entails that
there are no propositional attitudes. Ramsey, Stich and Garon (1990)
have argued that if connectionist models of cognition are basically
correct, then there are no discrete representational states as
conceived in ordinary commonsense psychology and classical cognitive
science. Others, however (e.g., Smolensky 1989), hold that certain
types of higher-level patterns of activity in a neural network may be
roughly identified with the representational states of commonsense
psychology. Still others (e.g., Fodor &amp; Pylyshyn 1988, Heil 1991,
Horgan and Tienson 1996) argue that language-of-thought style
representation is both necessary in general and realizable within
connectionist architectures. (MacDonald &amp; MacDonald 1995 collects
the central contemporary papers in the classicist/connectionist debate,
and provides useful introductory material as well. See also Von Eckardt
2005.)</p>

<p>

Whereas Stich (1983) accepts that mental processes are
computational, but denies that computations are sequences of mental
representations, others accept the notion of mental representation, but
deny that CTM provides the correct account of mental states and
processes.</p>

<p>

Van Gelder (1995) denies that psychological processes are
computational. He argues that cognitive systems are <em>dynamic</em>,
and that cognitive states are not relations to mental symbols, but
quantifiable states of a complex system consisting of (in the case of
human beings) a nervous system, a body and the environment in which
they are embedded. Cognitive processes are not rule-governed sequences
of discrete symbolic states, but continuous, evolving total states of
dynamic systems determined by continuous, simultaneous and mutually
determining states of the systems' components. Representation in a
dynamic system is essentially information-theoretic, though the bearers
of information are not symbols, but state variables or parameters. (See
also Port and Van Gelder 1995; Clark 1997a, 1997b, 2008.)</p>

<p>

Horst (1996), on the other hand, argues that though computational
models may be useful in scientific psychology, they are of no help in
achieving a philosophical understanding of the intentionality of
commonsense mental states. CTM attempts to <em>reduce</em> the
intentionality of such states to the intentionality of the mental
symbols they are relations to. But, Horst claims, the relevant notion
of symbolic content is essentially bound up with the notions of
convention and intention. So CTM involves itself in a vicious
circularity: the very properties that are supposed to be reduced are
(tacitly) appealed to in the reduction.</p>

<h2><a name="Thought">9. Thought and Language</a></h2>

<p>

To say that a mental object has semantic properties is,
paradigmatically, to say that it is <em>about</em>, or true or
false of, an object or objects, or that it is true or false
<em>simpliciter</em>. Suppose I think that ocelots take snuff. I am
thinking about ocelots, and if what I think of them (that they take
snuff) is true of them, then my thought is true. According to RTM such
states are to be explained as relations between agents and mental
representations. To think that ocelots take snuff is to token in some
way a mental representation whose content is that ocelots take snuff.
On this view, the semantic properties of mental states are the semantic
properties of the representations they are relations to.</p>

<p>

Linguistic acts seem to share such properties with mental states.
Suppose I <em>say</em> that ocelots take snuff. I am talking about
ocelots, and if what I say of them (that they take snuff) is true of
them, then my utterance is true. Now, to say that ocelots take snuff is
(in part) to utter a sentence that means that ocelots take snuff. Many
philosophers have thought that the semantic properties of linguistic
expressions are inherited from the intentional mental states they are
conventionally used to express (Grice 1957, Fodor 1978,
Schiffer1972/1988, Searle 1983). On this view, the semantic properties
of linguistic expressions are the semantic properties of the
representations that are the mental relata of the states they are
conventionally used to express.</p>

<p>

(Others, however, e.g., Davidson (1975, 1982) have suggested that
the kind of thought human beings are capable of is not possible without
language, so that the dependency might be reversed, or somehow mutual
(see also Sellars 1956). (But see Martin 1987 for a defense of the
claim that thought is possible without language. See also Chisholm and
Sellars 1958.) Schiffer (1987) subsequently despaired of the success of
what he calls “Intention Based Semantics.”)</p>

<p>

It is also widely held that in addition to having such properties as
reference, truth-conditions and truth — so-called
<em>extensional</em> properties — expressions of natural
languages also have <em>intensional</em> properties, in virtue of
expressing properties or propositions — i.e., in virtue of having
<em>meanings</em> or <em>senses</em>, where two expressions may have
the same reference, truth-conditions or truth value, yet express
different properties or propositions (Frege 1892/1997). If the semantic
properties of natural-language expressions are inherited from the
thoughts and concepts they express (or vice versa, or both), then an
analogous distinction may be appropriate for mental
representations.</p>

</div>

<div id="bibliography">

<h2><a name="Bib">Bibliography</a></h2>

<ul class="hanging">

<li>Almog, J., Perry, J. and Wettstein, H. (eds.), (1989), <em>Themes
from Kaplan</em>, New York: Oxford University Press.</li>

<li>Alter, T. and Walter, S. (2007), <em>Phenomenal Concepts and
Phenomenal Knowledge: New Essays on Consciousness and
Physicalism</em>, Oxford: Oxford University Press.</li>

<li>Aristotle, <em>De Anima</em>, in <em>The Complete Works of
Aristotle: The Revised Oxford Translation</em>, Oxford: Oxford
University Press, 1984.</li>

<li>Baker, L. R. (1995), <em>Explaining Attitudes: A Practical Approach
to the Mind</em>, Cambridge: Cambridge University Press.</li>

<li>Ballard, D.H. (1986), “Cortical Connections and Parallel
Processing: Structure and Function,” <em>The Behavioral and Brain
Sciences</em>, 9: 67–120.</li>

<li>Ballard, D.H and Hayes, P.J. (1984), “Parallel Logical Inference,”
<em>Proceedings of the Sixth Annual Conference of the Cognitive Science
Society</em>, Rochester, NY.</li>

<li>Bayne, T. and Montague, M. (eds.), (2011), <em>Cognitive
Phenomenology</em>, Oxford: Oxord University Press.</li>

<li>Beaney, M. (ed.) (1997), <em>The Frege Reader</em>, Oxford:
Blackwell Publishers.</li>

<li>Berkeley, G. <em>Principles of Human Knowledge</em>, in M.R. Ayers
(ed.), <em>Berkeley: Philosophical Writings</em>, London: Dent,
1975.</li>

<li>Block, N. (1983), “Mental Pictures and Cognitive Science,”
<em>Philosophical Review</em>, 93: 499–542.</li>

<li>––– (1986), “Advertisement for a Semantics for Psychology,”
in P.A. French, T.E. Uehling and H.K. Wettstein (eds.), <em>Midwest
Studies in Philosophy, Vol. X</em>, Minneapolis: University of
Minnesota Press: 615–678.</li>

<li>––– (1996), “Mental Paint and Mental Latex,” in E.
Villanueva (ed.), <em>Philosophical Issues, 7: Perception</em>:
19–49.</li>

<li>––– (2003), “Mental Paint,” in M. Hahn and
B. Ramberg (eds.), <em>Reflections and Replies: Essays on the
Philosophy of Tyler Burge</em>, Cambridge, Mass.: The MIT Press.</li>

<li>Block, N. (ed.) (1981), <em>Readings in Philosophy of Psychology,
Vol. 2</em>, Cambridge, Mass.: Harvard University Press.</li>

<li>––– (ed.) (1982), <em>Imagery</em>, Cambridge,
Mass.: The MIT Press.</li>

<li>Boghossian, P. A. (1995), “Content,” in J. Kim and
E. Sosa (eds.), <em>A Companion to Metaphysics</em>, Oxford:
Blackwell, 94–96.</li>

<li>Brandom, R. (2002), “Non-inferential Knowledge, Perceptual
Experience, and Secondary Qualities: Placing McDowell's Empiricism,” in
N.H. Smith (ed.), <em>Reading McDowell: On Mind and World</em>, London:
Routledge.</li>

<li>Burge, T. (1979), “Individualism and the Mental,” in P.A. French,
T.E. Uehling and H.K.Wettstein (eds.), <em>Midwest Studies in
Philosophy, Vol. IV</em>, Minneapolis: University of Minnesota Press:
73–121.  (Reprinted, with Postscript, in Burge 2007.)</li>

<li>––– (1986a), “Individualism and Psychology,”
<em>Philosophical Review</em>, 95: 3–45.</li>

<li>––– (1986b), “Intellectual Norms and Foundations of
Mind,” <em>The Journal of Philosophy</em>, 83: 697–720.</li>

<li>––– (2007), <em>Foundations of Mind: Philosophical Essays,
Volume 2</em>, Oxford: Oxford University Press.</li>

<li>––– (2010), <em>Origins of Objectivity</em>, Oxford: Oxford
University Press.</li>

<li>Chalmers, D. (1993), “Connectionism and Compositionality: Why Fodor
and Pylyshyn Were Wrong,” <em>Philosophical Psychology</em>, 6:
305–319.</li>

<li>––– (1996), <em>The Conscious Mind</em>, New York: Oxford
University Press.</li>

<li>––– (2003), “The Content and Epistemology of Phenomenal
Belief,” in Q. Smith &amp; A. Jokic (eds.), <em>Consciousness: New
Philosophical Perspectives</em>, Oxford: Oxford University Press:
220–272.</li>

<li>––– (2004a), “The Representational Character of
Experience,” in B. Leiter (ed.), <em>The Future for Philosophy</em>,
Oxford: Oxford University Press: 153–181.</li>

<li>––– (2004b), “Phenomenal Concepts and the Knowledge
Argument,” in P. Ludlow, Y. Nagasawa and D. Stoljar (eds.), <em>There's
Something About Mary: Essays on Phenomenal Consciousness and Frank
Jackson's Knowledge Argument</em>, Cambridge, Mass.: The MIT Press.</li>

<li>Chisholm, R. and Sellars, W. (1958), “The Chisholm-Sellars
Correspondence on Intentionality,” in H. Feigl, M. Scriven and G.
Maxwell (eds.), <em>Minnesota Studies in the Philosophy of Science, Vol.
II</em>, Minneapolis: University of Minnesota Press: 529–539.</li>

<li>Chomsky, N. (1965), <em>Aspects of the Theory of Syntax</em>,
Cambridge, Mass.: The MIT Press.</li>

<li>Churchland, P.M. (1981), “Eliminative Materialism and the
Propositional Attitudes,” <em>Journal of Philosophy</em>, 78:
67–90.</li>

<li>––– (1989), “On the Nature of Theories: A
Neurocomputational Perspective,” in W. Savage (ed.), <em>Scientific
Theories: Minnesota Studies in the Philosophy of Science</em>, Vol. 14,
Minneapolis: University of Minnesota Press: 59–101.</li>

<li>Clark, A. (1997a), “The Dynamical Challenge,” <em>Cognitive
Science</em>, 21: 461–481.</li>

<li>––– (1997b), <em>Being There: Putting Brain, Body and World
Together Again</em>, Cambridge, MA: The MIT Press.</li>

<li>––– (2001), “Reasons, Robots and the Extended
Mind,” <em>Mind and Language</em>, 16: 121–145.</li>

<li>––– (2005), “Intrinsic Content, Active Memory, and the
Extended Mind,” <em>Analysis</em>, 65: 1–11.</li>

<li>––– (2008). <em>Supersizing the Mind</em>, Oxford: Oxford University Press.</li>

<li>Clark, A., and Chalmers, D. (1998), “The Extended
Mind,” <em>Analysis</em>, 58: 7–19.</li>

<li>Collins, A. (1987), <em>The Nature of Mental Things</em>, Notre
Dame: Notre Dame University Press.</li>

<li>Crane, T. (1995), <em>The Mechanical Mind</em>, London: Penguin
Books Ltd.</li>

<li>Davidson, D. (1973), “Radical Interpretation,” <em>Dialectica</em>
27: 313–328.</li>

<li>––– (1974), “Belief and the Basis of Meaning,”
<em>Synthese</em>, 27: 309–323.</li>

<li>––– (1975), “Thought and Talk,” in
S. Guttenplan (ed.),
<em>Mind and Language</em>, Oxford: Clarendon Press: 7–23.</li>

<li>––– (1982), “Rational Animals,” <em>Dialectica</em>, 4:
317–327.</li>

<li>Dennett, D. (1969), <em>Content and Consciousness</em>, London:
Routledge &amp; Kegan Paul.</li>

<li>––– (1981), “The Nature of Images and the Introspective
Trap,” pages 132–141 of Dennett 1969, reprinted in Block 1981:
128–134.</li>

<li>––– (1987), <em>The Intentional Stance</em>, Cambridge,
Mass.: The MIT Press.</li>

<li>––– (1987a), “True Believers: The Intentional Strategy and
Why it Works,” in Dennett 1987: 13–35.</li>

<li>––– (1987b), “Reflections: Real Patterns, Deeper Facts, and
Empty Questions,” in Dennett 1987: 37–42.</li>

<li>––– (1988), “Quining Qualia,” in A.J. Marcel and E.
Bisiach (eds.), <em>Consciousness in Contemporary Science</em>, Oxford:
Clarendon Press: 42–77.</li>

<li>––– (1991), “Real Patterns,” <em>The Journal of
Philosophy</em>, 87: 27–51.</li>

<li>Devitt, M. (1996), <em>Coming to Our Senses: A Naturalistic Program
for Semantic Localism</em>, Cambridge: Cambridge University Press.</li>

<li>Dretske, F. (1969), <em>Seeing and Knowing</em>, Chicago: The
University of Chicago Press.</li>

<li>––– (1981), <em>Knowledge and the Flow of Information</em>,
Cambridge, Mass.: The MIT Press.</li>

<li>––– (1988), <em>Explaining Behavior: Reasons in a World of
Causes</em>, Cambridge, Mass.: The MIT Press.</li>

<li>––– (1995), <em>Naturalizing the Mind</em>, Cambridge,
Mass.: The MIT Press.</li>

<li>––– (1996), “Phenomenal Externalism, or If Meanings
Ain't in the Head, Where are Qualia?”, in E. Villanueva
(ed.), <em>Philosophical Issues 7: Perception</em>: 143–158.</li>

<li>––– (1999), “The Mind's Awareness of
Itself,” <em>Philosophical Studies</em>, 95: 103–124.</li>

<li>––– (1998), “Minds, Machines, and Money: What Really
Explains Behavior,” in J. Bransen and S. Cuypers (eds.), <em>Human
Action, Deliberation and Causation, Philosophical Studies Series
77</em>, Dordrecht: Kluwer Academic Publishers. Reprinted in Dretske
2000.</li>

<li>––– (2000), <em>Perception, Knowledge and Belief</em>,
Cambridge: Cambridge University Press.</li>

<li>Evans, G. (1982), <em>The Varieties of Reference</em>, Oxford:
Oxford University Press.</li>

<li>Farkas, K. (2008), <em>The Subject's Point of View</em>, Oxford: Oxford University Press.</li>

<li>Field, H. (1978), “Mental representation,” <em>Erkenntnis</em>, 13:
9–61.</li>

<li>Flanagan, O. (1992), <em>Consciousness Reconsidered</em>,
Cambridge, Mass.: The MIT Press.</li>

<li>Fodor, J.A. (1975), <em>The Language of Thought</em>, Cambridge,
Mass.: Harvard University Press.</li>

<li>––– (1978), “Propositional Attitudes,” <em>The Monist</em>
61: 501–523.</li>

<li>––– (1981), <em>Representations</em>, Cambridge, Mass.: The
MIT Press.</li>

<li>––– (1981a), “Introduction,” in Fodor 1981: 1–31.</li>

<li>––– (1981b), “Methodological Solipsism Considered as a
Research Strategy in Cognitive Psychology,” in Fodor 1981:
225–253.</li>

<li>––– (1981c), “The Present Status of the Innateness
Controversy,” in Fodor 1981: 257–316.</li>

<li>––– (1982), “Cognitive Science and the Twin-Earth Problem,”
<em>Notre Dame Journal of Formal Logic</em>, 23: 98–118.</li>

<li>––– (1987), <em>Psychosemantics</em>, Cambridge, Mass.: The
MIT Press.</li>

<li>––– (1990a), <em>A Theory of Content and Other Essays</em>,
Cambridge, Mass.: The MIT Press.</li>

<li>––– (1990b), “Psychosemantics or: Where Do Truth Conditions
Come From?” in W.G. Lycan (ed.), <em>Mind and Cognition: A Reader</em>,
Oxford: Blackwell Publishers: 312–337.</li>

<li>––– (1994), <em>The Elm and the Expert</em>, Cambridge,
Mass.: The MIT Press.</li>

<li>––– (1998), <em>Concepts: Where Cognitive Science Went
Wrong</em>, Oxford: Oxford University Press.</li>

<li>––– (2000), <em>The Mind Doesn't Work that Way: The Scope
and Limits of Computational Psychology</em>, Cambridge, Mass.: The MIT
Press.</li>

<li>––– (2003), <em>LOT 2: The Language of Thought
Revisited</em>, Oxford: Clarendon Press.</li>

<li>––– (2008), <em>The Mind Doesn't Work that Way: The Scope
and Limits of Computational Psychology</em>, Cambridge, Mass.: The MIT
Press.</li>

<li>Fodor, J.A. and Lepore, E. (2002), <em>The Compositionality
Papers</em>, Oxford: Clarendon Press.</li>

<li>Fodor, J.A. and Pylyshyn, Z. (1981), “How Direct is Visual
Perception?: Some Reflections on Gibson's ‘Ecological Approach’,”
<em>Cognition</em>, 9: 207–246.</li>

<li>––– (1988), “Connectionism and Cognitive
Architecture: A Critical Analysis,” <em>Cognition</em>, 28:
3–71.</li>

<li>Frege, G. (1884), <em>The Foundations of Arithmetic</em>, trans.
J.L. Austin, New York: Philosophical Library (1954).</li>

<li>––– (1892), “On <em>Sinn</em> and <em>Bedeutung</em>”, in
Beany 1997: 151–171.</li>

<li>––– (1918), “Thought”, in Beany 1997: 325–345.</li>

<li>Geach, P. (1957), <em>Mental Acts: Their Content and Their
Objects</em>, London: Routledge &amp; Kegan Paul.</li>

<li>Gibson, J.J. (1966), <em>The senses considered as perceptual
systems</em>, Boston: Houghton Mifflin.</li>

<li>––– (1979), <em>The ecological approach to visual
perception</em>, Boston: Houghton Mifflin.</li>

<li>Goldman, A. (1993), “The Psychology of Folk Psychology,”
<em>Behavioral and Brian Sciences</em>, 16: 15–28.</li>

<li>Goodman, N. (1976), <em>Languages of Art</em>, 2nd ed.,
Indianapolis: Hackett.</li>

<li>Grice, H.P. (1957), “Meaning,” <em>Philosophical Review</em>, 66:
377–388; reprinted in <em>Studies in the Way of Words</em>, Cambridge,
Mass.: Harvard University Press (1989): 213–223.</li>

<li>Gunther, Y.H. (ed.) (2003), <em>Essays on Nonconceptual
Content</em>, Cambridge, Mass.: The MIT Press.</li>

<li>Harman, G. (1973), <em>Thought</em>, Princeton: Princeton
University Press.</li>

<li>––– (1987), “(Non-Solipsistic) Conceptual Role Semantics,” in
E. Lepore (ed.), <em>New Directions in Semantics</em>, London: Academic
Press: 55–81.</li>

<li>––– (1990), “The Intrinsic Quality of
Experience,” in J.  Tomberlin (ed.), <em>Philosophical
Perspectives 4: Action Theory and Philosophy of Mind</em>, Atascadero:
Ridgeview Publishing Company: 31–52.</li>

<li>Harnish, R. (2002), <em>Minds, Brains, Computers</em>, Malden,
Mass.: Blackwell Publishers Inc.</li>

<li>Haugeland, J. (1981), “Analog and analog,” <em>Philosophical
Topics</em>, 12: 213–226.</li>

<li>Heil, J. (1991), “Being Indiscrete,” in J. Greenwood
(ed.), <em>The Future of Folk Psychology</em>, Cambridge: Cambridge
University Press: 120–134.</li>

<li>Horgan, T. and Tienson, J. (1996), <em>Connectionism and the
Philosophy of Psychology</em>, Cambridge, Mass: The MIT Press.</li>

<li>––– (2002), “The Intentionality of
Phenomenology and the Phenomenology of Intentionality,” in D.J.
Chalmers (ed.), <em>Philosophy of Mind</em>, Oxford: Oxford University
Press.</li>

<li>Horst, S. (1996), <em>Symbols, Computation, and
Intentionality</em>, Berkeley: University of California Press.</li>

<li>Hume, D. (1739), <em>A Treatise of Human Nature</em>, L.A.
Selby-Bigg (ed.), rev. P.H. Nidditch, Oxford: Oxford University Press
(1978).</li>

<li>Jackendoff, R. (1987), <em>Computation and Cognition</em>,
Cambridge, Mass.: The MIT Press.</li>

<li>Jackson, F. (1982), “Epiphenomenal Qualia,” <em>Philosophical
Quarterly</em>, 32: 127–136.</li>

<li>––– (1986), “What Mary Didn't Know,” <em>Journal of
Philosophy</em>, 83: 291–295.</li>

<li>Johnson-Laird, P.N. (1983), <em>Mental Models</em>, Cambridge,
Mass.: Harvard University Press.</li>

<li>Johnson-Laird, P.N. and Wason, P.C. (1977), <em>Thinking: Readings
in Cognitive Science</em>, Cambridge University Press.</li>

<li>Kaplan, D. (1989), “Demonstratives,” in Almog, Perry and Wettstein
1989: 481–614.</li>

<li>Kosslyn, S.M. (1980), <em>Image and Mind</em>, Cambridge, Mass.:
Harvard University Press.</li>

<li>––– (1982), “The Medium and the Message in Mental
Imagery,” in Block 1982: 207–246.</li>

<li>––– (1983), <em>Ghosts in the Mind's Machine</em>, New
York: W.W. Norton &amp; Co.</li>

<li>Kosslyn, S.M. and Pomerantz, J.R. (1977), “Imagery, Propositions,
and the Form of Internal Representations,” <em>Cognitive
Psychology</em>, 9: 52–76.</li>

<li>Kriegel, U. (2011), <em>The Sources of Intentionality</em>,
Oxford: Oxford University Press.</li>

<li>Kriegel, U. (ed.) forthcoming, <em>Phenomenal Intentionality: New
Essays</em>, Oxford: Oxford University Press.</li>

<li>Leeds, S. (1993), “Qualia, Awareness, Sellars,” <em>Noûs</em>
XXVII: 303–329.</li>

<li>Lerdahl, F. and Jackendoff, R. (1983), <em>A Generative Theory of
Tonal Music</em>, Cambridge, Mass.: The MIT Press.</li>

<li>Levine, J. (1993), “On Leaving Out What It's Like,” in M. Davies
and G. Humphreys (eds.), <em>Consciousness</em>, Oxford: Blackwell
Publishers: 121–136.</li>

<li>––– (1995), “On What It Is Like to Grasp a Concept,” in E.
Villanueva (ed.), <em>Philosophical Issues 6: Content</em>, Atascadero:
Ridgeview Publishing Company: 38–43.</li>

<li>––– (2001), <em>Purple Haze</em>, Oxford: Oxford University
Press.</li>

<li>Lewis, D. (1971), “Analog and Digital,” <em>Noûs</em>, 5:
321–328.</li>

<li>––– (1974), “Radical Interpretation,” <em>Synthese</em>, 27:
331–344.</li>

<li>Loar, B. (1981), <em>Mind and Meaning</em>, Cambridge: Cambridge
University Press.</li>

<li>––– (1996), “Phenomenal States” (Revised Version), in N.
Block, O. Flanagan and G. Güzeldere (eds.), <em>The Nature of
Consciousness</em>, Cambridge, Mass.: The MIT Press: 597–616.</li>

<li>––– (2003a), “Transparent Experience and the Availability of
Qualia,” in Q. Smith and A. Jokic (eds.), <em>Consciousness: New
Philosophical Perspectives</em>, Oxford: Clarendon Press: 77–96.</li>

<li>––– (2003b), “Phenomenal Intentionality as the Basis of Mental
Content,” in M. Hahn and B. Ramberg (eds.), <em>Reflections and Replies:
Essays on the Philosophy of Tyler Burge</em>, Cambridge, Mass.: The MIT
Press.</li>

<li>Locke, J. (1689), <em>An Essay Concerning Human Understanding</em>,
P.H. Nidditch (ed.), Oxford: Oxford University Press (1975).</li>

<li>Lycan, W.G. (1987), <em>Consciousness</em>, Cambridge, Mass.: The
MIT Press.</li>

<li>––– (1986), <em>Consciousness and Experience</em>,
Cambridge, Mass.: The MIT Press.</li>

<li>MacDonald, C. and MacDonald, G. (1995), <em>Connectionism: Debates
on Psychological Explanation</em>, Oxford: Blackwell Publishers.</li>

<li>Marr, D. (1982), <em>Vision</em>, New York: W.H. Freeman and
Company.</li>

<li>Martin, C.B. (1987), “Proto-Language,” <em>Australasian Journal of
Philosophy</em>, 65: 277–289.</li>

<li>McCulloch, W.S. and Pitts, W. (1943), “A Logical Calculus of the
Ideas Immanent in Nervous Activity,” <em>Bulletin of Mathematical
Biophysics</em>, 5: 115–33.</li>

<li>McDowell, J. (1986), “Singular Thought and the Extent of Inner
Space,” in P. Pettit and J. McDowell (eds.), <em>Subject, Thought, and
Context</em>, Oxford: Clarendon Press: 137–168.</li>

<li>––– (1994), <em>Mind and World</em>, Cambridge, Mass.:
Harvard University Press.</li>

<li>McGinn, C. (1977), “Charity, Interpretation, and Belief,”
<em>Journal of Philosophy</em>, 74: 521–535.</li>

<li>––– (1982), “The Structure of Content,” in A. Woodfield
(ed.), <em>Thought and Content</em>, Oxford: Oxford University Press:
207–258.</li>

<li>––– (1989), <em>Mental Content</em>, Oxford: Blackwell
Publishers.</li>

<li>––– (1991), <em>The Problem of Consciousness</em>, Oxford:
Blackwell Publishers.</li>

<li>––– (1991a), “Content and Consciousness,” in McGinn 1991:
23–43.</li>

<li>––– (1991b), “Can We Solve the Mind-Body Problem?” in McGinn
1991: 1–22.</li>

<li>––– (2004), <em>Mindsight: Image, Dream, Meaning</em>,
Cambridge, Mass.: Harvard University Press.</li>

<li>Millikan, R. (1984), <em>Language, Thought and other Biological
Categories</em>, Cambridge, Mass.: The MIT Press.</li>

<li>Menary, R. (ed.) (2010), <em>The Extended Mind</em>, Cambridge, Mass.:  The MIT Press.</li>

<li>Minsky, M. (1974), “A Framework for Representing Knowledge,” MIT-AI
Laboratory Memo 306 June. (A shorter version appears in J. Haugeland
(ed.), <em>Mind Design II</em>, Cambridge, Mass.: The MIT Press
(1997).)</li>

<li>Nagel, T. (1974), “What Is It Like to Be a Bat?” <em>Philosophical
Review</em>, 83: 435–450.</li>

<li>Newell, A. and Simon, H.A. (1972), <em>Human Problem Solving</em>,
New York: Prentice-Hall.</li>

<li>––– (1976), “Computer Science as Empirical
Inquiry: Symbols and Search,” <em>Communications of the Association for
Computing Machinery</em>, 19: 113–126.</li>

<li>O'Callaghan, C. (2007), <em>Sounds</em>, Oxford:  Oxford University Press.</li>

<li>Osherson, D.N., Kosslyn, S.M. and Hollerbach, J.M. (1990),
<em>Visual Cognition and Action: An Invitation to Cognitive Science,
Vol. 2</em>, Cambridge, Mass.: The MIT Press.</li>

<li>Papineau, D. (1987), <em>Reality and Representation</em>, Oxford:
Blackwell Publishers.</li>

<li>Peacocke, C. (1983), <em>Sense and Content</em>, Oxford: Clarendon
Press.</li>

<li>––– (1989), “Perceptual Content,” in Almog, Perry and
Wettstein 1989: 297–329.</li>

<li>––– (1992), “Scenarios, Concepts and Perception,” in T.
Crane (ed.), <em>The Contents of Experience</em>, Cambridge: Cambridge
University Press: 105–35.</li>

<li>––– (2001), “Does Perception Have a Nonconceptual
Content?” <em>Journal of Philosophy</em>, 99: 239–264.</li>

<li>Pinker, S. (1989), <em>Learnability and Cognition</em>, Cambridge,
Mass.: The MIT Press.</li>

<li>Pitt, D. (2004), “The Phenomenology of Cognition, Or, What Is it
Like to Think That P?” <em>Philosophy and Phenomenological
Research</em>, 69: 1–36.</li>

<li>––– (2009), “Intentional
Psychologism” <em>Philosophical Studies</em>, 146:
117–138.</li>

<li>––– (2011), “Introspection, Phenomenality
and the Availability of Intentional Content,” in Bayne and
Montague 2011.</li>

<li>–––, forthcoming, “Indexical
Thought,” in Kriegel (ed.) forthcoming.</li>

<li>Port, R., and Van Gelder, T. (1995), <em>Mind as Motion:
Explorations in the Dynamics of Cognition</em>, Cambridge, Mass.: The
MIT Press.</li>

<li>Putnam, H. (1975), “The Meaning of ‘Meaning’,”
in <em>Philosophical Papers, Vol. 2</em>, Cambridge: Cambridge
University Press: 215–71.</li>

<li>Pylyshyn, Z. (1979), “The Rate of ‘Mental Rotation’ of Images: A
Test of a Holistic Analogue Hypothesis,” <em>Memory and Cognition</em>,
7: 19–28.</li>

<li>––– (1981a), “Imagery and Artificial Intelligence,” in
Block 1981: 170–194.</li>

<li>––– (1981b), “The Imagery Debate: Analog Media versus
Tacit Knowledge,” <em>Psychological Review</em>, 88: 16–45.</li>

<li>––– (1984), <em>Computation and Cognition</em>, Cambridge,
Mass.: The MIT Press.</li>

<li>––– (2003), <em>Seeing and Visualizing: It's Not What You
Think</em>, Cambridge, Mass.: The MIT Press.</li>

<li>Raffman, D. (1995), “The Persistence of Phenomenology,” in T.
Metzinger (ed.), <em>Conscious Experience</em>, Paderborn:
Schönigh/Imprint Academic: 293–308.</li>

<li>Ramsey, W., Stich, S. and Garon, J. (1990), “Connectionism,
Eliminativism and the Future of Folk Psychology,” <em>Philosophical
Perspectives</em>, 4: 499–533.</li>

<li>Reid, T. (1764), <em>An Inquiry into the Human Mind</em>, D.R.
Brooks (ed.), Edinburgh: Edinburgh University Press (1997).</li>

<li>Rey, G. (1981), “Introduction: What Are Mental Images?” in Block
1981: 117–127.</li>

<li>––– (1991), “Sensations in a Language of Thought,” in E.
Villaneuva (ed.), <em>Philosophical Issues 1: Consciousness</em>,
Atascadero: Ridgeview Publishing Company: 73–112.</li>

<li>Rumelhart, D.E. (1989), “The Architecture of the Mind: A
Connectionist Approach,” in M.I. Posner (ed.), <em>Foundations of
Cognitive Science</em>, Cambridge, Mass.: The MIT Press: 133–159.</li>

<li>Rumelhart, D.E. and McClelland, J.L. (1986). <em>Parallel
Distributed Processing, Vol. I</em>, Cambridge, Mass.: The MIT
Press.</li>

<li>Schiffer, S. (1987), <em>Remnants of Meaning</em>, Cambridge,
Mass.: The MIT Press.</li>

<li>––– (1972), “Introduction”
(Paperback Edition), in
<em>Meaning</em>, Oxford: Clarendon Press (1972/1988): xi-xxix.</li>

<li>Searle, J.R. (1980), “Minds, Brains, and Programs,” <em>Behavioral
and Brain Sciences</em>, 3: 417–424.</li>

<li>––– (1983), <em>Intentionality</em>, Cambridge: Cambridge
University Press.</li>

<li>––– (1984) <em>Minds, Brains, and Science</em>, Cambridge:
Harvard University Press.</li>

<li>––– (1992), <em>The Rediscovery of the Mind</em>,
Cambridge, Mass.: The MIT Press.</li>

<li>Sellars, W. (1956), “Empiricism and the Philosophy of Mind,” in K.
Gunderson (ed.), <em>Minnesota Studies in the Philosophy of Science,
Vol. I</em>, Minneapolis: University of Minnesota Press: 253–329.</li>

<li>Shepard, R.N. and Cooper, L. (1982), <em>Mental Images and their
Transformations</em>, Cambridge, Mass.: The MIT Press.</li>

<li>Shoemaker, S. (1990), “Qualities and Qualia: What's in the Mind?”
<em>Philosophy and Phenomenological Research</em>, 50: 109–31.</li>

<li>Siewert, C. (1998), <em>The Significance of Consciousness</em>,
Princeton: Princeton University Press.</li>

<li>Smolensky, P. (1988), “On the Proper Treatment of Connectionism,”
<em>Behavioral and Brain Sciences</em>, 11: 1–74.</li>

<li>––– (1989), “Connectionist Modeling: Neural
Computation/Mental Connections,” in L. Nadel, L.A. Cooper, P. Culicover
and R.M. Harnish (eds.), <em>Neural Connections, Mental Computation</em>
Cambridge, Mass.:The MIT Press: 49–67.</li>

<li>––– (1991), “Connectionism and the Language of Thought,”
in B. Loewer and G. Rey (eds.), <em>Meaning in Mind: Fodor and His
Critics</em>, Oxford: Basil Blackwell Ltd.: 201–227.</li>

<li>Sterelny, K. (1989), “Fodor's Nativism,” <em>Philosophical
Studies</em>, 55: 119–141.</li>

<li>Stich, S. (1983), <em>From Folk Psychology to Cognitive
Science</em>, Cambridge, Mass.: The MIT Press.</li>

<li>––– (1996), <em>Deconstructing the Mind</em>, New York:
Oxford University Press.</li>

<li>Strawson, G. (1994), <em>Mental Reality</em>, Cambridge, Mass.: The
MIT Press.</li>

<li>––– (2008), <em>Real Materialism and Other Essays</em>, Oxford:  Oxford University Press.</li>

<li>Thau, M. (2002), <em>Consciousness and Cognition</em>, Oxford:
Oxford University Press.</li>

<li>Turing, A. (1950), “Computing Machinery and Intelligence,”
<em>Mind</em>, 59: 433–60.</li>

<li>Tye, M. (1991), <em>The Imagery Debate</em>, Cambridge, Mass.: The
MIT Press.</li>

<li>––– (1995), <em>Ten Problems of Consciousness</em>, Cambridge,
Mass.: The MIT Press.</li>

<li>––– (2000), <em>Consciousness, Color, and Content</em>,
Cambridge, Mass.: The MIT Press.</li>

<li>––– (2009), <em>Consciousness Revisited</em>,
Cambridge, Mass.: The MIT Press.</li>

<li>Van Gelder, T. (1995), “What Might Cognition Be, if not
Computation?”, <em>Journal of Philosophy</em>, XCI: 345–381.</li>

<li>Von Eckardt, B. (1993), <em>What Is Cognitive Science?</em>,
Cambridge, Mass.: The MIT Press.</li>

<li>––– (2005), “Connectionism and the
Propositional Attitudes,” in C.E. Erneling and D.M. Johnson (eds.),
<em>The Mind as a Scientific Object: Between Brain and Culture</em>,
Oxford: Oxford University Press.</li>

<li>Wittgenstein, L. (1953), <em>Philosophical Investigations</em>,
trans. G.E.M. Anscombe, Oxford: Blackwell Publishers.</li>
</ul>

</div>

<div id="academic-tools">

<h2><a name="Aca">Academic Tools</a></h2>

<blockquote>
<table>
<tbody><tr>
<td valign="top"><img src="../../symbols/sepman-icon.jpg" alt="sep man icon" /></td>
<td><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=mental-representation&amp;archive=win2019" target="other">How to cite this entry</a>.</td>
</tr>

<tr>
<td valign="top"><img src="../../symbols/sepman-icon.jpg" alt="sep man icon" /></td>
<td><a href="https://leibniz.stanford.edu/friends/preview/mental-representation/" target="other">Preview the PDF version of this entry</a> at the
 <a href="https://leibniz.stanford.edu/friends/" target="other">Friends of the SEP Society</a>.</td>
</tr>

<tr>
<td valign="top"><img src="../../symbols/inpho.png" alt="inpho icon" /></td>
<td><a href="https://www.inphoproject.org/entity?sep=mental-representation&amp;redirect=True" target="other">Look up this entry topic</a>
 at the <a href="https://www.inphoproject.org/" target="other">Indiana Philosophy Ontology Project</a>
 (InPhO).</td>
</tr>

<tr>
<td valign="top"><img src="../../symbols/pp.gif" alt="phil papers icon" /></td>
<td><a href="http://philpapers.org/sep/mental-representation/" target="other">Enhanced bibliography for this entry</a>
at <a href="http://philpapers.org/" target="other">PhilPapers</a>, with links to its database.</td>
</tr>

</tbody></table>
</blockquote>

</div>

<div id="other-internet-resources">

<h2><a name="Oth">Other Internet Resources</a></h2>

<ul>

<!-- LINK CHECKER COMMENTED OUT (Wed Jan  9 06:07:08 2013)
<li><a href="http://consc.net/guide.html/" target="other">Guide to the Philosophy of Mind</a>,
 Editor, David Chalmers.</li>

 LINK CHECKER -->
<!--LINK CHECKER COMMENTED OUT (Wed Jul 1 11:49:51 PDT 2015)

<li><a href="http://consc.net/mindpapers" target="other">MindPapers: Online Research in Philosophy</a>,
 Editors, David Chalmers and David Bourget.</li>

LINK CHECKER-->

<li><a href="http://host.uniroma3.it/progetti/kant/field/" target="other">A Field Guide to the Philosophy of Mind</a>,
 General editors, Marcho Nani and Massimo Marraffa.</li>

<li><a href="https://sites.google.com/site/minddict/" target="other">Dictionary of Philosophy of Mind</a>,
Creator and Founding  Editor, Chris Eliasmith, University of Waterloo.
Chief Editor, Eric Hochstein, University of Waterloo..</li>

<li><a href="http://www.rep.routledge.com/" target="other">Routledge Encyclopedia of Philosophy</a>,
 General Editor, Tim Crane.</li>

</ul>

</div>

<div id="related-entries">

<h2><a name="Rel">Related Entries</a></h2>

<p>

 <!--<a href="../cognition-embodied/">-->cognition-embodied<!--</a>--> |
 <a href="../cognitive-science/">cognitive science</a> |
 <a href="../concepts/">concepts</a> |
 <a href="../connectionism/">connectionism</a> |
 <a href="../consciousness-intentionality/">consciousness: and intentionality</a> |
 <a href="../consciousness-representational/">consciousness: representational theories of</a> |
 <a href="../folkpsych-simulation/">folk psychology: as mental simulation</a> |
 <a href="../information-semantic/">information: semantic conceptions of</a> |
 <a href="../intentionality/">intentionality</a> |
 <a href="../language-thought/">language of thought hypothesis</a> |
 <!--<a href="../logic and artificial intelligence/">-->logic and artificial intelligence<!--</a>--> |
 <a href="../materialism-eliminative/">materialism: eliminative</a> |
 <a href="../content-causal/">mental content: causal theories of</a> |
 <a href="../content-externalism/">mental content: externalism about</a> |
 <a href="../content-narrow/">mental content: narrow</a> |
 <a href="../content-nonconceptual/">mental content: nonconceptual</a> |
 <a href="../content-teleological/">mental content: teleological theories of</a> |
 <a href="../mental-imagery/">mental imagery</a> |
 <a href="../representation-medieval/">mental representation: in medieval philosophy</a> |
 <a href="../computational-mind/">mind: computational theory of</a> |
 <a href="../neuroscience/">neuroscience, philosophy of</a> |
 <a href="../perception-contents/">perception: the contents of</a> |
 <a href="../perception-problem/">perception: the problem of</a> |
 <a href="../qualia/">qualia</a> |
 <a href="../reference/">reference</a>

</p>

</div>

<div id="acknowledgments">

<h3>Acknowledgments</h3>

<p>

Thanks to Brad Armour-Garb, Mark Balaguer, Dave Chalmers, Jim
Garson, John Heil, Jeff Poland, Bill Robinson, Galen Strawson, Adam
Vinueza and (especially) Barbara Von Eckardt for comments on earlier
versions of this entry.</p>

</div>

</div><!-- #aueditable --><!--DO NOT MODIFY THIS LINE AND BELOW-->

<!-- END ARTICLE HTML -->

</div> <!-- End article-content -->

  <div id="article-copyright">
    <p>
 <a href="../../info.html#c">Copyright © 2012</a> by

<br />
David Pitt
&lt;<a href="mailto:dalanpitt%40yahoo%2ecom"><em>dalanpitt<abbr title=" at ">@</abbr>yahoo<abbr title=" dot ">.</abbr>com</em></a>&gt;
    </p>
  </div>

</div> <!-- End article -->

<!-- NOTE: article banner is outside of the id="article" div. -->
<div id="article-banner" class="scroll-block">
     <div id="article-banner-content">
  <a href="../../fundraising/">
  Open access to the SEP is made possible by a world-wide funding initiative.<br />
  Please Read How You Can Help Keep the Encyclopedia Free</a>
 </div>


</div> <!-- End article-banner -->

    </div> <!-- End content -->

    <div id="footer">

      <div id="footer-menu">
        <div class="menu-block">
          <h4><i class="icon-book"></i> Browse</h4>
          <ul role="menu">
            <li><a href="../../contents.html">Table of Contents</a></li>
            <li><a href="../../new.html">New in this Archive</a></li>
            
            <li><a href="../../published.html">Chronological</a></li>
            <li><a href="../../../../archives/">Archives <i class="icon-external-link"></i></a></li>
          </ul>
        </div>
        <div class="menu-block">
          <h4><i class="icon-info-sign"></i> About</h4>
          <ul role="menu">
            <li><a href="../../info.html">Editorial Information</a></li>
            <li><a href="../../about.html">About the SEP</a></li>
            <li><a href="../../board.html">Editorial Board</a></li>
            <li><a href="../../cite.html">How to Cite the SEP</a></li>
            <li><a href="../../special-characters.html">Special Characters</a></li>
            
            <li><a href="../../../../contact.html">Contact <i class="icon-external-link"></i></a></li>
          </ul>
        </div>
        <div class="menu-block">
          <h4><i class="icon-leaf"></i> Support SEP</h4>
          <ul role="menu">
            <li><a href="../../../../support/">Support the SEP</a></li>
            <li><a href="../../../../support/friends.html">PDFs for SEP Friends</a></li>
            <li><a href="../../../../support/donate.html">Make a Donation</a></li>
            <li><a href="../../../../support/sepia.html">SEPIA for Libraries</a></li>
          </ul>
        </div>
      </div> <!-- End footer menu -->

      <div id="mirrors">
        <div id="mirror-info">
          <h4><i class="icon-globe"></i> Mirror Sites</h4>
          <p>View this site from another server:</p>
        </div>
                <div class="btn-group">
<a class="btn dropdown-toggle" data-toggle="dropdown" href="https://plato.stanford.edu/"><span class="flag flag-usa"></span> USA (Main Site) <span class="caret"></span><span class="mirror-source">CSLI, Stanford University</span></a>          <ul class="dropdown-menu">
            <li><a href="https://stanford.library.sydney.edu.au/archives/win2019/entries/mental-representation/"><span class="flag flag-australia"></span> Australia <span class="mirror-source">Library, University of Sydney</span></a>           </li>
            <li><a href="https://seop.illc.uva.nl/archives/win2019/entries/mental-representation/"><span class="flag flag-netherlands"></span> Netherlands <span class="mirror-source">ILLC, University of Amsterdam</span></a>           </li>
          </ul>
        </div>
      </div> <!-- End mirrors -->
      
      <div id="site-credits">
        <p class="csli-logo"><a href="https://www-csli.stanford.edu/"><img src="../../symbols/SU_csli.png" width="355" alt="Stanford Center for the Study of Language and Information" /></a></p>
        <p>The Stanford Encyclopedia of Philosophy is <a href="../../info.html#c">copyright © 2016</a> by <a href="http://mally.stanford.edu/">The Metaphysics Research Lab</a>, Center for the Study of Language and Information (CSLI), Stanford University</p>
        <p>Library of Congress Catalog Data: ISSN 1095-5054</p>
      </div> <!-- End site credits -->

    </div> <!-- End footer -->

  </div> <!-- End container -->

   <!-- NOTE: Script required for drop-down button to work (mirrors). -->
  <script>
    $('.dropdown-toggle').dropdown();
  </script>





</body></html>