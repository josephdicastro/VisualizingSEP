<!DOCTYPE html><!--[if lt IE 7]> <html class="ie6 ie"> <![endif]--><!--[if IE 7]>    <html class="ie7 ie"> <![endif]--><!--[if IE 8]>    <html class="ie8 ie"> <![endif]--><!--[if IE 9]>    <html class="ie9 ie"> <![endif]--><!--[if !IE]> --><html xmlns="http://www.w3.org/1999/xhtml"><!-- <![endif]--><head>
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>
Moral Psychology: Empirical Approaches (Stanford Encyclopedia of Philosophy/Winter 2019 Edition)
</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="robots" content="noarchive, noodp" />
<meta property="citation_title" content="Moral Psychology: Empirical Approaches" />
<meta property="citation_author" content="Doris, John" />
<meta property="citation_author" content="Stich, Stephen" />
<meta property="citation_author" content="Phillips, Jonathan" />
<meta property="citation_author" content="Walmsley, Lachlan" />
<meta property="citation_publication_date" content="2006/04/19" />
<meta name="DC.title" content="Moral Psychology: Empirical Approaches" />
<meta name="DC.creator" content="Doris, John" />
<meta name="DC.creator" content="Stich, Stephen" />
<meta name="DC.creator" content="Phillips, Jonathan" />
<meta name="DC.creator" content="Walmsley, Lachlan" />
<meta name="DCTERMS.issued" content="2006-04-19" />
<meta name="DCTERMS.modified" content="2017-11-17" />

<!-- NOTE: Import webfonts using this link: -->
<link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,300,600,200&amp;subset=latin,latin-ext" rel="stylesheet" type="text/css" />

<link rel="stylesheet" type="text/css" media="screen,handheld" href="../../css/bootstrap.min.css" />
<link rel="stylesheet" type="text/css" media="screen,handheld" href="../../css/bootstrap-responsive.min.css" />
<link rel="stylesheet" type="text/css" href="../../css/font-awesome.min.css" />
<!--[if IE 7]> <link rel="stylesheet" type="text/css" href="../../css/font-awesome-ie7.min.css"> <![endif]-->
<link rel="stylesheet" type="text/css" media="screen,handheld" href="../../css/style.css" />
<link rel="stylesheet" type="text/css" media="print" href="../../css/print.css" />
<link rel="stylesheet" type="text/css" href="../../css/entry.css" />
<!--[if IE]> <link rel="stylesheet" type="text/css" href="../../css/ie.css" /> <![endif]-->
<script type="text/javascript" src="../../js/jquery-1.9.1.min.js"></script>
<script type="text/javascript" src="../../js/bootstrap.min.js"></script>

<!-- NOTE: Javascript for sticky behavior needed on article and ToC pages -->
<script type="text/javascript" src="../../js/jquery-scrolltofixed-min.js"></script>
<script type="text/javascript" src="../../js/entry.js"></script>

<!-- SEP custom script -->
<script type="text/javascript" src="../../js/sep.js"></script>
</head>

<!-- NOTE: The nojs class is removed from the page if javascript is enabled. Otherwise, it drives the display when there is no javascript. -->
<body class="archive article" id="pagetopright">
<div id="container">
<div id="header-wrapper">
  <div id="header">
    <div id="branding">
      <div id="site-logo"><a href="../../index.html"><img src="../../symbols/sep-man-red.png" alt="SEP logo" /></a></div>
      <div id="site-title"><a href="../../index.html">Stanford Encyclopedia of Philosophy Archive<div id="site-subtitle">Winter 2019 Edition</div></a></div>
    </div>
    <div id="navigation">
      <div class="navbar">
        <div class="navbar-inner">
          <div class="container">
            <button class="btn btn-navbar collapsed" data-target=".collapse-main-menu" data-toggle="collapse" type="button"> <i class="icon-reorder"></i> Menu </button>
            <div class="nav-collapse collapse-main-menu collapse">
              <ul class="nav">
                <li class="dropdown"><a id="drop1" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-book"></i> Browse</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop1">
                    <li><a href="../../contents.html">Table of Contents</a></li>
                    <li><a href="../../new.html">New in this Archive</a></li>
                    
                    <li><a href="../../published.html">Chronological</a></li>
                    <li><a href="../../../../archives/">Archives <i class="icon-external-link"></i></a></li>
                  </ul>
                </li>
                <li class="dropdown"><a id="drop2" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-info-sign"></i> About</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop2">
                    <li><a href="../../info.html">Editorial Information</a></li>
                    <li><a href="../../about.html">About the SEP</a></li>
                    <li><a href="../../board.html">Editorial Board</a></li>
                    <li><a href="../../cite.html">How to Cite the SEP</a></li>
                    <li><a href="../../special-characters.html">Special Characters</a></li>
                    
                    <li><a href="../../../../contact.html">Contact <i class="icon-external-link"></i></a></li>
                  </ul>
                </li>
                <li class="dropdown"><a id="drop3" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-leaf"></i> Support SEP</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop3">
                    <li><a href="../../../../support/">Support the SEP</a></li>
                    <li><a href="../../../../support/friends.html">PDFs for SEP Friends</a></li>
                    <li><a href="../../../../support/donate.html">Make a Donation</a></li>
                    <li><a href="../../../../support/sepia.html">SEPIA for Libraries</a></li>
                  </ul>
                </li>
              </ul>
            </div>
          </div>
        </div>
      </div>
    </div>
    <!-- End navigation -->
    
    <div id="search">
      <form id="search-form" method="get" action="../../../../search/searcher.py">
        <input type="search" name="query" placeholder="Search this archive" />
<input type="hidden" name="archive" value="win2019" />

        <div class="search-btn-wrapper"><button class="btn search-btn" type="submit"><i class="icon-search"></i></button></div>
      </form>
    </div>
    <!-- End search --> 
    
  </div>
  <!-- End header --> 
</div>
<!-- End header wrapper -->

<div id="content">

<!-- Begin article sidebar -->
<div id="article-sidebar" class="sticky" style="z-index: 999;">
  <div class="navbar">
    <div class="navbar-inner">
      <div class="container">
        <button class="btn btn-navbar collapsed" data-target=".collapse-sidebar" data-toggle="collapse" type="button"> <i class="icon-reorder"></i> Entry Navigation </button>
        <div id="article-nav" class="nav-collapse collapse-sidebar collapse">
          <ul class="nav">
            <li><a href="#toc">Entry Contents</a></li>
            <li><a href="#Bib">Bibliography</a></li>
            <li><a href="#Aca">Academic Tools</a></li>
            <li><a href="https://leibniz.stanford.edu/friends/preview/moral-psych-emp/">Friends PDF Preview <i class="icon-external-link"></i></a></li>
            <li><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=moral-psych-emp&amp;archive=win2019">Author and Citation Info <i class="icon-external-link"></i></a> </li>
            <li><a href="#pagetopright" class="back-to-top">Back to Top <i class="icon-angle-up icon2x"></i></a></li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</div><div></div>
<!-- End article sidebar --> 

<!-- NOTE: Article content must have two wrapper divs: id="article" and id="article-content" -->
<div id="article">
<div id="article-content">

<!-- BEGIN ARTICLE HTML -->


<div id="aueditable"><!--DO NOT MODIFY THIS LINE AND ABOVE-->

<h1>Moral Psychology: Empirical Approaches</h1><div id="pubinfo"><em>First published Wed Apr 19, 2006; substantive revision Fri Nov 17, 2017</em></div>

<div id="preamble">

<p>
Moral psychology investigates human functioning in moral contexts, and
asks how these results may impact debate in ethical theory. This work
is necessarily interdisciplinary, drawing on both the empirical
resources of the human sciences and the conceptual resources of
philosophical ethics. The present article discusses several topics
that illustrate this type of inquiry: thought experiments,
responsibility, character, egoism <em>v</em>. altruism, and moral
disagreement.</p>




</div>

<div id="toc">
<!--Entry Contents-->
<ul>
<li><a href="#IntrWhatMoraPsyc">1. Introduction: What is Moral Psychology?</a></li>
<li><a href="#ThouExpeMethEthi">2. Thought Experiments and the Methods of Ethics</a></li>
<li><a href="#MoraResp">3. Moral Responsibility</a></li>
<li><a href="#VirtEthiSkepAbouChar">4. Virtue Ethics and Skepticism About Character</a></li>
<li><a href="#EgoiVsAltr">5. Egoism <em>vs.</em> Altruism</a>
   <ul>
   <li><a href="#SomePhilBack">5.1 Some Philosophical Background</a></li>
   <li><a href="#AltrEvol">5.2 Altruism and Evolution</a></li>
   <li><a href="#Psyc">5.3 Psychology</a></li>
   <li><a href="#SociPuniHypo">5.4 The Social Punishment Hypothesis</a></li>
   <li><a href="#AverArouReduHypo">5.5 The Aversive-Arousal Reduction Hypothesis</a></li>
   <li><a href="#BeyoEgoiVsAltr">5.6 Beyond Egoism vs. Altruism</a></li>
   </ul></li>
<li><a href="#MoraDisa">6. Moral Disagreement</a></li>
<li><a href="#Conc">7. Conclusion</a></li>
<li><a href="#Bib">Bibliography</a></li>
<li><a href="#Aca">Academic Tools</a></li>
<li><a href="#Oth">Other Internet Resources</a></li>
<li><a href="#Rel">Related Entries</a></li>
</ul>
<!--Entry Contents-->





<hr />

</div>

<div id="main-text">



<!--pdf include  <div class="pagebreak">

</div> pdf include-->

<h2 id="IntrWhatMoraPsyc">1. Introduction: What is Moral Psychology?</h2>

<p>
Contemporary moral psychology—the study of human thought and
behavior in ethical contexts—is resolutely interdisciplinary:
psychologists freely draw on philosophical theories to help structure
their empirical research, while philosophers freely draw on empirical
findings from psychology to help structure their
 theories.<sup>[<a href="notes.html#note-1" id="ref-1">1</a>]</sup>
 </p>

<p>
While this extensive interdisciplinarity is a fairly recent
development (with few exceptions, most of the relevant work dates from
the past quarter century), it should not be a surprising development.
From antiquity to the present, philosophers have not been bashful
about making empirical claims, and many of these empirical claims have
been claims about human psychology (Doris &amp; Stich 2005). It is
therefore unremarkable that, with the emergence of scientific
psychology over the past century and a half, some of these
philosophers would think to check their work against the systematic
findings of psychologists (hopefully, while taking special care to
avoid being misled by scientific controversy; see Doris 2015, Chapter
3; Machery &amp; Doris forthcoming). </p>

<p>
Similarly, at least since the demise of behaviorism, psychologists
have been keenly interested in normative phenomena in general and
ethical phenomena in particular. It is therefore unremarkable that
some of these psychologists would seek to enrich their theoretical
frameworks with the conceptual resources of a field intensively
focused on normative phenomena: philosophical ethics. As a result, the
field demarcated by “moral psychology”, routinely involves
an admixture of empirical and normative inquiry, pursued by both
philosophers and psychologists—increasingly, in the form of
collaborative efforts involving practitioners from both fields. </p>

<p>
For philosophers, the special interest of this interdisciplinary
inquiry lies in the ways moral psychology may help adjudicate between
competing ethical theories. The plausibility of its associated moral
psychology is not, of course, the only dimension on which an ethical
theory may be evaluated; equally important are <em>normative</em>
questions having to do with how well a theory fares when compared to
important convictions about such things as justice, fairness, and the
good life. Such questions have been, and will continue to be, of
central importance for philosophical ethics. Nonetheless, it is
commonly supposed that an ethical theory committed to an impoverished
or inaccurate conception of moral psychology is at a serious
competitive disadvantage. As Bernard Williams (1973, 1985; cf.
Flanagan 1991) forcefully argued, an ethical conception that commends
relationships, commitments, or life projects that are at odds with the
sorts of attachments that can be reasonably expected to take root in
and vivify actual human lives is an ethical conception with—at
best—a very tenuous claim to our assent.</p>

<p>
With this in mind, problems in ethical theory choice making reference
to moral psychology can be framed by two related inquiries:</p>

<ol>

<li>What empirical claims about human psychology do advocates of
competing perspectives on ethical theory assert or presuppose?</li>

<li>How empirically well supported are these claims?</li>
</ol>

<p>
The first question is one of philosophical scholarship: what are the
psychological commitments of various positions in philosophical
ethics? The second question takes us beyond the corridors of
philosophy departments and to the sorts of questions asked, and sometimes
answered, by the human sciences, including psychology, anthropology,
sociology, history, cognitive science, linguistics and neuroscience.
Thus, contemporary moral psychology is <em>methodologically
pluralistic</em>: it aims to answer philosophical questions, but in an
empirically responsible way.</p>

<p>
However, it will sometimes be difficult to tell which claims in
philosophical ethics require empirical substantiation. Partly, this is
because it is sometimes unclear whether, and to what extent, a
contention counts as empirically assessable. Consider questions
regarding “normal functioning” in mental health care: are
the answers to these questions statistical, or evaluative (Boorse
1975; Fulford 1989; Murphy 2006)? For example, is “normal”
mental health simply the psychological condition of most people, or is
it <em>good</em> mental health? If the former, the issue is, at least
in principle, empirically decidable. If the latter, the issues must be
decided, if they can be decided, by arguments about value.</p>

<p>
Additionally, philosophers have not always been explicit about
whether, and to what extent, they are making empirical claims. For
example, are their depictions of moral character meant to identify
psychological features of actual persons, or to articulate ideals that
need not be instantiated in actual human psychologies? Such questions
will of course be complicated by the inevitable diversity of
philosophical opinion.</p>

<p>
In every instance, therefore, the first task is to carefully document
a theory’s empirically assessable claims, whether they are
explicit or, as may often be the case, tacit. Once claims apt for
empirical assessment have been located, the question becomes one of
identifying any relevant empirical literatures. The next job is to
assess those literatures, in an attempt to determine what conclusions
can be responsibly drawn from them. Science, particularly social
science, being what it is, many conclusions will be provisional; the
philosophical moral psychologist must be prepared to adjudicate
controversies in other fields, or offer informed conjecture regarding
future findings. Often, the empirical record will be crucially
incomplete. In such cases, philosophers may be forced to engage in
empirically disciplined conjecture, or even to engage in their own
empirical work, as some philosophers are beginning to
 do.<sup>[<a href="notes.html#note-2" id="ref-2">2</a>]</sup></p>
 
<p>
When the philosophical positions have been isolated, and putatively
relevant empirical literatures assessed, we can begin to evaluate the
plausibility of the philosophical moral psychology: Is the speculative
picture of psychological functioning that informs some region of
ethical theory compatible with the empirical picture that emerges from
systematic observation? In short, is the philosophical picture
<em>empirically adequate</em>? If it is determined that the
philosophical conception is empirically adequate, the result is
<em>vindicatory</em>. Conversely, if the philosophical moral
psychology in question is found to be empirically <em>in</em>adequate,
the result is <em>revisionary</em>, compelling alteration, or even
rejection, of those elements of the philosophical theory presupposing
the problematic moral psychology. The process will often be
<em>comparative</em>. Theory choice in moral psychology, like other
theory choice, involves tradeoffs, and while an empirically
undersupported approach may not be decisively eliminated from
contention on empirical grounds alone, it may come to be seen as less
attractive than theoretical options with firmer empirical
foundations.</p>

<p>
The winds driving the sort of disciplinary cross-pollination we
describe do not blow in one direction. As philosophers writing for an
encyclopedia of philosophy, we are naturally concerned with the ways
empirical research might shape, or re-shape, philosophical ethics. But
philosophical reflection may likewise influence empirical research,
since such research is often driven by philosophical suppositions that
may be more or less philosophically sound. The best interdisciplinary
conversations, then, should benefit both parties. To illustrate the
dialectical process we have described, we will consider a variety of
topics in moral psychology. Our primary concerns will be
philosophical: What are some of the most central problems in
philosophical moral psychology, and how might they be resolved?
However, as the hybrid nature of our topic invites us to do, we will
pursue these questions in an interdisciplinary spirit, and are hopeful
that our remarks will also engage interested scientists. Hopefully,
the result will be a broad sense of the problems and methods that will
structure research on moral psychology during the 21<sup>st</sup>
century.</p>

<h2 id="ThouExpeMethEthi">2. Thought Experiments and the Methods of Ethics</h2>

<p>
“Intuition pumps” or “thought experiments”
have long been well-used items in the philosopher’s toolbox
(Dennett 1984: 17–18; Stuart et al. 2018). Typically, a thought
experiment presents an example, often a hypothetical example, in order
to elicit some philosophically telling response. If a thought
experiment is successful, it may be concluded that competing theories
must account for the resulting response. These responses are supposed
to serve an <em>evidential role</em> in philosophical theory choice;
if you like, they can be understood as <em>data</em> competing
theories must
 accommodate.<sup>[<a href="notes.html#note-3" id="ref-3">3</a>]</sup>
 If an appropriate audience’s ethical responses to a thought
experiment conflict with the response a theory prescribes for the
case, the theory has suffered a counterexample.</p>

<p>
The question of whose responses “count” philosophically
(or, who is the “appropriate” audience) has been answered
in a variety of ways, but for many philosophers, the intended audience
for thought experiments seems to be some species of “ordinary
folk” (see Jackson 1998: 118, 129; Jackson &amp; Pettit 1995:
22–9; Lewis 1989: 126–9). Of course, the relevant folk
must possess such cognitive attainments as are required to understand
the case at issue; very young children are probably not an ideal
audience for thought experiments. Accordingly, some philosophers may
insist that the relevant responses are the considered judgments of
people with the training required to see “what is at stake
philosophically”. But if the responses are to help adjudicate
between competing theories, the responders must be more or less
theoretically neutral, and this sort of neutrality, we suspect, is
rather likely to be vitiated by philosophical education. A dilemma
emerges. On the one hand, philosophically naïve subjects may be
thought to lack the erudition required to grasp the philosophical
stakes. On the other, with increasing philosophical sophistication
comes, very likely, philosophical partiality; one audience is
naïve, and the other
 prejudiced.<sup>[<a href="notes.html#note-4" id="ref-4">4</a>]</sup></p>
 
<p>
However exactly the philosophically relevant audience is specified,
there are empirical questions that must be addressed in determining
the philosophical potency of a thought experiment. In particular, when
deciding what philosophical weight to give a response, philosophers
need to determine its <em>origins</em>. What features of the
<em>example</em> are implicated in a given judgment—are people
reacting to the substance of the case, or the style of exposition?
What features of the <em>audience</em> are implicated in their
reaction—do different demographic groups respond to the example
differently? Are there factors in the environment that are affecting
people’s intuitive judgments? Does the order in which people
consider examples affect their judgments? Such questions raise the
following concern: judgments about thought experiments dealing with
moral issues might be strongly influenced by <em>ethically
irrelevant</em> characteristics of the example or the audience or the
environment or the order of presentation. Whether a characteristic is
ethically relevant is a matter for philosophical discussion, but
determining the status of a particular thought experiment also
requires empirical investigation of its causally relevant
characteristics. We’ll now describe some examples of such
investigation.</p>

<p>
As part of their famous research on the “heuristics and
biases” that underlie human reasoning, Tversky and Kahneman
(1981) presented subjects with the following problem:</p>

<blockquote>

<p>
Imagine that the U.S. is preparing for the outbreak of an unusual
Asian disease, which is expected to kill 600 people. Two alternative
programs to combat the disease have been proposed. Assume that the
exact scientific estimate of the consequences of the programs are as
follows:</p>

<ul>

<li>If Program A is adopted, 200 people will be saved.</li>

<li>If Program B is adopted, there is a 1/3 probability that 600
people will be saved, and a 2/3 probability that no people will be
saved.</li>
</ul>
</blockquote>

<p>
A second group of subjects was given an identical problem, except that
the programs were described as follows:</p>

<blockquote>

<ul>

<li>If Program C is adopted, 400 people will die.</li>

<li>If Program D is adopted, there is a 1/3 probability that nobody
will die and a 2/3 probability that 600 people will die.</li>
</ul>
</blockquote>

<p>
On the first version of the problem, most subjects thought that
Program A should be adopted. But on the second version, most chose
Program D, despite the fact that the outcome described in A is
identical to the one described in C. The disconcerting implication of
this study is that ethical responses may be strongly influenced by the
manner in which cases are described or <em>framed</em>. Such framing
sensitivities, we are strongly inclined to think, constitute ethically
irrelevant influences on ethical responses. Unless this sort of
possibility can be confidently eliminated, one should hesitate to rely
on responses to a thought experiment for adjudicating theoretical
controversies. Such possibilities can only be eliminated through
systematic empirical
 work.<sup>[<a href="notes.html#note-5" id="ref-5">5</a>]</sup></p>
 
<p>
While a relatively small percentage of empirical work on
“heuristics and biases” directly addresses moral
reasoning, numerous philosophers who have addressed the issue
(Horowitz 1998; Doris &amp; Stich 2005; Sinnott-Armstrong 2005;
Sunstein 2005) agree that phenomena like framing effects are likely to
be pervasively implicated in responses to ethically freighted
examples, and argue that this state of affairs should cause
philosophers to view the thought-experimental method with considerable
concern.</p>

<p>
We turn now to order effects. In a pioneering study, Petrinovich and
O’Neill (1996) found that participants’ moral intuitions
varied with the order in which the thought experiments were presented.
Similar findings have been reported by Liao et al. (2012), Wiegman et
al. (2012), and Schwitzgebel &amp; Cushman (2011, 2015). The
Schwitzgebel and Cushman studies are particularly striking, since they
set out to explore whether order effects in moral intuitions were
smaller or non-existent in professional philosophers. Surprisingly,
they found that professional philosophers were also subject to order
effects, even though the thought experiments used are well known in
the field. Schwitzgebel and Cushman also report that in some cases
philosophers intuitions show substantial order effects when the
intuitions of non-philosophers don’t.</p>

<p>
Audience characteristics may also affect the outcome of thought
experiments. Haidt and associates (1993: 613) presented stories about
“harmless yet offensive violations of strong social norms”
to men and women of high and low socioeconomic status (SES) in
Philadelphia (USA), Porto Alegre, and Recife (both in Brazil). For
example:</p>

<blockquote>

<p>
A man goes to the supermarket once a week and buys a dead chicken. But
before cooking the chicken, he has sexual intercourse with it. Then he
cooks it and eats it. (Haidt et al. 1993: 617)</p>
</blockquote>

<p>
Lower SES subjects tended to “moralize” harmless and
offensive behaviors like that in the chicken story. These subjects
were more inclined than their high SES counterparts to say that the
actor should be “stopped or punished”, and more inclined
to deny that such behaviors would be “OK” if customary in
a given country (Haidt et al. 1993: 618–19). The point is not
that lower SES subjects are mistaken in their moralization of such
behaviors while the urbanity of higher SES subjects represents a more
rationally defensible response. The difficulty is deciding
which—if any—of the conflicting responses is fit to serve
as a constraint on ethical theory, when both may equally be the result
of more or less arbitrary cultural factors.</p>

<p>
In our experience, philosophical audiences typically decline to
moralize the offensive behaviors, and we ourselves share their
tolerant attitude. But of course these audiences—by virtue of
educational attainments, if not stock portfolios—are
overwhelmingly high SES. Haidt’s work suggests that it is a
mistake for a philosopher to say, as Jackson (1998: 32n4; cf. 37)
does, that “my intuitions reveal the folk conception in as much
as I am reasonably entitled, as I usually am, to regard myself as
typical”. The question is: typical of what demographic? Are
philosophers’ ethical responses determined by the philosophical
substance of the examples, or by cultural idiosyncrasies that are very
plausibly thought to be ethically irrelevant? Once again, until such
possibilities are ruled out by systematic empirical investigation, the
philosophical heft of a thought experiment is open to question.</p>

<p>
In recent years there has been a growing body of research reporting
that judgments evoked by moral thought experiments are affected by
environmental factors that look to be completely irrelevant to the
moral issue at hand. The presence of dirty pizza boxes and a whiff of
fart spray (Schnall et al. 2008a), the use of soap (Schnall et al.
2008b) or an antiseptic handwipe (Zhong et al. 2010), or even the
proximity of a hand sanitizer dispenser (Helzer &amp; Pizarro 2011)
have all been reported to influence moral intuitions. Tobia et al.
(2013) found that the moral intuitions of both students and
professional philosophers are affected by spraying the questionnaire
with a disinfectant spray. Valdesolo and DeSteno (2006) reported that
viewing a humorous video clip can have a substantial impact on
participant’s moral intuitions. And Strohminger et al. (2011)
have shown that hearing different kinds of audio clips (stand-up
comedy or inspirational stories from a volume called <em>Chicken Soup
for the Soul</em>) has divergent effects on moral intuitions.</p>

<p>
How should moral theorists react to findings like these? One might, of
course, eschew thought experiments in ethical theorizing. While this
methodological austerity is not without appeal, it comes at a cost.
Despite the difficulties, thought experiments are a window, in some
cases the only accessible window, into important regions of ethical
experience. In so far as it is disconnected from the thoughts and
feels of the lived ethical life, ethical theory risks being
“motivationally inaccessible”, or incapable of engaging
the ethical concern of agents who are supposed to live in accordance
with the normative standards of the
 theory.<sup>[<a href="notes.html#note-6" id="ref-6">6</a>]</sup>
 Fortunately, there is another possibility: continue pursuing the
research program that systematically investigates responses to
intuition pumps. In effect, the idea is to subject philosophical
thought experiments to the critical methods of experimental social
psychology. If investigations employing different experimental
scenarios and subject populations reveal a clear trend in responses,
we can begin to have some confidence that we are identifying a deeply
and widely shared moral conviction. Philosophical discussion may
establish that convictions of this sort should serve as a constraint
on moral theory, while responses to thought experiments that empirical
research determines to lack such solidity, such as those susceptible
to order, framing or environmental effects, or those admitting of
strong cultural variation, may be ones that ethical theorists can
safely disregard. </p>

<h2 id="MoraResp">3. Moral Responsibility</h2>

<p>
A philosophically informed empirical research program akin to the one
just described is more than a methodological fantasy. This approach
accurately describes a number of research programs aimed at informing
philosophical debates through interdisciplinary research.</p>

<p>
One of the earliest examples of this kind of work was inspired in
large part by the work of Knobe (2003a,b, 2006) and addressed
questions surrounding “folk morality” on issues ranging
from intentional action to causal responsibility (see Knobe 2010 for
review and discussion). This early work helped to spur the development
of a truly interdisciplinary research program with both philosophers
and psychologists investigating the folk morality of everyday life.
(See the <em>Stanford Encyclopedia of Philosophy</em> article on
Experimental Moral Philosophy for a more complete treatment of this
research.)</p>

<p>
Another related philosophical debate concerns the compatibility of
free will and moral responsibility with determinism. On the one hand,
incompatibilists insist that determinism (the view that all events are
jointly determined by antecedent events as governed by laws of
nature), is <em>incompatible</em> with moral responsibility.
Typically, these accounts also go on to specify what particular
capacity is required to be responsible for one’s own behavior
(e.g., that agents have alternate possibilities for behavior, or are
the “ultimate” source of their behavior, or both (Kane
2002: 5; Haji 2002:
 202–3).<sup>[<a href="notes.html#note-7" id="ref-7">7</a>]</sup>
 On the other hand, compatibilists argue that determinism and
responsibility are <em>compatible</em>, often by denying that
responsible agency requires that the actor have genuinely open
alternatives, or rejecting the ultimacy condition that requires
indeterminism (or impossible demands for self-creation). In short,
compatibilists hold that people may legitimately be held responsible
even though there is some sense in which they “could not have
done otherwise” or are not the “ultimate source” of
their behavior. Incompatibilists deny that this is the case.
Proponents of these two opposing positions have remained relatively
entrenched, and some participants have raised fears of a
“dialectical stalemate” (Fischer 1994: 83–5).</p>

<p>
A critical issue in these debates has been the claim that the
incompatibilist position better captures folk moral judgments about
agents whose actions have been completely determined (e.g., G.
Strawson 1986: 88; Smilansky 2003: 259; Pereboom 2001: xvi;
O’Connor 2000: 4; Nagel 1986: 113, 125; Campbell 1951: 451; Pink
2004: 12). For example, Robert Kane (1999: 218; cf. 1996: 83–5),
a leading incompatibilist, reports that in his experience “most
ordinary persons start out as natural incompatibilists”, and
“have to be talked out of this natural incompatibilism by the
clever arguments of philosophers”.</p>

<p>
Unsurprisingly, some compatibilists have been quick to assert the
contrary. For example, Peter Strawson (1982) famously argued that in
the context of “ordinary interpersonal relationships”,
people are not haunted by the specter of determinism; such
metaphysical concerns are irrelevant to their experience and
expression of the “reactive attitudes”—anger,
resentment, gratitude, forgiveness, and the like—associated with
responsibility assessment. Any anxiety about determinism, Strawson
insisted, is due to the “panicky metaphysics” of
philosophers, not incompatibilist convictions on the part of ordinary
people. However, incompatibilists have historically been thought to
have ordinary intuitions on their side; even some philosophers with
compatibilist leanings are prepared to concede the incompatibilist
point about “typical” response tendencies (e.g., Vargas
2005a,b).</p>

<p>
Neither side, so far as we are aware, has offered much in the way of
systematic evidence of actual patterns of folk moral judgments.
Recently however, a now substantial research program has begun to
offer empirical evidence on the relationship between determinism and
moral responsibility in folk moral judgments.</p>

<p>
Inspired by the work of Frankfurt (1988) and others, Woolfolk, Doris,
and Darley (2006) hypothesized that observers may hold actors
responsible even when the observers judge that the actors could not
have done otherwise, if the actors appear to “identify”
with their behavior. Roughly, the idea is that the actor identifies
with a behavior—and is therefore responsible for it—to the
extent that she “embraces” the behavior, or performs it
“wholeheartedly” regardless of whether genuine
alternatives for behavior are
 possible.<sup>[<a href="notes.html#note-8" id="ref-8">8</a>]</sup>
 Woolfolk et al.’s suspicion was, in effect, that people’s
(presumably tacit) theory of responsibility is compatibilist.</p>

<p>
To test this, subjects were asked to read a story about an agent who
was forced by a group of armed hijackers to kill a man who had been
having an affair with his wife. In the “low
identification” condition, the man was described as being
horrified at being forced to kill his wife’s lover, and as not
wanting to do so. In the “high identification” condition,
the man is instead described as welcoming the opportunity and wanting
to kill his wife’s lover. In both cases, the man is not given a
choice, and does kill his wife’s lover.</p>

<p>
Consistent with Woolfolk and colleagues’ hypothesis, subjects
judged that the highly identifying actor was more responsible, more
appropriately blamed, and more properly subject to guilt than the low
identification
 actor.<sup>[<a href="notes.html#note-9" id="ref-9">9</a>]</sup>
 This pattern in folk moral judgments seems to suggest that
participants were not consistently incompatibilist in their
responsibility attributions, because the lack of alternatives
available to the actor was not alone sufficient to rule out such
attributions.</p>

<p>
In response to these results, those who believe that folk morality is
incompatibilist may be quick to object that the study merely suggests
that responsibility attributions are influenced by identification, but
says nothing about incompatibilist commitments or the lack thereof.
Subjects still may have believed that the actor could have done
otherwise. To address this concern, Woolfolk and colleagues also
conducted a version of the study in which the man acted under the
influence of a “compliance drug”. In this case,
participants were markedly less likely to agree that the man
“was free to behave other than he did” and yet they still
held the agent who identified with the action as more responsible than
the agent who did not. These results look to pose a clear challenge to
the view that ordinary folk are typically incompatibilists.</p>

<p>
A related pattern of responses was obtained by Nahmias, Morris,
Nadelhoffer and Turner (2009) who instead described agents preforming
immoral behaviors in a “deterministic world” of the sort
often described in philosophy classrooms. One variation read as
follows:</p>

<blockquote>

<p>
Imagine that in the next century we discover all the laws of nature,
and we build a supercomputer which can deduce from these laws of
nature and from the current state of everything in the world exactly
what will be happening in the world at any future time. It can look at
everything about the way the world is and predict everything about how
it will be with 100% accuracy. Suppose that such a supercomputer
existed, and it looks at the state of the universe at a certain time
on March 25th, 2150 C.E., twenty years before Jeremy Hall is born. The
computer then deduces from this information and the laws of nature
that Jeremy will definitely rob Fidelity Bank at 6:00 PM on January
26th, 2195. As always, the supercomputer’s prediction is
correct; Jeremy robs Fidelity Bank at 6:00 PM on January 26th,
2195.</p>
</blockquote>

<p>
Subjects were then asked whether Jeremy was morally blameworthy. Most
said yes, indicating that they thought an agent could be morally
blameworthy even if his behaviors were entirely determined by natural
laws. Consistent with the Woolfolk et al. results, it appears that the
subjects’ judgments, at least those having to do with moral
blameworthiness, were not governed by a commitment to
incompatibilism.</p>

<p>
This emerging picture was complicated, however, by Nichols and Knobe
(2007), which argued that the ostensibly compatibilist responses were
performance errors driven by an affective response to the
agents’ immoral actions. To demonstrate this, all subjects were
asked to imagine two universes—a universe completely governed by
deterministic laws (Universe A) and a universe (Universe B) in which
everything is determined except for human decisions which are not
completely determined by deterministic laws and what has happened in
the past. In Universe B, but not Universe A, “each human
decision <em>does not have to happen</em> the way it does”. Some
subjects were assigned to a concrete condition, and asked to make a
judgment about a specific individual in specific circumstances, while
others were assigned to an abstract condition, and asked to make a
more general judgment, divorced from any particular individual. The
hypothesis was that the difference between these two conditions would
generate different responses regarding the relationship between
determinism and moral responsibility. Subjects in the concrete
condition read a story about a man, “Bill”, in the
deterministic universe who murders his wife and children in a
particularly ghastly manner, and were asked whether Bill was morally
responsible for what he had done. By contrast, subjects in the
abstract condition were asked “In Universe A, is it possible for
a person to be fully morally responsible for their actions?”
Seventy-two percent of subjects in the concrete condition gave a
compatibilist response, holding Bill responsible in Universe A,
whereas less than fifteen percent of subjects in the abstract
condition gave a compatibilist response, allowing that people could be
fully morally responsible in the deterministic Universe A.</p>

<p>
In line with previous experimental work demonstrating that increased
affective arousal amplified punitive responses to wrongdoing (Lerner,
Goldberg, &amp; Tetlock 1998), Nichols and Knobe hypothesized that
previously observed compatibilist responses were the result of the
affectively laden nature of the stimulus materials. When this
affective element was eliminated from the materials (as in the
abstract condition), participants instead exhibited an incompatibilist
pattern of responses.</p>

<p>
More recently, Nichols and Knobe’s line of reasoning has come
under fire from two directions. First, a number of studies have now
tried to systematically manipulate how affectively arousing the
immoral behavior performed is, but have not found that these changes
significantly alter participants’ judgments of moral
responsibility in deterministic scenarios. Rather, the differences
seem to be best explained simply by whether the case was described
abstractly or concretely (see Cova et al. 2012 for work with patients
who have frontotemporal dementia, and see Feltz &amp; Cova 2014 for a
meta-analysis). Second, a separate line of studies from Murray and
Nahmias (2014) argued that participants who exhibited the apparently
incompatibilist pattern of responses were making a critical error in
how they understood the deterministic scenario. In particular, they
argued these participants mistakenly took the agents, or their mental
states, in these deterministic scenarios to be “bypassed”
in the causal chain leading up to their behavior. In support of their
argument, Murray and Nahmias (2014) demonstrated that when analyses
were restricted to the participants who clearly did not take the agent
to be bypassed, these participants judged the agent to be morally
responsible (blameworthy, etc.) despite being in a deterministic
universe. Unsurprisingly, this line of argument has, in turn, inspired
a number of further counter-responses, both empirical (Rose &amp;
Nichols 2013) and theoretical (Björnsson &amp; Pereboom 2016),
which caution against the conclusions of Murray and Nahmias.</p>

<p>
While the debate continues over whether the compatibilist or
incompatibilist position better captures folk moral judgments of
agents in deterministic universes, a related line of research has
sprung up around what is widely taken to be the most convincing
contemporary form of argument for incompatibilism: manipulation
arguments (e.g., Mele 2006, 2013, Pereboom 2001, 2014).
Pereboom’s Four-Case version, for example, begins with the case
of an agent named Plum who is manipulated by neuroscientists who use a
radio-like technology to change Plum’s neural states, which
results in him wanting and then deciding to kill a man named White. In
this case, it seems clear that Plum did not freely decide to kill
White. Compare this case to a second one, in which the team of
neuroscientists programmed Plum at the beginning of his life in a way
that resulted in him developing the desire (and making the decision)
to kill White. The incompatibilist argues that these two cases do not
differ in a way that is relevant for whether Plum acted freely, and
so, once again, it seems that Plum did not freely decide to kill
White. Now compare this to a third case, in which Plum’s desire
and decision to kill White were instead determined by his cultural and
social milieu, rather than by a team of neuroscientists. Since the
only difference between the second and third case is the particular
technological process through which Plum’s mental states were
determined, he would again seem to not have freely decided to kill
White. Finally, in a fourth and final case, Plum’s desire and
decision to kill White was determined jointly by the past states and
the laws of nature in our own deterministic universe. Regarding these
four cases, Pereboom argues that, since there is no difference between
any of the four cases that is relevant to free will, if Plum was not
morally responsible in the first case, then he was not morally
responsible in the fourth.</p>

<p>
In response to this kind of manipulation-based argument for
incompatibilism, a number of researchers have taken aim at painting a
better empirical picture of ordinary moral judgments concerning
manipulated agents. This line of inquiry has been productive on two
levels. First, a growing number of empirical studies have investigated
moral responsibility judgments about cases of manipulation, and now
provide a clearer psychological picture for why manipulated agents are
judged to lack free will and moral responsibility. Second, continuing
theoretical work, informed by this empirical picture, has provided new
reasons for doubting that manipulation based arguments actually
provide evidence against compatibilism.</p>

<p>
One line of empirical research, led by Chandra Sripada (2012) has
asked whether manipulated agents are perceived to be unfree because
(a) they lack ultimate control over their actions (a capacity
incompatibilists take to be essential for moral responsibility) or
instead because (b) their psychological or volitional capacities (the
capacities focused on by compatibilists) have been damaged. Using a
statistical approach called Structural Equation Modeling (or SEM),
Sripada found that participants’ moral responsibility judgments
were best explained by whether they believed the psychological and
volitional capacities of the agent were damaged by manipulation and
not whether the agent lacked control over her actions. This finding
suggests that patterns of judgment in cases of manipulation are more
consistent with the predictions of compatibilism than with
incompatibilism.</p>

<p>
Taking a different approach, Phillips and Shaw (2014) demonstrated
that the reduction of moral responsibility that is typically observed
in cases of manipulation depends critically on the role of an
<em>intentional</em> manipulator. In particular, ordinary people were
shown to distinguish between (1) the moral responsibility of agents
who are made to do a particular act by features of the situation they
are in (i.e., situational determinism), and (2) the moral
responsibility of agents who are made to do that same act by another
intentional agent (i.e., manipulation). This work suggests that the
ordinary practice of assessing freedom and responsibility is likely to
clearly distinguish between cases that do and do not involve a
manipulator who intervenes with the intention of causing the
manipulated agent to do the immoral action. A series of studies by
Murray and Lombrozo (2016) further elaborates these findings by
providing evidence that the specific reduction of moral responsibility
that results from being manipulated arises from the perception that
the agent’s mental states are <em>bypassed</em>.</p>

<p>
Collectively, two lessons have come out of this work on the ordinary
practice of assessing the moral responsibility of manipulated agents:
(1) folk morality provides a natural way of distinguishing between the
different cases used in manipulation-based arguments (those that do
involve the intentional intervention of a manipulator vs. those that
don’t) and (2) folk morality draws an intimate link between the
moral responsibility of an agent and that agent’s mental and
volitional capacities. Building on this increasingly clear empirical
picture, Deery and Nahmias (2017) formalized these basic principles in
theoretical work that argues for a principled way of distinguishing
between the moral responsibility of determined and manipulated
agents.</p>

<p>
While the majority of evidence may currently be in favor of the view
that folk morality adheres to a kind of “natural
compatibilism” (Cova &amp; Kitano 2013), this remains a
contentious topic, and new work is continually emerging on both sides
of the debate (Andow &amp; Cova 2016; Bear &amp; Knobe 2016;
Björnsson 2014; Feltz &amp; Millan 2013; Figdor &amp; Phelan
2015; Knobe 2014). One thing that has now been agreed on by parties on
both sides of this debate, however, is a critical role for careful
empirical studies (Björnsson &amp; Pereboom 2016; Knobe 2014;
Nahmias 2011).</p>

<h2 id="VirtEthiSkepAbouChar">4. Virtue Ethics and Skepticism About Character</h2>

<p>
To date, empirically informed approaches to moral psychology have been
most prominent in discussions of moral character and virtue. The focus
is decades of experimentation in “situationist” social
psychology: unobtrusive features of situations have repeatedly been
shown to impact behavior in seemingly arbitrary, and sometimes
alarming, ways. Among the findings that have most interested
philosophers:</p>

<ul>

<li> <em>The Phone Booth Study</em> (Isen &amp; Levin (1972: 387):
people who had just found a dime in a payphone’s coin return
were 22 times more likely than those who did not find a dime to help a
woman who had dropped some papers (88% v. 4%). </li>

<li><em>The Good Samaritan Study</em> (Darley &amp; Batson 1973: 105):
unhurried passersby were 6 times more likely than hurried passersby to
help an unfortunate who appeared to be in significant distress (63% v.
10%).</li>

<li><em>The Obedience Experiments</em> (Milgram 1974) subjects
repeatedly punished a screaming victim with realistic (but simulated)
electric shocks at the polite request of an experimenter.</li>

<li><em>The Stanford Prison Study</em> (Zimbardo 2007): college
students role-playing as “guards” in a simulated prison
subjected student “prisoners” to grotesque verbal and
emotional abuse.</li>
</ul>

<p>
These experiments are <em>part of an extensive empirical literature,
where</em> social psychologists have time and again found that
disappointing omissions and appalling actions are readily induced by
apparently minor situational
 features.<sup>[<a href="notes.html#note-10" id="ref-10">10</a>]</sup>
 The striking fact is not that people fail standards for good conduct,
but that they can be so <em>easily</em> induced to do so.</p>

<p>
Exploiting this observation, “character skeptics” contend
that if moral conduct varies so sharply, often for the worse, with
minor perturbations in circumstance, ostensibly good character
provides very limited assurance of good conduct. In addition to this
claim in <em>descriptive psychology</em>, concerning the fragility of
moral character, some character skeptics also forward a thesis in
<em>normative ethics</em>, to the effect that character merits less
attention in ethical thought than it traditionally
 gets.<sup>[<a href="notes.html#note-11" id="ref-11">11</a>]</sup>
 </p>

<p>
Character skepticism contravenes the influential program of
contemporary <em>virtue ethics</em>, which maintains that advancing
ethical theory requires <em>more</em> attention to character, and
virtue ethicists offer vigorous
 resistance.<sup>[<a href="notes.html#note-12" id="ref-12">12</a>]</sup>
 Discussion has sometimes been overheated, but it has resulted in a
large literature in a vibrantly interdisciplinary field of
“character studies” (e.g., Miller et al. 
  2015).<sup>[<a href="notes.html#note-13" id="ref-13">13</a>]</sup>
 The literature is too extensive for the confines of this entry, but
we will endeavor to outline some of the main issues. </p>

<p>
The first thing to observe is that the science which inspires the
character skeptics may itself be subject to skepticism. Given the
uneven history of the human sciences, it might be argued that the
relevant findings are too uncertain to stand as a constraint on
philosophical theorizing. This contention is potentially buttressed by
recent prominent replication failures in social psychology. </p>

<p>
The psychology at issue is, like much of science, unfinished business.
But the replication controversy, and the attendant suspicion of
science, is insufficient grounds for dismissing the psychology out of
hand. Philosophical conclusions should not be based on a few studies;
the task of the philosophical consumer of science is to identify
<em>trends</em> in <em>convergent</em> strands of evidence (Doris
2015: 49, 56; Machery &amp; Doris forthcoming). The observation that
motivates character skepticism—the surprising situational
sensitivity of behavior—is supported by a wide range of
scientific findings, as well as by recurring themes in history and
biography (Doris 2002, 2005). The strong situational
discriminativeness of behavior is accepted as fact by high proportion
of involved scientists; accordingly, it is not much contested in
debates about character skepticism.</p>

<p>
But the philosophical implications of this fact remain, after
considerable debate, a contentious issue. The various responses to
character skepticism need not be forwarded in isolation, and some of
them may be combined as part of a multi-pronged defense. Different
rejoinders have differing strengths and weaknesses, particularly with
respect to the differing pieces of evidence on which character
skeptics rely; the phenomena are not unitary, and accommodating them
all may preclude a unitary response. </p>

<p>
One way of defusing empirically motivated skepticism—dubbed by
Alfano (2013) “the dodge”—is simply to deny that
virtue ethics makes empirical claims. On this understanding, virtue
ethics is cast as a “purely normative” endeavor aiming at
erecting ethical ideals in complete absence of empirical commitments
regarding actual human psychologies. This sort of purity is perhaps
less honored than honored in the breach: historically, virtue ethics
has been typified by an interest in how actual people <em>become</em>
good. Aristotle (<em>Nicomachean Ethics</em>, 1099b18–19)
thought that anyone not “maimed” with regard to the
capacity for virtue may acquire it “by a certain kind of study
and care”, and contemporary Aristotelians have emphasized the
importance of moral education and development (e.g., Annas 2011). More
generally, virtue-based approaches have been claimed to have an
advantage over major Kantian and consequentialist competitors with
respect to “psychological realism”—the advantage of
a more lifelike moral psychology (see Anscombe 1958: 1, 15; Williams
1985; Flanagan 1991: 182; Hursthouse 1999: 19–20). </p>

<p>
To be sure, eschewing empirical commitment allows virtue ethics to
escape empirical threat: obviously, empirical evidence cannot be used
to undermine a theory that makes <em>no</em> empirical claims.
However, it is not clear such theories could claim advantages
traditionally claimed for virtue theories with regard to moral
development and psychological realism. In any event, they are not
contributions to empirical moral psychology, and needn’t be
further discussed here.</p>

<p>
Before seeing how the debate in moral psychology might be advanced, it
is necessary to correct a mischaracterization that serves to arrest
progress. It is too often said, particularly in reference to Doris
(1998, 2002) and Harman (1999, 2000), that character skepticism comes
to the view that character traits “do not exist” (e.g.,
Flanagan 2009: 55). Frequently, this attribution is made without
documentation, but when documentation is provided, it is typically in
reference to some early, characteristically pointed, remarks of Harman
(e.g., 1999). Yet in his most recent contribution, Harman (2009: 241)
says, “I do not think that social psychology demonstrates there
are no character traits”. For his part, Doris has repeatedly
asserted that traits exist, and has repeatedly drawn attention to such
assertions (Doris 1998: 507–509; 2002: 62–6; 2005: 667;
2010: 138–141; Doris &amp; Stich 2005: 119–20; Doris &amp;
Prinz 2009). </p>

<p>
With good reason, to say “traits do not exist” is
tantamount to denying that there are individual dispositional
differences, an unlikely view that character skeptics and antiskeptics
are united in rejecting. Quite unsurprisingly, this unlikely view is
seriously undersubscribed in both philosophy and psychology. It is
endorsed by neither the most aggressive critics of personality,
situationists in social psychology such as Ross and Nisbett (1991),
nor by the patron saint of situationism in personality psychology:
Mischel (1999: 45). Mischel disavows a trait-based approach, but his
skepticism concerns a <em>particular approach to traits</em>, not
individual dispositional differences more generally. </p>

<p>
Then the question of whether or not traits exist is <em>emphatically
not the issue</em> dividing more and less skeptical approaches to
character. Today, all mainstream parties to the debate are
“interactionist”, treating behavioral outcomes as the
function of a (complex) person by situation interaction (Mehl et al.
2015)—and it’s likely most participants have always been
so (Doris 2002: 25–6). Contemporary research programs in
personality and social psychology freely deploy <em>both</em> personal
and situational variables (e.g., Cameron, Payne, &amp; Doris 2013;
Leikas, Lönnqvist, &amp; Verkasalo 2012; Sherman, Nave, &amp;
Funder 2010). The issue worth discussing is not whether individual
dispositional differences exist, but <em>how these differences should
be characterized</em>, and how (or whether) these individual
differences, when appropriately characterized, <em>should inform
ethical thought</em>. </p>

<p>
An important feature of early forays into character skepticism was
that skeptics tended to focus on <em>behavioral implications</em> of
traits rather than the <em>psychological antecedents</em> of behavior
(Doris 2015: 15). Defenders of virtue ethics observe that character
skeptics have had much to say about situational variation in behavior
and little to say about the psychological processes underlying it,
with the result that they overlook the rational order in
people’s lives (Adams 2006: 115–232). These virtue
ethicists maintain that the behavioral variation provoking character
skepticism evinces not unreliability, but rationally appropriate
sensitivity to differing situations (Adams 2006; Kamtekar 2004). The
virtuous person, such as Aristotle’s exemplary
<em>phronimos</em> (“man of practical wisdom”) may
sometimes come clean, and sometimes dissemble, or sometimes fight, and
sometimes flee, depending on the particular ethical demands of his
circumstances.</p>

<p>
For example, in the Good Samaritan Study, the hurried passersby was on
the way to an appointment where they had agreed to give a
presentation; perhaps these people made a rational
determination—perhaps even an ethically defensible
determination—to weigh the demands of punctuality and
professionalism over ethical requirement to check on the welfare of a
stranger in apparent distress. However attractive one finds such
accounting for this case (note that some of Darley and Batson’s
[1973] hurried passersby failed to notice the victim, which strains
explanations in terms of their rational discriminations), there are
other cases where the “rationality response” seems plainly
unattractive. These are cases of ethically irrelevant influences
 (<a href="#ThouExpeMethEthi">Sec. 2 above</a>;
 Doris &amp; Stich 2005), where it seems unlikely the influence could
be cited as part of a rationalizing explanation of the behavior:
it’s odd to cite failing to find a dime as
<em>justification</em> for failing to help—or for that matter,
finding a dime as <em>justification</em> for doing so.</p>

<p>
It is certainly appropriate for virtue ethicists to emphasize
practical rationality in their accounts of character. This is a
central theme in the tradition going back to Aristotle himself, who is
probably the most oft-cited canonical philosopher in contemporary
virtue ethics. But while the rationality response may initially
accommodate some of the troubling behavioral evidence, it encounters
further empirical difficulty. There is an extensive empirical
literature problematizing familiar conceptions of rationality:
psychologists have endlessly documented a dispiriting range of
reasoning errors (Baron 1994, 2001; Gilovich et al. 2002; Kahneman et
al. 1982; Tversky &amp; Kahneman 1973; Kruger &amp; Dunning 1999;
Nisbett &amp; Borgida 1975; Nisbett &amp; Ross 1980; Stich 1990;
Tversky &amp; Kahneman 1981). In light of this evidence, character
skeptics claim that the vagaries afflicting behavior also afflict
reasoning (Alfano 2013; Olin &amp; Doris 2014). </p>

<p>
Research supporting this discouraging assessment of human rationality
is controversial, and not all psychologists think things are so bleak
(Gigerenzer 2000; Gigerenzer et al. 1999; for philosophical commentary
see Samuels &amp; Stich 2002). Nevertheless, if virtue ethics is to
have an empirically credible moral psychology, it needs to account for
the empirical challenges to practical reasoning: how can the relevant
excellence in practical reasoning be developed? </p>

<p>
Faced with the challenge to practical rationality, virtue ethicists
may respond that their theories concern <em>excellent</em> reasoning,
not the <em>ordinary</em> reasoning studied in psychology. Practical
wisdom, and the ethical virtue it supports, are expected to be
<em>rare</em>, and not widely instantiated. This state of affairs, it
is said, is quite compatible with the disturbing, but not
exceptionlessly disturbing, behavior in experiments like
Milgram’s (see Athanassoulis 1999: 217–219; DePaul 1999;
Kupperman 2001: 242–3). If this account is supposed to be part
of an empirically contentful moral psychology, rather than unverified
speculation, we require a detailed and empirically substantiated
account of how the virtuous few get that way—remember that an
emphasis on moral development is central to the virtue ethics
tradition. Moreover, if virtue ethics is supposed to have widespread
practical implications—as opposed to being merely a celebration
of a tiny “virtue elite”—it should have an account
of how the less-than-virtuous-many may at least tolerably
<em>approximate</em> virtue. </p>

<p>
This point is underscored by the fact that for some of the troubling
evidence, as in the Stanford Prison Study, the worry is not so much
that people fail standards of virtue, but that they fail standards of
<em>minimal decency</em>. Surely an approach to ethics that celebrates
moral development, even one that acknowledges (or rather, insists)
that most people will not attain its ideal, might be expected to have
an account of how people can become minimally decent.</p>

<p>
Recently, proponents of virtue ethics have been increasingly proposing
a suggestive solution to this problem: virtue is a skill acquired
through effortful practice, so virtue is a kind of expertise (Annas
2011; Bloomfield 2000, 2001, 2014; Jacobson 2005; Russell 2015; Snow
2010; Sosa 2009; Stichter 2007, 2011; for reservations, see Doris, in
preparation). The virtuous are expert at morality and—given the
Aristotelian association of virtue and happiness—expert at life.
</p>

<p>
An extensive scientific literature indicates that developing expert
skill requires extensive preparation, whether the practitioner is a
novelist, doctor, or chess master—around 10,000 hours of
“deliberate practice”, according to a popular
generalization (Ericsson 2014; Ericsson et al. 1993). The
“10,000–hour rule” is likely an oversimplification,
but there is no doubt that attaining expertise requires intensive
training. Because of this, people rarely achieve eminence in more than
one area; for instance, “baseball trivia” experts display
superior recall for baseball-related material, but not for
non-baseball material (Chiesi et al. 1979). Conversely, becoming
expert at morality, or (even more ambitiously) expert at the whole of
life, would apparently require a <em>highly</em> generalized form of
expertise: to be good, there’s a <em>lot</em> to be good at.
Moreover, it’s quite unclear what deliberate practice at life
involves; how exactly does one get better at being good? </p>

<p>
One obvious problem concerns specifying the “good” in
question. Expertises like chess have been effectively studied in part
because there are accepted standards of excellence (the
“ELO” score used for ranking chess players; Glickman
1995). To put it blithely, there aren’t any chess skeptics. But
there have, historically, been <em>lots</em> of moral skeptics. And if
there’s not moral knowledge, how could there be moral experts?
And even if there are moral experts, there’s the problem of how
are they to be identified, since it is not clear we are possessed of
standard independent of expert opinion itself (like winning chess
matches) for doing so (for the “metaethics of expertise”,
see McGrath 2008, 2011).</p>

<p>
Even if these notorious philosophical difficulties can be
resolved—as defenders of expertise approaches to virtue must
think they can—matters remain complicated, because if moral
expertise is like other expertises, practice alone—assuming we
have a clear notion of what “moral practice”
entails—will be insufficient. While practice matters in
attaining expertise, other factors, such as talent, also matter
(Hambrick et al. 2014; Macnamara et al. 2014). And some of the
required endowments may be quite unequally distributed across
populations: practice cannot make a jockey into an NFL lineman, or an
NFL lineman into a jockey. </p>

<p>
What are the natural endowments required for moral expertise, and how
widely are they distributed in the population? If they are rare, like
the skill of a chess master or the strength of an NFL lineman, virtue
will also be rare. Some virtue ethicists believe virtue should be
widely attainable, and they will resist this result (Adams 2006:
119–123, and arguably Aristotle <em>Nicomachean Ethics</em>
1099b15–20). But even virtue ethicists who embrace the rarity of
virtue require an account of what the necessary natural endowments
are, and if they wish to also have an account of how the less
well-endowed may achieve at least minimal decency, they should have
something to say about how moral development will proceed across a
population with widely varying endowments.</p>

<p>
What is needed, for the study of moral character research to advance,
is an account of the biological, psychological, and social factors
requisite for successful moral development—on the expertise
model, the conditions conducive to developing “moral
skill”. This, quite obviously, is a tall order, and the research
needed to systematically address these issue is in comparative
infancy. Yet the expertise model, in exploiting connections with areas
in which skill acquisition has been well studied, such as music and
sport, provides a framework for moving discussion of character beyond
the empirically under-informed conjectures and assumptions about
“habituation” that have been too frequent in previous
literature (Doris 2015: 128).</p>

<h2 id="EgoiVsAltr">5. Egoism <em>vs.</em> Altruism</h2>

<h3 id="SomePhilBack">5.1 Some Philosophical Background</h3>

<p>
People often behave in ways that benefit others, and they sometimes do
this knowing that it will be costly, unpleasant or dangerous. But at
least since Plato’s classic discussion in the second Book of the
<em>Republic</em>, debate has raged over <em>why</em> people behave in
this way. Are their motives <em>really</em> altruistic, or is their
behavior ultimately motivated by self-interest? Famously, Hobbes gave
this answer:</p>

<blockquote>

<p>
No man giveth but with intention of good to himself, because gift is
voluntary; and of all voluntary acts, the object is to every man his
own good; of which, if men see they shall be frustrated, there will be
no beginning of benevolence or trust, nor consequently of mutual help.
(1651 [1981: Ch. 15])</p>
</blockquote>

<p>
Views like Hobbes’ have come to be called
 <em>egoism</em>,<sup>[<a href="notes.html#note-14" id="ref-14">14</a>]</sup>
 and this rather depressing conception of human motivation has been
favored by any number of eminent philosophical advocates, including
Bentham, J.S. Mill and
 Nietzsche.<sup>[<a href="notes.html#note-15" id="ref-15">15</a>]</sup>
 Egoism is also arguably the dominant view about human motivation in
much of contemporary social science (see Grant 1997). Dissenting
voices, though perhaps fewer in number, have been no less eminent.
Butler, Hume, Rousseau and Adam Smith have all argued that, sometimes
at least, human motivation is genuinely altruistic.</p>

<p>
Though the issue that divides egoistic and altruistic accounts of
human motivation is largely empirical, it is easy to see why
philosophers have thought that the competing answers will have
important consequences for moral theory. For example, Kant famously
argued that a person should act “not from inclination but from
duty, and by this would his conduct first acquire true moral
worth” (1785 [1949: Sec. 1, parag. 12]). But egoism maintains
that <em>all</em> human motivation is ultimately self-interested, and
thus people <em>can’t</em> act “from duty” in the
way that Kant urged. Thus if egoism is true, Kant’s account
would entail that no conduct has “true moral worth”.
Additionally, if egoism is true, it would appear to impose a strong
constraint on how a moral theory can answer the venerable question
“Why should I be moral?” since, as Hobbes clearly saw, the
answer will have to ground the motivation to be moral in the
agent’s self-interest.
 <sup><sup>[<a href="notes.html#note-16" id="ref-16">16</a>]</sup></sup></p>
 
<p>
It is easy to find philosophers suggesting that altruism is required
for morality or that egoism is incompatible with morality—and
easier still to find philosophers who claim that <em>other</em>
philosophers think this. Here are a few examples culled from a
standard reference work that happened to be close at hand.</p>

<blockquote>

<p>
Moral behavior is, at the most general level, altruistic behavior,
motivated by the desire to promote not only our own welfare but the
welfare of others. (Rachels 2000: 81)</p>

<p>
[O]ne central assumption motivating ethical theory in the Analytic
tradition is that the function of ethics is to combat the inherent
egoism or selfishness of individuals. Indeed, many thinkers define the
basic goal of morality as ‘selflessness’ or
‘altruism’. (Schroeder 2000: 396)</p>

<p>
Philosophers since Socrates worried that humans might be capable of
acting only to promote their own self-interest. But if that is all we
can do, then it seems morality is impossible. (LaFollette 2000a:
5)</p>
</blockquote>

<p>
While the egoism/altruism debate has historically been of great
philosophical interest, the issue centrally concerns psychological
questions about the nature of human motivation, so it’s no
surprise that psychologists have done a great deal of empirical
research aimed at determining which view is correct.</p>

<p>
Before considering the empirical literature, we must be clear on what
the debate is about. As we’ve already intimated, while advocates
of altruism and of egoism agree that people often help others, they
disagree about <em>why</em> they do this. Defenders of altruism insist
that, sometimes at least, people are motivated by an ultimate desire
for the well-being of another person, while defenders of egoism
maintain that all ultimate desires are self-interested. This
formulation invites questions about (1) what it is for a behavior to
be <em>motivated by an ultimate desire</em>, and (2) the distinction
between <em>desires that are self-interested</em> and <em>desires that
are for the well-being of others</em>.</p>

<p>
Although the second question will need to be considered in any
comprehensive treatment, some rough and ready examples of the
distinction will suffice
 here.<sup>[<a href="notes.html#note-17" id="ref-17">17</a>]</sup>
 Desires to save someone else’s life, to alleviate someone
else’s suffering, or to make someone else happy are paradigm
cases of desires for the well-being of others, while desires to
experience pleasure, get rich, and become famous are typical examples
of self-interested desires. The self-interested desires to experience
pleasure and to avoid pain have played an especially prominent role in
the debate, since one version of egoism, often called
<em>hedonism</em>, maintains that these are our <em>only</em> ultimate
desires.</p>

<p>
The first question, regarding ultimate desires, is the crucial one for
our present purposes, and requires a fuller exposition; it can be
usefully explicated with the help of a familiar account of
<em>practical
 reasoning</em>.<sup>[<a href="notes.html#note-18" id="ref-18">18</a>]</sup>
 On this account, practical reasoning is a causal process via which a
desire and a belief give rise to or sustain another desire. For
example, a desire to drink an espresso and a belief that the best
place to get an espresso is at the espresso bar on Main Street may
cause a desire to go to the espresso bar on Main Street. This desire
can then join forces with another belief to generate a third desire,
and so on. Sometimes this process will lead to a desire to perform a
relatively simple or “basic” action, and that desire, in
turn, will cause the agent to perform the basic action without the
intervention of any further desires. Desires produced or sustained by
this process of practical reasoning are <em>instrumental</em>
desires—the agent has them because she thinks that satisfying
them will lead to something else that she desires. But not
<em>all</em> desires can be instrumental desires. If we are to avoid
circularity or an infinite regress there must be some desires that are
<em>not</em> produced because the agent thinks that satisfying them
will facilitate satisfying some other desire. These desires that are
not produced or sustained by practical reasoning are the agent’s
<em>ultimate</em> desires, and the objects of ultimate desires are
desired for their own sake. A behavior is <em>motivated</em> by a
specific ultimate desire when that desire is part of the practical
reasoning process that leads to the behavior.</p>


<!--pdf include  

<div class="pagebreak">
</div> pdf include-->

<h3 id="AltrEvol">5.2 Altruism and Evolution</h3>

<p>
Readers familiar with some of the popular literature on the evolution
of morality that has appeared in the last few decades might suspect
that recent work in evolutionary biology has resolved the debate
between egoists and altruists. For some readers—and some
writers—seem to interpret evolutionary theory as showing that
altruism is biologically impossible. If altruistic organisms were
somehow to emerge, this literature sometimes suggests, they would lose
the competition for survival and reproduction to their selfish
conspecifics, and they would quickly become extinct. On this view, the
appearance of altruism is simply an illusion. In the memorable words
of biologist Michael Ghiselin (1974: 247) “Scratch an
‘altruist’ and watch a ‘hypocrite’
bleed”. But as Sober and Wilson (1998) have argued with great
clarity, there is no <em>simple</em> connection between evolutionary
theory and the philosophical debate between egoism and altruism.</p>

<p>
This is because the concept of altruism that is important in
evolutionary theory is quite different from the concept of altruism
invoked in the philosophical debate. For biologists, an organism
behaves altruistically if and only if the behavior in question reduces
its own fitness while increasing the fitness of one or more other
organisms. Roughly speaking, an organism’s fitness is a measure
of how many descendants it will
 have.<sup>[<a href="notes.html#note-19" id="ref-19">19</a>]</sup>
 As Sober and Wilson note, on this evolutionary account of altruism,
an organism can be altruistic even if it does not have a mind capable
of having beliefs and desires. Thus there can be no easy inference
from biological altruism to psychological altruism. Nor does the
inference go in the opposite direction. To make the point, Sober and
Wilson (Ch. 10) note that natural selection might well equip humans or
other sophisticated organisms with ultimate desires to foster the
welfare of their offspring under certain circumstances. Organisms with
these ultimate desires would be <em>psychological</em> altruists,
though the behavior that the desires gave rise to would typically
<em>not</em> be <em>evolutionarily</em> altruistic, since by helping
their offspring organisms typically are increasing their own fitness.
So, contrary to the presumption that evolutionary biology has resolved
the debate between egoists and altruists in favor of egoism, it
appears that evolutionary theory has nothing to offer that will enable
us to make progress in that
 debate.<sup>[<a href="notes.html#note-20" id="ref-20">20</a>]</sup>
 Since that debate turns on the nature of human motivation, perhaps
experimental psychology can move the debate forward.</p>

<h3 id="Psyc">5.3 Psychology</h3>

<p>
The psychological literature relevant to the egoism <em>vs.</em>
altruism debate is
 vast.<sup>[<a href="notes.html#note-21" id="ref-21">21</a>]</sup>
 In the interests of a tolerable brevity, we will focus on the work of
Daniel Batson and associates, who have done some of the most
influential and philosophically sophisticated work in this area.
Batson, along with many other researchers, begins by borrowing an idea
that has deep roots in philosophical discussions of altruism. Though
the details and the terminology differ significantly from author to
author, the core idea is that altruism is often the product of an
<em>emotional response</em> to the distress of another person. Aquinas
(1270 [1917]: II–II, 30, 3), for example, maintains that
“mercy is the heartfelt sympathy for another’s distress,
impelling us to succour him if we can”. And Adam Smith (1759
[1853: I, I, 1. 1]) tells us that </p>

<blockquote>

<p>
pity or compassion [is] the emotion we feel for the misery of others,
when we either see it, or are made to conceive it in a very lively
manner </p>
</blockquote>

<p>
and these emotions </p>

<blockquote>

<p>
interest [man] in the fortunes of others, and render their happiness
necessary to him, though he derives nothing from it except the
pleasure of seeing it. </p>
</blockquote>

<p>
Batson (1991: 58) labels this response “empathy” which he
characterizes as “an other-oriented emotional reaction to seeing
someone suffer”, and terms the traditional idea that empathy
leads to altruism the <em>“empathy-altruism
hypothesis”.</em> On Batson’s account (1991: 86), empathy
</p>

<blockquote>

<p>
includes feeling sympathetic, compassionate, warm, softhearted,
tender, and the like, and according to the empathy-altruism
hypothesis, it evokes altruistic motivation. </p>
</blockquote>

<p>
Batson (1991: 117) contrasts empathy to a cluster of affective
responses he calls “personal distress” which is
“made up of more self-oriented feelings such as upset, alarm,
anxiety, and distress”. In more recent work, Batson (2011:
11–20) distinguishes his conception of empathy from a number of
related psychological states which other authors have labeled
“empathy”.</p>

<p>
If the philosophical tradition that suggests the empathy-altruism
hypothesis is on the right track, and Batson believes it is, we would
predict that when people feel empathy they will desire to help those
who evoke the emotion, and thus they will be more inclined to engage
in helping behavior than people who do not feel empathy. This does not
mean that people will <em>always</em> engage in helping behavior when
they feel empathy, since people typically have various and conflicting
desires, and not all conflicts are resolved in favor of
empathy’s urgings. Nor does it mean that when people feel little
or no empathy they will not engage in helping behavior, since the
desire to help can also be produced by a variety of processes in which
empathy plays no role. But we should expect that typically people
feeling empathy will be more likely to help than people who
aren’t feeling empathy, and the stronger the empathy the more
likely it is that they will engage in helping behavior.</p>

<p>
In order to put this claim to empirical test, it is important to have
ways of inducing empathy in the laboratory, and there is a substantial
body of literature suggesting how this can be done. For example,
Stotland (1969) showed that subjects who were instructed to
<em>imagine</em> how a specified person (often called “the
target”) <em>felt</em> when undergoing what subjects believed to
be a painful medical procedure reported stronger feelings of empathy
and showed greater physiological arousal than subjects who were
instructed to watch the target person’s movements. Relatedly,
Krebs (1975) demonstrated that subjects who observe someone
<em>similar to themselves</em> undergo painful experiences show more
physiological arousal, report identifying with the target more
strongly, and report feeling worse while waiting for the painful
stimulus to begin than do subjects who observe the same painful
experiences administered to someone who is not similar to themselves.
Krebs also showed that subjects are more willing to help at some
personal cost when the sufferer is similar to themselves. Batson
(1991: 82–87) interprets these findings as indicating that
people are more inclined to feel empathy for those they believe to be
similar to themselves, and thus that empathy can often be evoked by
providing a person with evidence that she and a target person are
similar.</p>

<p>
To make the case that empathy leads to helping behavior, Batson relies
in part on work by others, including the just-cited Krebs (1975) study
and a study by Dovidio et al. (1990). In that latter study,
Stotland’s technique for manipulating empathy by instructing
subjects to take the perspective of the person in distress was used to
induce empathy for a young woman. Subjects focused on one of two quite
different problems that the young woman faced. When given an
opportunity to help the young woman, subjects in whom empathy had been
evoked were more likely to help than subjects in a low empathy
condition, and the increase in helping was specific to the problem
that had evoked the empathy. Many of Batson’s own experiments,
some of which we’ll describe below, also support the contention
that both spontaneously evoked empathy and empathy engendering
experimental manipulations increase the likelihood of helping
behavior. Another important source of support for the link between
empathy and helping behavior is a meta-analysis of a large body of
experimental literature by Eisenberg and Miller (1987) which found
positive correlations between empathy and prosocial behavior in
studies using a variety of techniques to assess empathy. On the basis
of these and other findings, Batson (1991: 95) argues that </p>

<blockquote>

<p>
there is indeed an empathy-helping relationship; feeling empathy for a
person in need increases the likelihood of helping to relieve that
need.</p>
</blockquote>

<p>
It might be thought that establishing a causal link between empathy
and helping behavior would be bad news for egoism. But, as Batson
makes clear, the fact that empathy leads to helping behavior does not
resolve the dispute between egoism and altruism, since it does not
address the nature of the <em>motivation</em> for the helping behavior
that empathy evokes. One possibility is that empathy does indeed cause
a genuinely altruistic desire to help—an ultimate desire for the
well-being of the sufferer. But there are also a variety of egoistic
routes by which empathy might lead to helping behavior. Perhaps the
most obvious of these is that empathy might simply be (or cause) an
unpleasant experience, and that people are motivated to help because
they believe this is the best way to <em>stop</em> the unpleasant
experience that is caused by someone else’s distress. Quite a
different family of egoistic possibilities focus on the rewards to be
expected for helping and/or the punishments to be expected for
withholding assistance. If people believe that others will reward or
sanction them for helping or failing to help in certain circumstances,
and if the feeling of empathy marks those cases in which social
sanctions or rewards are most likely, then we would expect people to
be more helpful when they feel empathy, even if their ultimate
motivation is purely egoistic. A variation on this theme focuses on
rewards or punishments that are self-administered. If people believe
that helping may make them feel good, or that failing to help may make
them feel bad, and that these feelings will be most likely to occur in
cases where they feel empathy, then once again we would expect people
who empathize to be more helpful, though their motives may be not at
all altruistic.</p>

<p>
For more than three decades, Batson and his collaborators have
systematically explored these egoistic hypotheses and many others.
Their strategy is to design experiments in which the altruistic
explanation of the link between empathy and helping can be compared to
one or another specific egoistic explanation. Reviewing all of these
experiments would require far more space than we
 have.<sup>[<a href="notes.html#note-22" id="ref-22">22</a>]</sup>
 Instead we’ll focus on two clusters of experiments that
illustrate the potential philosophical rewards of designing and
interpreting experiments in this area, as well as some of the
difficulties of the project.</p>

<h3 id="SociPuniHypo">5.4 The Social Punishment Hypothesis</h3>

<p>
One of the more popular egoist alternatives to the empathy-altruism
hypothesis is the idea that people engage in helping behavior because
they fear that other people will punish them if they do not. If I
don’t help, the actor is supposed to worry, people will be angry
or they will think badly of me, and this may have negative effects on
how they treat me in the future. As it stands, this egoist hypothesis
can’t explain the fact that empathy increases the likelihood of
helping, but a more sophisticated version is easy to construct by
adding the assumption that people think social sanctions for not
helping are more likely when the target engenders empathy.</p>

<p>
To test this hypothesis—which Batson calls the <em>socially
administered empathy-specific punishment hypothesis</em>—against
the empathy-altruism hypothesis, Batson and his associates (Fultz et
al. 1986) designed an experiment in which they manipulated both the
level of empathy that subjects felt for the target and the likelihood
that anyone would know whether or not the subject had opted to help a
person in need. Others can form a negative evaluation of your decision
not to help only if they <em>know</em> the choice you are facing and
the decision you have made; if your decision is secret, you need have
no fear of social sanctions. Thus the socially administered
empathy-specific punishment hypothesis predicts that subjects who
exhibit high empathy on a given occasion will be more likely to help
when they believe others will know if they fail to do so. On the
empathy-altruism hypothesis, by contrast, high empathy subjects are
motivated by an ultimate desire to help, and thus their helping levels
should be high whether or not others would know if they decided not to
help. In the low empathy condition, both hypotheses predict that
levels of helping will be low. These predictions are summarized in
Tables 1 and 2.</p>

<div class="figure avoid-break center">

<table class="cellpad-med-dense cell-center centered avoid-break vert-top topbottom-rules">
<tbody><tr>
  <td rowspan="2" style="width:10em"><strong>Potential for Negative
Social Evaluation</strong></td>
  <td colspan="2"><strong>Empathy</strong> </td> </tr>
<tr>
  <td><strong>Low</strong></td>
  <td><strong>High</strong></td> </tr>
<tr class="rule-above">
  <td>High</td>
  <td>Low </td>
  <td>High</td> </tr>
<tr>
  <td>Low </td>
  <td>Low</td>
  <td>Low </td> </tr>
</tbody></table>

<p>
<span class="figlabel">Table 1:</span> Predictions About the Amount of
Helping On the Socially Administered Empathy-Specific Punishment
Hypothesis</p>
</div>

<div class="figure avoid-break center">

<table class="cellpad-med-dense cell-center centered avoid-break vert-top topbottom-rules">
<tbody><tr>
  <td rowspan="2" style="width:10em"><strong>Potential for Negative
Social Evaluation</strong></td>
  <td colspan="2"><strong>Empathy</strong> </td> </tr>
<tr>
  <td><strong>Low</strong></td>
  <td><strong>High</strong></td> </tr>
<tr class="rule-above">
  <td>High</td>
  <td>Low </td>
  <td>High</td> </tr>
<tr>
  <td>Low </td>
  <td>Low</td>
  <td>High </td> </tr>
</tbody></table>

<p>
<span class="figlabel">Table 2:</span> Predictions About the Amount of
Helping On the Empathy-Altruism Hypothesis</p>
</div>

<p>
Subjects in the experiment were told that they were participating in
an impression formation study, and that they had been randomly
assigned to the role of “listener” in which they would
read confidential notes from another student participant, the
“communicator”. They were given two notes from Janet
Arnold, an out-of-state freshman who reveals that she is very lonely
and hoping to find a friend. After completing a form on which subjects
indicated their impressions of Janet and their emotional responses to
her note, they were presented with an unexpected opportunity to
befriend Janet by volunteering to take part in a study of long-term
relationships involving an initial meeting with Janet and periodic
phone interviews about the development of their friendship.
Participants who were willing to help were asked how much time they
were willing to spend with Janet during the next month.</p>

<p>
To manipulate empathy, Batson and his associates used the Stotland
technique. Subjects assigned to the low-empathy condition were
instructed to </p>

<blockquote>

<p>
Read the information in the communicator’s notes carefully,
trying to be as objective as possible. Try to focus on the techniques
used to get the communicator’s message across. </p>
</blockquote>

<p>
Subjects assigned to the high-empathy condition were instructed to
</p>

<blockquote>

<p>
Read the information in the communicator’s notes carefully,
trying to take the perspective of the individual writing the notes.
Try to imagine how this individual feels about what he or she writes.
(1991: 132)</p>
</blockquote>

<p>
Four steps were taken to manipulate the perceived potential for
negative social evaluation. In the <em>low-potential</em> condition
(1991: 132):</p>

<ol start="1" type="1">

<li>Subjects were told that they would be the only person ever to read
the communicator’s notes, and the notes were delivered in a
sealed envelope.</li>

<li>Subjects were assured that the questionnaires reporting their
reactions to Janet’s note would be anonymous.</li>

<li>Subjects’ responses to the invitation to participate in the
long-term relationship study were returned to the professor in a
sealed envelope, so no one would know if they did not want to help
Janet. (Since they believed the professor had not read Janet’s
note, they could be expected to surmise that he would not know that
Janet needed a friend.)</li>

<li>In the letter inviting them to participate in the relationship
study, subjects were told that Janet would be contacted

<blockquote>
only if you want a meeting; if you do not, then we will not contact
the communicator and he or she will not know that you were ever asked
about actually meeting.
</blockquote></li>
</ol>

<p>
In the <em>high-potential</em> condition (1991: 133):</p>

<ol start="1" type="1">

<li>Subjects were told that the experimenter would read the
communicator’s notes. Also, the experimenter would collect the
questionnaire when the subject completed it and would compare the
content of the notes with the impressions the subject formed.</li>

<li>No envelope was provided for their response to the invitation to
participate in the long-term relationship study, so subjects could
infer that the experimenter would know about Janet’s need for a
friend, about their emotional reaction to Janet, and would also know
whether or not they had agreed to help Janet.</li>

<li>Subjects were told that Janet would know if they decided not to
help.</li>
</ol>

<p>
As Batson notes, procedures in the high-potential condition
“were designed to highlight the possibility of negative social
evaluation if the participant decided not to volunteer to spend time
with Janet”.</p>

<p>The results, given in Table 3, indicate that the socially administered
empathy-specific punishment hypothesis did not fare well.</p>

<div class="figure avoid-break center">

<table class="cellpad-med-dense cell-center centered avoid-break vert-top topbottom-rules">
<tbody><tr>
  <td rowspan="2" style="width:10em"><strong>Potential for Negative
Social Evaluation</strong></td>
  <td colspan="2"><strong>Empathy</strong> </td> </tr>
<tr>
  <td><strong>Low</strong></td>
  <td><strong>High</strong></td> </tr>
<tr class="rule-above">
  <td>High</td>
  <td>0.67 </td>
  <td>1.71</td> </tr>
<tr>
  <td>Low </td>
  <td>1.29</td>
  <td>2.44 </td> </tr>
</tbody></table>

<p>
<span class="figlabel">Table 3:</span> Amount of Help Offered Janet
(Fultz et al. 1986: Study 2)</p>
</div>


<p> On the basis
of this experiment and a similar experiment in which empathy for Janet
was not manipulated but was measured by self-report, Batson concludes
that the socially administered empathy-specific punishment hypothesis
is not consistent with the experimental facts.</p>

<blockquote>

<p>
Contrary to what the social-evaluation version of the empathy-specific
punishment hypothesis predicted, eliminating anticipated negative
social evaluation in these two studies did not eliminate the
empathy-helping relationship. Rather than high empathy leading to more
help only under high social evaluation, it led to more helping under
both low and high social evaluation. This pattern of results is not
consistent with what would be expected if empathically aroused
individuals are egoistically motivated to avoid looking bad in the
eyes of others; it is quite consistent with what would be expected if
empathy evokes altruistic motivation to reduce the victim’s
need. (Batson 1991: 134)</p>
</blockquote>

<p>
Though two experiments hardly make a conclusive case, we are inclined
to agree with Batson that these studies make the socially administered
empathy-specific punishment hypothesis look significantly less
plausible than the empathy-altruism hypothesis. So one popular egoist
hypothesis has been dealt a serious blow: high empathy subjects were
more likely to help <em>whether or not</em> they could expect their
behavior to be socially scrutinized. At least in some circumstances,
empathy appears to facilitate helping independently of the threat of
social sanction.</p>

<h3 id="AverArouReduHypo">5.5 The Aversive-Arousal Reduction Hypothesis</h3>

<p>
Another popular egoistic strategy for explaining the link between
empathy and helping behavior is the <em>aversive-arousal reduction
hypothesis</em>, which maintains that the empathy evoked by witnessing
someone in need is an unpleasant or aversive experience, and that
helping is motivated by the desire to diminish that aversive
experience. If this is right, Batson maintains, people in a high
empathy condition will sometimes have two quite different ways of
reducing the aversive experience—they can help the person in
need or they can simply <em>leave</em>. Which strategy a person adopts
will depend, in part, on how difficult or costly it is to depart the
scene. If escape is easy, people will be more likely to take that
option, while if leaving is more difficult people will be more likely
to help, since that is a less costly way of ending the aversive
experience. If, on the other hand, the empathy-altruism hypothesis is
correct and empathy leads to genuinely altruistic motivation, we would
expect people in a high empathy condition to help whether escape is
easy or hard, since only helping will satisfy an altruistic desire.
Altruism and egoism both allow that even in the absence of empathy, an
emotionally disturbing need situation will produce feelings of
personal distress, thus they would <em>both</em> predict that people
in a low empathy condition will be more inclined to help when escape
is difficult, and less inclined when escape is easy. Batson summarizes
these predictions in Tables 4 and 5 (Batson 1991: 111).</p>

<div class="figure avoid-break center">

<table class="cellpad-med-dense cell-center centered avoid-break topbottom-rules">
<tbody><tr>
  <td rowspan="2"><strong>Escape</strong></td>
  <td colspan="2"><strong>Empathy</strong> </td> </tr>
<tr>
  <td><strong>Low</strong></td>
  <td><strong>High</strong></td> </tr>
<tr class="rule-above">
  <td>Easy</td>
  <td>Low </td>
  <td>Low</td> </tr>
<tr>
  <td>Difficult </td>
  <td>High</td>
  <td>High/Very High </td> </tr>
</tbody></table>

<p>
<span class="figlabel">Table 4:</span> Predictions from the
Aversive-Arousal Reduction Hypothesis for the Rate of Helping in an
Escape X Empathy Design</p>
</div>

<div class="figure avoid-break center">

<table class="cellpad-med-dense cell-center centered avoid-break topbottom-rules">
<tbody><tr>
  <td rowspan="2"><strong>Escape</strong></td>
  <td colspan="2"><strong>Empathy</strong> </td> </tr>
<tr>
  <td><strong>Low</strong></td>
  <td><strong>High</strong></td> </tr>
<tr class="rule-above">
  <td>Easy</td>
  <td>Low </td>
  <td>High</td> </tr>
<tr>
  <td>Difficult </td>
  <td>High</td>
  <td>High</td> </tr>
</tbody></table>

<p>
<span class="figlabel">Table 5:</span> Predictions from the
Empathy-Altruism Hypothesis for the Rate of Helping in an Escape X
Empathy Design</p>
</div>

<p>
To test these predictions, Batson and his associates conducted a total
of six experiments. In one of these (experiment 1 in Batson et al.
1981), student subjects were required to watch, via what they believed
to be closed circuit TV transmission—actually a scripted video
recording—as another student subject, Elaine—actually a
confederate—attempted to perform a task while receiving electric
shocks at random intervals. Observer subjects were told that their
task would be to form and report an impression of how Elaine performs
under aversive conditions. On the tape, Elaine is clearly finding the
shocks very uncomfortable, and after her second trial at doing the
task, she explains to Martha, the assistant administering the shocks,
that she is unusually sensitive to mild electric shocks because of a
childhood trauma. Martha then suggests that perhaps the observer
subject might be willing to help Elaine by taking her place, and the
experimenter asks whether the subject is willing to do that. To
manipulate ease of escape, some subjects were told that if they decide
not to take Elaine’s place, they will be required to watch eight
additional trials, while other subjects were told that if they decide
not to take Elaine’s place they are free to go. To manipulate
the level of empathy that subjects feel for Elaine, subjects were
given a copy of a personal values and interests questionnaire,
allegedly filled out by Elaine, in order to help them form an
impression of her performance. In the high empathy condition,
Elaine’s values and interests were very similar to the
subject’s (which had been determined in a screening session
several weeks before), while in the low empathy condition, they were
very different. The results, given in Table 6, clearly exhibit the
pattern predicted by the empathy-altruism hypothesis, not the pattern
predicted by the aversive-arousal reduction hypothesis.</p>

<div class="figure avoid-break center">

<table class="cellpad-med-dense cell-center centered avoid-break topbottom-rules">
<tbody><tr>
  <td rowspan="2"><strong>Escape</strong></td>
  <td colspan="2"><strong>Empathy</strong> </td> </tr>
<tr>
  <td><strong>Low</strong></td>
  <td><strong>High</strong></td> </tr>
<tr class="rule-above">
  <td>Easy</td>
  <td>0.18 </td>
  <td>0.91</td> </tr>
<tr>
  <td>Difficult </td>
  <td>0.64</td>
  <td>0.82</td> </tr>
</tbody></table>

<p>
<span class="figlabel">Table 6:</span> Proportion of Subjects Agreeing
to Take Shocks for Elaine (Batson et al. 1981, Experiment 1)</p>
</div>

<p>
In additional experiments, Batson and his associates used four
different techniques to create the low- and high-empathy conditions,
two techniques for manipulating ease of escape, and two different need
situations (Batson et al. 1981; Toi &amp; Batson 1982; Batson et al.
1983). The results in all of these experiments exhibited the same
pattern. Intriguingly, in another experiment, Batson and colleagues
attempted to break the pattern by telling the subjects that the shock
level they would have to endure was the highest of four options,
“clearly painful but not harmful”. They reasoned that,
under these circumstances, even if high empathy subjects had an
ultimate desire to help, this desire might well be overridden by the
desire to avoid a series of very painful shocks. As expected, the
pattern of results in this experiment fit the pattern in Table 4.</p>

<p>
These are impressive findings. Over and over again, in well designed
and carefully conducted experiments, Batson and his associates have
produced results which are clearly compatible with the predictions of
the empathy-altruism hypothesis, as set out in Table 5, and clearly
incompatible with the predictions of the aversive-arousal reduction
hypothesis, as set out in Table 4. Even the “clearly painful
shock” experiment, which produced results in the pattern of
Table 4, are comfortably compatible with the empathy-altruism
hypothesis. As we noted earlier, the empathy-altruism hypothesis
allows that high empathy subjects may have desires that are stronger
than their ultimate desire to help the target, and the desire to avoid
a painful electric shock is a very plausible candidate.</p>

<p>
There is, however, a problem to be overcome before we conclude that
the aversive-arousal reduction hypothesis cannot explain the findings
that Batson and his associates have reported. In arguing that Table 4
reflects the predictions made by the aversive-arousal reduction
hypothesis, Batson must assume that escape will alleviate the aversive
affect in both low &amp; high empathy situations, and that subjects
<em>believe</em> this (although the belief may not be readily
available to introspection). We’ll call this the <em>out of
sight, out of mind</em>
 assumption.<sup>[<a href="notes.html#note-23" id="ref-23">23</a>]</sup>
 Elaborating on an idea suggested by Hoffman (1991) and Hornstein
(1991), an advocate of egoism might propose that although subjects do
believe this when they have little empathy for the target, <em>they do
not believe it when they have high empathy for the target</em>.
Perhaps high empathy subjects believe that if they escape they will
continue to be troubled by the thought or memory of the distressed
target and thus that physical escape will not lead to psychological
escape. Indeed, in cases where empathy is strong and is evoked by
attachment, this is just what common sense would lead us to expect. Do
you really believe that if your mother was in grave distress and you
left without helping her you would not continue to be troubled by the
knowledge that she was still in distress? We’re guessing that
you don’t. But if the high-empathy subjects in Batson’s
experiments believe that they will continue to be plagued by
distressing thoughts about the target even after they depart, then the
egoistic aversive-arousal reduction hypothesis predicts that these
subjects will be inclined to help in both the easy physical escape and
the difficult physical escape conditions, since helping is the only
strategy they believe will be effective for reducing the aversive
arousal. So neither the results reported in Table 6 nor the results of
any of Batson’s other experiments would give us a reason to
prefer the empathy-altruism hypothesis over the aversive-arousal
reduction hypothesis, because both hypotheses make the same
prediction.</p>

<p>
Is it the case that high empathy subjects in experiments like
Batson’s believe that unless they help they will continue to
think about the target and thus continue to feel distress, and that
this belief leads to helping because it generates an egoistic
instrumental desire to help? This is, of course, an empirical
question, and a cleverly designed experiment by Stocks and his
associates (Stocks et al. 2009) suggests that, in situations like
those used in Batson’s experiments, a belief that they will
continue to think about the target does <em>not</em> play a
significant role in causing the helping behavior in high empathy
subjects.</p>

<p>
We believe that Batson’s work on the aversive-arousal reduction
hypothesis, buttressed by the Stocks et al. finding, is a major
advance in the egoism vs. altruism debate. The aversive-arousal
reduction hypothesis has been one of the most popular egoistic
strategies for explaining helping behavior. But the experimental
findings strongly suggest that in situations like those that Batson
and his associates have studied, the empathy-altruism hypothesis
offers a much better explanation of the subjects’ behavior than
the aversive-arousal reduction hypothesis.</p>

<h3 id="BeyoEgoiVsAltr">5.6 Beyond Egoism vs. Altruism</h3>

<p>
Thus far we have been following Batson (1991), and much of the
philosophical tradition, in viewing the debate as having only two
sides. If all human behavior is ultimately motivated by
self-interested desires, then the egoist wins; if some human behavior
is motivated by ultimate desires for the well-being of other people,
then the altruist wins. But recent work has made it clear that these
are not the only two options. A third option, which Batson et al.
(2011) label “principlism”, is that some human behavior is
motivated by an ultimate desire to adhere to a set of moral
principles. So, for example, it seems possible that people might have
an ultimate desire to do their moral duty as spelled out in a set of
principles, or an ultimate desire to obey God’s commandments
that are revealed in holy
 scripture.<sup>[<a href="notes.html#note-24" id="ref-24">24</a>]</sup>
 Action that is motivated in this way might well involve helping
behavior, if the principles or the scripture require it under certain
circumstances. However, that helping behavior would not be altruistic,
since it is not motivated by an ultimate desire for the well-being of
others, and it would not be egoistic, since it is not ultimately
motivated by self-interested desires. If there are actions that are
motivated in this way, then egoism is false. And if some helping
behavior is egoistically motivated and the rest is motivated by an
ultimate desire to adhere to a set of moral principles, then altruism
is false as well. So once we recognize principlism as a possibility,
it is clear that egoism and altruism might both be false. </p>

<p>
Another option is that some helping behavior might not be motivated by
ultimate desires at all. Gęsiarz and Crockett (2015) argue that,
in addition to the goal-directed system, behavior, including helping
behavior, is sometimes produced by what they call the
<em>habitual</em> and <em>Pavlovian</em> systems. The habitual system
leads to actions that have the highest expected value based on
previous life experiences rather than possible consequences. As a
result, helping behavior may be repeated in the future and in
circumstances in which motivating factors like the promise of rewards
are absent if the behavior has been rewarded in the past. Like the
habitual system, the Pavlovian system produces behavior with the
highest expected value based on the past. Unlike the habitual system,
however, the Pavlovian system produces behaviour that has been
successful in the <em>evolutionary</em> past, rather than in an
individual’s past. This means that behavioral dispositions that
have led to reproductive success in a individual’s evolutionary
past may have become innate or “hard-wired” through
natural selection. If it is indeed the case that some helping behavior
is produced by the habitual or Pavolvian systems, then egoism is
false. And if some helping behavior is egoistically motivated and the
rest is produced by the habitual and Pavlovian systems, then altruism
is also false. </p>

<p>
In some summaries of his work, Batson maintains that his research
program has resolved the age-old debate between egoists and altruists
and established that humans can and do sometimes behave
altruistically:</p>

<blockquote>

<p>
In study after study, with no clear exceptions, we find results
conforming to the pattern predicted by the empathy-altruism
hypothesis, the hypothesis that empathic emotion evokes altruistic
motivation. At present, there is no egoistic explanation for the
results of these studies…. Pending new evidence or a plausible
new egoistic explanation for the existing evidence, the
empathy-altruism hypothesis, however improbable, seems to be true.
(Batson 1991: 174)</p>
</blockquote>

<p>
We cannot endorse this assessment. In our view, Batson and his
collaborators have accomplished a great deal. They have formulated a
sophisticated altruist hypothesis that can be tested against competing
egoist hypotheses, and they have designed experiments which strongly
suggest that many of those egoist hypothesis are false. But, as we
have just argued, to show that altruism is true, it is not enough to
show that egoism is false. It must also be shown that episodes of
helping behavior that can’t be explained egoistically
can’t be explained by another process, such as principalistic
ultimate motivation. In addition, the defender of altruism must show
that non-egoistic episodes of helping behavior are not the product of
the habitual or Pavlovian systems. None of Batson’s experiments
were designed to rule out these non-egoistic options or others that
might be suggested. </p>

<p>
On a more positive note, we believe that Batson and associates have
shown quite conclusively that the methods of experimental psychology
can move the debate forward. Indeed, in our view, Batson and his
associates have made more progress in this area during the last three
decades than philosophers using the traditional philosophical
methodology of <em>a priori</em> arguments buttressed by anecdote and intuition
have made in the previous two millennia. Their work powerfully
demonstrates the utility of empirical methods in moral psychology.</p>

<h2 id="MoraDisa">6. Moral Disagreement</h2>

<p>
Given that moral disagreement—about abortion, say, or capital
punishment—so often seems intractable, is there any reason to
think that moral problems admit objective resolutions? While this
difficulty is of ancient coinage, contemporary philosophical
discussion was spurred by Mackie’s (1977: 36–8)
“argument from relativity” or, as it is called by later
writers, the “argument from disagreement” (Brink 1989:
197; Loeb 1998). Such “radical” differences in moral
judgment as are frequently observed, Mackie (1977: 36) argued,
“make it difficult to treat those judgments as apprehensions of
objective truths”.</p>

<p>
Mackie supposed that his argument undermines <em>moral realism</em>,
the view that, as Smith (1994: 9, cf. 13) puts it, </p>

<blockquote>

<p>
moral questions have correct answers, that the correct answers are
made correct by objective moral facts … and … by
engaging in moral argument, we can discover what these objective moral
facts
 are.<sup>[<a href="notes.html#note-25" id="ref-25">25</a>]</sup>
 </p>
</blockquote>

<p>
This notion of objectivity, as Smith recognizes, requires
<em>convergence</em> in moral views—the right sort of argument,
reflection and discussion is expected to result in very substantial
moral agreement (Smith 1994:
 6).<sup>[<a href="notes.html#note-26" id="ref-26">26</a>]</sup></p>
 
<p>
While moral realists have often taken pretty optimistic positions on
the extent of actual moral agreement (e.g., Sturgeon 1988: 229; Smith
1994: 188), there is no denying that there is an abundance of
persistent moral disagreement; on many moral issues there is a
striking <em>failure of convergence</em> even after protracted
argument. Anti-realists like Mackie have a ready explanation for this
phenomenon: Moral judgment is not objective in Smith’s sense,
and moral argument cannot be expected to accomplish what Smith and
other realists think it
 can.<sup>[<a href="notes.html#note-27" id="ref-27">27</a>]</sup>
 Conversely, the realist’s task is to <em>explain away</em>
failures of convergence; she must provide an explanation of the
phenomena consistent with it being the case that moral judgment is
objective and moral argument is rationally resolvable. Doris and
Plakias (2008) call these “defusing explanations”. The
realist’s strategy is to insist that the preponderance of actual
moral disagreement is due to limitations of disputants or their
circumstances, and insist that (very substantial, if not
 unanimous)<sup>[<a href="notes.html#note-28" id="ref-28">28</a>]</sup>
 moral agreement <em>would</em> emerge in <em>ideal</em> conditions,
when, for example, disputants are fully rational and fully informed of
the relevant non-moral facts.</p>

<p>
It is immediately evident that the relative merits of these competing
explanations cannot be fairly determined without close discussion of
the factors implicated in actual moral disagreements. Indeed, as acute
commentators with both realist (Sturgeon 1988: 230) and anti-realist
(Loeb 1998: 284) sympathies have noted, the argument from disagreement
cannot be evaluated by <em>a priori</em> philosophical means alone;
what’s needed, as Loeb observes, is “a great deal of
further empirical research into the circumstances and beliefs of
various cultures”. This research is required not only to
accurately assess the extent of actual disagreement, but also to
determine <em>why</em> disagreement persists or dissolves. Only then
can realists’ attempts to “explain away” moral
disagreement be fairly assessed.</p>

<p>
Richard Brandt, who was a pioneer in the effort to integrate ethical
theory and the social sciences, looked primarily to anthropology to
help determine whether moral attitudes can be expected to converge
under idealized circumstances. It is of course well known that
anthropology includes a substantial body of work, such as the classic
studies of Westermarck (1906) and Sumner (1908 [1934]), detailing the
radically divergent moral outlooks found in cultures around the world.
But as Brandt (1959: 283–4) recognized, typical ethnographies do
not support confident inferences about the convergence of attitudes
under ideal conditions, in large measure because they often give
limited guidance regarding how much of the moral disagreement can be
traced to disagreement about factual matters that are not moral in
nature, such as those having to do with religious or cosmological
views.</p>

<p>
With this sort of difficulty in mind, Brandt (1954) undertook his own
anthropological study of Hopi people in the American southwest, and
found issues for which there appeared to be serious moral disagreement
between typical Hopi and white American attitudes that could not
plausibly be attributed to differences in belief about nonmoral
 facts.<sup>[<a href="notes.html#note-29" id="ref-29">29</a>]</sup>
 A notable example is the Hopi attitude toward animal suffering, an
attitude that might be expected to disturb many non-Hopis:</p>

<blockquote>

<p>
[Hopi children] sometimes catch birds and make “pets” of
them. They may be tied to a string, to be taken out and
“played” with. This play is rough, and birds seldom
survive long. [According to one informant:] “Sometimes they get
tired and die. Nobody objects to this”. (Brandt 1954: 213)</p>
</blockquote>

<p>
Brandt (1959: 103) made a concerted effort to determine whether this
difference in moral outlook could be traced to disagreement about
nonmoral facts, but he could find no plausible explanation of this
kind; his Hopi informants didn’t believe that animals lack the
capacity to feel pain, for example, nor did they have cosmological
beliefs that would explain away the apparent cruelty of the practice,
such as beliefs to the effect that animals are rewarded for martyrdom
in the afterlife. The best explanation of the divergent moral
judgments, Brandt (1954: 245, 284) concluded, is a “basic
difference of attitude”, since “groups do sometimes make
divergent appraisals when they have identical beliefs about the
objects”.</p>

<p>
Moody-Adams argues that little of philosophical import can be
concluded from Brandt’s—and indeed from
much—ethnographic work. Deploying Gestalt psychology’s
doctrine of “situational meaning” (e.g., Dunker 1939),
Moody-Adams (1997: 34–43) contends that all institutions,
utterances, and behaviors have meanings that are peculiar to their
cultural milieu, so that we cannot be certain that participants in
cross-cultural disagreements are talking about the same
 thing.<sup>[<a href="notes.html#note-30" id="ref-30">30</a>]</sup>
 The problem of situational meaning, she thinks, threatens
“insuperable” methodological difficulty for those
asserting the existence of intractable intercultural disagreement
(1997: 36). Advocates of ethnographic projects will likely
respond—not unreasonably, we think—that judicious
observation and interview, such as that to which Brandt aspired,
<em>can</em> motivate confident assessments of evaluative diversity.
Suppose, however, that Moody-Adams is right, and the methodological
difficulties are insurmountable. Now, there’s an equitable
distribution of the difficulty: if observation and interview are
really as problematic as Moody-Adams suggests, <em>neither</em> the
realists’ <em>nor</em> the anti-realists’ take on
disagreement can be supported by appeal to empirical evidence. We do
not think that such a stalemate obtains, because we think the
implicated methodological pessimism excessive. Serious empirical work
can, we think, tell us a lot about cultures and the differences
between them. The appropriate way of proceeding is with close
attention to particular studies, and what they show and fail to
 show.<sup>[<a href="notes.html#note-31" id="ref-31">31</a>]</sup></p>
 

<p>
As Brandt (1959: 101–2) acknowledged, the anthropological
literature of his day did not always provide as much information on
the exact contours and origins of moral attitudes and beliefs as
philosophers wondering about the prospects for convergence might like.
However, social psychology and cognitive science have recently
produced research which promises to further discussion; during the
last 35 years, there has been an explosion of “cultural
psychology” investigating the cognitive and emotional processes
of different cultures (Shweder &amp; Bourne 1982; Markus &amp;
Kitayama 1991; Ellsworth 1994; Nisbett &amp; Cohen 1996; Nisbett 1998,
2003; Kitayama &amp; Markus 1999; Heine 2008; Kitayama &amp; Cohen
2010; Henrich 2015). Here we will focus on some cultural differences
found close to (our) home, differences discovered by Nisbett and his
colleagues while investigating regional patterns of violence in the
American North and South. We argue that these findings support
Brandt’s pessimistic conclusions regarding the likelihood of
convergence in moral judgment.</p>

<p>
The Nisbett group’s research can be seen as applying the tools
of cognitive social psychology to the “culture of honor”,
a phenomenon that anthropologists have documented in a variety of
groups around the world. Although these groups differ in many
respects, they manifest important commonalities:</p>

<blockquote>

<p>
A key aspect of the culture of honor is the importance placed on the
insult and the necessity to respond to it. An insult implies that the
target is weak enough to be bullied. Since a reputation for strength
is of the essence in the culture of honor, the individual who insults
someone must be forced to retract; if the instigator refuses, he must
be punished—with violence or even death. (Nisbett &amp; Cohen
1996: 5)</p>
</blockquote>

<p>
According to Nisbett and Cohen (1996: 5–9), an important factor
in the genesis of southern honor culture was the presence of a herding
economy. Honor cultures are particularly likely to develop where
resources are liable to theft, and where the state’s coercive
apparatus cannot be relied upon to prevent or punish thievery. These
conditions often occur in relatively remote areas where herding is a
main form of subsistence; the “portability” of herd
animals makes them prone to theft. In areas where farming rather than
herding dominates, cooperation among neighbors is more important,
stronger government infrastructures are more common, and
resources—like decidedly unportable farmland—are harder to
steal. In such agrarian social economies, cultures of honor tend not
to develop. The American South was originally settled primarily by
peoples from remote areas of Britain. Since their homelands were
generally unsuitable for farming, these peoples have historically been
herders; when they emigrated from Britain to the American South, they
initially sought out remote regions suitable for herding, and in such
regions, the culture of honor flourished.</p>

<p>
In the contemporary South, police and other government services are
widely available and herding has all but disappeared as a way of life,
but certain sorts of violence continue to be more common than they are
in the North. Nisbett and Cohen (1996) maintain that patterns of
violence in the South, as well as attitudes toward violence, insults,
and affronts to honor, are best explained by the hypothesis that a
culture of honor persists among contemporary white non-Hispanic
southerners. In support of this hypothesis, they offer a compelling
array of evidence, including:</p>

<ul>

<li>demographic data indicating that (1) among southern whites,
homicides rates are higher in regions more suited to herding than
agriculture, and (2) white males in the South are much more likely
than white males in other regions to be involved in homicides
resulting from arguments, although they are <em>not</em> more likely
to be involved in homicides that occur in the course of a robbery or
other felony (Nisbett &amp; Cohen 1996: Ch. 2)</li>

<li>survey data indicating that white southerners are more likely than
northerners to believe that violence would be “extremely
justified” in response to a variety of affronts, and that if a
man failed to respond violently to such affronts, he was “not
much of a man” (Nisbett &amp; Cohen 1996: Ch. 3)</li>

<li>legal scholarship indicating that southern states “give
citizens more freedom to use violence in defending themselves, their
homes, and their property” than do northern states (Nisbett
&amp; Cohen 1996: Ch. 5, p. 63)</li>
</ul>

<p>
Two experimental studies—one in the field, the other in the
laboratory—are especially striking.</p>

<p>
In the field study (Nisbett &amp; Cohen 1996: 73–5), letters of
inquiry were sent to hundreds of employers around the United States.
The letters purported to be from a hardworking 27-year-old Michigan
man who had a single blemish on his otherwise solid record. In one
version, the “applicant” revealed that he had been
convicted for manslaughter. The applicant explained that he had been
in a fight with a man who confronted him in a bar and told onlookers
that “he and my fiancée were sleeping together. He
laughed at me to my face and asked me to step outside if I was man
enough”. According to the letter, the applicant’s nemesis
was killed in the ensuing fray. In the other version of the letter,
the applicant revealed that he had been convicted of motor vehicle
theft, perpetrated at a time when he needed money for his family.
Nisbett and his colleagues assessed 112 letters of response, and found
that southern employers were significantly more likely to be
cooperative and sympathetic in response to the manslaughter letter
than were northern employers, while no regional differences were found
in responses to the theft letter. One southern employer responded to
the manslaughter letter as follows:</p>

<blockquote>

<p>
As for your problems of the past, anyone could probably be in the
situation you were in. It was just an unfortunate incident that
shouldn’t be held against you. Your honesty shows that you are
sincere…. I wish you the best of luck for your future. You have
a positive attitude and a willingness to work. These are qualities
that businesses look for in employees. Once you are settled, if you
are near here, please stop in and see us. (Nisbett &amp; Cohen 1996:
75)</p>
</blockquote>

<p>
No letters from northern employers were comparably sympathetic.</p>

<p>
In the laboratory study (Nisbett &amp; Cohen 1996: 45–8)
subjects—white males from both northern and southern states
attending the University of Michigan—were told that saliva
samples would be collected to measure blood sugar as they performed
various tasks. After an initial sample was collected, the unsuspecting
subject walked down a narrow corridor where an experimental
confederate was pretending to work on some filing. The confederate
bumped the subject and, feigning annoyance, called him an
“asshole”. A few minutes after the incident, saliva
samples were collected and analyzed to determine the level of
cortisol—a hormone associated with high levels of stress,
anxiety and arousal, and testosterone—a hormone associated with
aggression and dominance behavior. As Figure 1 indicates, southern
subjects showed dramatic increases in cortisol and testosterone
levels, while northerners exhibited much smaller changes.</p>

<div class="figure avoid-break center">
<img src="moral-psych-emp-plain.svg" style="max-width:100%" alt="[two graphs: for both a solid line indicates ’culture of honor subjects’ and a dotted line ’non-culture of honor subjects’. The graph on the left has a y-axis measuring per cent change in cortisol level from 0 to 85 and a x-axis with ’control’ and ’insult’; a solid line goes from 40% for control to 85% for insult and a dotted line from 40% for control to 35% for insult. The right graph has the same x-axis but the y-axis is labeled ’% change in testosterone level’ and goes from 0 to 15; the solid line goes from about 4% for control to about 14% for insult and the dotted line from about 4% to 5%.]" />

<p class="center">
<span class="figlabel">Figure 1</span></p>
</div>

<p>
The two studies just described suggest that southerners respond more
strongly to insult than northerners, and take a more sympathetic view
of others who do so, manifesting just the sort of attitudes that are
supposed to typify honor cultures. We think that the data assembled by
Nisbett and his colleagues make a persuasive case that a culture of
honor persists in the American South. Apparently, this culture affects
people’s judgments, attitudes, emotion, behavior, and even their
physiological responses. Additionally, there is evidence that child
rearing practices play a significant role in passing the culture of
honor on from one generation to the next, and also that relatively
permissive laws regarding gun ownership, self-defense, and corporal
punishment in the schools both reflect and reinforce southern honor
culture (Nisbett &amp; Cohen 1996: 60–63, 67–9). In short,
it seems to us that the culture of honor is deeply entrenched in
contemporary southern culture, despite the fact that many of the
material and economic conditions giving rise to it no longer widely
 obtain.<sup>[<a href="notes.html#note-32" id="ref-32">32</a>]</sup></p>
 

<p>
We believe that the North/South cultural differences adduced by
Nisbett and colleagues support Brandt’s conclusion that moral
attitudes will often fail to converge, even under ideal conditions.
The data should be especially troubling for the realist, for despite
the differences that we have been recounting, contemporary northern
and southern Americans might be expected to have rather more in
common—from circumstance to language to belief to
ideology—than do, say, Yanomamö and Parisians. So if there
is little ground for expecting convergence in the case at hand, there
is probably little ground in a good many others.</p>

<p>
Fraser and Hauser (2010) are not convinced by our interpretation of
Nisbett and Cohen’s data. They maintain that while those data do
indicate that northerners and southerners differ in the strength of
their disapproval of insult-provoked violence, they do not show that
northerners and southerners have a real moral disagreement. They go on
to argue that the work of Abarbanell and Hauser (2010) provides a much
more persuasive example of a systematic moral disagreement between
people in different cultural groups. Abarbanell and Hauser focused on
the moral judgments of rural Mayan people in the Mexican state of
Chiapas. They found that people in that community do not judge
<em>actions</em> causing harms to be worse than <em>omissions</em>
(failures to act) which cause identical harms, while nearby urban
Mayan people and Western internet users judge actions to be
substantially worse than omissions. </p>

<p>
Though we are not convinced by Fraser and Hauser’s
interpretation of the Nisbett and Cohen data, we agree that the
Abarbanell and Hauser study provides a compelling example of a
systematic cultural difference in moral judgement. Barrett et al.
(2016) provides another example. That study looked at the extent to
which an agent’s intention affected the moral judgments of
people in eight traditional small-scale societies and two Western
societies, one urban, one rural. They found that in some of these
societies, notably including both Western groups, the agent’s
intention had a major effect, while in other societies agent intention
had little or no effect. </p>

<p>
As we said at the outset, realists defending conjectures about
convergence may attempt to <em>explain away</em> evaluative diversity
by arguing that the diversity is to be attributed to shortcomings of
discussants or their circumstances. If this strategy can be made good,
moral realism may survive an empirically informed argument from
disagreement: so much the worse for the instance of moral reflection
and discussion in question, not so much the worse for the objectivity
of morality. While we cannot here canvass all the varieties of this
suggestion, we will briefly remark on some of the more common forms.
For concreteness, we will focus on Nisbett and Cohen’s
study.</p>

<p>
<em>Impartiality</em>. One strategy favored by moral realists
concerned to explain away moral disagreement is to say that such
disagreement stems from the distorting effects of individual interest
(see Sturgeon 1988: 229–230; Enoch 2009: 24–29); perhaps
persistent disagreement doesn’t so much betray deep features of
moral argument and judgment as it does the doggedness with which
individuals pursue their perceived advantage. For instance, seemingly
moral disputes over the distribution of wealth may be due to
perceptions—perhaps mostly inchoate—of individual and
class interests rather than to principled disagreement about justice;
persisting moral disagreement in such circumstances fails the
impartiality condition, and is therefore untroubling to the moral
realist. But it is rather implausible to suggest that North/South
disagreements as to when violence is justified will fail the
impartiality condition. There is no reason to think that southerners
would be unwilling to universalize their judgments across relevantly
similar individuals in relevantly similar circumstances, as indeed
Nisbett and Cohen’s “letter study” suggests. One can
advocate a violent honor code without going in for special
 pleading.<sup>[<a href="notes.html#note-33" id="ref-33">33</a>]</sup>
 We do not intend to denigrate southern values; our point is that
while there may be good reasons for criticizing the honor-bound
southerner, it is not obvious that the reason can be failure of
impartiality, if impartiality is (roughly) to be understood along the
lines of a willingness to universalize one’s moral
judgments.</p>

<p>
<em>Full and vivid awareness of relevant nonmoral facts</em>. Moral
realists have argued that moral disagreements very often derive from
disagreement about nonmoral issues. According to Boyd (1988: 213; cf.
Brink 1989: 202–3; Sturgeon 1988: 229), </p>

<blockquote>

<p>
careful philosophical examination will reveal … that agreement
on nonmoral issues would eliminate <em>almost all</em> disagreement
about the sorts of moral issues which arise in ordinary moral
practice. </p>
</blockquote>

<p>
Is this a plausible conjecture for the data we have just considered?
We find it hard to imagine what agreement on nonmoral facts could do
the trick, for we can readily imagine that northerners and southerners
might be in full agreement on the relevant nonmoral facts in the cases
described. Members of both groups would presumably agree that the job
applicant was cuckolded, for example, or that calling someone an
“asshole” is an insult. We think it much more plausible to
suppose that the disagreement resides in differing and deeply
entrenched evaluative attitudes regarding appropriate responses to
cuckolding, challenge, and insult.</p>

<p>
Savvy philosophical readers will be quick to observe that terms like
“challenge” and “insult” look like
“thick” ethical terms, where the evaluative and
descriptive are commingled (see Williams 1985: 128–30);
therefore, it is very difficult to say what the extent of the factual
disagreement is. But this is of little help for the expedient under
consideration, since the disagreement-in-nonmoral-fact response
apparently <em>requires</em> that one <em>can</em> disentangle factual
and moral disagreement.</p>

<p>
It is of course possible that full and vivid awareness of the nonmoral
facts might motivate the sort of change in southern attitudes
envisaged by the (at least the northern) moral realist. Were
southerners to become vividly aware that their culture of honor was
implicated in violence, they might be moved to change their moral
outlook. (We take this way of putting the example to be the most
natural one, but nothing philosophical turns on it. If you like,
substitute the possibility of northerners endorsing honor values after
exposure to the facts.) On the other hand, southerners might insist
that the values of honor should be nurtured even at the cost of
promoting violence; the motto “death before dishonor”,
after all, has a long and honorable history. The burden of argument,
we think, lies with the realist who asserts—<em>culture and
history notwithstanding</em>—that southerners would change their
mind if vividly aware of the pertinent facts.</p>

<p>
<em>Freedom from “Abnormality</em>”. Realists may contend
that much moral disagreement may result from failures of rationality
on the part of discussants (Brink 1989: 199–200). Obviously,
disagreement stemming from cognitive impairments is no embarrassment
for moral realism; at the limit, that a disagreement persists when
some or all disputing parties are quite insane shows nothing deep
about morality. But it doesn’t seem plausible that
southerners’ more lenient attitudes towards certain forms of
violence are readily attributed to widespread cognitive disability. Of
course, this is an empirical issue, but we don’t know of any
evidence suggesting that southerners suffer some cognitive impairment
that prevents them from understanding demographic and attitudinal
factors in the genesis of violence, or any other matter of fact. What
is needed to press home a charge of irrationality is evidence of
cognitive impairment <em>independent</em> of the attitudinal
differences, and further evidence that this impairment is implicated
in adherence to the disputed values. In this instance, as in many
others, we have difficulty seeing how charges of abnormality or
irrationality can be made without one side begging the question
against the other.</p>

<p>
We are inclined to think that Nisbett and colleagues’ work
represents a potent counterexample to any theory maintaining that
rational argument tends to convergence on important moral issues; the
evidence suggests that the North/South differences in attitudes
towards violence and honor might well persist even under the sort of
ideal conditions we have considered. Admittedly, our conclusions must
be tentative. On the philosophical side, we have not considered every
plausible strategy for “explaining away” moral
disagreement and grounding expectations of
 convergence.<sup>[<a href="notes.html#note-34" id="ref-34">34</a>]</sup>
 On the empirical side, we have reported on but a few studies, and
those we do consider here, like any empirical work, might be
criticized on either conceptual or methodological
 grounds.<sup>[<a href="notes.html#note-35" id="ref-35">35</a>]</sup>
 Finally, we should make clear what we are <em>not</em> claiming: we
do not take our conclusions here—even if fairly earned—to
be a “refutation” of all versions of moral realism, since
there are versions of moral realism that do not require convergence
(Bloomfield 2001; Shafer-Landau 2003). Rather, we hope to have given
an idea of the empirical work philosophers must encounter, if they are
to make defensible conjectures regarding moral disagreement.</p>

<h2 id="Conc">7. Conclusion</h2>

<p>
Progress in ethical theorizing often requires progress on difficult
psychological questions about how human beings can be expected to
function in moral contexts. It is no surprise, then, that moral
psychology is a central area of inquiry in philosophical ethics. It
should also come as no surprise that empirical research, such as that
conducted in psychology departments, may substantially abet such
inquiry. Nor then, should it surprise that research in moral
psychology has become <em>methodologically pluralistic</em>,
exploiting the resources of, and endeavoring to contribute to, various
disciplines. Here, we have illustrated how such interdisciplinary
inquiry may proceed with regard to central problems in philosophical
ethics.</p>

</div>

<div id="bibliography">

<h2 id="Bib">Bibliography</h2>



<ul class="hanging">

<li>Abarbanell, Linda and Marc D. Hauser, 2010, “Mayan Morality:
An Exploration of Permissible Harms”, <em>Cognition</em>,
115(2): 207–224. doi:10.1016/j.cognition.2009.12.007</li>

<li>Adams, Robert Merrihew, 2006, <em>A Theory of Virtue: Excellence
in Being for the Good</em>, Oxford: Oxford University Press.
doi:10.1093/acprof:oso/9780199207510.001.0001</li>

<li>Alfano, Mark, 2013, <em>Character as Moral Fiction</em>,
Cambridge: Cambridge University Press.
doi:10.1017/CBO9781139208536</li>

<li>–––, 2016, <em>Moral Psychology: An
Introduction</em>, Cambridge: Polity Press.</li>

<li>Andow, James and Florian Cova, 2016, “Why Compatibilist
Intuitions Are Not Mistaken: A Reply to Feltz and Millan”,
<em>Philosophical Psychology</em>, 29(4): 550–566.
doi:10.1080/09515089.2015.1082542</li>

<li>Annas, Julia, 2005, “Comments on John Doris’ <em>Lack
of Character</em>”, <em>Philosophy and Phenomenological
Research</em>, 71(3): 636–642.
doi:10.1111/j.1933-1592.2005.tb00476.x</li>

<li>–––, 2011, <em>Intelligent Virtue</em>, Oxford:
Oxford University Press.
doi:10.1093/acprof:oso/9780199228782.001.0001</li>

<li>Anscombe, G.E.M., 1958, “Modern Moral Philosophy”,
<em>Philosophy</em>, 33(124): 1–19.
doi:10.1017/S0031819100037943</li>

<li>Appiah, Kwame Anthony, 2008, <em>Experiments in Ethics</em>,
Cambridge, MA: Harvard University Press.</li>

<li>Aquinas, Thomas, 1270 [1917], <em>The Summa Theologica</em>, Vol
2, Part II, New York: Benziger Brothers.</li>

<li>Aristotle, <em>Nichomachean Ethics</em>, in <em>The Complete Works
of Aristotle</em>, edited by J. Barnes, Princeton: Princeton
University Press, 1984.</li>

<li>Arpaly, Nomy, 2005, “Comments on <em>Lack of Character</em>
by John Doris”, <em>Philosophy and Phenomenological
Research</em>, 71(3): 643–647.
doi:10.1111/j.1933-1592.2005.tb00477.x</li>

<li>Athanassoulis, Nafsika, 1999, “A Response to Harman: Virtue
Ethics and Character Traits”, <em>Proceedings of the
Aristotelian Society</em>, 100(1): 215–222.
doi:10.1111/j.0066-7372.2003.00012.x</li>

<li>Badhwar, Neera K., 2009, “The Milgram Experiments, Learned
Helplessness, and Character Traits”, <em>The Journal of
Ethics</em>, 13(2–3): 257–289.
doi:10.1007/s10892-009-9052-4</li>

<li>Baron, Jonathan, 1994, “Nonconsequentialist
Decisions”, <em>Behavioral and Brain Sciences</em>, 17(1):
1–42. doi:10.1017/S0140525X0003301X</li>

<li>–––, 2001, <em>Thinking and Deciding</em>,
3<sup>rd</sup> edition, Cambridge: Cambridge University Press.</li>

<li>Barrett, H.C., A. Bolyanatz, A. Crittenden, D.M.T. Fessler, S.
Fitzpatrick, M. Gurven, J. Henrich, M. Kanovsky, G. Kushnick, A.
Pisor, B. Scelza, S. Stich, C. von Rueden, W. Zhao and S. Laurence,
2016, “Small-Scale Societies Exhibit Fundamental Variation in
the Role of Intentions in Moral Judgment”, <em>Proceedings of
the National Academy of Sciences</em>, 113(17): 4688–4693.
doi:10.1073/pnas.1522070113</li>

<li>Batson, C. Daniel, 1991, <em>The Altruism Question: Toward a
Social-Psychological Answer</em>, Hillsdale, NJ: Lawrence Erlbaum
Associates.</li>

<li>–––, 1998, “Altruism and Prosocial
Behavior”, in Daniel T. Gilbert, Susan T. Fiske, and Gardner
Lindzey (eds.), <em>The Handbook of Social Psychology</em>, volume 2,
fourth edition, Boston: McGraw-Hill, pp. 282–316.</li>

<li>–––, 2011, <em>Altruism in Humans</em>, Oxford:
Oxford University Press.
doi:10.1093/acprof:oso/9780195341065.001.0001</li>

<li>–––, 2012, “A History of Prosocial
Behavior Research”, in Arie W. Kruglanski and Wolfgang Stroebe,
(eds.), <em>Handbook of the History of Social Psychology</em>, New
York: Psychology Press, pp. 243–264.
doi:10.4324/9780203808498.ch12</li>

<li>–––, 2015, “Testing the Empathy-Altruism
Hypothesis Against Egoistic Alternatives”, in Lorraine L.
Besser-Jones and Michael Slote (eds.), <em>The Routledge Companion to
Virtue Ethics</em>, New York: Routledge, pp. 385–400.</li>

<li>Batson, C. Daniel, Bruce D. Duncan, Paula Ackerman, Terese
Buckley, and Kimberly Birch, 1981, “Is Empathic Emotion a Source
of Altruistic Motivation?” <em>Journal of Personality and Social
Psychology</em>, 40(2): 290–302.
doi:10.1037/0022-3514.40.2.290</li>

<li>Batson, C.D., K. O’Quin, J. Fultz, M. Vanderplas and A.M.
Isen, 1983, “Influence of Self-reported Distress and Empathy and
Egoistic Versus Altruistic Motivation to Help”, <em>Journal of
Personality and Social Psychology</em>, 45(3): 706–718.
doi:10.1037/0022-3514.45.3.706</li>

<li>Batson, C. Daniel, Nadia Ahmad and E.L. Stocks, 2011, “Four
Forms of Prosocial Motivation: Egoism, Altruism, Collectivism, and
Principlism”, In David Dunning (ed.), <em>Social
Motivation</em>, New York: Psychology Press, pp. 103–126.</li>

<li>Bear, Adam and Joshua Knobe, 2016, “What Do People Find
Incompatible With Causal Determinism?” <em>Cognitive
Science</em>, 40(8): 2025–2049. doi:10.1111/cogs.12314</li>

<li>Beatty, John, 1992, “Fitness: Theoretical Contexts”,
in Evelyn Fox Keller and Elisabeth A. Lloyd (eds.), <em>Keywords in
Evolutionary Biology</em>, Cambridge, MA: Harvard University
Press.</li>

<li>Besser-Jones, Lorraine, 2008, “Social Psychology, Moral
Character, and Moral Fallibility”, <em>Philosophy and
Phenomenological Research</em>, 76(2): 310–332.
doi:10.1111/j.1933-1592.2007.00134.x</li>

<li>Björnsson, Gunnar, 2014, “Incompatibilism and
‘Bypassed’ Agency”, in Alfred R. Mele (ed.),
<em>Surrounding Free Will</em>, Oxford: Oxford University Press, pp.
95–112. doi:10.1093/acprof:oso/9780199333950.003.0006</li>

<li>Björnsson, Gunnar and Derk Pereboom, 2016, “Traditional
and Experimental Approaches to Free Will and Moral
Responsibility”, in Sytsma and Buckwalter 2016: 142–157.
doi:10.1002/9781118661666.ch9</li>

<li>Bloomfield, Paul, 2000, “Virtue Epistemology and the
Epistemology of Virtue”, <em>Philosophy and Phenomenological
Research</em>, 60(1): 23–43. doi:10.2307/2653426 </li>

<li>–––, 2001, <em>Moral Reality</em>, New York:
Oxford University Press. doi:10.1093/0195137132.001.0001</li>

<li>–––, 2014, “Some Intellectual Aspects of
the Cardinal Virtues”, in <em>Oxford Studies in Normative
Ethics</em>, volume 3, Mark Timmons (ed.), pp. 287–313.
doi:10.1093/acprof:oso/9780199685905.003.0013</li>

<li>Boorse, Christopher, 1975, “On the Distinction between
Disease and Illness”, <em>Philosophy and Public Affairs</em>,
5(1): 49–68.</li>

<li>Boyd, Richard, 1988, “How to Be a Moral Realist”, in
Sayre-McCord 1988b: 181–228.</li>

<li>Brandt, Richard B., 1954, <em>Hopi Ethics: A Theoretical
Analysis</em>, Chicago: The University of Chicago Press.</li>

<li>–––, 1959, <em>Ethical Theory: The Problems of
Normative and Critical Ethics</em>, Englewood Cliff, NJ:
Prentice-Hall.</li>

<li>Bratman, Michael E., 1996, “Identification, Decision, and
Treating as a Reason”, <em>Philosophical Topics</em>, 24(2):
1–18. doi:10.5840/philtopics19962429</li>

<li>Brink, David Owen, 1989, <em>Moral Realism and the Foundations of
Ethics</em>, Cambridge: Cambridge University Press.
doi:10.1017/CBO9780511624612</li>

<li>Broad, C.D., 1930, <em>Five Types of Ethical Theory</em>, New
York: Harcourt, Brace.</li>

<li>Cameron, C. Daryl, B. Keith Payne, and John M. Doris, 2013,
“Morality in High Definition: Emotion Differentiation Calibrates
the Influence of Incidental Disgust on Moral Judgments”,
<em>Journal of Experimental Social Psychology</em>, 49(4):
719–725. doi:10.1016/j.jesp.2013.02.014</li>

<li>Campbell, C.A., 1951, “Is ‘Freewill’ a
Pseudo-problem?” <em>Mind</em>, 60(240): 441–465.
doi:10.1093/mind/LX.240.441</li>

<li>Cappelen, Herman, 2012, <em>Philosophy Without Intuitions</em>,
Oxford: Oxford University Press.
doi:10.1093/acprof:oso/9780199644865.001.0001</li>

<li>Cervone, Daniel and Yuichi Shoda (eds.), 1999, <em>The Coherence
of Personality: Social-Cognitive Bases of Consistency, Variability,
and Organization</em>, New York and London: Guilford Press.</li>

<li>Chiesi, Harry L., George J. Spilich, and James F. Voss, 1979,
“Acquisition of domain-related information in relation to high
and low domain knowledge”, <em>Journal of verbal learning and
verbal behavior</em>, 18(3): 257–273.
doi:10.1016/S0022-5371(79)90146-4</li>

<li>Cialdini, Robert B., Stephanie L. Brown, Brian P. Lewis, Carol
Luce and Stephen L. Neuberg, 1997, “Reinterpreting the
Empathy-Altruism Relationship: When One into One Equals
Oneness”, <em>Journal of Personality and Social Psychology</em>,
73(3), 481– 494. doi:10.1037/0022-3514.73.3.481</li>

<li>Cova, Florian and Yasuko Kitano, 2013, “Experimental
Philosophy and the Compatibility of Free Will and Determinism: A
Survey”, <em>Annals of the Japan Association for Philosophy of
Science</em>, 22: 17–37. doi:10.4288/jafpos.22.0_17</li>

<li>Cova, Florian, Maxime Bertoux, Sacha Bourgeois-Gironde, and Bruno
Dubois, 2012, “Judgments about Moral Responsibility and
Determinism in Patients with Behavioural Variant of Frontotemporal
Dementia: Still Compatibilists”, <em>Consciousness and
Cognition</em>, 21(2): 851–864.
doi:10.1016/j.concog.2012.02.004</li>

<li>Cuneo, Terence, 2014, <em>Speech and Morality: On the Metaethical
Implications of Speaking</em>, Oxford: Oxford University Press.
doi:10.1093/acprof:oso/9780198712725.001.0001</li>

<li>Darley, John M. and C. Daniel Batson, 1973, “‘From
Jerusalem to Jericho’: A Study of Situational and Dispositional
Variables In Helping Behavior”, <em>Journal of Personality and
Social Psychology</em>, 27(1): 100–108.
doi:10.1037/h0034449</li>

<li>Decety, Jean and Thalia Wheatley (eds.), 2015, <em>The Moral
Brain: A Multidisciplinary Perspective</em>, Cambridge, MA: MIT
Press.</li>

<li>Deery, Oisin and Eddy Nahmias, 2017, “Defeating Manipulation
Arguments: Interventionist Causation and Compatibilist
Sourcehood”, <em>Philosophical Studies</em>, 174(5):
1255–1276. doi:10.1007/s11098-016-0754-8.</li>

<li>Dennett, Daniel C., 1984, <em>Elbow Room: The Varieties of Free
Will Worth Wanting</em>, Cambridge, MA: MIT Press.</li>

<li>DePaul, Michael, 1999, “Character Traits, Virtues, and
Vices: Are There None?” in <em>Proceedings of the 20th World
Congress of Philosophy, v. 1</em>, Bowling Green, OH: Philosophy
Documentation Center, pp. 141–157.</li>

<li>Deutsch, Max, 2015, <em>The Myth of the Intuitive: Experimental
Philosophy and Philosophical Method</em>, Cambridge, MA: MIT Press.
doi:10.7551/mitpress/9780262028950.001.0001</li>

<li>Dixon, Thomas, 2008, <em>The Invention of Altruism: Making Moral
Meanings in Victorian Britain</em>, Oxford: Oxford University Press.
doi:10.5871/bacad/9780197264263.001.0001</li>

<li>Donnellan, M. Brent, Richard E. Lucas, and William Fleeson (eds.),
2009, “Personality and Assessment at Age 40: Reflections on the
Past Person-Situation Debate and Emerging Directions of Future
Person-Situation Integration and Assessment at Age 40”,
<em>Journal of Research in Personality</em>, special issue, 43(2):
117–290.</li>

<li>Doris, John M., 1998, “Persons, Situations, and Virtue
Ethics”, <em>Noûs</em>, 32(4): 504–530.
doi:10.1111/0029-4624.00136</li>

<li>–––, 2002, <em>Lack of Character: Personality
and Moral Behavior</em>, New York: Cambridge University Press.
doi:10.1017/CBO9781139878364</li>

<li>–––, 2005, “Précis” and
“Replies: Evidence and Sensibility”, <em>Philosophy and
Phenomenological Research</em>, 71(3): 632–5, 656–77.
doi:10.1111/j.1933-1592.2005.tb00479.x</li>

<li>–––, 2006, “Out of Character: On the
Psychology of Excuses in the Criminal Law”, in H. LaFollette
(ed.), <em>Ethics in Practice</em>, third edition, Oxford: Blackwell
Publishing.</li>

<li>–––, 2010, “Heated Agreement: <em>Lack of
Character</em> as <em>Being for the Good</em>”,
<em>Philosophical Studies</em>, 148(1): 135–46.
doi:10.1007/s11098-010-9507-2</li>

<li>–––, 2015, <em>Talking to Our Selves:
Reflection, Ignorance, and Agency</em>, Oxford: Oxford University
Press. doi:10.1093/acprof:oso/9780199570393.001.0001</li>

<li>–––, forthcoming, <em>Character Trouble:
Undisciplined Essays on Personality and Agency</em>, Oxford: Oxford
University Press.</li>

<li>–––, in preparation, “Making Good: In
Search of Moral Expertise”.</li>

<li>Doris, John M. and Alexandra Plakias, 2008, “How to Argue
about Disagreement: Evaluative Diversity and Moral Realism”, in
Sinnott-Armstrong 2008b: 303–353.</li>

<li>Doris, John M. and Jesse J. Prinz, 2009, “Review of K.
Anthony Appiah, <em>Experiments in Ethics</em>”, <em>Notre Dame
Philosophical Reviews</em>, 2009-10-03. URL =
 &lt;<a href="http://ndpr.nd.edu/news/experiments-in-ethics/" target="other">http://ndpr.nd.edu/news/experiments-in-ethics/</a>&gt;</li>
 
<li>Doris, John M. and The Moral Psychology Research Group (eds.).,
2010, <em>The Moral Psychology Handbook</em>, Oxford: Oxford
University Press. doi:10.1093/acprof:oso/9780199582143.001.0001</li>

<li>Doris, John M. and Stephen P. Stich, 2005, “As a Matter of
Fact: Empirical Perspectives on Ethics”, in Frank Jackson and
Michael Smith (eds.), <em>The Oxford Handbook of Contemporary
Philosophy</em>, Oxford: Oxford University Press.</li>

<li>Dovidio, John F., Judith Allen, and David A. Schroeder, 1990,
“Specificity of Empathy-induced Helping: Evidence for Altruistic
Motivation”, <em>Journal of Personality and Social
Psychology</em>, 59(2): 249–60.
doi:10.1037/0022-3514.59.2.249</li>

<li>Dunker, Karl, 1939, “Ethical Relativity? (An Enquiry into
the Psychology of Ethics)”, <em>Mind</em>, 48(189): 39–53.
doi:10.1093/mind/XLVIII.189.39</li>

<li>Eisenberg, Nancy and Paul A. Miller, 1987, “The relation of
empathy to prosocial and related behaviors”, <em>Psychological
Bulletin</em>, 101(1) 91–119.
doi:10.1037/0033-2909.101.1.91</li>

<li>Ellsworth, Phoebe C., 1994, “Sense, Culture, and
Sensibility”, in Shinobu Kitayama and Hazel Rose Markus (eds.),
<em>Emotion and Culture: Empirical Studies of Mutual Influence</em>,
Washington: American Psychological Association.</li>

<li>Enoch, David, 2009, “How is Moral Disagreement a Problem for
Realism?” <em>The Journal of Ethics</em>, 13(1): 15–50.
doi:10.1007/s10892-008-9041-z. </li>

<li>–––, 2011, <em>Taking Morality Seriously: A
Defense of Robust Realism</em>, Oxford: Oxford University Press.
doi:10.1093/acprof:oso/9780199579969.001.0001</li>

<li>Ericsson, K. Anders, 2014, “Why Expert Performance Is
Special and Cannot Be Extrapolated From Studies of Performance in the
General Population: A Response to Criticisms”,
<em>Intelligence</em>, 45: 81–103.
doi:10.1016/j.intell.2013.12.001</li>

<li>Ericsson, K. Anders, Ralf Th. Krampe, and Clemens
Tesch-Römer, 1993, “The Role of Deliberate Practice in the
Acquisition of Expert Performance”, <em>Psychological
Review</em>, 100(3): 363–406.
doi:10.1037/0033-295X.100.3.363</li>

<li>Feltz, Adam and Florian Cova, 2014, “Moral Responsibility
and Free Will: A Meta-Analysis”, <em>Consciousness and
Cognition</em>, 30: 234–246.
doi:10.1016/j.concog.2014.08.012</li>

<li>Feltz, Adam and Melissa Millan, 2013, “An Error Theory for
Compatibilist Intuitions”, <em>Philosophical Psychology</em>,
28(4): 529–555. doi:10.1080/09515089.2013.865513</li>

<li>Figdor, Carrie and Mark Phelan, 2015, “Is Free Will
Necessary for Moral Responsibility? A Case for Rethinking Their
Relationship and the Design of Experimental Studies in Moral
Psychology”, <em>Mind and Language</em>, 30(5): 603–627.
doi:10.1111/mila.12092</li>

<li>Fischer, John Martin, 1994, <em>The Metaphysics of Free Will</em>,
Oxford: Blackwell.</li>

<li>Flanagan, Owen, 1991, <em>Varieties of Moral Personality: Ethics
and Psychological Realism</em>, Cambridge, MA: Harvard University
Press.</li>

<li>–––, 2009, “Moral Science? Still
Metaphysical After All These Years”, in Darcia Narvaez and
Daniel K. Lapsley (eds.), <em>Personality, Identity, and
Character</em>, Cambridge: Cambridge University Press, pp.
52–78.</li>

<li>Frankfurt, Harry, 1988, <em>The Importance of What We Care
About</em>, Cambridge: Cambridge University Press.</li>

<li>Fraser, Ben and Marc Hauser, 2010, “The Argument from
Disagreement and the Role of Cross-Cultural Empirical Data”,
<em>Mind and Language</em>, 25(5): 541–560.
doi:10.1111/j.1468-0017.2010.01400.x</li>

<li>Fulford, K.W.M., 1989, <em>Moral Theory and Medical Practice</em>,
Cambridge: Cambridge University Press.</li>

<li>Fultz, Jim, C. Daniel Batson, Victoria A. Fortenbach, Patricia M.
McCarthy, and Laurel L. Varney, 1986, “Social Evaluation and the
Empathy-Altruism Hypothesis”, <em>Journal of Personality and
Social Psychology</em>, 50(4): 761–769.
doi:10.1037/0022-3514.50.4.761</li>

<li>Gęsiarz, Filip and Molly J. Crockett, 2015,
“Goal-directed, Habitual and Pavlovian Prosocial
Behavior”, <em>Frontiers in Behavioral Neuroscience</em>, 9:
135. doi:10.3389/fnbeh.2015.00135</li>

<li>Ghiselin, Michael, 1974, <em>The Economy of Nature and the
Evolution of Sex</em>, Berkeley: University of California Press.</li>

<li>Gigerenzer, Gerd, 2000, <em>Adaptive Thinking: Rationality in the
Real World</em>, New York: Oxford University Press.
doi:10.1093/acprof:oso/9780195153729.001.0001</li>

<li>Gigerenzer, Gerd, Peter M. Todd, and the ABC Research Group.,
1999, <em>Simple Heuristics that Make Us Smart</em>, New York: Oxford
University Press.</li>

<li>Gilovich, Thomas, Dale W. Griffin, and Daniel Kahneman (eds.),
2002, <em>Heuristics and Biases: The Psychology of Intuitive
Judgment</em>, New York: Cambridge University Press.</li>

<li>Glickman, Mark E., 1995, “A Comprehensive Guide to Chess
Ratings”, <em>American Chess Journal</em>, 3: 59–102.</li>

<li>Goldman, Alvin I., 1970, <em>A Theory of Human Action</em>,
Englewood-Cliffs, NJ: Prentice-Hall.</li>

<li>Grant, Colin, 1997, “Altruism: A Social Science
Chameleon”, <em>Zygon</em>, 32(3): 321–40.
doi:10.1111/0591-2385.00094/</li>

<li>Haidt, Jonathan, Silvia Helena Koller, and Maria G. Dias, 1993,
“Affect, Culture, and Morality, Or Is It Wrong to Eat Your
Dog?” <em>Journal of Personality and Social Psychology</em>,
65(4): 613–28. doi:10.1037/0022-3514.65.4.613</li>

<li>Haji, Ishtiyaque, 2002, “Compatiblist Views of Freedom and
Responsibility”, in Robert Kane (ed.), <em>The Oxford Handbook
of Free Will</em>, New York: Oxford University Press.</li>

<li>Hambrick, David Z., Frederick L. Oswald, Erik M. Altmann,
Elizabeth J. Meinz, Fernand Gobet, and Guillermo Campitelli, 2014,
“Deliberate Practice: Is That All It Takes to Become an
Expert?” <em>Intelligence</em>, 45: 34–45.
doi:10.1016/j.intell.2013.04.001</li>

<li>Harman, Gilbert, 1999, “Moral Philosophy Meets Social
Psychology: Virtue Ethics and the Fundamental Attribution
Error”, <em>Proceedings of the Aristotelian Society</em>, 99:
315–331.</li>

<li>–––, 2000, “The Nonexistence of Character
Traits”, <em>Proceedings of the Aristotelian Society</em>, 100:
223–226. doi:10.1111/j.0066-7372.2003.00013.x</li>

<li>–––, 2009, “Skepticism about Character
Traits”, <em>The Journal of Ethics</em>, 13(2–3):
235–242. doi:10.1007/s10892-009-9050-6</li>

<li>Heine, Steven J., 2008, <em>Cultural Psychology</em>, New York:
W.W. Norton.</li>

<li>Helzer, Erik G. and David A. Pizarro, 2011, “Dirty Liberals!
Reminders of Physical Cleanliness Influence Moral and Political
Attitudes”, <em>Psychological Science</em>, 22(4):
517–522. doi:10.1177/0956797611402514</li>

<li>Henrich, Joseph, 2015, <em>The Secret of Our Success: How Culture
Is Driving Human Evolution, Domesticating Our Species, and Making Us
Smarter</em>, Princeton, NJ: Princeton University Press.</li>

<li>Hobbes, Thomas, 1651 [1981], <em>Leviathan: Edited with an
Introduction by C.B. Macpherson</em>, London: Penguin Books.</li>

<li>Hoffman, Martin L., 1991, “Is Empathy Altruistic?”
<em>Psychological Inquiry</em>, 2(2): 131–133.
doi:10.1207/s15327965pli0202_6</li>

<li>Hornstein, Harvey A., 1991, “Empathic Distress and Altruism:
Still Inseparable”, <em>Psychological Inquiry</em>, 2,
133–135. doi:10.1207/s15327965pli0202_7</li>

<li>Horowitz, Tamara, 1998, “Philosophical Intuitions and
Psychological Theory”, in Michael R. DePaul and William Ramsey
(eds.), <em>Rethinking Intuition: The Psychology of Intuition and its
Role in Philosophical Inquiry</em>, Lanham, Maryland: Rowman and
Littlefield.</li>

<li>Hursthouse, Rosalind, 1999, <em>On Virtue Ethics</em>, Oxford and
New York: Oxford University Press.
doi:10.1093/0199247994.001.0001</li>

<li>Isen, Alice M. and Paula F. Levin, 1972, “Effect of Feeling
Good on Helping: Cookies and Kindness”, <em>Journal of
Personality and Social Psychology</em>, 21(3): 384–388.
doi:10.1037/h0032317</li>

<li>Jackson, Frank, 1998, <em>From Metaphysics to Ethics: A Defense of
Conceptual Analysis</em>, New York: Oxford University Press.
doi:10.1093/0198250614.001.0001</li>

<li>Jackson, Frank and Philip Pettit, 1995, “Moral Functionalism
and Moral Motivation”, <em>Philosophical Quarterly</em>,
45(178): 20–40. doi:10.2307/2219846</li>

<li>Jacobson, Daniel, 2005, “Seeing By Feeling: Virtues, Skills,
and Moral Perception”, <em>Ethical Theory and Moral
Practice</em>, 8(4): 387–409. doi:10.1007/s10677-005-8837-1</li>

<li>Kahneman, Daniel, 2011, <em>Thinking, Fast and Slow</em>, New
York: Farrar, Straus and Giroux.</li>

<li>Kahneman, Daniel, Paul Slovic, and Amos Tversky, 1982,
<em>Judgment Under Uncertainty: Heuristics and Biases</em>, Cambridge:
Cambridge University Press. doi:10.1017/CBO9780511809477</li>

<li>Kamtekar, Rachana, 2004, “Situationism and Virtue Ethics on
the Content of Our Character”, <em>Ethics</em>, 114(3):
458–91. doi:10.1086/381696</li>

<li>Kane, Robert, 1996, <em>The Significance of Free Will</em>,
Oxford: Oxford University Press. doi:10.1093/0195126564.001.0001</li>

<li>–––, 1999, “Responsibility, Luck, and
Chance: Reflections on Free Will and Indeterminism”, <em>Journal
of Philosophy</em>, 96(5): 217–240.
doi:10.5840/jphil199996537</li>

<li>–––, 2002, “Introduction: The Contours of
Contemporary Free Will Debates”, in Robert Kane (ed.), <em>The
Oxford Handbook of Free Will</em>, New York: Oxford University
Press.</li>

<li>Kant, Immanuel, 1785 [1949], <em>Fundamental Principles of the
Metaphysics of Morals</em>, Translated by Thomas K. Abbott. Englewood
Cliffs, NJ: Prentice Hall / Library of Liberal Arts.</li>

<li>Kitayama, Shinobu and Hazel Rose Markus, 1999, “Yin and Yang
of the Japanese Self: The Cultural Psychology of Personality
Coherence”, in Cervone and Shoda 1999: ch. 8.</li>

<li>Kitayama, Shinobu and Dov Cohen, 2010, <em>Handbook of Cultural
Psychology</em>, New York: Guilford Press.</li>

<li>Knobe, Joshua, 2003a, “Intentional Action and Side Effects
in Ordinary Language”, <em>Analysis</em>, 63(279):
190–193. doi:10.1111/1467-8284.00419</li>

<li>–––, 2003b, “Intentional Action in Folk
Psychology: An Experimental Investigation”, <em>Philosophical
Psychology</em>, 16(2): 309–324. doi:10.1080/09515080307771</li>

<li>–––, 2006, “The Concept of Intentional
Action: A Case Study in the Uses of Folk Psychology”,
<em>Philosophical Studies</em>, 130(2): 203–231.
doi:10.1007/s11098-004-4510-0</li>

<li>–––, 2010, “Person as Scientist, Person as
Moralist”, <em>Behavioral and Brain Sciences</em>, 33(4):
315–329. doi:10.1017/S0140525X10000907</li>

<li>–––, 2014, “Free Will and the Scientific
Vision”, in Edouard Machery and Elizabeth O’Neill (eds.),
<em>Current Controversies in Experimental Philosophy</em>, New York
and London: Routledge.</li>

<li>Knobe, Joshua and Brian Leiter, 2007, “The Case for
Nietzschean Moral Psychology”, in Brian Leiter and Neil
Sinhababu (eds.) <em>Nietzsche and Morality</em>, Oxford: Oxford
University Press. 83–109.</li>

<li>Krebs, Dennis, 1975, “Empathy and Altruism”,
<em>Journal of Personality and Social Psychology</em>, 32(6):
1134–1146. doi:10.1037/0022-3514.32.6.1134</li>

<li>Kruger, Justin and David Dunning, 1999, “Unskilled and
Unaware of It: How Difficulties in Recognizing One’s Own

Incompetence Lead to Inflated Self-Assessments”, <em>Journal of
Personality and Social Psychology</em>, 77(6): 1121–1134.
doi:10.1037/0022-3514.77.6.1121</li>

<li>Kupperman, Joel J., 2001, “The Indispensability of
Character”, <em>Philosophy</em>, 76(02): 239–50.
doi:10.1017/S0031819101000250</li>

<li>Ladd, John, 1957, <em>The Structure of a Moral Code: A
Philosophical Analysis of Ethical Discourse Applied to the Ethics of
the Navaho Indians</em>, Cambridge, MA: Harvard University Press.</li>

<li>LaFollette, Hugh, 2000a, “Introduction”, in LaFollette
2000b: 1–12.</li>

<li>––– (ed.), 2000b, <em>The Blackwell Guide to
Ethical Theory</em>, Oxford: Blackwell Publishing.</li>

<li>Leikas, Sointu, Jan-Erik Lönnqvist, and Markku Verkasalo,
2012, “Persons, Situations, and Behaviors: Consistency and
Variability of Different Behaviors in Four Interpersonal
Situations”, <em>Journal of Personality and Social
Psychology</em>, 103(6): 1007–1022. doi:10.1037/a0030385</li>

<li>Lerner, Jennifer S., Julie H. Goldberg, and Philip E. Tetlock,
1998, “Sober Second Thought: The Effects of Accountability,
Anger, and Authoritarianism on Attributions of Responsibility”,
<em>Personality and Social Psychology Bulletin</em>, 24(6):
563–574. doi:10.1177/0146167298246001</li>

<li>Lewis, David, 1989, “Dispositional Theories of Value”,
<em>Proceedings of the Aristotelian Society</em>, 63 (supp):
113–37.</li>

<li>Liao, S. Matthew, Alex Wiegmann, Joshua Alexander, and Gerard
Vong, 2012, “Putting the Trolley in Order: Experimental
Philosophy and the Loop Case”, <em>Philosophical
Psychology</em>, 25(5): 661–671.
doi:10.1080/09515089.2011.627536</li>

<li>Loeb, Don., 1998, “Moral Realism and the Argument from
Disagreement”, <em>Philosophical Studies</em>, 90(3):
281–303. doi:10.1023/A:1004267726440</li>

<li>Machery, Edouard, 2010, “The Bleak Implications of Moral
Psychology”, <em>Neuroethics</em>, 3(3): 223–231.
doi:10.1007/s12152-010-9063-7</li>

<li>Machery, Edouard and John M. Doris, forthcoming, “An Open
Letter to Our Students: Going Interdisciplinary”, in Voyer and
Tarantola forthcoming.</li>

<li>MacIntyre, Alasdair, 1967, “Egoism and Altruism”, in
Paul Edwards (ed.), <em>The Encyclopedia of Philosophy</em>, vol. 2,
first edition, New York: Macmillan, pp. 462–466.</li>

<li>Mackie, J.L., 1977, <em>Ethics: Inventing Right and Wrong</em>,
New York: Penguin Books.</li>

<li>Macnamara, Brooke N., David Z. Hambrick, and Frederick L. Oswald,
2014, “Deliberate Practice and Performance in Music, Games,
Sports, Education, and Professions: A Meta-Analysis”,
<em>Psychological Science</em>, 25(8): 1608–1618.
doi:10.1177/0956797614535810</li>

<li>Markus, Hazel R. and Shinobu Kitayama, 1991, “Culture and
the Self: Implications for Cognition, Emotion, and Motivation”,
<em>Psychological Review</em>, 98(2): 224–253.
doi:10.1037/0033-295X.98.2.224</li>

<li>May, Joshua, 2011, “Egoism, Empathy, and Self-Other
Merging”, <em>Southern Journal of Philosophy</em>, 49(s1):
25–39. doi:10.1111/j.2041-6962.2011.00055.x</li>

<li>McGrath, Sarah, 2008, “Moral Disagreement and Moral
Expertise”, in <em>Oxford Studies in Metaethics</em>, volume 3,
Russ Shafer-Landau (ed.), New York: Oxford University Press, pp.
87–108.</li>

<li>–––, 2011, “Skepticism about Moral
Expertise as a Puzzle for Moral Realism”, <em>Journal of
Philosophy</em>, 108(3): 111–137.
doi:10.5840/jphil201110837</li>

<li>Mehl, Matthias R., Kathryn L. Bollich, John M. Doris, and Simine
Vazire, 2015, “Character and Coherence: Testing the Stability of
Naturalistically Observed Daily Moral Behavior”, in Miller et
al. 2015: 630–51.
doi:10.1093/acprof:oso/9780190204600.003.0030</li>

<li>Mele, Alfred R., 2006, <em>Free Will and Luck</em>, New York:
Oxford University Press. doi:10.1093/0195305043.001.0001</li>

<li>–––, 2013, “Manipulation, Moral
Responsibility, and Bullet Biting”, <em>Journal of Ethics</em>,
17(3): 167–84. doi:10.1007/s10892-013-9147-9</li>

<li>Merritt, Maria W., 2000, “Virtue Ethics and Stuationist
Personality Psychology”, <em>Ethical Theory and Moral
Practice</em>, 3(4): 365–83. doi:10.1023/A:1009926720584</li>

<li>–––, 2009, “Aristotelean Virtue and the
Interpersonal Aspect of Ethical Character”, <em>Journal of Moral
Philosophy</em>, 6(1): 23–49. doi:10.1163/174552409X365919</li>

<li>Meritt, Maria W., John M. Doris, and Gilbert Harman, 2010,
“Character”, in Doris et al. 2010: 355–401.</li>

<li>Milgram, Stanley, 1974, <em>Obedience to Authority</em>, New York:
Harper and Row.</li>

<li>Miller, Christian B., 2003, “Social Psychology and Virtue
Ethics”, <em>The Journal of Ethics</em>, 7(4): 365–92.
doi:10.1023/A:1026136703565</li>

<li>–––, 2013, <em>Moral Character: An Empirical
Theory</em>, Oxford: Oxford University Press.
doi:10.1093/acprof:oso/9780199674350.001.0001</li>

<li>–––, 2014, <em>Character and Moral
Psychology</em>, Oxford: Oxford University Press.
doi:10.1093/acprof:oso/9780199674367.001.0001</li>

<li>Miller, Christian B., R. Michael Furr, Angela Knobel, and William
Fleeson (eds.), 2015, <em>Character: New Directions from Philosophy,
Psychology, and Theology</em>, New York: Oxford University Press.
doi:10.1093/acprof:oso/9780190204600.001.0001</li>

<li>Mischel, Walter, 1968, <em>Personality and Assessment</em>, New
York: John J. Wiley and Sons.</li>

<li>–––, 1999, “Personality Coherence and
Dispositions in a Cognitive-Affective Personality System (CAPS)
Approach”, in Cervone and Shoda 1999: ch. 2.</li>

<li>Montmarquet, James, 2003, “Moral Character and Social
Science Research”, <em>Philosophy</em>, 78(03): 355–368.
doi:10.1017/S0031819103000342</li>

<li>Moody-Adams, Michele M., 1997, <em>Fieldwork in Familiar Places:
Morality, Culture, and Philosophy</em>, Cambridge, MA: Harvard
University Press.</li>

<li>Murphy, Dominic, 2006, <em>Psychiatry in the Scientific
Image</em>, Cambridge, MA: MIT Press.</li>

<li>Murray, Dylan and Eddy Nahmias, 2014, “Explaining Away
Incompatibilist Intuitions”, <em>Philosophy and Phenomenological
Research</em>, 88(2): 434–467.
doi:10.1111/j.1933-1592.2012.00609.x</li>

<li>Murray, Dylan and Tania Lombrozo, 2016, “Effects of
Manipulation on Attributions of Causation, Free Will, and Moral
Responsibility”, <em>Cognitive Science</em>, 41(2):
447–481. doi: 10.1111/cogs.12338.</li>

<li>Nado, Jennifer, 2016, “The Intuition Deniers”,
<em>Philosophical Studies</em>, 173(3): 781–800.
doi:10.1007/s11098-015-0519-9.</li>

<li>Nagel, Thomas, 1970, <em>The Possibility of Altruism</em>, Oxford:
Oxford University Press.</li>

<li>–––, 1986, <em>The View From Nowhere</em>, New
York and Oxford: Oxford University Press.</li>

<li>Nahmias, Eddy, 2011, “Intuitions about Free Will,
Determinism, and Bypassing”, in Robert Kane (ed.), <em>The
Oxford Handbook of Free Will</em>, second edition, Oxford: Oxford
University Press.</li>

<li>Nahmias, Eddy, Stephen G. Morris, Thomas Nadelhoffer, and Jason
Turner, 2009, “Is Incompatiblism Intuitive?”
<em>Philosophy and Phenomenological Research</em>, 73(1): 28–53.
doi:10.1111/j.1933-1592.2006.tb00603.x</li>

<li>Nichols, Shaun and Joshua Knobe, 2007, “Moral Responsibility
and Determinism: The Cognitive Science of Folk Intuitions”,
<em>Noûs</em>, 41(4): 663–685.
doi:10.1111/j.1468-0068.2007.00666.x</li>

<li>Nisbett, Richard E., 1998, “Essence and Accident”, in
John M. Darley and Joel Cooper (eds.), <em>Attribution and Social
Interaction: The Legacy of Edward E. Jones</em>, Washington: American
Psychological Association.</li>

<li>–––, 2003, <em>The Geography of Thought: How
Asians and Westerners Think Differently … and Why</em>, New
York: Free Press.</li>

<li>Nisbett, Richard E. and Eugene Borgida, 1975, “Attribution
and the psychology of prediction”, <em>Journal of Personality
and Social Psychology</em>, 32(5): 932–943.
doi:10.1037/0022-3514.32.5.932</li>

<li>Nisbett, Richard E. and Dov Cohen, 1996, <em>Culture of Honor: The
Psychology of Violence in the South</em>, Boulder, CO: Westview
Press.</li>

<li>Nisbett, Richard E. and Lee Ross, 1980, <em>Human Inference:
Strategies and Shortcomings of Social Judgment</em>, Englewood Cliffs,
NJ: Prentice-Hall.</li>

<li>O’Connor, Timothy, 2000, <em>Persons and Causes: The
Metaphysics of Free Will</em>, New York: Oxford University Press.
doi:10.1093/019515374X.001.0001</li>

<li>Olin, Lauren and John M. Doris, 2014, “Vicious Minds: Virtue
Epistemology, Cognition, and Skepticism”, <em>Philosophical
Studies</em>, 168(3): 665–92. doi:10.1007/s11098-013-0153-3</li>

<li>Pereboom, Derk, 2001, <em>Living Without Free Will</em>,
Cambridge: Cambridge University Press.
doi:10.1017/CBO9780511498824</li>

<li>–––, 2014, <em>Free Will, Agency, and Meaning in
Life</em>, Oxford: Oxford University Press.
doi:10.1093/acprof:oso/9780199685516.001.0001</li>

<li>Petrinovich, Lewis and Patricia O’Neill, 1996,
“Influence of Wording and Framing Effects on Moral
Intuitions”, <em>Ethology and Sociobiology</em>, 17(3):
145–171. doi:10.1016/0162-3095(96)00041-6</li>

<li>Phillips, Jonathan and Alex Shaw, 2014, “Manipulating
Morality: Third-Party Intentions Alter Moral Judgments by Changing
Causal Reasoning”, <em>Cognitive Science</em>, 39(6):
1320–47. doi:10.1111/cogs.12194</li>

<li>Piliavin, Jane Allyn and Hong-Wen Charng, 1990, “Altruism: A
Review of Recent Theory and Research”, <em>Annual Review of
Sociology</em>, 16: 27–65.
doi:10.1146/annurev.so.16.080190.000331</li>

<li>Pink, Thomas, 2004, <em>Free Will: A Very Short Introduction</em>,
New York: Oxford University Press.
doi:10.1093/actrade/9780192853585.001.0001</li>

<li>Prinz, Jesse J., 2009, “The Normativity Challenge: Cultural
Psychology Provides the Real Threat to Virtue Ethics”, <em>The
Journal of Ethics</em>, 13(2–3): 117–144.
doi:10.1007/s10892-009-9053-3</li>

<li>Pust, Joel, 2000, <em>Intuitions as Evidence</em>, New York:
Garland Publishing. </li>

<li>Rachels, James, 2000, “Naturalism”, in LaFollette
2000b: 74–91.</li>

<li>Railton, Peter, 1986a, “Facts and Values”,
<em>Philosophical Topics</em>, 14(2): 5–31.
doi:10.5840/philtopics19861421</li>

<li>–––, 1986b, “Moral Realism”,
<em>Philosophical Review</em>, 95(2): 163–207.
doi:10.2307/2185589 </li>

<li>Rawls, John, 1951, “Outline of a Decision Procedure for
Ethics”, <em>Philosophical Review</em>, 60(2): 177–97.
doi:10.2307/2181696 </li>

<li>–––, 1971, <em>A Theory of Justice</em>,
Cambridge, MA: Harvard University Press.</li>

<li>Rosati, Connie S., 1995, “Persons, Perspectives, and Full
Information Accounts of the Good”, <em>Ethics</em>, 105(2):
296–325. doi:10.1086/293702</li>

<li>Rose, David and Shaun Nichols, 2013, “The Lesson of
Bypassing”, <em>Review of Philosophy and Psychology</em>, 4(4):
599–619. doi:10.1007/s13164-013-0154-3</li>

<li>Ross, Lee and Richard E. Nisbett, 1991, <em>The Person and the
Situation: Perspectives of Social Psychology</em>, Philadelphia:
Temple University Press.</li>

<li>Russell, Daniel C., 2009, <em>Practical Intelligence and the
Virtues</em>, Oxford: Oxford University Press.
doi:10.1093/acprof:oso/9780199565795.001.0001</li>

<li>–––, 2015, “From Personality to Character
to Virtue”, in Mark Alfano (ed.), <em>Current Controversies in
Virtue Theory</em>, New York: Routledge, pp. 91–106.</li>

<li>Samuels, Richard and Stephen Stich, 2002,
“Rationality”, <em>Encyclopedia of Cognitive Science</em>,
Chichester: Wiley. doi:10.1002/0470018860.s00171</li>

<li>Samuels, Steven M. and William D. Casebeer, 2005, “A social
psychological view of morality: Why knowledge of situational
influences on behaviour can improve character development
practices”, <em>Journal of Moral Education</em>, 34(1):
73–87. doi:10.1080/03057240500049349</li>

<li>Sarkissian, Hagop, 2010, “Minor Tweaks, Major Payoffs: The
Problems and Promise of Situationism in Moral Philosophy”,
<em>Philosophers’ Imprint</em>, 10(9). URL =
 &lt;<a href="http://hdl.handle.net/2027/spo.3521354.0010.009" target="other">http://hdl.handle.net/2027/spo.3521354.0010.009</a>&gt;</li>
 
<li>Sarkissian, Hagop and Jennifer Cole Wright (eds.)., 2014,
<em>Advances in Experimental Moral Psychology</em>, London: Bloomsbury
Press.</li>

<li>Sayre-McCord, Geoffrey, 1988a, “Introduction: The Many Moral
Realisms”, in Sayre-McCord 1988b: 1–24.</li>

<li>––– (ed.), 1988b, <em>Essays in Moral
Realism</em>, Ithaca and London: Cornell University Press.</li>

<li>–––, 2015, “Moral Realism”, <em>The
Stanford Encyclopedia of Philosophy</em> (Spring 2015 Edition), Edward
N. Zalta (ed.), URL =
 &lt;<a href="https://plato.stanford.edu/archives/spr2015/entries/moral-realism/" target="other">https://plato.stanford.edu/archives/spr2015/entries/moral-realism/</a>&gt;</li>
 
<li>Schnall, Simone, Jonathan Haidt, Gerald L. Clore, and Alexander H.
Jordan, 2008a, “Disgust as Embodied Moral Judgment”,
<em>Personality and Social Psychology Bulletin</em>, 34(8):
1069–1109. doi:10.1177/0146167208317771</li>

<li>Schnall, Simone, Jennifer Benton, and Sophie Harvey, 2008b,
“With a Clean Conscience: Cleanliness Reduces the Severity of
Moral Judgments”, <em>Psychological Science</em>, 19(12):
1219–1222. doi:10.1111/j.1467-9280.2008.02227.x</li>

<li>Schroeder, William, 2000, “Continental Ethics”, in
LaFollette 2000b: 375–399.</li>

<li>Schroeder, David A., Louis A. Penner, John F. Dovidio, and Jane A.
Piliavin, 1995, <em>The Psychology of Helping and Altruism: Problems
and Puzzles</em>, New York: McGraw-Hill.</li>

<li>Schulz, Armin W., 2011, “Sober and Wilson’s
Evolutionary Arguments for Psychological Altruism: A
Reassessment”, <em>Biology and Philosophy</em>, 26(2):
251–260. doi:10.1007/s10539-009-9179-5</li>

<li>Schwitzgebel, Eric and Fiery Cushman, 2011, “Expertise in
Moral Reasoning? Order Effects on Moral Judgment in Professional
Philosophers and Non-Philosophers”, <em>Mind and Language</em>,
27(2): 135–153. doi:10.1111/j.1468-0017.2012.01438.x.</li>

<li>–––, 2015, “Philosophers’ Biased
Judgments Persist Despite Training, Expertise, and Reflection”,
<em>Cognition</em>, 141: 127–137.
doi:10.1016/j.cognition.2015.04.015</li>

<li>Shafer-Landau, R., 2003, <em>Moral Realism: A Defence</em>,
Oxford: Clarendon Press. doi:10.1093/0199259755.001.0001</li>

<li>Sherman, Ryne A., Christopher S. Nave, and David C. Funder, 2010,
“Situational Similarity and Personality Predict Behavioral
Consistency”, <em>Journal of Personality and Social
Psychology</em>, 99(2): 330–343. doi:10.1037/a0019796</li>

<li>Shweder, Richard A., and Edmund J. Bourne, 1982, “Does the
Concept of the Person Vary Cross-Culturally?” in Anthony J.
Marsella and Geoffrey M. White (eds.), <em>Cultural Conceptions of
Mental Health and Therapy</em>, Boston, MA: D. Reidel Publishing.</li>

<li>Singer, Peter, 1974, “Sidgwick and Reflective
Equilibrium”, <em>Monist</em>, 58(3): 490–517.
doi:10.5840/monist197458330</li>

<li>Sinnott-Armstrong, Walter P., 2005, “Moral Intuitionism
Meets Empirical Psychology”, in Terry Horgan and Mark Timmons
(eds.), <em>Metaethics After Moore</em>, New York: Oxford University
Press. doi:10.1093/acprof:oso/9780199269914.003.0016</li>

<li>––– (ed.), 2008a, <em>Moral Psychology, Vol. 1,
The Evolution of Morality: Adaptations and Innateness</em>, Cambridge,
MA: MIT Press.</li>

<li>––– (ed.), 2008b, <em>Moral Psychology, Vol. 2,
The Cognitive Science of Morality: Intuition and Diversity</em>,
Cambridge, MA: MIT Press.</li>

<li>––– (ed.), 2008c, <em>Moral Psychology, Vol.3,
The Neuroscience of Morality: Emotion, Brain Disorders, and
Development</em>, Cambridge, MA: MIT Press.</li>

<li>––– (ed.), 2014, <em>Moral Psychology, Vol.4,
Free Will and Moral Responsibility</em>, Cambridge, MA: MIT Press.
</li>

<li>Slote, Michael Anthony, 1964, “An Empirical Basis for
Psychological Egoism”, <em>Journal of Philosophy</em>, 61(18):
530–537. doi:10.2307/2023495</li>

<li>Smilansky, Saul, 2003, “Compatibilism: the Argument from
Shallowness”, <em>Philosophical Studies</em>, 115(3):
257–282. doi:10.1023/A:1025146022431</li>

<li>Smith, Adam, 1759 [1853], <em>The Theory of Moral Sentiments</em>,
London: Henry G. Bohn. Originally published 1759,</li>

<li>Smith, Michael, 1994, <em>The Moral Problem</em>, Cambridge: Basil
Blackwell.</li>

<li>Snare, F.E., 1980, “The Diversity of Morals”
<em>Mind</em>, 89(355): 353–369.
doi:10.1093/mind/LXXXIX.355.353</li>

<li>Snow, Nancy E., 2010, <em>Virtue as Social Intelligence: An
Empirically Grounded Theory</em>, London and New York: Routledge.</li>

<li>Sober, Elliott and David Sloan Wilson, 1998, <em>Unto Others: The
Evolution and Psychology of Unselfish Behavior</em>, Cambridge, MA:
Harvard University Press.</li>

<li>Solomon, Robert C., 2003, “Victims of Circumstances? A
Defense of Virtue Ethics in Business”, <em>Business Ethics
Quarterly</em>, 13(1): 43–62. doi:10.5840/beq20031314</li>

<li>–––, 2005, “‘What’s Character
Got to Do with It?’”, <em>Philosophy and Phenomenological
Research</em>, 71(3): 648–655.
doi:10.1111/j.1933-1592.2005.tb00478.x</li>

<li>Sosa, Ernest, 2007, “Intuitions: Their Nature and Epistemic
Efficacy”, <em>Grazer Philosophische Studien</em>, 74(1):
51–67. doi:10.1163/9789401204651_004</li>

<li>–––, 2009, “Situations Against Virtues:
The Situationist Attack on Virtue Theory”, in Chrysostomos
Mantzavinos (ed.), <em>Philosophy of the Social Sciences:
Philosophical Theory and Scientific Practice</em>, New York: Cambridge
University Press. 274–290. doi:10.1017/CBO9780511812880.021</li>

<li>Sreenivasan, Gopal, 2002, “Errors about errors: Virtue
theory and trait attribution”, <em>Mind</em>, 111(441):
47–68. doi:10.1093/mind/111.441.47</li>

<li>Sripada, Chandra Sekhar, 2012, “What Makes a Manipulated
Agent Unfree?” <em>Philosophy and Phenomenological
Research</em>, 85(3): 563–93.
doi:10.1111/j.1933-1592.2011.00527.x</li>

<li>Stich, Stephen, 1990, <em>The Fragmentation of Reason: Preface to
a Pragmatic Theory of Cognitive Evaluation</em>, Cambridge, MA: The
MIT Press.</li>

<li>–––, 2007, “Evolution, Altruism and
Cognitive Architecture: A Critique of Sober and Wilson’s
Argument for Psychological Altruism”, <em>Biology and
Philosophy</em>, 22(2): 267–281.
doi:10.1007/s10539-006-9030-1</li>

<li>Stich, Stephen, John M. Doris, and Erica Roedder, 2010,
“Altruism”, in Doris et al. 2010: 147–205.</li>

<li>Stich, Stephen and Kevin P. Tobia, 2016, “Experimental
Philosophy and the Philosophical Tradition”, in Sytsma and
Buckwalter 2016: 3–21. doi:10.1002/9781118661666.ch1</li>

<li>–––, 2018, “Intuition and Its
Critics”, in Stuart, Fehige, and Brown 2018: ch. 21.</li>

<li>Stichter, Matt, 2007, “Ethical Expertise: The Skill Model of
Virtue”, <em>Ethical Theory and Moral Practice</em>, 10(2):
183–194. doi:10.1007/s10677-006-9054-2</li>

<li>–––, 2011, “Virtues, Skills, and Right
Action”, <em>Ethical Theory and Moral Practice</em>, 14(1):
73–86. doi:10.1007/s10677-010-9226-y</li>

<li>Stocks, Eric L., David A. Lishner and Stephanie K. Decker, 2009,
“Altruism or Psychological Escape: Why Does Empathy Promote
Prosocial Behavior?” <em>European Journal of Social
Psychology</em>, 39(5): 649–665. doi:10.1002/ejsp.561</li>

<li>Stotland, Ezra, 1969, “Exploratory Studies of
Empathy”, in Leonard Berkowitz (ed.), <em>Advances in
Experimental Social Psychology</em>, Vol. 4. New York: Academic Press,
pp. 271–314.</li>

<li>Strawson, P.F., 1982, “Freedom and Resentment”, in
Gary Watson (ed.), <em>Free Will</em>, New York: Oxford University
Press. Originally published, 1962,</li>

<li>Strawson, Galen, 1986, <em>Freedom and Belief</em>, Oxford: Oxford
University Press. doi:10.1093/acprof:oso/9780199247493.001.0001</li>

<li>Strohminger, Nina, Richard L. Lewis and David E. Meyer, 2011,
“Divergent Effects of Different Positive Emotions on Moral
Judgment”, <em>Cognition</em>, 119(2): 295–300.
doi:10.1016/j.cognition.2010.12.012</li>

<li>Stuart, Michael T., Yiftach Fehige, and James Robert Brown (eds.),
2018, <em>The Routledge Companion to Thought Experiments</em>, New
York: Routledge.</li>

<li>Sturgeon, Nicholas L., 1988, “Moral Explanations”, in
Sayre-McCord 1988b: 229–255.</li>

<li>Sumner, William Graham, 1908 [1934], <em>Folkways</em>, Boston:
Ginn and Company.</li>

<li>Sunstein, Cass R., 2005, “Moral Heuristics”,
<em>Behavioral and Brain Sciences</em>, 28(4): 531–42.
doi:10.1017/S0140525X05000099</li>

<li>Swanton, Christine, 2003, <em>Virtue Ethics: A Pluralistic
View</em>, Oxford: Oxford University Press.
doi:10.1093/0199253889.001.0001</li>

<li>Sytsma, Justin and Wesley Buckwalter (eds.), 2016, <em>A Companion
to Experimental Philosophy</em>, Oxford: Blackwell.</li>

<li>Tetlock, Philip E., 1999, “Review of <em>Culture of Honor:
The Psychology of Violence in the South</em> by Robert Nisbett and Dov
Cohen”, <em>Political Psychology</em>, 20(1): 211–13.
doi:10.1111/0162-895X.t01-1-00142</li>

<li>Tiberius, Valerie, 2015, <em>Moral Psychology: A Contemporary
Introduction</em>, New York: Routledge. </li>

<li>Tobia, Kevin Patrick, Gretchen B. Chapman, and Stephen Stich,
2013, “Cleanliness is Next to Morality, Even for
Philosophers”, <em>Journal of Consciousness Studies</em>, 20(11
and 12): 195–204.</li>

<li>Toi, Miho and C. Daniel Batson, 1982, “More Evidence that
Empathy is a Source of Altruistic Motivation”, <em>Journal of
Personality and Social Psychology</em>, 43(2): 281–292.
doi:10.1037/0022-3514.43.2.281</li>

<li>Tversky, Amos and Daniel Kahneman, 1973, “Availability: A
heuristic for judging frequency and probability”, <em>Cognitive
Psychology</em>, 5(2): 207–232.
doi:10.1016/0010-0285(73)90033-9</li>

<li>–––, 1981, “The Framing of Decisions and
the Psychology of Choice”, <em>Science</em>, 211(4481):
453–463. doi:10.1126/science.7455683 </li>

<li>Upton, Candace L., 2009, <em>Situational Traits of Character:
Dispositional Foundations and Implications for Moral Psychology and
Friendship</em>, Lanham, Maryland: Lexington Books.</li>

<li>Vargas, Manuel, 2005a, “The Revisionist’s Guide to
Responsibility”, <em>Philosophical Studies</em>, 125(3):
399–429. doi:10.1007/s11098-005-7783-z</li>

<li>–––, 2005b, “Responsibility and the Aims
of Theory: Strawson and Revisionism”, <em>Pacific Philosophical
Quarterly</em>, 85(2): 218–241.
doi:10.1111/j.0279-0750.2004.00195.x</li>

<li>Valdesolo, Piercarlo and David DeSteno, 2006, “Manipulations
of Emotional Context Shape Moral Judgment”, <em>Psychological
Science</em>, 17(6): 476–477.
doi:10.1111/j.1467-9280.2006.01731.x</li>

<li>Velleman, J. David, 1992, “What Happens When Someone
Acts?” <em>Mind</em>, 101(403): 461–81.
doi:10.1093/mind/101.403.461</li>

<li>Voyer, Benjamin G. and Tor Tarantola (eds.), forthcoming,
<em>Moral Psychology: A Multidisciplinary Guide</em>, Springer.</li>

<li>Vranas, Peter B.M., 2005, “The Indeterminacy Paradox:
Character Evaluations and Human Psychology”,
<em>Noûs</em>, 39(1): 1–42.</li>

<li>Watson, Gary, 1996, “Two Faces of Responsibility”,
<em>Philosophical Topics</em> 24(2): 227–48. doi:
10.5840/philtopics199624222</li>

<li>Webber, Jonathan, 2006a, “Character, Consistency, and
Classification”, <em>Mind</em>, 115(459): 651–658.
doi:10.1093/mind/fzl651</li>

<li>–––, 2006b, “Virtue, Character and
Situation”, <em>Journal of Moral Philosophy</em>, 3(2):
193–213. doi:10.1177/1740468106065492 </li>

<li>–––, 2007a, “Character, Common-Sense, and
Expertise”, <em>Ethical Theory and Moral Practice</em>, 10(1):
89–104. doi:10.1007/s10677-006-9041-7</li>

<li>–––, 2007b, “Character, Global and
Local”, <em>Utilitas</em>, 19(04): 430–434.
doi:10.1017/S0953820807002725</li>

<li>Westermarck, Edvard, 1906, <em>Origin and Development of the Moral
Ideas</em>, 2 volumes, New York: MacMillian.</li>

<li>Wiegmann, Alex, Yasmina Okan, and Jonas Nagel, 2012, “Order
Effects in Moral Judgment”, <em>Philosophical Psychology</em>,
25(6): 813–836. doi:10.1080/09515089.2011.631995</li>

<li>Williams, Bernard, 1973, “A Critique of
Utilitarianism”, in <em>Utilitarianism: For and Against</em>, by
J.J.C. Smart and Bernard Williams, Cambridge: Cambridge University
Press.</li>

<li>–––, 1985, <em>Ethics and the Limits of
Philosophy</em>, Cambridge, MA: Harvard University Press.</li>

<li>Woolfolk, Robert L., John M. Doris and John M. Darley, 2006,
“Identification, Situational Constraint, and Social Cognition:
Studies in the Attribution of Moral Responsibility”,
<em>Cognition</em>, 100(2), 283–301.
doi:10.1016/j.cognition.2005.05.002</li>

<li>Zhong, Chen-Bo, Brendan Strejcek, and Niro Sivanathan, 2010,
“A Clean Self Can Render Harsh Moral Judgment”,
<em>Journal of Experimental Social Psychology</em>, 46(5):
859–862. doi:10.1016/j.jesp.2010.04.003</li>

<li>Zimbardo, Philip G., 2007, <em>The Lucifer Effect: Understanding
How Good People Turn Evil</em>, Oxford: Blackwell Publishing Ltd.</li>
</ul>

</div>

<div id="academic-tools">

<h2 id="Aca">Academic Tools</h2>

<blockquote>
<table class="vert-top">
<tbody><tr>
<td><img src="../../symbols/sepman-icon.jpg" alt="sep man icon" /></td>
<td><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=moral-psych-emp&amp;archive=win2019" target="other">How to cite this entry</a>.</td>
</tr>

<tr>
<td><img src="../../symbols/sepman-icon.jpg" alt="sep man icon" /></td>
<td><a href="https://leibniz.stanford.edu/friends/preview/moral-psych-emp/" target="other">Preview the PDF version of this entry</a> at the
 <a href="https://leibniz.stanford.edu/friends/" target="other">Friends of the SEP Society</a>.</td>
</tr>

<tr>
<td><img src="../../symbols/inpho.png" alt="inpho icon" /></td>
<td><a href="https://www.inphoproject.org/entity?sep=moral-psych-emp&amp;redirect=True" target="other">Look up this entry topic</a>
 at the <a href="https://www.inphoproject.org/" target="other">Indiana Philosophy Ontology Project</a>
 (InPhO).</td>
</tr>

<tr>
<td><img src="../../symbols/pp.gif" alt="phil papers icon" /></td>
<td><a href="http://philpapers.org/sep/moral-psych-emp/" target="other">Enhanced bibliography for this entry</a>
at <a href="http://philpapers.org/" target="other">PhilPapers</a>, with links to its database.</td>
</tr>

</tbody></table>
</blockquote>

</div>





<div id="other-internet-resources">

<h2 id="Oth">Other Internet Resources</h2>



<ul>
   
<li><a href="http://www.moralpsychology.net/" target="other">Moral Psychology Research Group</a></li>

<li><a href="http://www.philosophyexperiments.com/" target="other">Philosophy Experiments</a></li>

<li><a href="http://eclectic.ss.uci.edu/~drwhite/sccs/" target="other">Standard Cross-Cultural Sample Free Distribution Site</a>,
 University of California, Irvine.</li>

<li><a href="https://bayesian.org/" target="other">International Society for Bayesian Analysis</a></li>

<li><a href="http://www.yourmorals.org/blog/" target="other">Your Morals Blog</a></li>

</ul>

</div>

<div id="related-entries">

<h2 id="Rel">Related Entries</h2>

<p>

 <a href="../egoism/">egoism</a> |
 <a href="../ethics-virtue/">ethics: virtue</a> |
 <a href="../experimental-moral/">experimental moral philosophy</a> |
 <a href="../moral-realism/">moral realism</a> |
 <a href="../practical-reason/">practical reason</a> |
 <a href="../reasoning-moral/">reasoning: moral</a>

</p>

</div>




</div><!-- #aueditable --><!--DO NOT MODIFY THIS LINE AND BELOW-->

<!-- END ARTICLE HTML -->

</div> <!-- End article-content -->

  <div id="article-copyright">
    <p>
 <a href="../../info.html#c">Copyright © 2017</a> by

<br />
<a href="http://artsci.wustl.edu/~pnp/people/index.php?person_id=32" target="other">John Doris</a>
&lt;<a href="mailto:jdoris%40wustl%2eedu"><em>jdoris<abbr title=" at ">@</abbr>wustl<abbr title=" dot ">.</abbr>edu</em></a>&gt;<br />
<a href="https://philosophy.rutgers.edu/people/faculty/details/182-faculty1/faculty-profiles/635-stich-stephen" target="other">Stephen Stich</a>
&lt;<a href="mailto:stich%2esteve%40gmail%2ecom"><em>stich<abbr title=" dot ">.</abbr>steve<abbr title=" at ">@</abbr>gmail<abbr title=" dot ">.</abbr>com</em></a>&gt;<br />
<a href="https://pbs.dartmouth.edu/people/jonathan-s-phillips" target="other">Jonathan Phillips</a>
&lt;<a href="mailto:jonathan%2es%2ephillips%40dartmouth%2eedu"><em>jonathan<abbr title=" dot ">.</abbr>s<abbr title=" dot ">.</abbr>phillips<abbr title=" at ">@</abbr>dartmouth<abbr title=" dot ">.</abbr>edu</em></a>&gt;<br />
Lachlan Walmsley
&lt;<a href="mailto:lachlan%2ewalmsley%40anu%2eedu%2eau"><em>lachlan<abbr title=" dot ">.</abbr>walmsley<abbr title=" at ">@</abbr>anu<abbr title=" dot ">.</abbr>edu<abbr title=" dot ">.</abbr>au</em></a>&gt;
    </p>
  </div>

</div> <!-- End article -->

<!-- NOTE: article banner is outside of the id="article" div. -->
<div id="article-banner" class="scroll-block">
     <div id="article-banner-content">
  <a href="../../fundraising/">
  Open access to the SEP is made possible by a world-wide funding initiative.<br />
  Please Read How You Can Help Keep the Encyclopedia Free</a>
 </div>


</div> <!-- End article-banner -->

    </div> <!-- End content -->

    <div id="footer">

      <div id="footer-menu">
        <div class="menu-block">
          <h4><i class="icon-book"></i> Browse</h4>
          <ul role="menu">
            <li><a href="../../contents.html">Table of Contents</a></li>
            <li><a href="../../new.html">New in this Archive</a></li>
            
            <li><a href="../../published.html">Chronological</a></li>
            <li><a href="../../../../archives/">Archives <i class="icon-external-link"></i></a></li>
          </ul>
        </div>
        <div class="menu-block">
          <h4><i class="icon-info-sign"></i> About</h4>
          <ul role="menu">
            <li><a href="../../info.html">Editorial Information</a></li>
            <li><a href="../../about.html">About the SEP</a></li>
            <li><a href="../../board.html">Editorial Board</a></li>
            <li><a href="../../cite.html">How to Cite the SEP</a></li>
            <li><a href="../../special-characters.html">Special Characters</a></li>
            
            <li><a href="../../../../contact.html">Contact <i class="icon-external-link"></i></a></li>
          </ul>
        </div>
        <div class="menu-block">
          <h4><i class="icon-leaf"></i> Support SEP</h4>
          <ul role="menu">
            <li><a href="../../../../support/">Support the SEP</a></li>
            <li><a href="../../../../support/friends.html">PDFs for SEP Friends</a></li>
            <li><a href="../../../../support/donate.html">Make a Donation</a></li>
            <li><a href="../../../../support/sepia.html">SEPIA for Libraries</a></li>
          </ul>
        </div>
      </div> <!-- End footer menu -->

      <div id="mirrors">
        <div id="mirror-info">
          <h4><i class="icon-globe"></i> Mirror Sites</h4>
          <p>View this site from another server:</p>
        </div>
                <div class="btn-group">
<a class="btn dropdown-toggle" data-toggle="dropdown" href="https://plato.stanford.edu/"><span class="flag flag-usa"></span> USA (Main Site) <span class="caret"></span><span class="mirror-source">CSLI, Stanford University</span></a>          <ul class="dropdown-menu">
            <li><a href="https://stanford.library.sydney.edu.au/archives/win2019/entries/moral-psych-emp/"><span class="flag flag-australia"></span> Australia <span class="mirror-source">Library, University of Sydney</span></a>           </li>
            <li><a href="https://seop.illc.uva.nl/archives/win2019/entries/moral-psych-emp/"><span class="flag flag-netherlands"></span> Netherlands <span class="mirror-source">ILLC, University of Amsterdam</span></a>           </li>
          </ul>
        </div>
      </div> <!-- End mirrors -->
      
      <div id="site-credits">
        <p class="csli-logo"><a href="https://www-csli.stanford.edu/"><img src="../../symbols/SU_csli.png" width="355" alt="Stanford Center for the Study of Language and Information" /></a></p>
        <p>The Stanford Encyclopedia of Philosophy is <a href="../../info.html#c">copyright © 2016</a> by <a href="http://mally.stanford.edu/">The Metaphysics Research Lab</a>, Center for the Study of Language and Information (CSLI), Stanford University</p>
        <p>Library of Congress Catalog Data: ISSN 1095-5054</p>
      </div> <!-- End site credits -->

    </div> <!-- End footer -->

  </div> <!-- End container -->

   <!-- NOTE: Script required for drop-down button to work (mirrors). -->
  <script>
    $('.dropdown-toggle').dropdown();
  </script>





</body></html>