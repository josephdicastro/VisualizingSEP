{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo \n",
    "import json \n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = 'mongodb://localhost:27017'\n",
    "client = pymongo.MongoClient(conn)\n",
    "db = client.visualizing_sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sep_network_json(sep_collection):\n",
    "    \"\"\" exports the JSON that makes up the network graph \"\"\"\n",
    "\n",
    "    # update this for each archive update \n",
    "\n",
    "    sepData = {\n",
    "        'Edition': 'Winter 2020',\n",
    "        'EditionURL': 'https://plato.stanford.edu/archives/win2020'\n",
    "    }\n",
    "    \n",
    "    #init empty lists \n",
    "    nodes_list = []\n",
    "    links_list = []\n",
    "\n",
    "    #extract unique list of domain tags for primary domain menu\n",
    "    #we have to do this separately, because there aren't any articles where 'jewish philosophy' is the primary domain, but we have to make sure that jewish pihlosophy shows up in the menu. \n",
    "\n",
    "    domain_tags = list(db.sep_entries.find( filter={},\n",
    "                                        projection={'domain_tags':1, '_id':0}))\n",
    "    domain_tags_individual = []\n",
    "\n",
    "    for tag in domain_tags:\n",
    "        semisplit_tags = tag['domain_tags'].split(';')\n",
    "        for semisplit_tag in semisplit_tags:\n",
    "            commasplit_tags = semisplit_tag.split(',')\n",
    "            for commasplit_tag in commasplit_tags:\n",
    "                if commasplit_tag != '':\n",
    "                    domain_tags_individual.append(commasplit_tag.strip())\n",
    "\n",
    "    primary_domains = sorted(set(domain_tags_individual))\n",
    "\n",
    "    #loop through all entries\n",
    "    for entry in tqdm(sep_collection, desc='Processing'):\n",
    "        inpho_json = entry['inpho_json']\n",
    "        entry_type = inpho_json['type']\n",
    "        word_count = len(entry['preamble_text'].split()) + len(entry['main_text'].split())\n",
    "        preamble_text = entry['preamble_text']\n",
    "        article_url = sepData['EditionURL'] + entry['page_url']\n",
    "        toc_text = entry['toc'].replace('<a ', '<a target=\"_blank\" ').replace('href=\"','href=\"' + article_url)\n",
    "\n",
    "        node_object = { 'id': entry['page_url'], \n",
    "                        'article_url': article_url,\n",
    "                        'title': entry['title'],\n",
    "                        'author': entry['author'],\n",
    "                        'toc':toc_text,\n",
    "                        'pubdate':entry['pubdate'],\n",
    "                        'entry_type': entry_type,\n",
    "                        'preamble_text': preamble_text,\n",
    "                        'word_count': f\"{word_count:,}\",\n",
    "                        'primary_domain': entry['primary_domain'],\n",
    "                        'domain_tags': entry['domain_tags'].replace(', ',',').strip()\n",
    "                    }\n",
    "\n",
    "        nodes_list.append(node_object)\n",
    "\n",
    "        for link in entry['outlinks']:\n",
    "            out_link = {'source':entry['page_url'], 'target':link['link'], 'targetTitle':entry['title']}\n",
    "            if out_link not in links_list:\n",
    "                links_list.append(out_link)\n",
    "\n",
    "    articles_object = {'nodes': nodes_list, 'links':links_list}\n",
    "    network_object = {'sepData': sepData, 'articles' : articles_object, 'domains':primary_domains}\n",
    "    with open('../../static/sep_network.json', 'w', encoding='UTF-8') as f:\n",
    "        json.dump(network_object,f,ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Processing: 100%|██████████| 1705/1705 [00:05<00:00, 293.95it/s]\n"
     ]
    }
   ],
   "source": [
    "#get sep entries stored in mongo\n",
    "collection_to_export = db.sep_entries\n",
    "\n",
    "sep_articles = list(collection_to_export.find({}).sort('title'))\n",
    "create_sep_network_json(sep_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36964bitpythondataconda8971416e9bae4e8197b8a061b72f9dc8",
   "display_name": "Python 3.6.9 64-bit ('PythonData': conda)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}