{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### THIS SCRIPT CLEANS THE COLLECTED SEP ###   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo \n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm\n",
    "from bson.objectid import ObjectId\n",
    "from pprint import pprint\n",
    "\n",
    "import lib_sepinpho as sep\n",
    "\n",
    "##### INIT GLOBAL VARIABLES#####\n",
    "\n",
    "#init Mongo\n",
    "conn = 'mongodb://localhost:27017'\n",
    "client = pymongo.MongoClient(conn)\n",
    "\n",
    "#create database\n",
    "db = client.visualizing_sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##### Cleaning Sep_Entries ########\n",
    "##### Fall 2020 Edition: Completed 10.1.2020 ########\n",
    "##### Spring 2021 Edition: No Updates ########\n",
    "##### Summer & Fall 2021 Edition: No Updates ########\n",
    "\n",
    "#1. Check for entries with InPhO apis.\n",
    "\n",
    "collection_to_clean = db.sep_entries\n",
    "\n",
    "sep_no_inpho = pd.DataFrame(collection_to_clean.find( filter={'inpho_api': 'Error: No InPhO entry'},\n",
    "                                         projection = ['title'],\n",
    "                                         sort=[('title',1)]\n",
    "                                        ))\n",
    "#export to csv to made edits in this file\n",
    "sep_no_inpho.to_csv('noinpho.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'no_inphojson.csv' does not exist: b'no_inphojson.csv'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-c00092db2ca5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#import cleaned data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0minpho_updates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'no_inphojson.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minpho_updates\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    683\u001b[0m         )\n\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1135\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1136\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1917\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'no_inphojson.csv' does not exist: b'no_inphojson.csv'"
     ]
    }
   ],
   "source": [
    "# read the values to update from the CSV and batch update the entries\n",
    "\n",
    "collection_to_update = db.sep_entries\n",
    "\n",
    "#import cleaned data\n",
    "inpho_updates = pd.read_csv('no_inphosjon.csv')\n",
    "\n",
    "for index,row in tqdm(inpho_updates.iterrows()):\n",
    "    title = row['title']\n",
    "    api_endpoint = row['api_endpoint']\n",
    "    json_type = row['json_type']\n",
    "\n",
    "    sep.update_sep_json(title,api_endpoint, json_type, collection_to_update)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[{'_id': None, 'count': 17}]\n"
     ]
    }
   ],
   "source": [
    "##### Cleaning Sep_Entries ########\n",
    "##### Summer: Completed 7.16.2020 ########\n",
    "##### Summer: Completed 10.1.2020 ########\n",
    "\n",
    "#2. Check for duplicate InPhO JSON data.\n",
    "\n",
    "collection_to_clean = db.sep_entries_dupe\n",
    "result = list(collection_to_clean.aggregate([\n",
    "                                {\n",
    "                                    '$group' : { '_id' : \"$inpho_json.ID\",\n",
    "                                    'count': { '$sum': 1 }\n",
    "                                    }\n",
    "                                },\n",
    "                                {\n",
    "                                    '$match': { 'count': {'$ne': 1 }}\n",
    "                                }]))\n",
    "\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#Find any article that doesn't have domain info\n",
    "\n",
    "collection_to_update = db.sep_entries\n",
    "no_domains = pd.DataFrame(collection_to_update.find(\n",
    "    {'primary_domain': {'$exists': False}},\n",
    "    projection={'page_url':1, 'title':1, '_id':0}\n",
    "))\n",
    "#export to csv to made edits in this file\n",
    "no_domains.to_csv('no_domains.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find any article that doesn't have inpho tag info\n",
    "\n",
    "collection_to_update = db.sep_entries\n",
    "no_domains = pd.DataFrame(collection_to_update.find(\n",
    "    {'inpho_json': {'$exists': False}},\n",
    "    projection={'page_url':1, 'title':1, '_id':0}\n",
    "))\n",
    "#export to csv to made edits in this file\n",
    "no_domains.to_csv('no_inphosjon.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "22it [00:00, 215.96it/s]acknowledged: /entries/abu-bakr-al-razi/\n",
      " True\n",
      "[{'_id': ObjectId('615291d29050fcc8b5bd9ed1'), 'title': 'Abu Bakr al-Razi', 'domain_tags': 'Thinker, Philosophy of Religion, Ethics', 'primary_domain': 'Thinker'}]\n",
      "acknowledged: /entries/cudworth/\n",
      " True\n",
      "[{'_id': ObjectId('615291db9050fcc8b5bd9edc'), 'title': 'Ralph Cudworth', 'domain_tags': 'Thinker, Metaphysics, Epistemology', 'primary_domain': 'Thinker'}]\n",
      "acknowledged: /entries/fuller-margaret/\n",
      " True\n",
      "[{'_id': ObjectId('615291eb9050fcc8b5bd9eee'), 'title': 'Margaret Fuller', 'domain_tags': 'Thinker, Feminist Philosophy', 'primary_domain': 'Thinker'}]\n",
      "acknowledged: /entries/hegel-social-political/\n",
      " True\n",
      "[{'_id': ObjectId('615291f09050fcc8b5bd9ef5'), 'title': 'Hegel’s Social and Political Philosophy', 'domain_tags': 'Social and Political Philosophy, Thinker', 'primary_domain': 'Social and Political Philosophy'}]\n",
      "acknowledged: /entries/hutcheson/\n",
      " True\n",
      "[{'_id': ObjectId('615291f19050fcc8b5bd9ef8'), 'title': 'Francis Hutcheson', 'domain_tags': 'Thinker, Ethics', 'primary_domain': 'Thinker'}]\n",
      "acknowledged: /entries/infinity/\n",
      " True\n",
      "[{'_id': ObjectId('615291f69050fcc8b5bd9efe'), 'title': 'Infinity', 'domain_tags': 'Philosophy of Mathematics, Philosophy of Physics, Metaphysics', 'primary_domain': 'Philosophy of Mathematics'}]\n",
      "acknowledged: /entries/legal-probabilism/\n",
      " True\n",
      "[{'_id': ObjectId('615291fb9050fcc8b5bd9f06'), 'title': 'Legal Probabilism', 'domain_tags': 'Philosophy of Law', 'primary_domain': 'Philosophy of Law'}]\n",
      "acknowledged: /entries/neoliberalism/\n",
      " True\n",
      "[{'_id': ObjectId('615292059050fcc8b5bd9f13'), 'title': 'Neoliberalism', 'domain_tags': 'Social and Political Philosophy', 'primary_domain': 'Social and Political Philosophy'}]\n",
      "acknowledged: /entries/sin-christian/\n",
      " True\n",
      "[{'_id': ObjectId('6152921c9050fcc8b5bd9f33'), 'title': 'Sin in Christian Thought', 'domain_tags': ' Philosophy of Religion, Ethics', 'primary_domain': ' Philosophy of Religion'}]\n",
      "acknowledged: /entries/understanding/\n",
      " True\n",
      "[{'_id': ObjectId('615292259050fcc8b5bd9f3e'), 'title': 'Understanding', 'domain_tags': 'Epistemology, Philosophy of Science', 'primary_domain': 'Epistemology'}]\n",
      "acknowledged: /entries/africana-contemporary/\n",
      " True\n",
      "[{'_id': ObjectId('615292599050fcc8b5bd9f58'), 'title': 'Contemporary Africana Philosophy', 'domain_tags': 'African and African-American Philosophy', 'primary_domain': 'African and African-American Philosophy'}]\n",
      "acknowledged: /entries/argument/\n",
      " True\n",
      "[{'_id': ObjectId('6152925b9050fcc8b5bd9f5b'), 'title': 'Argument and Argumentation', 'domain_tags': 'Logic, Philosophy of Language', 'primary_domain': 'Logic'}]\n",
      "acknowledged: /entries/causation-regularity/\n",
      " True\n",
      "[{'_id': ObjectId('615292619050fcc8b5bd9f64'), 'title': 'Regularity and Inferential Theories of Causation', 'domain_tags': 'Metaphysics', 'primary_domain': 'Metaphysics'}]\n",
      "acknowledged: /entries/critical-phil-race/\n",
      " True\n",
      "[{'_id': ObjectId('615292659050fcc8b5bd9f6a'), 'title': 'Critical Philosophy of Race', 'domain_tags': 'Social and Political Philosophy', 'primary_domain': 'Social and Political Philosophy'}]\n",
      "acknowledged: /entries/hist-westphilmusic-since-1800/\n",
      " True\n",
      "[{'_id': ObjectId('6152927a9050fcc8b5bd9f83'), 'title': 'History of Western Philosophy of Music: since 1800', 'domain_tags': 'Aesthetics and Philosophy of Art', 'primary_domain': 'Aesthetics and Philosophy of Art'}]\n",
      "acknowledged: /entries/hist-westphilmusic-to-1800/\n",
      " True\n",
      "[{'_id': ObjectId('6152927b9050fcc8b5bd9f86'), 'title': 'History of Western Philosophy of Music: Antiquity to 1800', 'domain_tags': 'Aesthetics and Philosophy of Art', 'primary_domain': 'Aesthetics and Philosophy of Art'}]\n",
      "acknowledged: /entries/ibn-rushd/\n",
      " True\n",
      "[{'_id': ObjectId('6152927c9050fcc8b5bd9f88'), 'title': 'Ibn Rushd [Averroes]', 'domain_tags': 'Thinker, Metaphysics, Logic, Philosophy of Religion, Ethics', 'primary_domain': 'Thinker'}]\n",
      "acknowledged: /entries/legal-interpretation/\n",
      " True\n",
      "[{'_id': ObjectId('615292869050fcc8b5bd9f97'), 'title': 'Legal Interpretation', 'domain_tags': 'Philosophy of Law', 'primary_domain': 'Philosophy of Law'}]\n",
      "acknowledged: /entries/moral-phenomenology/\n",
      " True\n",
      "[{'_id': ObjectId('615292959050fcc8b5bd9faa'), 'title': 'Moral Phenomenology', 'domain_tags': 'Continental Philosophy, Ethics, Philosophy of Mind', 'primary_domain': 'Continental Philosophy'}]\n",
      "acknowledged: /entries/public-goods/\n",
      " True\n",
      "[{'_id': ObjectId('615292a09050fcc8b5bd9fb8'), 'title': 'Public Goods', 'domain_tags': 'Social and Political Philosophy, Ethics', 'primary_domain': 'Social and Political Philosophy'}]\n",
      "acknowledged: /entries/self-defense/\n",
      " True\n",
      "[{'_id': ObjectId('615292ac9050fcc8b5bd9fc6'), 'title': 'Self-Defense', 'domain_tags': 'Ethics, Social and Political Philosophy', 'primary_domain': 'Ethics'}]\n",
      "acknowledged: /entries/spacetime-theories-classical/\n",
      " True\n",
      "[{'_id': ObjectId('615292ae9050fcc8b5bd9fca'), 'title': 'Absolute and Relational Space and Motion: Classical Theories', 'domain_tags': 'Philosophy of Physics, Philosophy of Science', 'primary_domain': 'Philosophy of Physics'}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#update articles in no_domains with new domain data  \n",
    "#Fall Update: Completed 10.1.2020#\n",
    "#SPring 2021 Update: Completed 4.3.2021\n",
    "# Summer and Fall 2021 Updates: Completed 9.27.2021\n",
    "\n",
    "\n",
    "collection_to_update = db.sep_entries\n",
    "\n",
    "#import cleaned data\n",
    "nodmain_updates = pd.read_csv('no_domains.csv')\n",
    "\n",
    "for index,row in tqdm(nodmain_updates.iterrows()):\n",
    "    page_url = row['page_url']\n",
    "    primary_domain = row['primarydomain']\n",
    "    domain_list = row['domainlist']\n",
    "\n",
    "    sep.update_domain_info(page_url, domain_list, primary_domain, collection_to_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "#now test again for no domain info\n",
    "\n",
    "collection_to_update = db.sep_entries\n",
    "no_domains = list(collection_to_update.find(\n",
    "    {'primary_domain': {'$exists': False}},\n",
    "    projection={'page_url':1, 'title':1, '_id':0}\n",
    "))\n",
    "\n",
    "pprint(no_domains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#test for and remove editors notes\n",
    "#Spring 2021 Update: I manually updated 8 articles in compass to remove the Editors Note from the preamble\n",
    "\n",
    "collection_to_update = db.sep_entries\n",
    "\n",
    "editors_notes = list(collection_to_update.find(\n",
    "    {'preamble_text': {'$regex': '^\\['}},\n",
    "    projection={'page_url':1, 'title':1, 'preamble_text':1, '_id':0}\n",
    "))\n",
    "pprint(len(editors_notes))\n",
    "# pprint(editors_notes)\n",
    "\n",
    "for article in editors_notes:\n",
    "    print(article['page_url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.9"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit (conda)"
  },
  "interpreter": {
   "hash": "4089cdf5756c583c1eb5e2261855f70ecb5f18d1bb6db32aef7ba0d4704c2ea0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}