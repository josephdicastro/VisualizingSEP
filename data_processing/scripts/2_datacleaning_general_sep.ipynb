{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### THIS SCRIPT CLEANS THE COLLECTED SEP ###   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo \n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm\n",
    "from bson.objectid import ObjectId\n",
    "from pprint import pprint\n",
    "\n",
    "import lib_sepinpho as sep\n",
    "\n",
    "##### INIT GLOBAL VARIABLES#####\n",
    "\n",
    "#init Mongo\n",
    "conn = 'mongodb://localhost:27017'\n",
    "client = pymongo.MongoClient(conn)\n",
    "\n",
    "#create database\n",
    "db = client.visualizing_sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##### Cleaning Sep_Entries ########\n",
    "##### Fall 2020 Edition: Completed 10.1.2020 ########\n",
    "##### Spring 2021 Edition: No Updates ########\n",
    "##### Summer & Fall 2021 Edition: No Updates ########\n",
    "##### Winter Edition: 1.3.2022 ########\n",
    "\n",
    "# #1. Check for entries with InPhO apis.\n",
    "\n",
    "# collection_to_clean = db.sep_entries_dupe\n",
    "\n",
    "# sep_no_inpho = pd.DataFrame(collection_to_clean.find( filter={'inpho_api': 'Error: No InPhO entry'},\n",
    "#                                          projection = ['page_url','title'],\n",
    "#                                          sort=[('title',1)]\n",
    "#                                         ))\n",
    "# #export to csv to made edits in this file\n",
    "# sep_no_inpho.to_csv('noinpho.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read the values to update from the CSV and batch update the entries\n",
    "##### Winter Edition: 1.3.2022 ########\n",
    "\n",
    "# collection_to_update = db.sep_entries\n",
    "\n",
    "# #import cleaned data\n",
    "# inpho_updates = pd.read_csv('noinpho.csv')\n",
    "\n",
    "# for index,row in tqdm(inpho_updates.iterrows()):\n",
    "#     title = row['title']\n",
    "#     api_endpoint = row['api_endpoint']\n",
    "#     json_type = row['json_type']\n",
    "\n",
    "#     sep.update_sep_json(title,api_endpoint, json_type, collection_to_update)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'_id': None, 'count': 17}]\n"
     ]
    }
   ],
   "source": [
    "##### Cleaning Sep_Entries ########\n",
    "##### Summer: Completed 7.16.2020 ########\n",
    "##### Summer: Completed 10.1.2020 ########\n",
    "##### Winter Edition: 1.3.2022 (none) ########\n",
    "\n",
    "#2. Check for duplicate InPhO JSON data.\n",
    "\n",
    "collection_to_clean = db.sep_entries\n",
    "result = list(collection_to_clean.aggregate([\n",
    "                                {\n",
    "                                    '$group' : { '_id' : \"$inpho_json.ID\",\n",
    "                                    'count': { '$sum': 1 }\n",
    "                                    }\n",
    "                                },\n",
    "                                {\n",
    "                                    '$match': { 'count': {'$ne': 1 }}\n",
    "                                }]))\n",
    "\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##### Winter Edition: 1.3.2022 ########\n",
    "\n",
    "#Find any article that doesn't have domain info\n",
    "\n",
    "# collection_to_update = db.sep_entries_dupe\n",
    "# no_domains = pd.DataFrame(collection_to_update.find(\n",
    "#     {'primary_domain': {'$exists': False}},\n",
    "#     projection={'page_url':1, 'title':1, '_id':0}\n",
    "# ))\n",
    "# #export to csv to made edits in this file\n",
    "# no_domains.to_csv('no_domains.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update articles in no_domains with new domain data  \n",
    "#Fall Update: Completed 10.1.2020#\n",
    "#SPring 2021 Update: Completed 4.3.2021\n",
    "# Summer and Fall 2021 Updates: Completed 9.27.2021\n",
    "# Winter 2021: 1.3.2022\n",
    "\n",
    "\n",
    "# collection_to_update = db.sep_entries\n",
    "\n",
    "# #import cleaned data\n",
    "# nodmain_updates = pd.read_csv('no_domains.csv')\n",
    "\n",
    "# for index,row in tqdm(nodmain_updates.iterrows()):\n",
    "#     page_url = row['page_url']\n",
    "#     primary_domain = row['primarydomain']\n",
    "#     domain_list = row['domainlist']\n",
    "\n",
    "#     sep.update_domain_info(page_url, domain_list, primary_domain, collection_to_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "#now test again for no domain info\n",
    "\n",
    "collection_to_update = db.sep_entries\n",
    "no_domains = list(collection_to_update.find(\n",
    "    {'primary_domain': {'$exists': False}},\n",
    "    projection={'page_url':1, 'title':1, '_id':0}\n",
    "))\n",
    "\n",
    "pprint(no_domains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find any article that doesn't have inpho tag info\n",
    "\n",
    "collection_to_update = db.sep_entries\n",
    "no_domains = pd.DataFrame(collection_to_update.find(\n",
    "    {'inpho_json': {'$exists': False}},\n",
    "    projection={'page_url':1, 'title':1, '_id':0}\n",
    "))\n",
    "#export to csv to made edits in this file\n",
    "no_domains.to_csv('no_inphosjon.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#test for and remove editors notes\n",
    "#Spring 2021 Update: I manually updated 8 articles in compass to remove the Editors Note from the preamble\n",
    "#winter 2021: 1.3.2022\n",
    "\n",
    "collection_to_update = db.sep_entries\n",
    "\n",
    "editors_notes = list(collection_to_update.find(\n",
    "    {'preamble_text': {'$regex': '^\\['}},\n",
    "    projection={'page_url':1, 'title':1, 'preamble_text':1, '_id':0}\n",
    "))\n",
    "pprint(len(editors_notes))\n",
    "# pprint(editors_notes)\n",
    "\n",
    "for article in editors_notes:\n",
    "    print(article['page_url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "interpreter": {
   "hash": "4089cdf5756c583c1eb5e2261855f70ecb5f18d1bb6db32aef7ba0d4704c2ea0"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit (conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "orig_nbformat": 2,
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
